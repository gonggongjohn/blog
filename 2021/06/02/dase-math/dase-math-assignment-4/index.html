

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="GONGGONGJOHN">
  <meta name="keywords" content="">
  
    <meta name="description" content="一  构建模型使得预测值与真实值的误差最小常用向量2-范数度量，求解模型过程中需要计算梯度，求梯度：  \(f(A) &#x3D; \frac{1}{2} ||Ax + b - y ||_2^2\)，求 \(\frac{\partial f}{\partial A}\) \(f(x) &#x3D; \frac{1}{2} ||Ax + b - y ||_2^2\)，求 \(\frac{\partial f}{\par">
<meta property="og:type" content="article">
<meta property="og:title" content="数据科学与工程数学基础 作业4">
<meta property="og:url" content="http://gonggongjohn.me/2021/06/02/dase-math/dase-math-assignment-4/index.html">
<meta property="og:site_name" content="GONGGONGJOHN&#39;s Blog">
<meta property="og:description" content="一  构建模型使得预测值与真实值的误差最小常用向量2-范数度量，求解模型过程中需要计算梯度，求梯度：  \(f(A) &#x3D; \frac{1}{2} ||Ax + b - y ||_2^2\)，求 \(\frac{\partial f}{\partial A}\) \(f(x) &#x3D; \frac{1}{2} ||Ax + b - y ||_2^2\)，求 \(\frac{\partial f}{\par">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://gonggongjohn.me/2021/06/02/dase-math/dase-math-assignment-4/1.png">
<meta property="article:published_time" content="2021-06-02T02:00:00.000Z">
<meta property="article:modified_time" content="2022-02-10T09:00:53.615Z">
<meta property="article:author" content="GONGGONGJOHN">
<meta property="article:tag" content="Mathematics">
<meta property="article:tag" content="DataScience">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://gonggongjohn.me/2021/06/02/dase-math/dase-math-assignment-4/1.png">
  
  
  <title>数据科学与工程数学基础 作业4 - GONGGONGJOHN&#39;s Blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"gonggongjohn.me","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="GONGGONGJOHN's Blog" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>GONGGONGJOHN&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="数据科学与工程数学基础 作业4">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-06-02 10:00" pubdate>
        2021年6月2日 上午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      13k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      111 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">数据科学与工程数学基础 作业4</h1>
            
            <div class="markdown-body">
              <h2 id="一">一</h2>
<blockquote>
<p>构建模型使得预测值与真实值的误差最小常用向量2-范数度量，求解模型过程中需要计算梯度，求梯度：</p>
<ul>
<li><p><span class="math inline">\(f(A) = \frac{1}{2} ||Ax + b - y ||_2^2\)</span>，求 <span class="math inline">\(\frac{\partial f}{\partial A}\)</span></p></li>
<li><p><span class="math inline">\(f(x) = \frac{1}{2} ||Ax + b - y ||_2^2\)</span>，求 <span class="math inline">\(\frac{\partial f}{\partial x}\)</span></p></li>
</ul>
<p>，其中 <span class="math inline">\(A \in \mathbb{R}^{m \times n}, x \in \mathbb{R}^n, b, y \in \mathbb{R}^m\)</span></p>
</blockquote>
<p>由 <span class="math display">\[
\begin{aligned}
f(\textbf{A}, x) &amp;= \frac{1}{2} || \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} ||_2^2 \\
&amp;=\frac{1}{2} \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)
\end{aligned}
\]</span> 可知 <span class="math display">\[
\begin{aligned}
df &amp;= d \left[\ Tr \left(\frac{1}{2} \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)\right) \right] \\
&amp;= \frac{1}{2} Tr \left[ d \left( \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right)\right] \\
&amp;=\frac{1}{2} Tr \left[ d\left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] \\
&amp;=\frac{1}{2} Tr \left[ \textbf{x}^T \cdot d \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \cdot \textbf{x} \right] \\
&amp;=\frac{1}{2} \left\{ Tr \left[ \textbf{x}^T \cdot d \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] + Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \cdot \textbf{x} \right] \right\} \\
&amp;= \frac{1}{2} \left\{ Tr \left[ d \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \cdot \textbf{x}^T \right] + Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] \right\} \\
&amp;= \frac{1}{2} \left\{ Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] + Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] \right\} \\
&amp;= \frac{1}{2} Tr \left[ 2 \cdot \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] \\
&amp;= Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right]
\end{aligned}
\]</span> 故 <span class="math display">\[
\frac{\partial f}{\partial \textbf{A}} = \left(\textbf{x} \cdot (\textbf{A} \textbf{x}+\textbf{b}-\textbf{y})^T\right)^T = (\textbf{A} \textbf{x}+\textbf{b}-\textbf{y}) \cdot \textbf{x}^T
\]</span> 又 <span class="math display">\[
\begin{aligned}
df &amp;=\frac{1}{2} Tr \left[ d\left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] \\
&amp;=\frac{1}{2} Tr \left[ d\textbf{x}^T \cdot \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \\
&amp;=\frac{1}{2} \left\{ Tr \left[ d\textbf{x}^T \cdot \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] + Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \right\} \\
&amp;= \frac{1}{2} \left\{ Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] + Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \right\} \\
&amp;= \frac{1}{2} Tr \left[ 2 \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \\
&amp;= Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right]
\end{aligned}
\]</span> 故 <span class="math display">\[
\frac{\partial f}{\partial \textbf{x}} = \left( \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \right)^T = \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)
\]</span></p>
<h2 id="二">二</h2>
<blockquote>
<p>利用迹微分法求解 <span class="math display">\[
\frac{\partial \tr (W^{-1})}{\partial W}
\]</span> ，其中 <span class="math inline">\(W \in \mathbb{R}^{m \times m}\)</span></p>
</blockquote>
<p>由 <span class="math display">\[
\begin{aligned}
d \ Tr(\textbf{W}^{-1}) &amp;= Tr \left[ d  \left( \textbf{W}^{-1} \right) \right] \\
&amp;=Tr \left[ - \textbf{W}^{-1} \cdot d\textbf{W} \cdot \textbf{W}^{-1} \right] \\
&amp;=Tr \left[ -\left(\textbf{W}^{-1}\right)^2 \cdot d \textbf{W} \right]
\end{aligned}
\]</span> 可知 <span class="math display">\[
\frac{\partial Tr(\textbf{W}^{-1})}{\partial \textbf{W}} = -\left( \textbf{W}^{-2} \right)^T
\]</span></p>
<h2 id="三">三</h2>
<blockquote>
<p>二次型是数据分析中常用函数，求 <span class="math display">\[
\frac{\partial x^T A x}{\partial x}, \frac{\partial x^T A x}{\partial A}
\]</span> ，其中 <span class="math inline">\(A \in \mathbb{R}^{m \times m}, x \in \mathbb{R}^m\)</span></p>
</blockquote>
<p>由 <span class="math display">\[
\begin{aligned}
d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) &amp;= d \ Tr \left(\textbf{x}^T \textbf{A} \textbf{x} \right) \\
&amp;=Tr \left[ d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) \right] \\
&amp;=Tr \left[ d \textbf{x}^T \cdot \textbf{A} \textbf{x} + \textbf{x}^T \textbf{A} \cdot d\textbf{x}  \right] \\
&amp;=Tr \left[\textbf{x}^T \textbf{A}^T d\textbf{x} \right] + Tr \left[ \textbf{x}^T \textbf{A} d\textbf{x}\right] \\
&amp;=Tr \left[ \textbf{x}^T (\textbf{A}^T + \textbf{A}) d\textbf{x}\right]
\end{aligned}
\]</span> 故 <span class="math display">\[
\frac{\partial \textbf{x}^T \textbf{A} \textbf{x}}{\partial \textbf{x}} = \left(\textbf{x}^T (\textbf{A}^T + \textbf{A})\right)^T = (\textbf{A}+\textbf{A}^T)\textbf{x}
\]</span> 又 <span class="math display">\[
\begin{aligned}
d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) &amp;=Tr \left[ d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) \right] \\
&amp;=Tr \left[ \textbf{x}^T \cdot d \textbf{A} \cdot \textbf{x} \right] \\
&amp;=Tr \left[\textbf{x} \textbf{x}^T d \textbf{A} \right] \\
\end{aligned}
\]</span> 故 <span class="math display">\[
\frac{\partial \textbf{x}^T \textbf{A} \textbf{x}}{\partial \textbf{A}} = \left(\textbf{x}\textbf{x}^T \right)^T = \textbf{x}\textbf{x}^T
\]</span></p>
<h2 id="四">四</h2>
<blockquote>
<p>定义 <span class="math inline">\((\exp(z))_i = \exp(z_i), (\ln (z))_i = \ln (z_i)\)</span>，则 <span class="math display">\[
f(z) = \frac{\exp(z)}{\boldsymbol{1}^T \exp(z)}
\]</span> 成为Softmax函数，如果 <span class="math inline">\(q = f(z), J = -p^T \ln (q)\)</span>，其中 <span class="math inline">\(p,q,z \in \mathbb{R}^n\)</span>，并且 <span class="math inline">\(\boldsymbol{1}^T p = 1\)</span>，则</p>
<ul>
<li>证明：<span class="math inline">\(\frac{\partial J}{\partial z} = q - p\)</span></li>
<li>若 <span class="math inline">\(z = Wx\)</span>，其中 <span class="math inline">\(W \in \mathbb{R}^{n \times m}, x \in \mathbb{R}^m, \frac{\partial J}{\partial W} = (q - p)x^T\)</span> 是否成立。</li>
</ul>
</blockquote>
<p><span class="math inline">\(\forall \textbf{x}, \textbf{y}, \textbf{z} \in \mathbb{R}^2, \lambda \in \mathbb{R}\)</span></p>
<p><strong>(1)</strong> 任取 <span class="math inline">\(i, j \in \{1,2,...,n\}\)</span></p>
<p>易得 <span class="math display">\[
\frac{\partial J}{\partial q_j} = - \frac{p_j}{q_j}
\]</span> 当 <span class="math inline">\(i \neq j\)</span> 时， <span class="math display">\[
\frac{\partial q_j}{\partial z_i} = - \frac{e^{z_i + z_j}}{\left( \sum_\limits{k = 1}^n e^{z_k} \right)^2} = -q_i \cdot q_j
\]</span> 当 <span class="math inline">\(i = j\)</span> 时， <span class="math display">\[
\frac{\partial q_j}{\partial z_i} = \frac{e^{z_i} \cdot \left( \sum_\limits{k = 1}^n e^{z_k} \right) - e^{2z_i}}{\left( \sum_\limits{k = 1}^n e^{z_k} \right)^2} = q_i - q_i^2
\]</span> 故 <span class="math display">\[
\begin{aligned}
\frac{\partial J}{\partial z_i} &amp;= \sum_{j = 1}^n \frac{\partial J}{\partial q_j} \cdot \frac{\partial q_j}{\partial z_i} \\
&amp;=\sum_{j \neq i} \left( - \frac{p_j}{q_j} \right) (-q_i q_j) + \left(- \frac{p_i}{q_i} \right) (q_i - q_i^2) \\
&amp;=q_i \cdot \sum_{j \neq i} p_j - p_i(1-q_i) \\
\end{aligned}
\]</span> 于是由 <span class="math inline">\(1^T p = \sum_\limits{i = 1}^n p_i = 1\)</span> 可知 <span class="math display">\[
\frac{\partial J}{\partial z_i} = q_i (1 - p_i) - p_i(1-q_i) = q_i - p_i
\]</span> 即 <span class="math display">\[
\frac{\partial J}{\partial \textbf{z}} = \textbf{q} - \textbf{p}
\]</span> <strong>(2)</strong> 由 <span class="math inline">\(d \ Tr (\textbf{W} \textbf{x}) = Tr \left( d \textbf{W} \cdot \textbf{x} \right) = Tr(\textbf{x} \cdot d \textbf{W})\)</span> 可知 <span class="math display">\[
\frac{\partial J}{\partial \textbf{W}} = \textbf{x}^T
\]</span> 故 <span class="math display">\[
\frac{\partial J}{\partial \textbf{W}} = \frac{\partial J}{\partial \textbf{z}} \cdot \frac{\partial \textbf{z}}{\partial \textbf{W}} = (\textbf{q} - \textbf{p}) \textbf{x}^T
\]</span> 成立</p>
<h2 id="五">五</h2>
<blockquote>
<p>以下内容是利用极大似然估计求解多元正态分布模型的关键步骤： <span class="math display">\[
L = -\frac{Nd}{2} \ln (2 \pi) - \frac{N}{2} \ln |\Sigma| - \frac{1}{2} \sum_t (x_t - \mu)^T \Sigma^{-1} (x_t - \mu)
\]</span> ，<span class="math inline">\(L\)</span> 是对数似然，<span class="math inline">\(N\)</span> 为样本数，<span class="math inline">\(d\)</span> 为样本维数，<span class="math inline">\(\Sigma \in \mathbb{R}^{d \times d}\)</span> 为协方差矩阵（对称矩阵），<span class="math inline">\(\mu \in \mathbb{R}^d\)</span> 为期望向量。</p>
<ul>
<li><p>求 <span class="math inline">\(\frac{\partial L}{\partial \mu}\)</span></p></li>
<li><p>当 <span class="math inline">\(\mu = \frac{1}{N} \sum_t x_t\)</span> 使，求 <span class="math inline">\(\frac{\partial L}{\partial \Sigma}\)</span>，并求使 <span class="math inline">\(\frac{\partial L}{\partial \Sigma} = 0\)</span> 成立的 <span class="math inline">\(\Sigma\)</span>。</p></li>
</ul>
</blockquote>
<p><strong>(1)</strong> <span class="math display">\[
\begin{aligned}
\frac{\partial L}{\partial \boldsymbol{\mu}} &amp;= -\frac{1}{2} \sum_{t = 1}^N \frac{\partial}{\partial \boldsymbol{\mu}} \left[ (\textbf{x}_t - \boldsymbol{\mu})^T \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu})\right] \\
&amp;= -\frac{1}{2} \sum_{t = 1}^N \frac{\partial \left[(\textbf{x}_t - \boldsymbol{\mu})^T \right]}{\partial \boldsymbol{\mu}} \cdot \frac{\partial \left[ (\textbf{x}_t - \boldsymbol{\mu})^T \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu}) \right]}{\partial[\textbf{x}_t - \boldsymbol{\mu}]} \\
&amp;=-\frac{1}{2} \sum_{t = 1}^N \left[ -2\Sigma^{-1}(\textbf{x}_t - \boldsymbol{\mu}) \right] \\
&amp;=\Sigma^{-1} \cdot \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu})
\end{aligned}
\]</span> <strong>(2)</strong></p>
<p>由 <span class="math display">\[
\begin{aligned}
dL &amp;= Tr \left[ d \left( - \frac{Nd}{2} \ln (2 \pi) - \frac{N}{2} \ln |\Sigma| - \frac{1}{2} \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu})^T \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu}) \right) \right] \\
&amp;= Tr \left[ - \frac{N}{2} d \left(  \ln |\Sigma| \right) - \frac{1}{2} \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu})^T \cdot d \left(\Sigma^{-1}\right) \cdot (\textbf{x}_t - \boldsymbol{\mu}) \right] \\
&amp;= Tr \left[ - \frac{N}{2|\Sigma|}\cdot |\Sigma| \Sigma^{-1} d \Sigma + \frac{1}{2} \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu}) (\textbf{x}_t - \boldsymbol{\mu})^T \cdot \Sigma^{-1} d \Sigma \cdot \Sigma^{-1} \right] \\
&amp;= Tr \left[ \left(- \frac{N}{2}\cdot \Sigma^{-1} + \frac{1}{2} \sum_{t = 1}^N \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu}) (\textbf{x}_t - \boldsymbol{\mu})^T \cdot \Sigma^{-1}\right) d \Sigma \right]
\end{aligned}
\]</span> 及 <span class="math inline">\(\Sigma\)</span> 为对称矩阵可知 <span class="math display">\[
\frac{\partial L}{\partial \Sigma} = \frac{1}{2} \sum_{t = 1}^N \Sigma^{-1}(\textbf{x} - \boldsymbol{\mu})(\textbf{x} - \boldsymbol{\mu})^T \Sigma^{-1} - \frac{N}{2} \Sigma^{-1}
\]</span> 故当 <span class="math inline">\(\Sigma = \frac{1}{N}(\textbf{x} - \boldsymbol{\mu})(\textbf{x} - \boldsymbol{\mu})^T\)</span> 时，<span class="math inline">\(\frac{\partial L}{\partial \Sigma} = 0\)</span></p>
<h2 id="六">六</h2>
<blockquote>
<p>求 <span class="math display">\[
\frac{\partial |X_k|}{\partial X}
\]</span> ，其中 <span class="math inline">\(X \in \mathbb{R}^{m \times m}\)</span> 为可逆矩阵。</p>
</blockquote>
<p>由 <span class="math inline">\(\textbf{X} \in \mathbb{R}^{m \times m}\)</span> 可逆可知 <span class="math display">\[
\begin{aligned}
\frac{\partial \left|\textbf{X}^k\right|}{\partial \textbf{X}} &amp;= \frac{\partial \left|\textbf{X}^k\right|}{\partial \textbf{|X|}} \cdot \frac{\partial \left|\textbf{X}\right|}{\partial \textbf{X}} \\
&amp;=k |\textbf{X}|^{k - 1} \cdot |\textbf{X}| \cdot (\textbf{X}^{-1})^T \\
&amp;= k |\textbf{X}|^k \left( \textbf{X}^{-1} \right)^T
\end{aligned}
\]</span></p>
<h2 id="七">七</h2>
<blockquote>
<p>求 <span class="math display">\[
\frac{\partial \tr (AXBX^T C)}{\partial X}
\]</span> ，其中 <span class="math inline">\(A \in \mathbb{R}^{m \times n}, X \in \mathbb{R}^{n \times k}, B \in \mathbb{R}^{k \times k}, C \in \mathbb{R}^{n \times m}\)</span></p>
</blockquote>
<p>由 <span class="math display">\[
\begin{aligned}
d \left( \textbf{A} \textbf{x} \textbf{B} \textbf{x}^T \textbf{C} \right) &amp;=Tr \left[d \left(\textbf{A} \textbf{x} \textbf{B} \textbf{x}^T \textbf{C} \right) \right] \\
&amp;=Tr \left[\textbf{A} \cdot d \textbf{x} \cdot \textbf{B} \textbf{x}^T \textbf{C} + \textbf{A} \textbf{x} \textbf{B} \cdot d \textbf{x}^T \cdot \textbf{C} \right] \\
&amp;=Tr \left[ \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} d \textbf{x} \right] + Tr \left[ d \textbf{x}^T \cdot \textbf{C}\textbf{A}\textbf{x}\textbf{B} \right] \\
&amp;=Tr \left[ \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} d \textbf{x} \right] + Tr \left[ \textbf{B}^T\textbf{x}^T \textbf{A}^T \textbf{C}^T d \textbf{x} \right] \\
&amp;=Tr \left[ \left( \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} + \textbf{B}^T\textbf{x}^T \textbf{A}^T \textbf{C}^T \right) d \textbf{x}\right]
\end{aligned}
\]</span> 可知 <span class="math display">\[
\frac{\partial Tr \left(\textbf{A} \textbf{x} \textbf{B} \textbf{x}^T \textbf{C} \right)}{\partial \textbf{X}} = \left( \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} + \textbf{B}^T\textbf{x}^T \textbf{A}^T \textbf{C}^T \right)^T = \textbf{A}^T \textbf{C}^T \textbf{x} \textbf{B}^T + \textbf{C} \textbf{A} \textbf{x} \textbf{B}
\]</span></p>
<h2 id="八">八</h2>
<blockquote>
<p>求激活函数 <span class="math display">\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]</span> 的导数</p>
</blockquote>
<p><span class="math display">\[
\frac{d \sigma}{d \textbf{x}} = \frac{d}{d \textbf{x}} \left( \frac{1}{1+e^{- \textbf{x}}} \right) = \frac{e^{- \textbf{x}}}{\left(1+e^{-\textbf{x}}\right)^2} = \sigma(\textbf{x}) \left(1-\sigma(\textbf{x}) \right)
\]</span></p>
<h2 id="九">九</h2>
<blockquote>
<p>求 <span class="math display">\[
\frac{\partial}{\partial x} \exp \left\{ - \frac{1}{2 ||\sigma||_2^2} ||x - \mu||_2^2 \right\}
\]</span> ，其中 <span class="math inline">\(x, \mu, \sigma \in \mathbb{R}^n\)</span></p>
</blockquote>
<p>由 <span class="math display">\[
\begin{aligned}
d\left( e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \right) &amp;=Tr \left[ d \left( e^{-\frac{2}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \right)\right] \\
&amp;=Tr \left[ -\frac{1}{2||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \cdot d \left( ||\textbf{x} - \boldsymbol{\mu}||_2^2\right) \right] \\
&amp;=Tr \left[ -\frac{1}{2||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \cdot d \left( (\textbf{x} - \boldsymbol{\mu})^T (\textbf{x} - \boldsymbol{\mu}) \right) \right] \\
&amp;=Tr \left[ -\frac{(\textbf{x} - \boldsymbol{\mu})^T}{||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \cdot d\textbf{x} \right]
\end{aligned}
\]</span> 可知 <span class="math display">\[
\frac{\partial}{\partial \textbf{x}} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} = \left(-\frac{(\textbf{x} - \boldsymbol{\mu})^T}{||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2}\right)^T = -\frac{(\textbf{x} - \boldsymbol{\mu})}{||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2}
\]</span></p>
<h2 id="十">十</h2>
<blockquote>
<p>阅读以下代码，填写更新梯度部分的代码。（提交时，需要提交补全的代码，以及最后10次输出的截图）</p>
</blockquote>
<p><strong>实现代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>N, D_in, H, D_out = <span class="hljs-number">64</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">100</span>, <span class="hljs-number">10</span><br><span class="hljs-comment"># 随机创建一些训练数据</span><br>x = np.random.randn(N, D_in)<br>y = np.random.randn(N, D_out)<br>w1 = np.random.randn(D_in, H)<br>w2 = np.random.randn(H, D_out)<br>learning_rate = <span class="hljs-number">1e-6</span><br><span class="hljs-keyword">for</span> it <span class="hljs-keyword">in</span> range(<span class="hljs-number">500</span>):<br>    <span class="hljs-comment"># Forward pass</span><br>    h = x.dot(w1)  <span class="hljs-comment"># N * H</span><br>    h_relu = np.maximum(h, <span class="hljs-number">0</span>)  <span class="hljs-comment"># N * H</span><br>    y_pred = h_relu.dot(w2)  <span class="hljs-comment"># N * D_out</span><br>    <span class="hljs-comment"># compute loss</span><br>    loss = np.square(y_pred - y).sum()<br>    print(it, loss)<br>    <span class="hljs-comment"># Backward pass</span><br>    <span class="hljs-comment"># compute the gradient</span><br>    grad_y_pred = y_pred - y<br>    grad_w2 = h_relu.T.dot(grad_y_pred)<br>    grad_h_relu = grad_y_pred.dot(w2.T)<br>    grad_h = grad_h_relu.copy()<br>    grad_h[h &lt; <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    grad_w1 = x.T.dot(grad_h)<br>    w1 -= learning_rate * grad_w1<br>    w2 -= learning_rate * grad_w2<br></code></pre></td></tr></table></figure>
<p><strong>输出结果（最后10次循环）：</strong></p>
<img src="/2021/06/02/dase-math/dase-math-assignment-4/1.png" srcset="/img/loading.gif" lazyload class="" width="1">

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数据科学数学基础</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Mathematics/">Mathematics</a>
                    
                      <a class="hover-with-bg" href="/tags/DataScience/">DataScience</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/06/08/os/os-exp-memory/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">操作系统实验 内存管理</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/06/01/os/os-exp-io/">
                        <span class="hidden-mobile">操作系统实验 I/O子系统</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
