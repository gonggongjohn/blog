<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>GONGGONGJOHN&#39;s Blog</title>
  
  
  <link href="http://gonggongjohn.me/atom.xml" rel="self"/>
  
  <link href="http://gonggongjohn.me/"/>
  <updated>2022-12-18T10:23:10.284Z</updated>
  <id>http://gonggongjohn.me/</id>
  
  <author>
    <name>GONGGONGJOHN</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>当代人工智能 课程项目五 多模态情感分析实验报告</title>
    <link href="http://gonggongjohn.me/2022/07/05/contemporary-ai/contemporary-ai-exp-5/"/>
    <id>http://gonggongjohn.me/2022/07/05/contemporary-ai/contemporary-ai-exp-5/</id>
    <published>2022-07-05T02:00:00.000Z</published>
    <updated>2022-12-18T10:23:10.284Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>多模态学习是近几年来机器学习中的一个较为新兴的领域，不同模态的组合和应用场景延伸出了一系列多模态学习任务。其中，多模态情感分析作为一个经典的多模态任务，有着极为广泛的应用，也是现如今建立多模态模型的一项常用的基准评价任务。在本文中，我们从零开始设计并实现了一个基于Transformer构架的文本-图像双模态情感分析模型，并使用预训练和对比学习方法来提升其分类效果。通过与一系列经典及较新的单模态和多模态基准模型进行比较，我们得以较为全面的衡量所设计模型的精度和特点。最后，我们通过消融实验，探究了模型在单模态输入下的分类表现，以及预训练为模型来带来的精度提升幅度。</p><p>本项目中涉及的所有核心代码均由本人亲自实现，代码中所有借鉴其他模型的地方，报告中已全部给出相关原文或地址。</p><p><strong>关键字：多模态情绪识别，Transformer, XLMRoBERTa，Swin Transformer，预训练模型，对比学习</strong></p><h2 id="项目介绍">项目介绍</h2><h3 id="任务介绍">任务介绍</h3><p>传统机器学习领域往往是针对单模态数据来进行处理和分析的，而真实世界中，一个事物的特征往往由多个模态共同组成，在许多场景下，我们需要共同考虑这些特征才能得到一个较好的表征。多模态学习正是在这样的背景下所提出的。传统的多模态学习模型往往由多个单模态模型及一系列融合技巧组成，而随着近年来预训练方法的提出，多模态预训练模型也正逐渐成为多模态理解模型的主流，尤其是在<strong>视觉-语言领域</strong>取得了显著的效果。</p><p>在多模态任务中，<strong>多模态情感分析</strong>是一个经典且十分重要的任务。根据模态数据的不同组合，多模态情感分析能够广泛地用于不同的场景任务下，例如产品口碑分析、大众情绪倾向分析及心理健康预警等。由于图像和文本是真实世界中主流且较易处理的数据模态，因此这里我们近考虑这种双模态情况。<strong>图像-文本双模态情感分析</strong>任务的具体表述如下：对于一组<strong>匹配的图像文本对</strong> <span class="math inline">\((I, T) \in \mathcal{D}\)</span>，要求给出一个<strong>情感倾向分类结果</strong> <span class="math inline">\(c \in \mathcal{C}\)</span>，使得该情感是对应图像文本对所表现出的情感倾向。</p><h3 id="数据集介绍">数据集介绍</h3><p>本项目所使用的数据集为一个给定的数据集，该数据集中共包含了<strong>5129</strong>组匹配的图像-文本对。其中，训练集共有<strong>4000</strong>个样本，每个样本带有一个与之对应的情感分类标签，其具体分布如下表所示；测试集共有<strong>511</strong>个样本，测试集的情感标签需要我们使用模型推理得到。</p><table><thead><tr class="header"><th>标签</th><th>样本数（图像-文本对）</th></tr></thead><tbody><tr class="odd"><td>积极（Positive）</td><td>2388</td></tr><tr class="even"><td>中性（Neutral）</td><td>419</td></tr><tr class="odd"><td>消极（Negative）</td><td>1193</td></tr><tr class="even"><td><strong>总计</strong></td><td><strong>4000</strong></td></tr></tbody></table><p>在数据集中，一个带标签样本的结构如下图所示。由于数据集是从互联网的非结构化信息中抽取的，数据集中的同质样本规格并不统一，且文字样本中还存在着一些无关信息。可以看到，数据集中图像和文本对于情感倾向的判断均或多或少确实一些信息，需要结合两种模态的特征才能得到一个较为准确的情感倾向分类。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/dataset_visualize.png" class="" title="dataset_visualize"><h2 id="基准模型">基准模型</h2><h3 id="单模态模型">单模态模型</h3><p>单模态模型仅考虑单一的输入形式，在当前任务中，也即分别考虑文本和图像数据。在本文中，我们共实现了4中单模态基准模型，分别对应于一个<strong>经典Baseline</strong>和一个<strong>强Baseline</strong>。其中，<strong>Bert</strong>和<strong>XLMRoberta</strong>模型仅使用文本数据作为输入，<strong>ResNet</strong>和<strong>Swin Transformer</strong>仅使用图像数据作为输入。</p><h4 id="bert">Bert</h4><p>使用文本数据进行情感分析，也即根据文本的语义进行多分类任务。近年来，随着<strong>语言模型（Language Model）</strong>和<strong>Transformer构架</strong>的提出，使用<strong>预训练（Pretrain）</strong>方法来处理文本数据已经成为了现代模型的一大主流，其中最为经典的即为Google于2018年提出的<strong>Bert（Bidirectional Encoder Representation from Transformers）</strong>模型。</p><p>Bert模型是一个<strong>自编码语言模型（Autoencoder Language Model）</strong>，其网络构架如下图所示。Bert的主体由多个Transformer结构组成，网络首先接受一串由<strong>词项</strong>和<strong>特殊标识符（CLS、SEP）</strong>经过嵌入得到的句子向量，并使用Transformer构架计算句子的语言特征，得到一串同等长度的语言特征向量。通过将网络的输出与下游的网络结构相连接，我们就可以使用Bert模型进行各种自然语言处理任务。对于当前文本分类任务，我们只需要使用网络输出中的第一项（即CLS标识符的特征表示），并将其连接至一个全连接层即可得到文本的概率分类结果。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/bert_structure.png" class="" title="bert_structure"><p>Huggingface的transformers工具提供了一套便捷的类Transformer模型实现工具，我们使用其实现了Bert情感分类模型。对于预训练权重，我们使用<strong>bert-base-cased</strong>进行了初始化，并通过连接一个 <span class="math inline">\(768 \to 3\)</span> 的<strong>线性层（Linear）</strong>进行了微调。</p><h4 id="xlmroberta">XLMRoBERTa</h4><p>通过进一步分析数据集我们可以发现，该数据集中存在多种语言的文本数据，如下图所示。而传统的类Bert模型通常仅针对单语料进行训练，其词条化规则也通常不能适应不同语言的语言特性。为了解决这一问题，一个传统的方法是人工找出数据集中出现的所有语言，并使用在对应语言的语料上训练的模型进行推理。然而，这样做的编码和推理复杂度降大大增加，且不具有自适应性。幸运的是，随着多语言推理需求的增加，同时支持多种语言的类Bert模型相继被提出，这使得我们可以通过一个统一的模型来对数据集中的所有样本进行推理。这里我们使用Facebook团队于2019年提出的<strong>XLMRoBERTa</strong>模型作为基准模型。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/dataset_multilingual.png" class="" title="dataset_multilingual"><p>XLMRoBERTa是一个多语言预训练模型，通过名字就可以看出，其是一个RoBERTa和XLM的结合体。RoBERTa通过对预训练任务的改进和参数的调优，大幅提升了Bert的语义特征提取能力；XLM通过对文本嵌入方法的改进，使得多语言文本可以通过一种统一的方法输入模型。在此基础之上，XLMRoBERTa使用了多语言的训练语料对模型进行了训练，其语料的具体语言分布如下图所示。可以看到，整个训练语料超过了2.5TB，这也使得模型在面对不同语言输入时均能获得良好的嵌入表现。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/xlmroberta_corpus.png" class="" title="xlmroberta_corpus"><p>本次实验中，我们使用官方提供的<strong>xlm-roberta-base</strong>作为基准模型的预训练模型。与Bert类似，我们将模型输出的[CLS]特征连接至一个 <span class="math inline">\(768 \to 3\)</span> 的线性层进行了微调。</p><h4 id="resnet">ResNet</h4><p>接下来我们来考虑基于图像输入的基准模型。基于图像的情感分析也即根据图像的特征进行多分类任务，决定其分类表现的核心在于是否有一个较好的视觉特征提取器。ResNet是现代计算机视觉模型中一个里程碑式的网络结构，由<strong>Kaiming He</strong>等人于2016年提出。ResNet通过提出<strong>残差连接（Residue Connection）</strong>这一思想，有效地解决了网络层数加深导致的<strong>输入特征消失</strong>以及<strong>学习偏差</strong>的问题。</p><p>ResNet中最重要的部分即为<strong>残差块（Residue Block）</strong>，其基本结构如下图所示。可以看到，相比普通的卷积块，残差块通过加入一个直接连接输入和输出的快速通道来将输入的特征直接叠加到输出特征之上，从而使得输入特征得以保留。从函数的角度上来看，若输入向量为 <span class="math inline">\(\boldsymbol{x}\)</span>，卷积层变换函数为 <span class="math inline">\(g(x)\)</span>，则一个残差块的输出结果为 <span class="math display">\[f(\boldsymbol{x}) = \boldsymbol{x} + g(\boldsymbol{x})\]</span> 。可以看到，即使卷积层没有学到任何有用的特征（卷积层退化为常数映射 <span class="math inline">\(g(\boldsymbol{x}) = C\)</span>），输出结果中仍然包含输入的特征，从而有效地防止学习偏差的问题。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/resblock_architecture.png" class="" title="resblock_architecture"><p>在本次实验中，我们使用<strong>ResNet-50</strong>作为基准模型的网络结构。对于预训练权重，我们使用在<strong>ImageNet-1K</strong>上训练得到的参数对网络进行了初始化，并通过连接一个 <span class="math inline">\(2048 \to 3\)</span> 得到最终的类别概率。</p><h4 id="swin-transformer">Swin Transformer</h4><p>随着Transformer在自然语言处理领域的发展以及对其模型构架的理解深入，其思想也逐渐被迁移到了计算机视觉领域上，并取得了十分优秀的表现，这也使得视觉预训练模型成为了CV领域中的一个新典范。作为一个强Baseline，我们使用Microsoft于2021年提出的<strong>Swin Transformer</strong>作为基准模型，该模型在各种下游任务中均取得了十分优异的表现。</p><p>Swin Transformer是一个纯Transformer构架模型，其所使用的核心思想和模型基本构架如下图所示。具体来说，Swin Transformer使用了一个层级式的特征抽取结构，利用滑动窗口逐块地提取每个区域的视觉特征，通过逐步扩大感受野来得到整个图像的视觉特征，这也想法与多层的卷积神经网络十分相似。而又由于Transformer天然的自注意力机制，使得其可以学习到每一个局部感受野中需要重点关注的区域，也使得其能够获得较好的特征提取表现。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/swin_transformer_illustrate.png" class="" title="swin_transformer_illustrate"><p>在本实验中，我们使用<strong>Swin-Base</strong>模型作为基准模型，其输出的分类特征为一个1024维的特征向量，通过一个 <span class="math inline">\(1024 \to 3\)</span> 的线性层，我们可以将其转化为类别概率。对于预训练权重，我们使用其官方提供的在ImageNet-1K上训练的<strong>microsoft/swin-base-patch4-window7-224</strong>模型对网络参数进行了初始化。随后，我们加上线性层，并进行了微调操作。</p><h3 id="双模态模型">双模态模型</h3><p>接下来我们同时考虑图像和文本的双模态输入，并构建一些符合直觉的基准模型。在本文中，我们实现了两种较为简单的双模态模型：<strong>特征拼接</strong>和<strong>加性模型</strong>，其都能够作为一个较为基础的Baseline。</p><h4 id="特征拼接">特征拼接</h4><p>要让模型能够同时考虑到多模态的输入，一个关键的问题在于如何使得多模态的特征能够共同影响分类的结果。一个最直接的方法便是将多模态特征直接拼接成一个更大的特征并送入分类器，事实上，早期的多模态模型也大都使用了这种方法，如Nan Xu等人提出的MultiSentiNet等。在本实验中，我们使用如下结构来作为特征拼接的双模态基准模型。文本和图像首先分别通过各自地特征提取器得到对应的嵌入特征，随后通过序列扩展的方式将其拼接成一个更长的特征串。具体来说，若输入文本得到的特征串为 <span class="math inline">\(k\)</span>，输入图像得到的特征串为 <span class="math inline">\(p\)</span>，则拼接后的特征串长度即为 <span class="math inline">\(k+p\)</span>。随后，我们将其直接输入一个 <span class="math inline">\(k+p \to 3\)</span> 的线性层，即可得到类别概率的输出。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/concatenate_structure.png" class="" title="concatenate_structure"><p>为了公平起见，对于文字和图像的特征提取器，我们统一使用<strong>XLMRoBERTa</strong>和<strong>Swin Transformer</strong>作为其骨干网络，并首先使用微调的方式使其能够较好地捕捉数据集上的特征。在进行多模态训练时，我们将两个骨干网络冻结，仅训练全连接层的参数。</p><h4 id="加性模型">加性模型</h4><p>对于向量空间模型而言，线性变换也是特征结合的一种常用方法。受到注意力机制中加性模型的启发，我们也可以通过对不同模态的特征进行加权求和的方式得到最终的特征串。事实上，不少序列预测模型也使用了加性模型作为其交叉注意力层的打分函数，例如ChuHan Wu等人提出的Fastformer模型。在本实验中，我们使用如下结构作为加性模型的双模态基准模型。所图所示，文本和图像输入首先仍然通过各自的特征提取器得到嵌入标识，并分别送入一个 <span class="math inline">\(k \to q\)</span> 和 <span class="math inline">\(p \to q\)</span> 的线性层使得文本和图像的特征长度能够对齐。随后，对于特征对的每一个位置，我们使用加权求和的方式得到一个模态融合的特征向量。最后，我们将这一特征向量输入一个 <span class="math inline">\(q \to 3\)</span> 的线性层，即可得到最终的类别概率输出。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/additive_structure.png" class="" title="additive_structure"><p>在这一模型中，我们仍然使用和拼接模型中相同的模型作为文本和图像的特征提取骨架。此外，为了增加模型的适应性，我们将加权后的向量输入一个<strong>tanh</strong>激活函数，并通过一个额外的线性变换来得到输出特征。具体来说，加权过程的表示如下：</p><p><span class="math display">\[\boldsymbol{m}_j = \boldsymbol{W} \tanh (\boldsymbol{\alpha}_{j1} t_j&#39; + \boldsymbol{\alpha}_{j2} i_j&#39;), j \in \{1, 2, \cdots, q\}\]</span></p><p>同样地，在训练过程中，我们将骨干网络冻结，仅训练加权网络及线性层的参数。</p><h2 id="多模态情感分类模型ptamsc">多模态情感分类模型——PTAMSC</h2><p>下面我们将引入一种改进的多模态情感分类模型，我们将其称为<strong>PTAMSC（Pure Transformer-flavored Augmented Multi-modal Sentiment Classifier）</strong>。我们将从模型构架、预训练过程与下游训练过程分别阐述该模型的相关细节。</p><h3 id="模型构架">模型构架</h3><p>从上面的基准模型中我们可以看出，单模态模型并不能够利用完整的输入信息，使得其情感分类效果存在上限；而使用简易的拼接或加性模型的双模态方法并不能将不同模态地表征数据合理地对其并结合在一起，使得分类效果反而出现了下降。受<strong>Transformer Encoder</strong>的启发，<strong>Cross Attention</strong>机制天然适用于对不同的表征进行融合和关注，这也自然地使得其能够较好地应用到多模态特征融合中。参考Zhen Li等人提出的<strong>CLMLF</strong>模型构架，本文的多模态情感分类模型基本构架如下图所示。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/ptamsc_structure.png" class="" title="ptamsc_structure"><p>首先，文本序列 <span class="math inline">\(\{s_1, s_2, \cdots, s_k \}\)</span> 和原始图像 <span class="math inline">\(I \in \mathbb{R}^{c \times w \times h}\)</span> 分别通过各自的特征提取骨架网络得到对应的特征表示 <span class="math inline">\(\{t1, t_2, \cdots, t_k \}\)</span> 和 <span class="math inline">\(\{i_1, i_2, \cdots, i_p \}\)</span>。随后，我们将其送入一个 <span class="math inline">\(L\)</span> 层的<strong>Transformer编码器</strong>，得到模态融合特征 <span class="math inline">\(\{m_1, m_2, \cdots, m_q \}\)</span>（其中 <span class="math inline">\(q = k + p\)</span>）。由于Transformer编码器得到的特征是分散在各个Token上的，因此我们再将其送入一个新的自注意力层得到整个序列的聚合特征表示 <span class="math inline">\(\{m_1&#39;, m_2&#39;, \cdots, m_q&#39; \}\)</span>。最后，我们将该特征表示连接到一个 <span class="math inline">\(q \to 3\)</span> 的线性层，即可得到最终的类别概率输出。</p><p>对于本实验，我们统一使用<strong>xlm-roberta-base</strong>和<strong>swin-base</strong>作为骨干网络的模型构架，因此特征长度 <span class="math inline">\(k = 768, p = 1024\)</span>。为了能够使其统一输入模态融合编码器，我们在实际实现时在图像特征提取器上方额外增加了两层Transformer编码器，这一结构结合下面的对比学习任务从一定程度上也可以实现文字表征和图像表征的<strong>特征对齐</strong>。我们使用<strong>GELU</strong>作为层与层之间非线性变换的激活函数，并使用<strong>点积模型</strong>作为自注意力层的打分计算模型。</p><h3 id="预训练任务多模态情感预分类">预训练任务——多模态情感预分类</h3><p>由于上面设计的网络是一个全Transformer的结构，借鉴Bert等预训练模型的思想，我们同样可以考虑对该模型进行<strong>预训练</strong>以提升其特征提取能力。通常来说，对模型的预训练可以通过<strong>监督（Supervised）</strong>或<strong>自监督（Self-supervised）</strong>任务来完成，其中前者多用于视觉模型，后者多用于语义模型。然而，一般的图像-文本自监督预训练任务如<strong>图像文本匹配（Image-Text Matching）</strong>等往往考虑的是图文之间内在特征的匹配程度，这与我们共同考虑获得一个外在情感打分的任务并不一致。由于情感分类本质上是一个监督学习任务，因此我们可以直接将这一任务也作为预训练时的任务，通过引入额外的数据集来让模型获得更好的初始特征提取能力，同时也彻底解决了预训练和下游任务不匹配的问题。Yan Ling等人的研究也表明了这一预训练任务本身就具有很强的有效性。</p><p>我们使用<strong>MVSA-Multi</strong>数据集对模型进行了预训练。该数据集由Niu Teng等人于2016年提出，是一个经典的双模态情感分析数据集，其具体样本分布及数量如下表所示。由于该数据集中的样本同样为图像+文本，且目标类别数同样为3，因此十分适合作为当前场景下的预训练数据集。</p><table><thead><tr class="header"><th>标签</th><th>样本数（图像-文本对）</th></tr></thead><tbody><tr class="odd"><td>积极（Positive）</td><td>11903</td></tr><tr class="even"><td>中性（Neutral）</td><td>4107</td></tr><tr class="odd"><td>消极（Negative）</td><td>1500</td></tr></tbody></table><p>我们以 <span class="math inline">\(9:1\)</span> 将数据集划分为了训练集和验证集。在预训练阶段，我们同时输入图像、文本和标签对模型进行监督训练，并使用<strong>交叉熵（CrossEntropy）</strong>作为模型的损失函数。对于超参数设置，我们将<strong>Batch Size</strong>设为<strong>32</strong>，特征提取骨架网络学习率设置为<strong>2e-6</strong>，其他部分学习率设置为<strong>5e-5</strong>，使用<strong>AdamW+Linear Scheduler</strong>分别作为模型的参数优化器和学习率规划器，共训练<strong>40</strong>代。随后，我们使用一张<strong>Nvidia A40</strong>显卡作为硬件环境对模型进行了预训练，训练中的Loss和在验证集上的分类准确率如下图所示。可以看到，预训练后的模型在验证集上的分类精度F1值能达到约<strong>0.64</strong>，且Loss随着预训练的过程推进逐步下降，表明该预训练任务及数据集是合适的，且模型在预训练过程中能够正确收敛。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/ptamsc_pretrain_summary.png" class="" title="ptamsc_pretrain_summary"><h3 id="下游推理">下游推理</h3><h4 id="对比学习">对比学习</h4><p>接下来我们在目标数据集上对模型进行训练。由于深度神经网络本质上是一个多层非线性模型，若直接使用原始数据对其进行训练，则其输出特征的距离语义无法明确。为了让模型能够更好地区分不同情感倾向的样本特征，我们可以采用<strong>对比学习（Contrastive Learning）</strong>的方法来专门对模型的正负样本特征进行强化。对比学习是一种自监督的学习方法，其通过<strong>代理任务（Proxy Task）</strong>将样本划分为正负样本，并尝试找到一种空间表征，使得正样本或负样本间的距离尽可能小，同时又使得正样本和负样本之间的距离足够的大。对于当前任务来说，我们希望拥有相同情感标签的输出表征足够的近，而拥有相反情感标签的输出表征足够的远。因此，对于一个拥有<strong>“积极”</strong>情感标签的样本，我们将所有同批次中标签为<strong>“积极”</strong>的样本均视为正样本，而将同批次中标签为<strong>“中性”</strong>或<strong>“消极”</strong>的样本视为负样本；相反的，对于标签为“消极”的样本，我们则将同批次中标签同为“消极”的样本视为正样本，反之则视为负样本。</p><p>我们采用CLMLF中基于标签的对比学习算法来从正负样本中获得对比学习损失。具体来说，对于一组数据中的两个同标签样本 <span class="math inline">\(x_i, x_j \in \mathcal{D}\)</span>，设其通过上述网络结构后的特征向量分别为 <span class="math inline">\(y_i, y_j\)</span>，则其损失函数被定义为</p><p><span class="math display">\[l_{ij} = -\log \frac{\exp \left\{ y_i^T y_j / \tau \right\}}{\sum_{y_k \in \mathcal{D} \land k \neq i} \exp \left\{ y_i^T y_k / \tau \right\} }\]</span> 其中 <span class="math inline">\(\tau\)</span> 为<strong>温度系数</strong>。这一损失函数本质上即为对比学习中最常用的<strong>InfoNCE Loss</strong>。从公式中我们可以看到，只有当两个正样本间的点积足够小，而所有正负样本对间的点积结果足够大，该损失的结果才会达到最小。</p><p>对数据集中所有满足以上条件的样本对计算上述损失并进行加权平均，就得到了整个网络的<strong>对比学习损失</strong>，也即 <span class="math display">\[\mathcal{L}_{Contrastive} = \frac{1}{|Pair(\mathcal{D})|} \sum_{(i, j) \in Pair(\mathcal{D})} l_{ij}\]</span></p><h4 id="损失函数">损失函数</h4><p>由于当前任务是一个监督多分类问题，因此我们使用交叉熵作为损失函数的主干部分。为了提升模型的分类表现，我们将上面提到的对比学习损失通过加权和的方式融入最终的损失函数中。 于是，整个模型的损失函数即为</p><p><span class="math display">\[\mathcal{L} = \lambda_1 \mathcal{L}_{Cross-Entropy} + \lambda_2 \mathcal{L}_{Contrastive}\]</span> 其中 <span class="math inline">\(\mathcal{L}_{Cross-Entropy}\)</span> 为交叉熵损失，<span class="math inline">\(\mathcal{L}_{Contrastive}\)</span> 为上述的对比学习损失，<span class="math inline">\(\lambda_1\)</span> 和 <span class="math inline">\(\lambda_2\)</span> 分别为两个子损失函数的权重。通过网格搜索，我们将其确定为 <span class="math inline">\(\boldsymbol{\lambda_1 = 0.55, \lambda_2 = 0.45}\)</span>。</p><h2 id="实验">实验</h2><h3 id="数据集预处理">数据集预处理</h3><p>为了使得目标数据集能够适配模型的输入结构并取得较优的效果，我们需要首先对数据集的文字和图像部分分别进行预处理。</p><p>通过读入数据集我们可以发现，原始数据集中文本数据所使用的存储编码并不一致，部分文件使用常规的<strong>UTF-8</strong>及<strong>ANSI（cp1252）</strong>格式无法正确读取，如下图所示。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/dataset_encode_error_detail.png" class="" title="dataset_encode_error_detail"><p>我们通过VSCode使用UTF-8编码打开读取错误的文件，发现其存在着大量特殊字符。经过一系列尝试，我们发现这些文件在使用<strong>GBK</strong>编码时均能够正确显示。正确解码后，我们发现其均为日语。为了方便模型统一进行推理，我们将这些文件统一翻译为了英文，并使用UTF-8编码进行保存。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/dataset_errortext_utf8_decode.png" class="" title="dataset_errortext_utf8_decode"><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/dataset_errortext_gbk_decode.png" class="" title="dataset_errortext_gbk_decode"><p>接下来我们对数据集中的图像进行预处理。由于数据集是从非结构化数据中获得的，因此每张图像的大小并不一致。为了适配目标神经网络的输入格式，我们需要将其变换至统一的尺寸。由于ImageNet中图像的尺寸为 <span class="math inline">\(\boldsymbol{224 \times 224}\)</span>，本项目中所使用的视觉预训练模型也均为该数据集上训练的模型，因此这里我们也将目标图片调整至这一大小。具体的，我们先将图像等比缩放至最近邻2的倍数大小，随后通过中心裁剪的方式将其变换为目标尺寸。随后，为了让模型更快收敛，我们参考ResNet实现中的建议，将每张图像标准化为一个特定统计特征的张量。具体实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 图像变换</span><br>img_transformer = transforms.Compose(<br>    [<br>        transforms.Resize(img_aligned_scale(target_size)),<br>        transforms.CenterCrop(target_size),<br>        transforms.ToTensor(),<br>        transforms.Normalize(mean=[<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], std=[<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])<br>    ]<br>)<br><span class="hljs-comment"># 将图像等比放大至2的倍数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img_aligned_scale</span>(<span class="hljs-params">target_size</span>):</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">20</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-number">2</span> ** i &gt;= target_size:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> ** i<br>    <span class="hljs-keyword">return</span> target_size<br></code></pre></td></tr></table></figure><p>经过上述预处理后，我们使用Pytorch中提供的<strong>Dataset</strong>和<strong>Dataloader</strong>接口，即可将其组合为模型训练所要求的数据格式。</p><h3 id="超参数调优">超参数调优</h3><p>特别的，我们使用<strong>网格搜索（Grid Search）</strong>的方法对两个<strong>特征提取骨干网络（Backbone）的微调学习率（lr1）</strong>、<strong>模态融合模型学习率（lr2）</strong>以及<strong>学习率预热步数（WarmUp）</strong>三个超参数的最优值进行了搜索，使用<strong>F1</strong>值作为结果评价指标，结果如下图所示。可以看到，随着微调学习率的增大，网络的训练结果先增大后剧烈降低，并在<strong>lr1=1e-5</strong>时分类表现达到最优；当恒定微调学习率时，网络的训练结果随着融合学习率的增大缓慢上升，并在学习率超过<strong>lr2=5e-3</strong>时出现了较大的波动；学习率预热步数对训练结果的影响较小，随着预热步数的增大，训练结果同样呈现先增大后见小的趋势，当<strong>warmup=10</strong>时，网络取得了最优的分类表现。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/xlm_hypertune.png" class="" title="xlm_hypertune"><p>根据上面的搜索结果，我们将三个超参数确定为<strong>lr1=1e-5, lr2=5e-3, warmup=10</strong>。对于其他超参数，我们采用了<strong>AdamW</strong>作为本文所有模型的优化器，其三个核心超参数被分别设为<strong>beta1=0.9, beta2=0.999, epsilon=1e-8</strong>。为了权衡模型的训练性能需求，我们将<strong>批大小（Batch Size）</strong>统一设置为<strong>32</strong>，训练次数Epoch被设为<strong>10</strong>。</p><h3 id="训练过程">训练过程</h3><p>我们首先使用上面提到的任务和配置对模型进行了预训练。以该结果作为模型的初始参数，我们继续使用目标数据集进行微调训练任务。对于数据集中的带标签部分，我们按照 <span class="math inline">\(8:2\)</span> 将其划分为了训练集和测试集，并使用上面的探索结果作为训练时的超参数设置。训练时的Loss及模型在验证集上的分类表现随迭代次数的变化情况如下图所示。可以看到，训练Loss在<strong>150</strong>步及<strong>750</strong>步附近均出现了明显的下降，其他区间均在一个特定范围中波动，总体上呈缓慢下降的趋势，表明模型优化成功。随着训练过程的推进，模型在验证集上的分类准确率最高达到了约<strong>0.75</strong>，F1值最高达到约<strong>0.64</strong>，这一结果均发生在约第<strong>7</strong>个Epoch的训练中。</p><img src="/2022/07/05/contemporary-ai/contemporary-ai-exp-5/ptamsc_train_summary.png" class="" title="ptamsc_train_summary"><h3 id="结果">结果</h3><p>我们实现并采用相同配置训练了上述所有提到的基准模型和主模型，并在验证集上使用各个模型对样本的情感类别标签进行了推理。对于分类效果，我们采用<strong>准确率（Accuracy）</strong>、<strong>精确率（Precision）</strong>、<strong>召回率（Recall）</strong>及<strong>F1</strong>作为评价指标。各个模型在验证集上的分类表现如下表所示：</p><table><thead><tr class="header"><th>模型</th><th>正确率（Accuracy）</th><th>精确率（Precision）</th><th>召回率（Recall）</th><th>F1值</th></tr></thead><tbody><tr class="odd"><td>Bert</td><td>72.99%</td><td>65.56%</td><td>54.47%</td><td>55.66%</td></tr><tr class="even"><td>XLMRoBERTa</td><td>73.58%</td><td>67.62%</td><td>59.48%</td><td>61.52%</td></tr><tr class="odd"><td>ResNet</td><td>57.93%</td><td>36.01%</td><td>33.71%</td><td>25.59%</td></tr><tr class="even"><td>Swin Transformer</td><td>66.73%</td><td>57.90%</td><td>54.02%</td><td>55.38%</td></tr><tr class="odd"><td>X+S(Concatenate)</td><td>70.25%</td><td>63.74%</td><td>54.88%</td><td>57.12%</td></tr><tr class="even"><td>X+S(Additive)</td><td>71.23%</td><td>66.31%</td><td>54.79%</td><td>55.01%</td></tr><tr class="odd"><td><strong>PTAMSC</strong></td><td><strong>76.51%</strong></td><td><strong>70.88%</strong></td><td><strong>63.34%</strong></td><td><strong>65.69%</strong></td></tr></tbody></table><p>可以看到，PTAMSC模型在验证集上的分类正确率达到了<strong>76.51%</strong>，F1值达到了<strong>65.69%</strong>，且在各个指标上均优于所有其他的单模态及多模态基准模型，表明了模型设计的合理性。此外，我们还能发现，对于单模态分类模型，强Baseline的表现均优于基础Baseline，其中XLMRoBERTa相比Bert提升了<strong>10.5%</strong>，Swin Transformer相比ResNet更是提升了<strong>116.4%</strong>。对于多模态模型而言，简单的拼接和加性多模态模型由于其特征无法对齐，分类效果反而出现了一定的下降。</p><h2 id="消融试验">消融试验</h2><p>接下来我们通过消融实验来探究多模态输入及训练过程中的预训练操作对模型分类表现带来的影响。</p><h3 id="单模态输入">单模态输入</h3><p>要研究多模态输入对分类结果的影响，我们将输入数据分别改为单文字和单图像输入，并使用训练完成的模型对输入数据进行推理，对比其分类精度。这里我们采用了两种方法实现这一操作：一种是直接取模型中对应模态的推理部分，也即模型分别退化为基准模型中的<strong>XLMRoBERTa</strong>和<strong>Swin Transformer</strong>分类模型；另一种是将其中一个模态的原始数据输入网络，另一模态的数据采用<strong>全0填充</strong>的方式进行替代并输入网络，类似于增加了一个输入掩码。单模态及多模态输入在验证集上的分类结果如下表所示。可以看到，相比退化的分类模型，在原始模型上通过遮盖文字的方式进行单模态输入带来了<strong>0.78%</strong>的正确率提升，而通过遮盖图像的方式进行单模态输入正确率则反而下降了<strong>0.41%</strong>。结合了双模态输入的原始模型分类表现则显著地高于单模态输入的所有模型，这一结果也证明了所设计模型对双模态特征表征融合的有效性。</p><table><thead><tr class="header"><th>模型</th><th>正确率（Accuracy）</th><th>精确率（Precision）</th><th>召回率（Recall）</th><th>F1值</th></tr></thead><tbody><tr class="odd"><td>XLMRoBERTa</td><td>73.58%</td><td>67.62%</td><td>59.48%</td><td>61.52%</td></tr><tr class="even"><td>Swin Transformer</td><td>66.73%</td><td>57.90%</td><td>54.02%</td><td>55.38%</td></tr><tr class="odd"><td>PTAMSC（仅文字）</td><td>72.99%</td><td>63.51%</td><td>59.25%</td><td>60.77%</td></tr><tr class="even"><td>PTAMSC（仅图像）</td><td>67.51%</td><td>62.89%</td><td>59.20%</td><td>59.20%</td></tr><tr class="odd"><td><strong>PTAMSC</strong></td><td><strong>76.51%</strong></td><td><strong>70.88%</strong></td><td><strong>63.34%</strong></td><td><strong>65.69%</strong></td></tr></tbody></table><h3 id="预训练带来的提升">预训练带来的提升</h3><p>接下来我们继续探究预训练是否给模型带来了分类精度的提升。在同样的训练配置下，我们分别采用<strong>直接在目标数据集上训练</strong>和<strong>在MVSA-Multi数据集上预训练+在目标数据集上微调</strong>的方式重新对模型进行训练，并在验证集上进行分类验证，结果如下表所示。可以看到，经过预训练的模型在验证集上带来了<strong>1.95%</strong>的正确率提升。继续分析后三个指标我们可以发现，预训练主要提升了模型分类的<strong>精确率</strong>，也即模型对于每个类别的<strong>分类置信度</strong>更高。</p><table><thead><tr class="header"><th>模型</th><th>正确率（Accuracy）</th><th>精确率（Precision）</th><th>召回率（Recall）</th><th>F1值</th></tr></thead><tbody><tr class="odd"><td>PTAMSC（直接训练）</td><td>74.56%</td><td>69.04%</td><td>63.18%</td><td>64.87%</td></tr><tr class="even"><td>PTAMSC（预训练+微调）</td><td><strong>76.51%</strong></td><td><strong>70.88%</strong></td><td><strong>63.34%</strong></td><td><strong>65.69%</strong></td></tr></tbody></table><h2 id="总结">总结</h2><p>在本文中，我们对多模态情感分析任务进行了全面的探索和建模。在对不同模态的各种基准模型进行分析和借鉴后，我们从零开始设计并实现了一个基于全Transformer构架的多模态情感分类模型PTAMSC。通过引入预训练和对比学习方法，我们得以显著地提升模型对情感特征的学习和捕捉能力。在目标数据集上，PTAMSC的分类表现全面超过了几种经典的基准模型，且通过消融实验我们可以发现，模型中所使用的几种训练和处理技巧均发挥了作用。最后，我们使用训练完成的模型对目标测试集进行了情感标签推理，结果可见随附的<strong>test_predict.txt</strong>文件。</p><h2 id="references">References</h2><ol type="1"><li>Jay Alammar. The illustrated bert, elmo, and co. (how nlp cracked transfer learning). https://jalammar.github.io/illustrated-bert/, 2018.</li><li>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine transla- tion by jointly learning to align and translate. CoRR, abs/1409.0473, 2015.</li><li>Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guil- laume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440–8451, Online, July 2020. Association for Computational Linguistics.</li><li>Alexis CONNEAU and Guillaume Lample. Cross-lingual language model pretraining. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.</li><li>Feilong Chen, Duzhan Zhang, Minglun Han, Xiuyi Chen, Jing Shi, Shuang Xu, and Bo Xu. Vlp: A survey on vision-language pre-training. 02 2022.</li><li>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pretraining of deep bidirectional transformers for language understanding. In Proceed- ings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.</li><li>Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (gelus), 2016.</li><li>Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778, 2016.</li><li>Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. ArXiv, abs/1711.05101, 2017.</li><li>Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, and Baining Guo. Swin transformer v2: Scaling up capacity and resolution. In International Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</li><li>Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021.</li><li>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. ArXiv, abs/1907.11692, 2019.</li><li>Zhen Li, Bing Xu, Conghui Zhu, and Tiejun Zhao. CLMLF:a contrastive learning and multi-layer fusion method for multimodal sentiment detection. In Findings of the Association for Computational Linguistics: NAACL 2022. Association for Com- putational Linguistics, 2022.</li><li>Yan Ling, Jianfei Yu, and Rui Xia. Vision-language pre-training for multimodal aspect-based sentiment analysis. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2149– 2159, Dublin, Ireland, May 2022. Association for Computational Linguistics.</li><li>Teng Niu, Shiai Zhu, Lei Pang, and Abdulmotaleb El Saddik. Sentiment analysis on multi-view social data. In Qi Tian, Nicu Sebe, Guo-Jun Qi, Benoit Huet, Richang Hong, and Xueliang Liu, editors, MultiMedia Modeling, pages 15–27, Cham, 2016. Springer International Publishing.</li><li>Aäron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. CoRR, abs/1807.03748, 2018.</li><li>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.</li><li>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davi- son, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Can- wen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Pro- cessing: System Demonstrations, pages 38–45, Online, October 2020. Association for Computational Linguistics.</li><li>Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, and Xing Xie. Fastformer: Additive attention can be all you need. CoRR, abs/2108.09084, 2021.</li><li>Nan Xu and Wenji Mao. Multisentinet: A deep semantic network for multimodal sentiment analysis. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM ’17, page 2399–2402, New York, NY, USA, 2017. Association for Computing Machinery.</li><li>Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into deep learning. arXiv preprint arXiv:2106.11342, 2021.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;多模态学习是近几年来机器学习中的一个较为新兴的领域，不同模态的组合和应用场景延伸出了一系列多模态学习任务。其中，多模态情感分析作为一个经典的多模态任务，有着极为广泛的应用，也是现如今建立多模态模型的一项常用的基准评价任务。在本文中，我</summary>
      
    
    
    
    <category term="当代人工智能" scheme="http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Artificial-Intelligence" scheme="http://gonggongjohn.me/tags/Artificial-Intelligence/"/>
    
  </entry>
  
  <entry>
    <title>当代人工智能 课程项目四 预训练模型的加载与使用（Transformers）实验报告</title>
    <link href="http://gonggongjohn.me/2022/06/30/contemporary-ai/contemporary-ai-exp-4/"/>
    <id>http://gonggongjohn.me/2022/06/30/contemporary-ai/contemporary-ai-exp-4/</id>
    <published>2022-06-30T02:00:00.000Z</published>
    <updated>2022-12-17T06:03:38.408Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>随着Transformer和BERT模型的提出，预训练模型在序列理解及生成任务中的应用正逐渐变得越来越广泛。代码语言理解是近年来从语言理解领域延伸出的一项新兴任务，这一任务的机器学习实现可以大大提高程度开发和调试的效率。在本文中，我们通过对两大NL-PL语言双模态预训练模型CodeBERT和CodeT5的加载和微调，完成了对代码语言理解基准数据集CodeXGLUE的代码摘要生成，并比较了两大模型的结果精度和特性。此外，我们还使用针对Python语言已完成微调的CodeT5模型，对本实验中的代码进行了代码注释生成，并对其生成结果进行了分析。</p><p><strong>关键字：自动代码摘要，NL-PL双模态理解，预训练模型，CodeBERT，CodeT5，CodeXGLUE</strong></p><h2 id="项目介绍">项目介绍</h2><h3 id="任务介绍">任务介绍</h3><p><strong>代码摘要（Code Summarization）</strong>是代码语言理解中的一大重要子任务，也是当今绝大多数代码理解和生成数据集中均有包含的一项机器学习算法评测任务。代码摘要的目标是对一段代码所实现的功能进行理解，并使用自然语言的方式给出合适的描述和概括。具体来说，给定一段代码文本序列 <span class="math inline">\(\{s_1, s_2, \cdots, s_n \}\)</span>，模型需要给出一段相应的自然语言文本序列<span class="math inline">\(\{w_1, w_2, \cdots, w_n\}\)</span>，使得这段文本序列能够对代码序列进行表征。</p><h3 id="数据集介绍">数据集介绍</h3><p><strong>CodeXGLUE</strong>是代码语言理解和生成任务的一大经典数据集，由微软亚洲研究院于2021年公开。CodeXGLUE是一个多任务组合而成的综合评价数据集，其基本情况如下图所示。可以看到，CodeXGLUE共由<strong>10</strong>个子任务组成，其中的数据取自<strong>14</strong>个原有的代码语言理解数据集，可用于评价代码理解模型在各种代码理解和生成相关的下游任务中的综合表现。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codexglue_summary.png" class="" title="codexglue_summary"><p>对于代码摘要任务，CodeXGLUE中使用了其在之前研究中就有涉及过的<strong>CodeSearchNet</strong>数据集。这一数据集是通过对公开的Github仓库代码及其README文件的第一段进行爬取，并通过一系列预处理去除无效和不匹配字符而得到的，其不同语言的样本数量如下图所示。在本实验中，我们使用了其规模最小的<strong>Ruby</strong>数据集作为微调数据集，其包含了<strong>24927</strong>个训练集样本，<strong>1400</strong>个验证集样本以及<strong>1261</strong>个测试集样本。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codesearchnet_summary.png" class="" title="codesearchnet_summary"><h2 id="任务一预训练模型微调">任务一：预训练模型微调</h2><h3 id="codebert">CodeBERT</h3><h4 id="模型分析">模型分析</h4><p><strong>CodeBERT</strong>是<strong>编程-自然语言双模态预训练模型</strong>的开山之作，由微软亚洲研究院联合哈尔滨工业大学、中山大学于2020年提出。受预训练模型Bert的启发，CodeBERT可以通过预训练<strong>对NL-PL的混合语义特征进行通用表示</strong>，并支持如自然语言代码搜索、代码文档生成等一系列多模态下游任务的推理和生成。</p><p>CodeBERT采用了和<strong>RoBERTa</strong>完全一样的模型结构，进而又与<strong>Bert</strong>的模型结构一致，因此其基本模型构架如下图所示。可以看到，类Bert模型的基本结构均由多层Transformer编码器组合而成，通过一系列的预训练任务来使得编码器能够根据文本的原始特征输出响应的上下文语义特征。RoBERTa通过对参数的分析优化了Bert的架构和预训练过程，从而进一步挖掘出了Bert的潜能。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/bert_structure.png" class="" title="bert_structure"><p>CodeBERT采用了<strong>NL-PL文本对</strong>的方式作为预训练阶段模型的输入表示，并使用分隔符进行标记。具体来说，模型的输入为 <span class="math inline">\([CLS], w_1, w_2, \cdots, w_n, [SEP], c_1, c_2, \cdots, c_m, [EOS]\)</span>，其中 <span class="math inline">\([CLS]\)</span> 为句体标识符，<span class="math inline">\([SEP]\)</span> 为NL/PL分隔符，<span class="math inline">\([EOS]\)</span> 为句体结束表示符，这种表示也是类Bert模型常用的文本对表示方式。</p><p>CodeBERT的预训练任务分为两个，其中一个是经典的<strong>遮盖语言建模（Masked Language Modeling）</strong>任务，也即随机地遮盖住NL-PL对中的某个部分，并让模型预测遮盖住的部分。另一个任务为<strong>词项替换检测（Replaced Token Detection）</strong>任务，其原理如下图所示。可以看到，RTD任务采用了一个类似<strong>GAN</strong>的结构，在前一个任务的基础上，通过两个生成器分别对遮盖住的NL词项和PL词项进行生成，并使用一个判别器对生成的词项进行替换检测来判断生成的词项是否为原来的词项。通过这种对抗学习的思想，预训练过程可以同时使用<strong>双模态（NL-PL）</strong>和<strong>单模态（PL）</strong>的语料对模型进行训练，从而提升模型的表征效果。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codebert_rtd.png" class="" title="codebert_rtd"><h4 id="微调实践">微调实践</h4><p>可以看到，CodeBERT本质上是一个语义编码模型，其本身并不具有文本生成的功能。要使用其来进行代码摘要任务，我们需要额外设计一个<strong>解码器（Decoder）</strong>来进行摘要文本生成。由于CodeBERT的编码器部分全部由Transformer结构组成，为了保持统一，在解码器部分，我们同样采用多层Transformer块的方式对文本进行解码。在CodeBERT的原始论文中，作者在代码摘要任务的评估中使用了<strong>6</strong>层Transformer作为解码器，其中包含<strong>12</strong>个注意力头和<strong>768</strong>维的隐藏层，这里我们<strong>保持这一原有设置进行实现</strong>。加入解码器后，整个代码摘要模型生成流程如下图所示。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codebert_codesum_structure.png" class="" title="codebert_codesum_structure"><p>我们使用<strong>Pytorch</strong>和<strong>transformers</strong>库对上面的结构进行了实现，部分代码参考了CodeBERT的原始代码实现。代码的具体细节见报告随附代码中的<strong>codebert_model.py</strong>。我们使用同样为Huggingface实现的<strong>datasets</strong>模块对CodeXGLUE数据集进行了加载，并将其作为微调任务中的训练、验证和测试数据集。由于其已经划分好了训练、验证和测试部分，我们只需要逐一加载即可。对于预训练模型，我们使用了微软官方提供的<strong>microsoft/codebert-base</strong>模型。为了复现原论文中的结果，我们将微调的超参数设置与原文中保持一致，也即将学习率设为<strong>5e-5</strong>，<strong>Batch Size</strong>设置为<strong>16</strong>，共训练<strong>8</strong>个Epochs（<strong>12464</strong>个Steps）。训练时Loss随迭代次数的变化情况如下图所示。可以看到，训练Loss在前<strong>2000</strong>代时快速下降，随后每隔约<strong>1000</strong>代出现一次波动并逐步下降，这与<strong>小批量梯度下降算法</strong>的Loss特征相吻合。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codebert_loss.png" class="" title="codebert_loss"><p>在每一代训练完成后，我们使用目标数据集中的验证集对模型的生成结果进行评估。我们使用<strong>BLEU-4（Bilingual Evaluation Understudy-4 Gram）</strong>和<strong>困惑度（Perplexity）</strong>作为生成结果的评价指标。结果如下图所示。可以看到，模型在验证集上BLEU-4的最好表现达到了<strong>13.26</strong>，出现在<strong>Epoch=7</strong>时；困惑度最低约为<strong>61.40</strong>，出现在<strong>Epoch=4</strong>的时候。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codebert_bleu_ppl.png" class="" title="codebert_bleu_ppl"><p>训练完成后，我们对测试集中的代码进行摘要文本生成，其BLEU-4结果如下表所示。可以看到，本次训练的模型在相同测试集上的生成结果与原论文的差距约为 <span class="math inline">\(\boldsymbol{0.7\%}\)</span>，考虑到初始化的随机性，该误差可接受。表明这一模型实现和训练过程与原论文相符。</p><table><thead><tr class="header"><th>模型</th><th>测试集预测结果</th><th>原始论文结果</th></tr></thead><tbody><tr class="odd"><td>CodeBERT+Transformer</td><td><strong>12.07</strong></td><td>12.16</td></tr></tbody></table><h3 id="codet5">CodeT5</h3><h4 id="模型分析-1">模型分析</h4><p><strong>CodeT5</strong>是一个<strong>端到端的NL-PL序列生成类预训练模型</strong>，由Salesforce亚洲研究院于2021年提出。CodeT5旨在解决此前模型仅对编码器或解码器进行预训练从而导致其在序列生成类任务上训练不连贯的问题，该模型希望通过一个完整的端到端预训练模型来提升序列生成的精度。</p><p>CodeT5基于机器翻译模型<strong>T5</strong>演化而来，其模型结构也与T5一致。而T5模型采用了一个标准的<strong>Transformer Encoder-Decoder</strong>构架，因此其模型结构如下图所示。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codet5_architecture.png" class="" title="codet5_architecture"><p>与CodeBERT类似，CodeT5同样采用了NL-PL文本对结合特殊分割符的方式作为预训练阶段模型的输入表示。此外，为了捕获更多代码语言中的特征，CodeT5还通过将代码转化为<strong>抽象语法树（Abstract Syntax Tree）</strong>的方式来标记其<strong>函数、变量标识符</strong>的位置，并作为<strong>片段嵌入层（Segment Embedding）</strong>输入模型。</p><p>CodeT5的预训练流程如下图所示。具体来说，其共有如下4个预训练任务：<strong>遮盖片段预测（Masked Span Prediction）</strong>、<strong>标识符标记（Identifier Tagging）</strong>、<strong>遮盖标识符预测（Masked Identifier Prediction）</strong>和<strong>双模态双向生成（Bimodal Dual Generation）</strong>。其中，MSP是一种经典的类Seq2Seq模型预训练任务，用于建立NL-PL转换的通用表征；IT和MIP任务用于学习代码语言特有的关键字和标识符信息；BDG任务本身即为双向生成预训练，可以有效消除预训练过程和下游任务训练中的任务差异。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codet5_pretrain_procedure.png" class="" title="codet5_pretrain_procedure"><h4 id="微调实践-1">微调实践</h4><p>由于CodeT5本身即为一个端到端的生成模型，因此我们无需增加额外的模块。Salesforce官方提供了一份CodeT5在各种下游任务中的实现代码，这里我们直接使用其中的代码摘要模块来完成对CodeXGLUE-Ruby数据集的微调任务。对于预训练模型，我们使用了其在HuggingFace上提供的<strong>Salesforce/codet5-base</strong>模型，并使用原论文中的超参数设置对目标数据集进行了微调。训练时Loss随迭代次数的变化情况如下图所示。可以看到，训练Loss在前<strong>500</strong>代时快速下降，随后每隔约<strong>500</strong>代出现一次波动并逐步下降，由于这一次训练的Batch Size更大（<strong>Batch Size=48</strong>），因此这一曲线符合小批量梯度下降的Loss特征，表明模型收敛有效。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codet5_loss.png" class="" title="codet5_loss"><p>与CodeBERT类似，在每一代训练完成后，我们使用目标数据集中的验证集对模型的生成结果进行评估，并同样使用<strong>BLEU-4</strong>和<strong>困惑度</strong>作为评价指标。结果如下图所示。可以看到，模型在验证集上BLEU-4的最好表现约为<strong>16.71</strong>，出现在<strong>Epoch=2</strong>时；困惑度最低约为<strong>1.423</strong>，出现在<strong>Epoch=2</strong>的时候。由于该模型本身即为一个端到端的模型，且预训练任务中已经有对文本生成的预训练，因此其收敛较快，多次训练后反而出现了效果下降的情况。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codet5_bleu_ppl.png" class="" title="codet5_bleu_ppl"><p>训练完成后，我们对测试集中的代码进行摘要文本生成，其BLEU-4结果如下表所示。可以看到，本次训练的模型在相同测试集上的生成结果与原论文的差距约为 <span class="math inline">\(\boldsymbol{0.6\%}\)</span>，考虑误差因素，该结果可被接受。此外，我们可以看到，相比CodeBERT+Transformer的代码摘要模型，CodeT5在Ruby数据集上的BLEU-4结果提升了约<span class="math inline">\(\boldsymbol{29.58\%}\)</span>，这一提升时十分可观的。</p><table><thead><tr class="header"><th>模型</th><th>测试集预测结果</th><th>原始论文结果</th></tr></thead><tbody><tr class="odd"><td>CodeT5</td><td><strong>15.64</strong></td><td>15.73</td></tr></tbody></table><h2 id="任务二python函数注释">任务二：Python函数注释</h2><p>接下来我们使用经过微调的CodeT5对本次实验的代码进行自动注释。CodeT5官方提供了一个已经完成微调的代码摘要模型<strong>检查点（Checkpoint）</strong>，这一检查点可以支持多个语言的代码摘要生成，我们直接使用transformers库的<strong>T5ForConditionalGeneration.from_pretrained()</strong>方法即可加载这一模型。</p><p>我们选取CodeBERT和CodeT5中实现代码中函数的部分（codet5/data/summarize/source.txt），并将其预处理为统一的格式以方便读取，预处理代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><br>instance_list = []<br><span class="hljs-keyword">with</span> open(<span class="hljs-string">&#x27;data/summarize/python/source.txt&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    line = f.readline()<br>    code_tmp = <span class="hljs-string">&#x27;&#x27;</span><br>    cnt = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> line:<br>        <span class="hljs-keyword">if</span> line == <span class="hljs-string">&#x27;[SEP]\n&#x27;</span>:<br>            cnt += <span class="hljs-number">1</span><br>            instance_list.append(&#123;<span class="hljs-string">&#x27;id&#x27;</span>: cnt, <span class="hljs-string">&#x27;code&#x27;</span>: code_tmp&#125;)<br>            code_tmp = <span class="hljs-string">&#x27;&#x27;</span><br>        <span class="hljs-keyword">else</span>:<br>            code_tmp += line<br>        line = f.readline()<br><span class="hljs-keyword">with</span> open(<span class="hljs-string">&#x27;data/summarize/python/source.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f_out:<br>    json.dump(instance_list, f_out)<br></code></pre></td></tr></table></figure><p>处理完成的代码文本见随附代码的<strong>codet5/data/summarize/source.json</strong>。随后，我们使用字符串方式将其逐行读入，并输入CodeT5模型中进行函数注释生成，结果如下图所示。可以看到，对于一些功能相对清晰的函数，CodeT5可以准确地概括其代码意图，甚至对于一些额外库中的对象（如Pandas中的Dataframe），模型也可以准确地生成其语义。然而，对于一些需要整体功能背景的函数段来说，CodeT5的摘要结果与其实际作用便存在着一些差距，如下图所示。</p><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codet5_inference.png" class="" title="codet5_inference"><img src="/2022/06/30/contemporary-ai/contemporary-ai-exp-4/codet5_inference_compare.png" class="" title="codet5_inference_compare"><p>完整生成结果可见<strong>codet5/data/summarize/summary.json</strong>。</p><h2 id="总结">总结</h2><p>在本文中，我们对预训练模型在代码摘要任务上的训练和推理过程进行了较为全面的探索。通过分别使用经过预训练的CodeBERT和CodeT5模型在CodeXGLUE数据集上进行微调并对比其生成结果，我们能够较好地看出近年来预训练模型在NL-PL双模态理解和生成任务上的发展。随后，我们使用经过预训练的CodeT5模型对实验代码进行实际的函数注释生成，通过对结果的分析，我们能够看出机器学习模型在该任务上的推理表现和特性。</p><h2 id="references">References</h2><ol type="1"><li>Jay Alammar. The illustrated transformer. http://jalammar.github.io/ illustrated-transformer/, 2018.</li><li>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Com- putational Linguistics.</li><li>Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. CodeBERT: A pre- trained model for programming and natural languages. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1536–1547, Online, November 2020. Association for Computational Linguistics.</li><li>Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin B. Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu, and Shujie Liu. Codexglue: A ma- chine learning benchmark dataset for code understanding and generation. CoRR, abs/2102.04664, 2021.</li><li>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. ArXiv, abs/1907.11692, 2019.</li><li>Microsoft. Codebert. https://github.com/microsoft/CodeBERT, 2021.</li><li>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learn- ing with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1–67, 2020.</li><li>Salesforce. Codet5. https://github.com/salesforce/CodeT5, 2021.</li><li>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45, Online, October 2020. Association for Computational Linguistics.</li><li>Yungao Xie, Hong Wen, and Qing Yang. Ternary sentiment classification of air- line passengers’twitter text based on bert. Journal of Physics: Conference Series, 1813:012017, 02 2021.</li><li>Shafiq Joty Steven C.H. Hoi Yue Wang, Weishi Wang. Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, 2021.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;随着Transformer和BERT模型的提出，预训练模型在序列理解及生成任务中的应用正逐渐变得越来越广泛。代码语言理解是近年来从语言理解领域延伸出的一项新兴任务，这一任务的机器学习实现可以大大提高程度开发和调试的效率。在本文中，我们</summary>
      
    
    
    
    <category term="当代人工智能" scheme="http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Artificial-Intelligence" scheme="http://gonggongjohn.me/tags/Artificial-Intelligence/"/>
    
  </entry>
  
  <entry>
    <title>当代人工智能 课程项目三 图像分类及经典CNN实现</title>
    <link href="http://gonggongjohn.me/2022/05/02/contemporary-ai/contemporary-ai-exp-3/"/>
    <id>http://gonggongjohn.me/2022/05/02/contemporary-ai/contemporary-ai-exp-3/</id>
    <published>2022-05-02T02:00:00.000Z</published>
    <updated>2022-12-17T05:50:15.329Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>在本文中，我们对卷积神经网络在图像分类中的发展进行了全面的梳理和探索。通过实现六大经典神经网络构架：LeNet、AlexNet、VGGNet、ResNet、MobileNet 和 ConvNeXt，并将其应用于 MNIST 数据集的分类任务中，我们可以看到不同网络构架和设计思想对分类结果的影响。此外，我们还通过硬件消耗和资源占用情况分析了不同网络构架的效能，讨论了不同网络结构的适用场景。</p><p><strong>关键字：图像分类，MNIST，LeNet，AlexNet，VGGNet，ResNet，MobileNet，ConvNeXt</strong></p><h2 id="项目介绍">项目介绍</h2><h3 id="任务介绍">任务介绍</h3><p>计算机视觉作为人工智能和计算机科学的一大重要领域，已经逐渐在越来越多的应用场景下发挥重要的作用。在计算机视觉中，图像分类是一项十分经典且基础的任务，其是很多下游任务（如语义分割、目标检测等）的前置任务。早期的图像分类主要使用特征工程方法，依赖人工设计的图像特征对图像进行判别。随着计算机算力和神经网络技术的发展，基于深度学习的图像分类方法在近十几年得到了前所未有的发展。</p><p>图像分类任务的具体定义如下：给定一组图像的计算机表示 <span class="math inline">\(\mathcal{I} = \{x_1, x_2, \cdots, x_n\}\)</span> 和类别集 <span class="math inline">\(\mathcal{C} = \{c_1, c_2, · · · , c_k\}\)</span>，我们需要让机器学习出一种映射 <span class="math inline">\(f : \mathcal{I} \to \mathcal{C}\)</span>，使得对于任意 <span class="math inline">\(x \in \mathcal{I}\)</span>，存在一 个<span class="math inline">\(c \in \mathcal{C}\)</span>，使得 <span class="math inline">\(f(x) = c\)</span>。</p><p>在本项目中，我们需要复现和对比近年来几大经典的基于<strong>卷积神经网络（Convolutional Neu- ral Network）</strong>的深度学习构架，实现对图像的多分类任务。</p><h3 id="数据集介绍">数据集介绍</h3><p><strong>MNIST（Modified NIST）</strong>数据集是一个手写体数字图像数据集，由 Yann LeCun 等人首先提出并用于验证其于 1989 年提出的卷积神经网络分类器。该数据集来自于由<strong>美国国家标准与技术研究所（National Institute of Standards and Technology）</strong>发起整理的<strong>Special Database 3</strong>和<strong>Special Database 1</strong>手写数字图像数据库，其中前者来自于高中生，后者来自于人口普查局的工作人员。</p><p>MNIST 数据集共包含<strong>70000</strong>张图像，其中训练集含有<strong>60000</strong>张图像，测试集含有<strong>10000</strong>张图像。MNIST 数据集中的图像为单通道黑白图像，图像尺寸为 <span class="math inline">\(28 \times 28\)</span>，其中手写数字被规范化到了中心的 <span class="math inline">\(20 \times 20\)</span> 范围内。数据集中的部分图像如下图所示。可以看到，该数据集在预处理过程中已经去除了大部分图像的噪声，因此在模式识别早期，其是一个很好的验证模型特征提取能力的数据集。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/mnist_visualize.png" class="" title="mnist_visualize"><p>由于 MNIST 数据集十分经典，许多现代神经网络推理框架中已经集成了该数据集，并将数据集中的内容与框架中的数据结构进行了统一，这为我们省去了许多读取和预处理的麻烦。在本项目中，我们使用 PyTorch 框架附带的<strong>TorchVision</strong>视觉图形库直接加载这一数据集，并将其数据格式转化为 PyTorch 中的<strong>张量（Tensor）</strong>格式，实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision.datasets <span class="hljs-keyword">import</span> MNIST<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToTensor<br><br>train_data = MNIST(<span class="hljs-string">&#x27;mnist&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=ToTensor(), download=<span class="hljs-literal">True</span>) test_data = MNIST(<span class="hljs-string">&#x27;mnist&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=ToTensor(), download=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="模型">模型</h2><h3 id="lenet">LeNet</h3><h4 id="模型介绍">模型介绍</h4><p><strong>LeNet</strong>是由<strong>Yann LeCun</strong>等人于 1989 年提出的一种卷积神经网络构架，其被认为是现代卷积神经网络的开山之作。在早期模式识别时代，绝大多数的模式识别系统都是靠人工设计的特征或是人工特征+自动学习算法的方式来实现的。而由于自然数据的多样式，无论是语音、字形还是其他类型的模式，几乎不可能完全靠手工来建立一个精确的识别系统。LeCun 等人认为，通过巧妙的对自动学习系统的构造，模式识别系统可以完全依赖自动学习技术，而不是手工设计的启发式方法。以字符识别为例，LeCun 等人在 1998 年的论文中证明人工设计特征抽取的工作可以通过特别设计的机器学习方法替代，并直接应用在原始的像素图像上。</p><p>LeNet 自提出以来有多个适用于不同任务的网络结构变种，现在我们所说的 LeNet 网络结构一般指 LeCun 等人在 1998 年论文中提出的 LeNet-5 网络。LeNet-5 的整体模型构架如下图所示：</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/lenet_architecture.png" class="" title="lenet_architecture"><p>可以看到，整个 LeNet-5 网络共有<strong>7</strong>层，包含<strong>卷积层</strong>、<strong>池化层</strong>和<strong>全连接层</strong>。<strong>卷积层</strong>的卷积核 大小统一为 5 × 5，步长统一为<strong>1</strong>，其中第一个卷积层（C1）有<strong>6</strong>个卷积核，第二个卷积层（C3）有<strong>16</strong>个卷积核，第三个卷积层（C5）有<strong>120</strong>个卷积核。<strong>池化层</strong>的池化核大小统一为 <span class="math inline">\(2 \times 2\)</span>，池化方式统一为<strong>平均池化（Average Pooling）</strong>。在经过最后一个卷积层后，输入数据变为一个 <span class="math inline">\(120 \times 1\)</span> 的特征向量，再经过一个<strong>84</strong>维的<strong>全连接层</strong>后连接到<strong>10</strong>维的<strong>输出层</strong>上。</p><p>由于LeNet提出时间较早，其网络结构的部分细节与现代常见的卷积神经网络结构并不相同。其中最为显著的便是<strong>第一池化层（S2）</strong>和<strong>第二卷积层（C3）</strong>之间的<strong>不完全连接</strong>特性。具体来说，为了使 C3 层的不同卷积核之间能够表示不同的图像特征，S2 层和 C3 之间并不采用完全连 接的方式，而是人为地将部分单元相连接，具体连接方式如下图所示。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/lenet_partial_connection.png" class="" title="lenet_partial_connection"><p>此外，与现代网络结构中不同，LeNet 中的池化层除了对上一层的结果进行平均池化操作外，还需要通过一个线性变换以及 Sigmoid 激活函数。具体来说，池化层的计算公式如下： <span class="math display">\[\mathrm{AvgPool}(ch, i) = \sigma \left( w_{ch} \cdot \frac{1}{4} \sum_{j = 1}^4 \mathrm{input}_j + b_{ch} \right)\]</span> 其中 <span class="math inline">\(w_{ch}\)</span> 和 <span class="math inline">\(b_{ch}\)</span> 为可训练参数（每个池化核各对应一个）。</p><h4 id="模型实现">模型实现</h4><p>下面我们使用<strong>Pytorch</strong>框架来实现LeNet-5网络构架。从上面的介绍中我们知道，LeNet-5在数据经过池化层后还需要通过一个<strong>线性变换+Sigmoid激活层</strong>的结构，这一操作在现代的卷积神经网络构架中是不常见的，在Pytorch中并没有相关的封装类，因此我们首先来实现这一结构（依通道作线形变换），具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ChannelWiseLinear2d</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, channel</span>):</span><br>        super(ChannelWiseLinear2d, self).__init__()<br>        self.w = nn.Parameter(torch.rand(channel))<br>        self.b = nn.Parameter(torch.rand(channel))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        bs, ch, w, h = x.shape<br>        w_full = torch.zeros(bs, ch, w, h)<br>        b_full = torch.zeros(bs, ch, w, h)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(ch):<br>            w_full[:, i, :, :] = torch.full((bs, w, h), self.w[i].item())<br>            b_full[:, i, :, :] = torch.full((bs, w, h), self.b[i].item())<br>        <span class="hljs-keyword">return</span> w_full * x + b_full<br></code></pre></td></tr></table></figure><p>根据上面的介绍我们还可以知道，LeNet-5中的S2和C3层之间采用了<strong>不完全连接</strong>的方式进行连接。若要使用Pytorch的卷积层来实现这一效果，一个可行的办法是手动构造一个<strong>遮盖矩阵（Mask Matrix）</strong>，将遮盖住的连接参数置为0并加以冻结，以阻止输入数据传入未被连接的单元。通过阅读LeNet的原始论文我们可以知道，这一处理主要是为了迫使不同的卷积核对输入学习出不同的特征以防止所有的卷积核收敛至相同的参数，若用论文中的原话，就是<strong>打破网络结构中的对称性（break of symmetry in the network）</strong>。在更为现代的神经网络结构中，我们通常会通过<strong>随机初始化（Random Initialization）</strong>的方法来打破这一对称性，并且可以证明，这一方法相比手动地连接不同层之间的单元更为有效。由于Pytorch默认使用随机方法初始化网络参数，因此我们不再需要使用LeNet原文中的不完全连接操作。</p><p>有了上面的准备之后，现在我们可以来实现完整的LeNet-5结构了，具体实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LeNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        super(LeNet, self).__init__()<br>        self.extractor = nn.Sequential(<br>            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>            ChannelWiseLinear2d(channel=<span class="hljs-number">6</span>),<br>            nn.Sigmoid(),<br>            nn.Conv2d(in_channels=<span class="hljs-number">6</span>, out_channels=<span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">5</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>            ChannelWiseLinear2d(channel=<span class="hljs-number">16</span>),<br>            nn.Sigmoid(),<br>            nn.Conv2d(in_channels=<span class="hljs-number">16</span>, out_channels=<span class="hljs-number">120</span>, kernel_size=<span class="hljs-number">5</span>)<br>        )<br>        self.dense = nn.Sequential(<br>            nn.Linear(in_features=<span class="hljs-number">120</span>, out_features=<span class="hljs-number">84</span>),<br>            nn.Linear(in_features=<span class="hljs-number">84</span>, out_features=<span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        feature = self.extractor(x)<br>        feature = feature.view(feature.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)<br>        out = self.dense(feature)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><p>事实上，在原始的LeNet-5网络结构中，输出层中的单元并不是普通的输出单元，而是由<strong>欧几里得径向基单元（Euclidean RBF unit）</strong>组成，其本质是一种对输入特征和目标特征之间差异程度的度量。与之相对应的，LeNet-5的原始论文中使用了一种经过改进的<strong>均方误差（Mean Squared Error）</strong>函数作为整个训练时的损失函数。随着后来深度学习模型的发展我们知道，这种度量方法逐渐被<strong>Softmax层+交叉熵损失（Cross Entropy Loss）</strong>的方法所取代。由于手动实现原始论文中的这一特殊单元和损失函数较为繁琐，且这并不是本文的重点，因此这里我们统一使用Softmax层+交叉熵损失的方法来实现分类结构。</p><p>我们使用<strong>TorchInfo</strong>工具打印出我们实现的LeNet-5网络结构，结果如下图所示。可以看到，整个网络共有<strong>61750</strong>个可训练参数，并且除了S3层和最后的输出层，其他网络层的参数和原始论文中相一致，表明了我们实现的正确性。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/lenet_implement_summary.png" class="" title="lenet_implement_summary"><h3 id="alexnet">AlexNet</h3><h4 id="模型介绍-1">模型介绍</h4><p><strong>AlexNet</strong>是由<strong>Alex Krizhevsky</strong>和<strong>Geoffrey Hinton</strong>等人于2012年提出的一种深度卷积神经网络构架，正是这一构架的提出使得深度学习方法在图像识别领域重新获得了新生。</p><p>AlexNet的整体网络构架如下图所示（Figure ）。事实上，通过阅读论文我们可以发现，这张原始论文中的构架图带有一定的误导性。由于在当时显存和算力并不足以对整个网络进行存储和计算，因此作者使用了<strong>并行计算</strong>的方法将整个网络拆成了两个部分同时进行计算。对于抽象的网络结构，我们需要将图中的上下两部分进行合并，也即<strong>每一层的通道数实际上应该为图中每一部分所展示的两倍</strong>。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/alexnet_architecture.png" class="" title="alexnet_architecture"><p>可以看到，整个AlexNet网络共有<strong>11</strong>层。与LeNet类似，AlexNet同样由卷积层、池化层和全连接层组成。其中，第一卷积层拥有<strong>96</strong>个卷积核，每个卷积核大小为 <span class="math inline">\(11 \times 11\)</span>，卷积步长为<strong>4</strong>；第二卷积层有<strong>256</strong>个卷积核，每个卷积核大小为 <span class="math inline">\(5 \times 5\)</span>，边界填充大小为<strong>2</strong>；第三卷积层由3个卷积核大小为3的卷积层组成，分别拥有<strong>384</strong>、<strong>384</strong>和<strong>256</strong>个卷积核。在每个卷积层后，均有一个池化核大小为 <span class="math inline">\(3 \times 3\)</span> 且步长为<strong>2</strong>的池化层。整个网络的最后由3个全连接层组成，每层分别有<strong>4096</strong>、<strong>4096</strong>和<strong>10</strong>个单元，这些全连接层将作为最终的特征分类器得到分类的结果。相比LeNet，AlexNet使用了<strong>更大的卷积核</strong>和<strong>更多的卷积核全连接结构</strong>，从而使得整个网络拥有了更好的泛化能力。</p><p>对于非线性层，AlexNet首次提出了<strong>ReLU（Rectified Linear Units）</strong>激活函数，其定义为： <span class="math display">\[\textrm{ReLU}(x) = \max \{0, x\}\]</span> 相比较LeNet使用的<strong>sigmoid</strong>和<strong>tanh</strong>激活函数（在AlexNet的原始论文中将其称为饱和激活函数），ReLU拥有更大的梯度，在训练过程中可以有效防止梯度过小和梯度消失等问题，从而加快网络的收敛。这一点在使用类梯度下降作为网络参数优化算法的年代是十分重要的。</p><p>此外，AlexNet在最后的全连接层还使用了<strong>Dropout</strong>方法来防止网络过拟合，这一方法也是同年由Krizhevsky和Hinton等人所提出的。Dropout方法的基本原理如下图所示。由于样本量有限，为了防止整个网络参数过拟合，我们在训练时随机关闭一些隐藏层单元使其不参与传播，这样每次参与传播的参数就仅为网络的一部分，且由于随机性，这样做就能有效缓解整个网络过拟合的问题。每次随机关闭隐藏单元的概率被称为<strong>丢弃率</strong>，是整个网络的超参数之一，通常设为 <span class="math inline">\(0.5\)</span> 左右。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/dropout_illustrate.png" class="" title="dropout_illustrate"><h4 id="模型实现-1">模型实现</h4><p>由于AlexNet原本是基于<strong>ImageNet</strong>数据集设计的（图像尺寸为 <span class="math inline">\(3 \times 224 \times 224\)</span>），而MNIST数据集中的原始图像尺寸为 <span class="math inline">\(1 \times 28 \times 28\)</span>， 这一输入在后几层卷积层中甚至无法完成一次卷积操作，因此我们首先需要将其放缩为与ImageNet中图像一致的 <span class="math inline">\(224 \times 224\)</span> 大小。在Pytorch中，我们只需要在网络的输入层后增加一个<strong>上采样（Upsample）</strong>层即可。对于当前数据集，我们设置缩放系数为<strong>8</strong>，上采样方法为<strong>双线性差值法（Bilinear）</strong>。</p><p>对于网络的其他部分，我们只需要根据上文中的网络结构一一添加相应层即可。完整实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AlexNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, dropout</span>):</span><br>        super(AlexNet, self).__init__()<br>        self.net = nn.Sequential(<br>            nn.Upsample(scale_factor=<span class="hljs-number">8</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>),<br>            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">11</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>            nn.Conv2d(in_channels=<span class="hljs-number">96</span>, out_channels=<span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>            nn.Conv2d(in_channels=<span class="hljs-number">256</span>, out_channels=<span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(),<br>            nn.Conv2d(in_channels=<span class="hljs-number">384</span>, out_channels=<span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(),<br>            nn.Conv2d(in_channels=<span class="hljs-number">384</span>, out_channels=<span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>            nn.Flatten(),<br>            nn.Linear(in_features=<span class="hljs-number">6400</span>, out_features=<span class="hljs-number">4096</span>),<br>            nn.ReLU(),<br>            nn.Dropout(p=dropout),<br>            nn.Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">4096</span>),<br>            nn.ReLU(),<br>            nn.Dropout(p=dropout),<br>            nn.Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.net(x)<br></code></pre></td></tr></table></figure><p>我们使用TorchInfo打印出AlexNet的网络结构，结果如下图所示。可以看到，整个AlexNet有着<strong>46764746</strong>个可训练参数，这一参数量几乎是LeNet-5的<strong>758</strong>倍，这也印证了AlexNet原始论文中的核心思想，即更大更深的神经网络可以带来更好的图像特征提取能力。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/alexnet_implement_summary.png" class="" title="alexnet_implement_summary"><h3 id="vggnet">VGGNet</h3><h4 id="模型介绍-2">模型介绍</h4><p><strong>VGGNet</strong>是由英国牛津大学<strong>视觉几何小组（Visual Geometry Group）</strong>的<strong>Karen Simonyan</strong>和<strong>Andrew Zisserman</strong>两人于2015年提出的一种经典CNN网络构架。VGGNet的原始论文中首次提出了<strong>网络块</strong>的思想，通过将不同的网络层以特定的结构进行组合，卷积神经网络能够根据任务的复杂程度<strong>成体系地</strong>扩大网络的规模。</p><p>VGGNet的整体网络构架如下图所示。可以看到，由于VGGNet本身就是为了可扩展而设计的，因此其并没有一个固定的网络结构，整个VGGNet的卷积部分都是由一个个的<strong>VGG块</strong>拼接而成的。每个VGG块包含了若干层填充大小为1的卷积层以及一个池化核为 <span class="math inline">\(2 \times 2\)</span> 、步长为<strong>2</strong>的池化层。在VGGNet的原始论文中作者发现，使用具有<strong>更小感受野的深层卷积网络</strong>对图像的特征提取效果要好于具有<strong>更大感受野的浅层卷积网络</strong>，因此整个VGGNet中的卷积核大小均固定为了 <span class="math inline">\(3 \times 3\)</span>。在整个网络的最后，VGGNet使用了和AlexNet一样的三层全连接结构，并使用了Dropout方法来防止全连接层过拟合。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/vgg_structure.png" class="" title="vgg_structure"><p>在VGGNet的原始论文中，作者介绍了6种不同深度的网络架构，分别包含了<strong>11</strong>、<strong>13</strong>、<strong>16</strong>和<strong>19</strong>层可训练网络层，其各层的配置如下图所示。对于层数越多的网络，其特征提取能力也越强，能够识别出更多图像中的特征信息，但与此同时，其需要调整的参数也越多，需要耗费更多的算力来对整个网络进行训练和推理。此外，由于参数量的增大，使得网络收敛到一个较好结果所需要的训练数据量也越大。因此在实际使用时，我们通常会根据任务的规模和复杂程度选择合适深度的网络。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/vgg_configurations.png" class="" title="vgg_configurations"><h4 id="模型实现-2">模型实现</h4><p>下面我们来实现VGGNet。从上面的介绍中我们知道，VGGNet中最为核心的元素即为<strong>可变深度的VGG块</strong>，因此我们首先来实现这一组件。由于VGG块的基本结构是确定的，因此我们在创建VGG块时只需要指定<strong>卷积层的个数</strong>以及<strong>输入输出的通道数</strong>即可。对于每个VGG块的第一个卷积层，我们将输入的通道数匹配为输出的通道数；对于后面的若干卷积层，我们只需要保持输出通道输和输入通道数一致即可。具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VGGBlock</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, conv_num, in_channels, out_channels</span>):</span><br>        super(VGGBlock, self).__init__()<br>        self.net = nn.Sequential()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(conv_num):<br>            self.net.add_module(<br>                <span class="hljs-string">&quot;conv_&#123;0&#125;&quot;</span>.format(i), nn.Sequential(<br>                    nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>                    nn.ReLU()<br>                )<br>            )<br>            in_channels = out_channels<br>        self.net.add_module(<span class="hljs-string">&quot;pool&quot;</span>, nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.net(x)<br></code></pre></td></tr></table></figure><p>由于MNIST数据集中的特征较为简单，这里我们只需实现原始论文中层数最少的**VGGNet-11}即可。与AlexNet类似，在输入核心网络结构前，我们同样需要将输入数据放缩到 <span class="math inline">\(224 \times 244\)</span> 大小。随后，我们只需要根据上文中各层的配置实现整个网络即可。具体实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VGGNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, dropout</span>):</span><br>        super(VGGNet, self).__init__()<br>        self.net = nn.Sequential(<br>            nn.Upsample(scale_factor=<span class="hljs-number">8</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>),<br>            VGGBlock(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">64</span>),<br>            VGGBlock(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">128</span>),<br>            VGGBlock(<span class="hljs-number">2</span>, <span class="hljs-number">128</span>, <span class="hljs-number">256</span>),<br>            VGGBlock(<span class="hljs-number">2</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>),<br>            VGGBlock(<span class="hljs-number">2</span>, <span class="hljs-number">512</span>, <span class="hljs-number">512</span>),<br>            nn.Flatten(),<br>            nn.Linear(in_features=<span class="hljs-number">512</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, out_features=<span class="hljs-number">4096</span>),<br>            nn.ReLU(),<br>            nn.Dropout(p=dropout),<br>            nn.Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">4096</span>),<br>            nn.ReLU(),<br>            nn.Dropout(p=dropout),<br>            nn.Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.net(x)<br></code></pre></td></tr></table></figure><p>我们使用TorchInfo打印出VGGNet-11的网络结构，结果如下图所示。可以看到，即使是规模最小的VGGNet-11，其可训练参数的规模也达到了<strong>超过1亿</strong>的级别，相比较AlexNet不到5000万的参数量多了整整一倍。对于如此大量的网络参数，我们往往需要借助GPU来进行训练和推理，并且由于参数量之大，其在较小规模的数据集上很容易过拟合。因此，在较为现代的实际使用场景下，我们通常会使用<strong>预训练（Pretrain）+微调（Finetune）</strong>的方法来训练出最终的分类网络。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/vgg_implement_summary.png" class="" title="vgg_implement_summary"><h3 id="resnet">ResNet</h3><h4 id="模型介绍-3">模型介绍</h4><p>ResNet是现代计算机视觉模型中一个里程碑式的网络结构，由<strong>Kaiming He</strong>等人于2016年提出。ResNet通过提出<strong>残差连接（Residue Connection）</strong>这一思想，有效地解决了网络层数加深导致的<strong>输入特征消失</strong>以及<strong>学习偏差</strong>的问题。</p><p>ResNet中最重要的部分即为<strong>残差块（Residue Block）</strong>，其基本结构如下图所示。可以看到，相比普通的卷积块，残差块通过加入一个直接连接输入和输出的快速通道来将输入的特征直接叠加到输出特征之上，从而使得输入特征得以保留。从函数的角度上来看，若输入向量为 <span class="math inline">\(\boldsymbol{x}\)</span>，卷积层变换函数为 <span class="math inline">\(g(x)\)</span>，则一个残差块的输出结果为 <span class="math display">\[f(\boldsymbol{x}) = \boldsymbol{x} + g(\boldsymbol{x})\]</span> 。可以看到，即使卷积层没有学到任何有用的特征（卷积层退化为常数映射 <span class="math inline">\(g(\boldsymbol{x}) = C\)</span>），输出结果中仍然包含输入的特征，从而有效地防止学习偏差的问题。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/resblock_architecture.png" class="" title="resblock_architecture"><p>从上图中我们还可以看到，ResNet中的残差层结构分为两种，其中一种在短路连接前需要进一步将输入进行一次卷积操作，从而使其尺寸减半。这一操作是实现不同尺度特征抽取的重要基础。</p><p>与VGGNet类似，ResNet同样被设计为了可扩展的形式，其网络结构主要由残差块和全连接部分组成。以ResNet-18为例，其主要网络构架如下图所示。与VGGnet不同，ResNet在网络开始的部分采用了和AlexNet相同的 <span class="math inline">\(7 \times 7\)</span> 卷积核，并加入了<strong>批归一化（Batch Normalization）</strong>这一操作，使得网络的特征尺度放缩到同一水平，从而使得网络更容易训练。随后的网络结构由8个残差块组成，其中第一组残差块包含了两个同尺寸连接的普通残差块，之后的三组残差块均有一个半尺寸连接的残差块和一个普通残差块组成。网络的最后为一个池化核大小为<strong>1</strong>的<strong>全局平均池化层（Global Average Pooling）</strong>和一个全连接层。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/resnet_structure.png" class="" title="resnet_structure"><p>可以看到，ResNet并没有在全连接层使用自AlexNet以来便被频繁使用的<strong>Dropout</strong>操作，这是由于ResNet中使用了全局平均池化层来替代传统网络中的多层全连接结构，在这一网络结构下，Batch Normalization操作已经足够替代Dropout，并且往往能够取得更好的结果。</p><h4 id="模型实现-3">模型实现</h4><p>对于当前实验，由于数据集的缘故，我们同样只需要实现层数最少的<strong>ResNet-18</strong>即可。与VGGNet的实现思路类似，我们首先来实现ResNet中最重要的组件<strong>残差块（Residue Block）</strong>。从上面的介绍中我们知道，ResNet中共有两种残差块。为了方便起见，我们直接将残差操作中的卷积层包装在公共残差块中，并在初始化时指定是否启用该残差块。具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResBlock</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, stride, res_conv=False</span>):</span><br>        super(ResBlock, self).__init__()<br>        self.net = nn.Sequential(<br>            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=stride),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(),<br>            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(out_channels)<br>        )<br>        <span class="hljs-keyword">if</span> res_conv:<br>            self.res_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=<span class="hljs-number">1</span>, stride=stride)<br>        <span class="hljs-keyword">else</span>:<br>            self.res_conv = <span class="hljs-literal">None</span><br>        self.relu = nn.ReLU()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        y = self.net(x)<br>        <span class="hljs-keyword">if</span> self.res_conv:<br>            x = self.res_conv(x)<br>        y = y + x<br>        <span class="hljs-keyword">return</span> self.relu(y)<br></code></pre></td></tr></table></figure><p>随后，我们只需要根据上文中的结构实现网络的其他部分即可。完整实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        super(ResNet, self).__init__()<br>        self.net = nn.Sequential(<br>            nn.Upsample(scale_factor=<span class="hljs-number">8</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>),<br>            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>),<br>            nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>        )<br>        self.net.add_module(<span class="hljs-string">&#x27;res_1&#x27;</span>, nn.Sequential(<br>            ResBlock(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, stride=<span class="hljs-number">1</span>),<br>            ResBlock(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, stride=<span class="hljs-number">1</span>)<br>        ))<br>        self.net.add_module(<span class="hljs-string">&#x27;res_2&#x27;</span>, nn.Sequential(<br>            ResBlock(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">128</span>, stride=<span class="hljs-number">2</span>, res_conv=<span class="hljs-literal">True</span>),<br>            ResBlock(in_channels=<span class="hljs-number">128</span>, out_channels=<span class="hljs-number">128</span>, stride=<span class="hljs-number">1</span>)<br>        ))<br>        self.net.add_module(<span class="hljs-string">&#x27;res_3&#x27;</span>, nn.Sequential(<br>            ResBlock(in_channels=<span class="hljs-number">128</span>, out_channels=<span class="hljs-number">256</span>, stride=<span class="hljs-number">2</span>, res_conv=<span class="hljs-literal">True</span>),<br>            ResBlock(in_channels=<span class="hljs-number">256</span>, out_channels=<span class="hljs-number">256</span>, stride=<span class="hljs-number">1</span>)<br>        ))<br>        self.net.add_module(<span class="hljs-string">&#x27;res_4&#x27;</span>, nn.Sequential(<br>            ResBlock(in_channels=<span class="hljs-number">256</span>, out_channels=<span class="hljs-number">512</span>, stride=<span class="hljs-number">2</span>, res_conv=<span class="hljs-literal">True</span>),<br>            ResBlock(in_channels=<span class="hljs-number">512</span>, out_channels=<span class="hljs-number">512</span>, stride=<span class="hljs-number">1</span>)<br>        ))<br>        self.net.add_module(<span class="hljs-string">&#x27;output&#x27;</span>, nn.Sequential(<br>            nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)),<br>            nn.Flatten(),<br>            nn.Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">10</span>)<br>        ))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.net(x)<br></code></pre></td></tr></table></figure><p>我们使用TorchInfo打印出ResNet-18的网络结构，结果如下图所示。可以看到，由于改进的网络设计，ResNet-18仅有1100万左右的训练参数，相比VGGNet-11少了近10倍，而其分类效果反而好于VGGNet-11，足以见得残差连接的重要性。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/resnet_implement_summary.png" class="" title="resnet_implement_summary"><h3 id="mobilenet">MobileNet</h3><h4 id="模型介绍-4">模型介绍</h4><p>随着移动端设备功能的日益强劲和CNN网络在计算机视觉相关任务中应用的日益广泛，人们希望能够通过改进CNN模型的构架，减小其资源消耗量，使得其在移动端进行推理成为可能。MobileNet是对轻量化CNN网络的一大重要尝试，由<strong>Andrew Howard</strong>和<strong>Menglong Zhu</strong>等人与2017年提出。</p><p>MobileNet的最大贡献在于提出了<strong>深度可分离卷积（Depthwise Separable Convolution）</strong>操作，相比传统的卷积操作，这一卷积方法能够大大减少参数数量。深度可分离卷积由<strong>逐深度卷积（Depthwise Convolution）</strong>和<strong>逐点卷积（Pointwise Convolution）</strong>构成，具体结构如下图所示。可以看到，相比传统卷积操作，逐深度卷积将卷积核拆分成为单通道形式，在不改变输入特征图像深度的情况下，对每一通道进行卷积操作，这样就得到了和输入特征图通道数一致的输出特征图。而随后的逐点卷积则是进一步在特征图的基础上改变输出的通道数，从而达到升维和降维的效果。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/deepwise_convolution_illustrate.png" class="" title="deepwise_convolution_illustrate"><p>MobileNet的整体网络构架如下图所示。可以看到，与VGGNet类似，MobileNet同样使用了连续的卷积块来对不同尺度的特征图进行连续的抽取，其卷积层通道数依次按照32、64、128、256、512的顺序最终升高到1024个输出通道。网络的池化和全连接部分与ResNet类似，同样使用了全局平均池化以及一个单层的全连接分类层。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/mobilenet_architecture.png" class="" title="mobilenet_architecture"><p>需要注意的是，MobileNet中每一个卷积层后的激活函数并不使用传统的ReLU激活函数，而是使用了一种称为<strong>ReLU6</strong>的改进激活函数，其定义如下： <span class="math display">\[\textrm{ReLU6}(x) = \min \{ \max\{0, x\}, 6 \}\]</span> 可以看到，这一激活函数将网络的输出最大结果限制为6。这一做法的原因在于防止移动端<strong>FP16（半精度）</strong>的计算环境下造成的精度损失，从而导致网络无法正常收敛的问题。</p><h4 id="模型实现-4">模型实现</h4><p>首先我们来实现带有深度可分离卷积操作的轻量级卷积块。一个轻量级卷积块的内部构架如下图所示。可以看到，这一卷积块与传统卷积块唯一的不同是将一个 <span class="math inline">\(3 \times 3\)</span> 卷积操作转变为了一个 <span class="math inline">\(3 \times 3\)</span> 逐深度卷积操作和一个 <span class="math inline">\(1 \times 1\)</span> 逐点卷积操作。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/mobileblock_illustrate.png" class="" title="mobileblock_illustrate"><p>在Pytorch中，若要实现逐深度卷积操作，我们只需要将<strong>groups</strong>参数设置为输入通道数即可。对于结构的其他部分，我们只需要依次调用实现即可，具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MobileBlock</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, stride=<span class="hljs-number">1</span></span>):</span><br>        super(MobileBlock, self).__init__()<br>        self.net = nn.Sequential(<br>            nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=<span class="hljs-number">3</span>, stride=stride, padding=<span class="hljs-number">1</span>, groups=in_channels, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(in_channels),<br>            nn.ReLU6(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU6(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.net(x)<br></code></pre></td></tr></table></figure><p>随后，我们只需要根据上文中的模型结构，利用轻量级卷积块完成整个MobileNet网络的构建即可。完整实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MobileNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        super(MobileNet, self).__init__()<br>        self.net = nn.Sequential(<br>            nn.Upsample(scale_factor=<span class="hljs-number">8</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>),<br>            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(<span class="hljs-number">32</span>),<br>            nn.ReLU6(inplace=<span class="hljs-literal">True</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">32</span>, out_channels=<span class="hljs-number">64</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">128</span>, stride=<span class="hljs-number">2</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">128</span>, out_channels=<span class="hljs-number">128</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">128</span>, out_channels=<span class="hljs-number">256</span>, stride=<span class="hljs-number">2</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">256</span>, out_channels=<span class="hljs-number">256</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">256</span>, out_channels=<span class="hljs-number">512</span>, stride=<span class="hljs-number">2</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">512</span>, out_channels=<span class="hljs-number">512</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">512</span>, out_channels=<span class="hljs-number">512</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">512</span>, out_channels=<span class="hljs-number">512</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">512</span>, out_channels=<span class="hljs-number">512</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">512</span>, out_channels=<span class="hljs-number">512</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">512</span>, out_channels=<span class="hljs-number">1024</span>, stride=<span class="hljs-number">2</span>),<br>            MobileBlock(in_channels=<span class="hljs-number">1024</span>, out_channels=<span class="hljs-number">1024</span>),<br>            nn.AvgPool2d(kernel_size=<span class="hljs-number">7</span>),<br>            nn.Flatten(),<br>            nn.Linear(in_features=<span class="hljs-number">1024</span>, out_features=<span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.net(x)<br></code></pre></td></tr></table></figure><p>我们使用TorchInfo打印出MobileNet的网络结构，结果如下图所示。可以看到，MobileNet的可训练参数总量仅有约<strong>320万</strong>，相比较前三个桌面级网络这一参数量小了好几十倍，这就意味着更小的资源消耗和更快的推理速度，也使得其在移动端推理成为了可能。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/mobilenet_implement_summary.png" class="" title="mobilenet_implement_summary"><h3 id="convnext">ConvNeXt</h3><h4 id="模型介绍-5">模型介绍</h4><p>上面所介绍的一系列模型均为CNN热潮兴起后所提出的一系列网络变种，这些改进模型在各种数据集上一度得到了极好的表现。而近几年来，随着注意力机制和预训练模型的兴起，许多基于<strong>Transformer</strong>构架的图像分类网络也随之出现，其中的不少表现都远远优于基于纯CNN构架的网络。<strong>ConvNeXt</strong>是2022年由<strong>Facebook AI Research（FAIR）</strong>提出的一种新一代纯CNN图像特征提取构架，且其优秀的表现重新将CNN结构带回了人们的视野中。</p><p>ConvNeXt是一个集大成的逐步演化结果，其从ResNet网络构架出发，通过引入Swin Transformer的相关构架设计思想，一步步地将整个网络结构优化到分类效果最好的状态。具体演化过程及其在ImageNet数据集上的表现如下图所示：</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/convnext_gradual_optimize.png" class="" title="convnext_gradual_optimize"><p>可以看到，ConvNeXt引入的主要特性包括了<strong>卷积层结构改进</strong>、<strong>深度可分离卷积（Depthwise Separable Convolution）</strong>，<strong>逆瓶颈层（Inverted Bottleneck）</strong>，<strong>大卷积核</strong>、<strong>GELU</strong>以及<strong>层归一化（Layer Normalization）</strong>，这些特性均在先前的各种网络结构中被证明是有效的。与其他较为现代的网络结构一样，ConvNeXt同样采用了网络结构块的形式对整个网络结构进行构建，使其可以成规模地扩张到不同级别的任务上。</p><p>一个ConvNeXt网络块的基本结构如下图所示。可以看到，相比传统的残差块，ConvNeXt使用了更大的输入层卷积核，将ReLU和Batch Normalization分别替换成了GELU和Layer Normalization，并减少了激活函数的数量。这些修改均借鉴与Swin-Transformer构架的设计，使得分类效果得以获得显著的提升。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/convnext_block_illustration.png" class="" title="convnext_block_illustration"><h4 id="模型实现-5">模型实现</h4><p>由于ConvNeXt的网络构架较为复杂，部分子组件的实现参考了其原始代码。首先我们来实现ConvNeXt块中需要用到的<strong>DropPath</strong>层和<strong>Layer Normalization</strong>层。具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">drop_path</span>(<span class="hljs-params">x, drop_prob: float = <span class="hljs-number">0.</span>, training: bool = False</span>):</span><br>    <span class="hljs-keyword">if</span> drop_prob == <span class="hljs-number">0.</span> <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> training:<br>        <span class="hljs-keyword">return</span> x<br>    keep_prob = <span class="hljs-number">1</span> - drop_prob<br>    shape = (x.shape[<span class="hljs-number">0</span>],) + (<span class="hljs-number">1</span>,) * (x.ndim - <span class="hljs-number">1</span>)<br>    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)<br>    random_tensor.floor_()<br>    output = x.div(keep_prob) * random_tensor<br>    <span class="hljs-keyword">return</span> output<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DropPath</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, drop_prob=None</span>):</span><br>        super(DropPath, self).__init__()<br>        self.drop_prob = drop_prob<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> drop_path(x, self.drop_prob, self.training)<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LayerNorm</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, normalized_shape, eps=<span class="hljs-number">1e-6</span>, data_format=<span class="hljs-string">&quot;channels_last&quot;</span></span>):</span><br>        super().__init__()<br>        self.weight = nn.Parameter(torch.ones(normalized_shape), requires_grad=<span class="hljs-literal">True</span>)<br>        self.bias = nn.Parameter(torch.zeros(normalized_shape), requires_grad=<span class="hljs-literal">True</span>)<br>        self.eps = eps<br>        self.data_format = data_format<br>        <span class="hljs-keyword">if</span> self.data_format <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;channels_last&quot;</span>, <span class="hljs-string">&quot;channels_first&quot;</span>]:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;not support data format &#x27;<span class="hljs-subst">&#123;self.data_format&#125;</span>&#x27;&quot;</span>)<br>        self.normalized_shape = (normalized_shape,)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">if</span> self.data_format == <span class="hljs-string">&quot;channels_last&quot;</span>:<br>            <span class="hljs-keyword">return</span> F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)<br>        <span class="hljs-keyword">elif</span> self.data_format == <span class="hljs-string">&quot;channels_first&quot;</span>:<br>            mean = x.mean(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>            var = (x - mean).pow(<span class="hljs-number">2</span>).mean(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>            x = (x - mean) / torch.sqrt(var + self.eps)<br>            x = self.weight[:, <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>] * x + self.bias[:, <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>]<br>            <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>有了上面的组件后，我们来构建<strong>ConvNeXt块</strong>。为了配合上面实现的LayerNorm层的输入格式，我们需要在第一个卷积层后将数据的排列方式进行变换，而后续的三层由于不涉及到通道的问题，因此可以直接进行传播。最后，我们将数据变换回原先的排布方式，并对输出进行残差连接和Dropout操作。实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Block</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, channels, drop_rate=<span class="hljs-number">0.</span>, layer_scale_init_value=<span class="hljs-number">1e-6</span></span>):</span><br>        super().__init__()<br>        self.dwconv = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=<span class="hljs-number">7</span>, padding=<span class="hljs-number">3</span>, groups=channels)<br>        self.body = nn.Sequential(<br>            LayerNorm(channels, eps=<span class="hljs-number">1e-6</span>, data_format=<span class="hljs-string">&quot;channels_last&quot;</span>),<br>            nn.Linear(in_features=channels, out_features=<span class="hljs-number">4</span> * channels),<br>            nn.GELU(),<br>            nn.Linear(in_features=<span class="hljs-number">4</span> * channels, out_features=channels)<br>        )<br>        <span class="hljs-keyword">if</span> layer_scale_init_value &gt; <span class="hljs-number">0</span>:<br>            self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((channels,)), requires_grad=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">else</span>:<br>            self.gamma = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> drop_rate &gt; <span class="hljs-number">0.</span>:<br>            self.drop_path = DropPath(drop_rate)<br>        <span class="hljs-keyword">else</span>:<br>            self.drop_path = nn.Identity()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        y = self.dwconv(x)<br>        <span class="hljs-comment"># [N, C, H, W] -&gt; [N, H, W, C]</span><br>        y = y.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        y = self.body(y)<br>        <span class="hljs-keyword">if</span> self.gamma <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            y = self.gamma * y<br>        <span class="hljs-comment"># [N, H, W, C] -&gt; [N, C, H, W]</span><br>        y = y.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        out = x + self.drop_path(y)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><p>随后我们就可以来实现整个ConvNeXt网络结构了。与前面几种网络结构类似，ConvNeXt依旧遵循单一块的不同变种组成整个卷积部分的模式。由于数据集的单一性，我们在这里仅实现规模较小的ConvNeXt-S网络即可满足分类的模型容量要求。完整实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ConvNeXT</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, drop_path_rate: float = <span class="hljs-number">0.</span>, layer_scale_init_value: float = <span class="hljs-number">1e-6</span>,</span></span><br><span class="hljs-function"><span class="hljs-params">                 head_init_scale: float = <span class="hljs-number">1.</span></span>):</span><br>        super().__init__()<br>        depths = [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">27</span>, <span class="hljs-number">3</span>]<br>        dims = [<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>]<br>        self.up = nn.Upsample(scale_factor=<span class="hljs-number">8</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>        self.downsample_layers = nn.ModuleList()<br>        stem = nn.Sequential(<br>            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">4</span>),<br>            LayerNorm(dims[<span class="hljs-number">0</span>], eps=<span class="hljs-number">1e-6</span>, data_format=<span class="hljs-string">&quot;channels_first&quot;</span>)<br>        )<br>        self.downsample_layers.append(stem)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">3</span>):<br>            downsample_layer = nn.Sequential(LayerNorm(dims[i], eps=<span class="hljs-number">1e-6</span>, data_format=<span class="hljs-string">&quot;channels_first&quot;</span>),<br>                                             nn.Conv2d(dims[i], dims[i+<span class="hljs-number">1</span>], kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>))<br>            self.downsample_layers.append(downsample_layer)<br><br>        self.stages = nn.ModuleList()<br>        dp_rates = [x.item() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> torch.linspace(<span class="hljs-number">0</span>, drop_path_rate, sum(depths))]<br>        cur = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">4</span>):<br>            stage = nn.Sequential(<br>                *[Block(channels=dims[i], drop_rate=dp_rates[cur + j], layer_scale_init_value=layer_scale_init_value)<br>                  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(depths[i])]<br>            )<br>            self.stages.append(stage)<br>            cur += depths[i]<br>        self.norm = nn.LayerNorm(dims[<span class="hljs-number">-1</span>], eps=<span class="hljs-number">1e-6</span>)  <span class="hljs-comment"># final norm layer</span><br>        self.head = nn.Linear(dims[<span class="hljs-number">-1</span>], <span class="hljs-number">10</span>)<br>        self.apply(self._init_weights)<br>        self.head.weight.data.mul_(head_init_scale)<br>        self.head.bias.data.mul_(head_init_scale)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_init_weights</span>(<span class="hljs-params">self, m</span>):</span><br>        <span class="hljs-keyword">if</span> isinstance(m, (nn.Conv2d, nn.Linear)):<br>            nn.init.trunc_normal_(m.weight, std=<span class="hljs-number">0.2</span>)<br>            nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward_features</span>(<span class="hljs-params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">4</span>):<br>            x = self.downsample_layers[i](x)<br>            x = self.stages[i](x)<br>        <span class="hljs-keyword">return</span> self.norm(x.mean([<span class="hljs-number">-2</span>, <span class="hljs-number">-1</span>]))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br>        x = self.up(x)<br>        x = self.forward_features(x)<br>        x = self.head(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>我们使用TorchInfo打印出ConvNeXt的网络结构，结果如下图所示。可以看到，作为一个2020年代的卷积神经网络，即使是规模较小的ConvNeXt-S网络的可训练参数依然高达4900万。并且由于大量的中间推理过程，训练和推理这一网络需要一个性能较为强劲的平台来作支撑。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/convnext_implement_summary.png" class="" title="convnext_implement_summary"><h2 id="效果对比">效果对比</h2><h3 id="分类效果">分类效果</h3><p>我们使用 MNIST 数据集中的训练集对上面实现的所有网络进行了训练，并使用训练好的网络在测试集上进行了分类预测。对于所有训练过程，我们统一使用<strong>交叉熵损失（Cross Entropy Loss）</strong>作为训练时的损失函数，并使用<strong>AdamW</strong>作为优化器。为了横向比较网络结构对分类结果的影响，我们在训练过程中使用了完全相同的超参数（<span class="math inline">\(Batch\_Size = 64, lr = 0.001, Dropout = 0.5, epoch = 5\)</span>）。对于分类结果的评价指标，我们使用了<strong>正确率（Accuracy）</strong>、<strong>准确率（Precision）</strong>、 <strong>召回率（Recall）</strong>和 <strong>F1值</strong>，其定义如下： <span class="math display">\[\begin{aligned}&amp;\textrm{Accuracy} = \frac{n_{correct}}{n_{total}}&amp;\textrm{Precision} = \frac{TP}{TP+FP} \\&amp;\textrm{Recall} = \frac{TP}{TP+FN}&amp;\textrm{F1} = \frac{2 \times \textrm{Precision} \times \textrm{Recall}}{\textrm{Precision} + \textrm{Recall}}\end{aligned}\]</span> 其中 <span class="math inline">\(TP\)</span>、<span class="math inline">\(FP\)</span>、<span class="math inline">\(FN\)</span> 分别为<strong>正确正例</strong>、<strong>错误正例</strong>和<strong>错误负例</strong>。由于当前问题为多分类问题，我们采用<strong>宏平均（Macro Average）</strong>的方式来计算多个类的平均指标结果。</p><p>各个模型的分类结果如下表所示：</p><table><thead><tr class="header"><th>模型名</th><th>正确率</th><th>精确率</th><th>召回率</th><th>F1值</th></tr></thead><tbody><tr class="odd"><td>LeNet</td><td>0.9744</td><td>0.9748</td><td>0.9740</td><td>0.9743</td></tr><tr class="even"><td>AlexNet</td><td>0.9869</td><td>0.9868</td><td>0.9868</td><td>0.9867</td></tr><tr class="odd"><td>VGGNet-11</td><td>0.9828</td><td>0.9827</td><td>0.9827</td><td>0.9827</td></tr><tr class="even"><td>ResNet-18</td><td><strong>0.9928</strong></td><td><strong>0.9928</strong></td><td><strong>0.9928</strong></td><td><strong>0.9928</strong></td></tr><tr class="odd"><td>MobileNet</td><td>0.9919</td><td>0.9919</td><td>0.9918</td><td>0.9919</td></tr><tr class="even"><td>ConvNeXt</td><td>0.9871</td><td>0.9871</td><td>0.9869</td><td>0.9869</td></tr></tbody></table><p>可以看到，<strong>ResNet-18</strong>在所有模型中获得了最好的分类效果，MobileNet和ConvNeXt的分类效果其次。提出时间较早的LeNet、AlexNet和VGGNet-11的分类效果排在了最后。为了保证结果的<strong>可复现性</strong>，我们使用<strong>torch.manual_seed()</strong>方法对参数的初始化随机种子进行了固定（随机种子为214748364）。</p><p>接下来我们对训练过程中各个模型的收敛情况进行跟踪。各个模型在训练过程中的Loss变化及每个Epoch后在测试集上的分类变化情况如下图所示。可以看到，由于随机梯度下降方法的特征随机性，同一模型在不同Batch中得到的Loss呈波动状态，但总体随着迭代步数（Step）的增加逐渐下降。从分类结果来看，ResNet和MobileNet的收敛速度极快，且始终保持在一个较高的水平逐步提升；AlexNet和VGGNet由于其模型容量的限制，其准确率在达到一定的高度后便很难再出现显著提升；LeNet和ConvNeXt的准确率变化幅度较大，并且ConvNeXt在五次迭代后分类准确率并没有趋近平缓，表明此时模型还没有完全收敛。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/model_loss_accuracy.png" class="" title="model_loss_accuracy"><p>接下来，我们使用不同的优化器对各个模型进行训练，以衡量相同条件下不同模型训练的困难程度。这里我们分别使用了<strong>SGD</strong>、<strong>Adam</strong>和<strong>AdamW</strong>三种优化器，对应于三种参数自适应能力递增的优化算法。对于SGD优化器，我们将学习率固定在<strong>0.1</strong>；对于Adam和AdamW优化器，我们将初始学习率设为<strong>0.001</strong>。各个模型在不同优化器下训练时的Loss变化情况如下图所示。可以看到，SGD优化器在<strong>LeNet-5</strong>、<strong>VGGNet-11</strong>和<strong>ConvNeXT</strong>上表现不佳，其中后两者的Loss在下降到一定程度后便不再下降，表明优化失败。而在剩下的三个模型上，SGD优化器则获得了较好的表现，模型参数逐渐收敛到了预期的效果。其他两个优化器由于拥有较强的适应能力，因此其在各个模型上均能取得较好的表现。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/optimizer_loss.png" class="" title="optimizer_loss"><p>从上面的分析我们可以知道，<strong>ResNet-18</strong>和<strong>MobileNet</strong>在实际应用场景下相对容易训练，而剩下的模型则需要较为强劲的优化器才能够获得较好的表现，这也从一定程度上解释了这两大模型流行的原因。</p><h3 id="效能">效能</h3><p>接下来我们对各个模型的计算资源效能进行评估。在当前实验下，我们使用<strong>Intel Xeon Gold 5318Y + NVIDIA A40</strong>平台进行了全部的训练和推理。对于训练过程，我们统一使用<strong>FP32</strong>作为计算精度，Batch Size 统一为 <strong>64</strong>，并将训练过程中的模型和中间数据全部放在<strong>CUDA缓存</strong>中。在这一配置下，各个模型在训练时的显存占用情况如下图所示。可以看到，较早提出的 LeNet 和 AlexNet 所占用的显存空间较小，能够在各种性能等级的平台上完成推理；ResNet 和 MobileNet 由于较为巧妙的结构设计，将显存占用量控制在了一个较为合适的水平内;而依赖深度堆叠的 VGGNet 和较新提出的 ConvNeXt 模型则需要较多的显存资源才能够完成推理（通过参考基线可以看出要完成 VGGNet 的训练至少需要一张 RTX 3080Ti 或同级别的显卡，而完 成 ConvNeXT 的训练则这少需要一张 RTX 3090 或同级别的显卡）。</p><img src="/2022/05/02/contemporary-ai/contemporary-ai-exp-3/cuda_usage.png" class="" title="cuda_usage"><p>对于计算资源的占用情况，我们通过<strong>训练用时</strong>、<strong>推理用时</strong>和<strong>浮点运算数（Floating Point Operations, FLOPs）</strong>三种指标来进行评估。其中，第三个指标衡量了<strong>模型完成一次推理所需要进行的运算量</strong>，是模型复杂程度的一个量化指标。在具体实现中，我们使用<strong>ptflops</strong>包中提供的<strong>get_model_complexity_info()</strong>函数来计算各个模型的 FLOPs 值，并使用<strong>time</strong>包中的<strong>perf_counter()</strong>函数计算其资源占用时间。计算结果如下表所示。可以看到，较早的模型往往拥有较小的模型复杂度和较快的推理时间，而较为现代的模型则通常拥有千万级甚至亿级的模型复杂度，且需要更为漫长的推理和训练时间。对于 2022 年最新的 ConvNext 模型，即使是其较小参数量的 Small 版本，在 Nvidia A40 服务级显卡上进行 5 次迭代训练也要<strong>超过 1660 秒（接近半小时）</strong>的训练时间，这一资源需求显然是桌面级设备所不能接受的。</p><table><thead><tr class="header"><th>模型名</th><th>FLOPs</th><th>训练用时（秒）</th><th>推理用时（秒）</th></tr></thead><tbody><tr class="odd"><td>LeNet</td><td>420K</td><td>56.6359</td><td>0.0317</td></tr><tr class="even"><td>AlexNet</td><td>940M</td><td>101.1776</td><td>0.0349</td></tr><tr class="odd"><td>VGGNet-11</td><td>7.57G</td><td>653.7334</td><td>0.0703</td></tr><tr class="even"><td>ResNet-18</td><td>1.75G</td><td>277.5996</td><td>0.0450</td></tr><tr class="odd"><td>MobileNet</td><td>580M</td><td>288.4978</td><td>0.0512</td></tr><tr class="even"><td>ConvNeXt-S</td><td>8.69G</td><td>1665.7066</td><td>0.1167</td></tr></tbody></table><h2 id="总结">总结</h2><p>在本实验中，我们分析并实现了基于卷积神经网络的 6 大图像分类网络构架:LeNet、AlexNet、VGGNet、ResNet、MobileNet 和 ConvNeXt，涵盖了自 1998 以来计算机视觉领域中的大部分 要网络结构和思想。通过在多个维度上比较不同网络构架在 MNIST 数据集上的训练和推理表现，我们能够较为全面的了解不同网络构架的特性和适用场景。在实现的过程中，我们能够看到深度学习方法在图像分类和图像模式识别任务上是如何一步步发展到今天的，也看到了计算资源的发展对模型结构的扩展起到的重要作用。</p><h2 id="references">References</h2><ol type="1"><li>Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization, 2016.</li><li>Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (gelus), 2016.</li><li>Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. ArXiv, abs/1207.0580, 2012.</li><li>Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Eﬀicient convolutional neural networks for mobile vision applications. ArXiv, abs/1704.04861, 2017.</li><li>Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778, 2016.</li><li>Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, ICML’15, page 448–456. JMLR.org, 2015.</li><li>Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc., 2012.</li><li>Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.</li><li>Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. Backpropagation Applied to Handwritten Zip Code Recognition. Neural Computation, 1(4):541–551, 12 1989.</li><li>Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie. A convnet for the 2020s. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</li><li>Yuanzhi Li and Yang Yuan. Convergence analysis of two-layer neural networks with relu activation. In Proceedings of the 31st International Conference on Neural In- formation Processing Systems, NIPS’17, page 597–607, Red Hook, NY, USA, 2017. Curran Associates Inc.</li><li>Cory Maklin. Dropout neural network layer in keras explained. https://towardsdatascience.com/machine-learning-part-20-dropout-keras-layers-explained-8c9f6dc4c9ab, 2019.</li><li>Mark Sandler, Andrew G. Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4510–4520, 2018.</li><li>K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In International Conference on Learning Representations, May 2015.</li><li>TylerYep. torchinfo. https://github.com/TylerYep/torchinfo, 2020.</li><li>Saining Xie, Ross B. Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5987–5995, 2017.</li><li>Christopher J.C. Burges Yann LeCun, Corinna Cortes. The mnist database of handwritten digits. http://yann.lecun.com/exdb/mnist/, 1998.</li><li>Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into deep learning. arXiv preprint arXiv:2106.11342, 2021.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;在本文中，我们对卷积神经网络在图像分类中的发展进行了全面的梳理和探索。通过实现六大经典神经网络构架：LeNet、AlexNet、VGGNet、ResNet、MobileNet 和 ConvNeXt，并将其应用于 MNIST 数据集的分</summary>
      
    
    
    
    <category term="当代人工智能" scheme="http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Artificial-Intelligence" scheme="http://gonggongjohn.me/tags/Artificial-Intelligence/"/>
    
  </entry>
  
  <entry>
    <title>当代人工智能 课程项目二 A*算法</title>
    <link href="http://gonggongjohn.me/2022/04/05/contemporary-ai/contemporary-ai-exp-2/"/>
    <id>http://gonggongjohn.me/2022/04/05/contemporary-ai/contemporary-ai-exp-2/</id>
    <published>2022-04-05T02:00:00.000Z</published>
    <updated>2022-12-05T11:47:42.608Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p><span class="math inline">\(A^*\)</span> 算法是一种经典的启发式搜索算法，其在路径规划、语意搜索和在线学习等任务中都有着极为广泛的应用。相比传统的遍历搜索，<span class="math inline">\(A^*\)</span> 通过启发式代价优先选择代价估计值最小的状态进行展开，从而更有可能较为高效地到达目标状态。在本文中，我们整理了 <span class="math inline">\(A^*\)</span> 算法的思想和相关性质，设计并实现了八数码问题和 K 短路问题的求解算法，并对测试数据进行了求解。</p><p>**关键字：启发式搜索，A*算法，八数码问题，K 短路问题**</p><h2 id="a算法">A*算法</h2><p><span class="math inline">\(A^*\)</span> 算法是一种启发式单源最小代价搜索算法，由Peter Hart、Nils Nilsson和Bertram Raphael三人于1968年作为一项机器人研究课题的一部分提出。与传统的遍历式搜索算法不同，<span class="math inline">\(A^*\)</span> 算法通过考虑更多的信息来估计每种状态到目标间的代价，并以此为依据智能地选择后续的搜索方向。具体来说，若设 <span class="math inline">\(\mathcal{H}\)</span> 为一个搜索问题的状态集合，定义每种状态 <span class="math inline">\(n \in \mathcal{H}\)</span> 的代价估计值 <span class="math inline">\(f(n) = g(n) + h(n)\)</span>，其中 <span class="math inline">\(g(n)\)</span> 为从初始状态到当前状态的实际代价，<span class="math inline">\(h(n)\)</span> 为从当前状态到目标状态的启发代价。在每一次迭代中，<span class="math inline">\(A^*\)</span>算法会计算每种候选状态的代价估计值，并选择代价估计值最小的状态进一步搜索。<span class="math inline">\(A^*\)</span>算法的算法流程如下：</p><figure><img src="algorithm_a_star.png" alt="algorithm_a_star" /><figcaption aria-hidden="true">algorithm_a_star</figcaption></figure><p>从上面的描述可以发现，设计<span class="math inline">\(A^*\)</span>算法的关键便是定义每种状态到目标状态的启发代价。对于一棵搜索树而言，并不是任意的启发函数都能保证<span class="math inline">\(A^*\)</span>算法找到最优解，其必须为一个<strong>可接受启发（Admissible Heuristic）</strong>，定义如下：</p><blockquote><p><strong>Definition 1（可接受启发）：</strong>设状态集合 <span class="math inline">\(\mathcal{H}\)</span>，函数<span class="math inline">\(h: \mathcal{H} \to \mathbb{R}\)</span> 为给定状态到目标状态的一个代价估计函数，<span class="math inline">\(h^*: \mathcal{H} \to \mathbb{R}\)</span> 为从给定状态到目标状态的真实代价函数。若对任意 <span class="math inline">\(n \in \mathcal{H}\)</span>，有 <span class="math inline">\(0 \leq h(n) \leq h^*(n)\)</span>，则称函数 <span class="math inline">\(h\)</span> 为一个<strong>可接受启发</strong>。</p></blockquote><p>对于一棵状态搜索树，若启发函数为可接受启发，则使用<span class="math inline">\(A^*\)</span>算法必定能够找出最优解。这是由于有如下定理保证：</p><blockquote><p><strong>Theorem 1：</strong>若状态搜索树满足如下条件：</p><ul><li><strong>分支因子（Branching Factor）</strong>是有限的</li><li>状态转移代价为正</li><li>启发函数为可接受启发</li></ul><p>则 <span class="math inline">\(A^*\)</span> 算法是<strong>完全（若存在解则能够找到解）</strong>且<strong>最优（能够找到最优解）</strong>的。</p><p><strong>Proof：</strong> <strong>完全性</strong></p><p>设解的深度为 <span class="math inline">\(d\)</span>，状态搜索树的最大分支因子为 <span class="math inline">\(b\)</span>，则算法最多遍历 <span class="math inline">\(b^d\)</span> 个结点即可找到该解，也即算法完全。</p><p><strong>最优性</strong></p><p>设最优状态结点为 <span class="math inline">\(A\)</span>，<span class="math inline">\(N\)</span> 为从根节点到最优状态结点的路径上的任意一点，任一个次优状态结点为 <span class="math inline">\(B\)</span>。 由代价估计函数的定义可知 <span class="math display">\[\begin{aligned}f(N) &amp;= g(N) + h(N) \\f(A) &amp;= g(A)\end{aligned}\]</span> 由于 <span class="math inline">\(h\)</span> 为可接受启发，因此有 <span class="math inline">\(h(N) \leq g(A) - g(N)\)</span>，于是有 <span class="math inline">\(f(N) \leq f(A)\)</span>。又由于 <span class="math inline">\(f(A) \leq f(B)\)</span>，因此 <span class="math inline">\(f(N) \leq f(B)\)</span>。由此可知最优路径上的每个结点 <span class="math inline">\(N\)</span> 都会优先于 <span class="math inline">\(B\)</span> 被展开。故 <span class="math inline">\(A\)</span> 会优先于 <span class="math inline">\(B\)</span> 被展开，也即最优性成立。</p></blockquote><p><span class="math inline">\(A^*\)</span>算法的效率主要取决于<strong>启发函数对目标状态的引导效率</strong>。在最坏情况下（启发函数不提供任何信息），<span class="math inline">\(A^*\)</span>算法退化为<strong>广度优先搜索算法</strong>，其时间复杂度为 <span class="math inline">\(\mathcal{O}(b^d)\)</span>，其中 <span class="math inline">\(b\)</span> 为分支因子，<span class="math inline">\(d\)</span> 为状态搜索树深度。由于要同时记录已搜索的结点和待搜索的结点，因此其最坏情况下的空间复杂度也为 <span class="math inline">\(\mathcal{O}(b^d)\)</span>。</p><h2 id="问题一小明玩球">问题一：小明玩球</h2><h3 id="问题描述">问题描述</h3><p>小明在一个九宫格中随机摆了八个球，每个球上标有1-8中的某一数字（球上数字不重复）。九宫格中留有一个空格，该空格用0表示。空格周围的球可以移动到空格中。现在，给出一种初始布局（即初始状态）和目标布局（本题的目标布局设为123804765），现在小明想找到一种最少步骤的移动方法，实现从初识布局到目标布局的转变，你能帮帮他吗？</p><p><strong>要求只能用<span class="math inline">\(A^*\)</span>算法。</strong></p><p><strong>输入格式</strong></p><p>输入初始状态，一行九个数字，空格用0表示，除0之外，分别表示从左到右从上到下的对应球上的数字。例：初始状态为283104765，即对应了下图所示的九宫格布局：</p><figure><img src="q1_example_input.PNG" alt="q1_example_input" /><figcaption aria-hidden="true">q1_example_input</figcaption></figure><p><strong>输出格式</strong></p><p>只有一行，该行只有一个数字，表示从初始状态到目标状态需要的最少移动次数（测试数据中无特殊无法到达的目标状态数据）。</p><p><strong>输入样例</strong></p><p>283104765</p><p><strong>输出样例</strong></p><p>4</p><h3 id="问题求解">问题求解</h3><h4 id="可解性判断">可解性判断</h4><p>尽管测试数据中保证了不存在无法到达的目标状态数据，但出于算法的完整性，我们首先对状态的可解性进行判断。对于一个八数码问题，其可解性可以通过比较当前状态和目标状态下九宫格数码排列的奇偶性来快速判断。这是由于有如下定理保证：</p><blockquote><p><strong>Theorem 2：</strong>一个八数码问题可解当且仅当当前状态的数码排列（除去空白格）与目标状态的数码排列（除去空白格）的奇偶性相同。</p><p><strong>Proof：</strong>由于横向移动操作不改变除去空白格后的数码排列，因此我们仅需考虑纵向移动。</p><p>当空白格向上移动时，涉及格点周围的数码排列由 <span class="math inline">\(\cdots xyz \cdots\)</span> 变为 <span class="math inline">\(\cdots yzx \cdots\)</span>；当空白格向下移动时，涉及格点周围的数码排列由 <span class="math inline">\(\cdots xyz \cdots\)</span> 变为 <span class="math inline">\(\cdots zxy \cdots\)</span>。易见两种操作均可分解为对换 <span class="math inline">\((x,y)\)</span> 和对换 <span class="math inline">\((x,z)\)</span>。由于对换改变排列的奇偶性，因此两种操作对数码排列的奇偶性均不改变，也即仅当当前状态和目标状态的数码排列同奇偶时该问题才可解。</p><p>又由于任一 <span class="math inline">\(n\)</span> 元排列均可由其同奇偶的其他 <span class="math inline">\(n\)</span> 元排列经过偶数次对换得到，因此在满足上述可解性的前提下，目标状态必定可达。</p></blockquote><p>对于当前问题，易知目标状态的除空数码排列12384765的逆序数位为<strong>7</strong>，也即该排列为一个<strong>奇排列</strong>。因此，对于初始状态的除空数码排列为<strong>偶排列</strong>的输入，我们可直接返回。</p><h4 id="启发函数">启发函数</h4><p>从上面的介绍中可以知道，为了能够高效地利用<span class="math inline">\(A^*\)</span>算法对问题进行求解，我们需要设计一个较为合理的启发函数。对于当前问题，我们使用<strong>总曼哈顿距离（Total Manhattan Distance）</strong>作为一个状态的启发代价。具体来说，若一个数码 <span class="math inline">\(i\)</span> 在当前状态 <span class="math inline">\(c\)</span> 的坐标为 <span class="math inline">\((x_i^c, y_i^c)\)</span>，其在目标状态 <span class="math inline">\(t\)</span> 对应的坐标为 <span class="math inline">\((x_i^t, y_i^t)\)</span>，则其曼哈顿距离定义为 <span class="math display">\[d(i_c, i_t) = |x_i^c - x_i^t| + |y_i^c - y_i^t|\]</span> 于是整个状态的总曼哈顿距离即为 <span class="math display">\[h(c, t) = \sum_{i = 0}^8 d(i_c) = \sum_{i = 0}^8 \left( |x_i^c - x_i^t| + |y_i^c - y_i^t| \right)\]</span></p><p>以样例输入为例，其启发距离如下图所示。可以看到，该状态下共有3个数码与目标状态下位置不一致，其曼哈顿距离分别为1，2，1，因此该状态的总曼哈顿距离为4。</p><figure><img src="q1_manhattan.png" alt="q1_manhattan" /><figcaption aria-hidden="true">q1_manhattan</figcaption></figure><p>由于允许了数码的直接移动，因此这一代价必定小于实际代价，也即 <span class="math inline">\(h(n)\)</span> 为一个可接受启发。</p><h4 id="搜索过程">搜索过程</h4><p>接下来我们使用<span class="math inline">\(A^*\)</span>算法求解该问题。对于当前问题，每一种九宫格布局对应了一个状态，也即为状态搜索树上的一个结点。若以空白格为中心，则对于一个状态，空白格可以有上、下、左、右四种移动方式，对应了4种新的状态。由此，以初始状态为根结点，我们便可以生成出整棵状态搜索树，如下图所示。根据<span class="math inline">\(A^*\)</span>算法的运行逻辑和上面定义的启发函数，对于每一步搜索，我们只需要从待搜索状态中选择<strong>代价估计值最小</strong>的状态作为当前选择的结点，枚举其下一步移动后的各个状态并计算相应的代价估计值，并将它们放入待搜索状态集合即可。</p><figure><img src="q1_status_tree.png" alt="q1_status_tree" /><figcaption aria-hidden="true">q1_status_tree</figcaption></figure><h3 id="算法实现">算法实现</h3><p>根据上面的算法分析，我们来实现具体的算法逻辑。对于一个输入的初始状态，我们首先判断其可解性。通过上面的分析可知，我们只需求解出输入数码（除去空白格）的<strong>逆序数</strong>即可。求解排列逆序数的一个经典方法便是对排列数组进行归并排序，并在归并过程中记录逆序对。我们可以快速实现这一过程：</p><figure class="highlight c++"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">get_inverse_number</span><span class="hljs-params">(<span class="hljs-keyword">int</span> _seq[], <span class="hljs-keyword">int</span> _aux_seq[], <span class="hljs-keyword">int</span> left, <span class="hljs-keyword">int</span> right)</span></span>&#123;<br>    <span class="hljs-keyword">int</span> ans = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">if</span>(left &lt; right)&#123;<br>        <span class="hljs-keyword">int</span> mid = (left + right) &gt;&gt; <span class="hljs-number">1</span>;<br>        ans += get_inverse_number(_seq, _aux_seq, left, mid);<br>        ans += get_inverse_number(_seq, _aux_seq, mid + <span class="hljs-number">1</span>, right);<br>        <span class="hljs-keyword">int</span> i, j, k;<br>        j = mid + <span class="hljs-number">1</span>, k = left;<br>        <span class="hljs-keyword">for</span>(i = left; i &lt;= mid &amp;&amp; j &lt;= right; )&#123;<br>            <span class="hljs-keyword">if</span>(_seq[i] &gt; _seq[j])&#123;<br>                _aux_seq[k++] = _seq[j++];<br>                ans += mid-i+<span class="hljs-number">1</span>;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                _aux_seq[k++] = _seq[i++];<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">while</span>(i &lt;= mid) _aux_seq[k++] = _seq[i++];<br>        <span class="hljs-keyword">while</span>(j &lt;= right) _aux_seq[k++] = _seq[j++];<br>        <span class="hljs-keyword">for</span>(i = left; i &lt;= right; i++) _seq[i] = _aux_seq[i];<br>    &#125;<br>    <span class="hljs-keyword">return</span> ans;<br>&#125;<br></code></pre></td></tr></table></figure><p>随后我们来实现搜索逻辑。为了方便起见，我们首先定义一个结构作为状态搜索树上的结点以支持后续的搜索操作。在一个结点中，我们需要保存当前状态的九宫格数字布局、从初始状态到当前状态的实际代价以及启发代价。此外，为了提高算法效率，我们还可以标记该状态下空白格的坐标。具体实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">status</span>&#123;</span><br>    <span class="hljs-keyword">int</span> layout[<span class="hljs-number">3</span>][<span class="hljs-number">3</span>];<br>    <span class="hljs-keyword">int</span> g, h;<br>    <span class="hljs-keyword">int</span> blank_x, blank_y;<br><br>    status(<span class="hljs-keyword">int</span> _layout[][<span class="hljs-number">3</span>], <span class="hljs-keyword">int</span> _g, <span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; _target_map[])&#123;<br>        h = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">3</span>; i++)<br>            <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">3</span>; j++)&#123;<br>                <span class="hljs-keyword">int</span> content = _layout[i][j];<br>                <span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; pos = _target_map[content];<br>                h += <span class="hljs-built_in">abs</span>(i - pos.first) + <span class="hljs-built_in">abs</span>(j - pos.second);<br>                layout[i][j] = content;<br>                <span class="hljs-keyword">if</span>(content == <span class="hljs-number">0</span>)&#123;<br>                    blank_x = i;<br>                    blank_y = j;<br>                &#125;<br>            &#125;<br>        g = _g;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>根据上面的算法流程，我们需要分别维护一个用于保存待搜索结点的开集以及一个用于保存已搜索结点的闭集。由于开集需要支持<strong>"取最小代价结点"</strong>的操作，因此我们使用一个优先队列来作为维护开集元素的数据结构。对于闭集，由于其元素唯一，且我们只需要其支持<strong>“查询给定元素是否存在于集合中”</strong>这一操作，因此我们直接使用集合结构来进行维护。由于元素均为为自定义结构，因此我们还需要覆写比较运算符来确定结构序的计算方法。代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">compare_open</span>&#123;</span><br>    <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">operator</span><span class="hljs-params">()</span> <span class="hljs-params">(status a, status b)</span></span>&#123;<br>        <span class="hljs-keyword">return</span> (a.g + a.h) &gt; (b.g + b.h);<br>    &#125;<br>&#125;;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">compare_close</span>&#123;</span><br>    <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">operator</span><span class="hljs-params">()</span> <span class="hljs-params">(status a, status b)</span></span>&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">3</span>; i++)<br>            <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">3</span>; j++)&#123;<br>                <span class="hljs-keyword">if</span>(a.layout[i][j] &lt; b.layout[i][j]) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(a.layout[i][j] &gt; b.layout[i][j]) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>&#125;;<br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-built_in">priority_queue</span>&lt;status, <span class="hljs-built_in">vector</span>&lt;status&gt;, compare_open&gt; open_set;<br>    <span class="hljs-built_in">set</span>&lt;status, compare_close&gt; close_set;<br>    <span class="hljs-comment">//Irrelevant codes</span><br>&#125;<br></code></pre></td></tr></table></figure><p>之后我们只需要根据算法分析中的搜索过程实现整个搜索逻辑即可，算法终止条件为<strong>目标状态结点已存在于闭集</strong>中。实现代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-comment">/* Get the inverse number of the initial sequence */</span><br>    <span class="hljs-keyword">if</span>(inverse_cnt % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>) &#123;<br>        <span class="hljs-function">status <span class="hljs-title">init_status</span><span class="hljs-params">(init_status_layout, <span class="hljs-number">0</span>, target_status_map)</span></span>;<br>        <span class="hljs-function">status <span class="hljs-title">target_status</span><span class="hljs-params">(target_status_layout, <span class="hljs-number">0</span>, target_status_map)</span></span>;<br>        open_set.push(init_status);<br>        <span class="hljs-keyword">while</span> (close_set.find(target_status) == close_set.end()) &#123;<br>            status current_status = open_set.top();<br>            open_set.pop();<br>            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">4</span>; i++) &#123;<br>                <span class="hljs-keyword">int</span> delta_x = move_direction[i][<span class="hljs-number">0</span>];<br>                <span class="hljs-keyword">int</span> delta_y = move_direction[i][<span class="hljs-number">1</span>];<br>                <span class="hljs-keyword">int</span> candidate_x = current_status.blank_x + delta_x;<br>                <span class="hljs-keyword">int</span> candidate_y = current_status.blank_y + delta_y;<br>                <span class="hljs-keyword">if</span> (candidate_x &lt; <span class="hljs-number">0</span> || candidate_x &gt; <span class="hljs-number">2</span> || candidate_y &lt; <span class="hljs-number">0</span> || candidate_y &gt; <span class="hljs-number">2</span>) <span class="hljs-keyword">continue</span>;<br>                <span class="hljs-keyword">int</span> candidate_layout[<span class="hljs-number">3</span>][<span class="hljs-number">3</span>];<br>                <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">3</span>; j++)<br>                    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> k = <span class="hljs-number">0</span>; k &lt; <span class="hljs-number">3</span>; k++) &#123;<br>                        <span class="hljs-keyword">if</span> (j == candidate_x &amp;&amp; k == candidate_y) &#123;<br>                            candidate_layout[j][k] = <span class="hljs-number">0</span>;<br>                        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (j == current_status.blank_x &amp;&amp; k == current_status.blank_y) &#123;<br>                            candidate_layout[j][k] = current_status.layout[candidate_x][candidate_y];<br>                        &#125; <span class="hljs-keyword">else</span> &#123;<br>                            candidate_layout[j][k] = current_status.layout[j][k];<br>                        &#125;<br>                    &#125;<br>                <span class="hljs-function">status <span class="hljs-title">candidate_status</span><span class="hljs-params">(candidate_layout, current_status.g + <span class="hljs-number">1</span>, target_status_map)</span></span>;<br>                <span class="hljs-keyword">if</span> (close_set.find(candidate_status) == close_set.end()) &#123;<br>                    open_set.push(candidate_status);<br>                &#125;<br>            &#125;<br>            close_set.insert(current_status);<br>        &#125;<br>        <span class="hljs-built_in">set</span>&lt;status, compare_close&gt;::iterator goal_iter = close_set.find(target_status);<br>        status goal_status = *goal_iter;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, goal_status.g);<br>    &#125;<br>    <span class="hljs-comment">//Irrelevant codes</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="测试数据结果">测试数据结果</h3><h4 id="测试数据1">测试数据1</h4><p><strong>输入</strong></p><p>024657318</p><p><strong>输出</strong></p><p>22</p><h4 id="测试数据2">测试数据2</h4><p><strong>输入</strong></p><p>587346120</p><p><strong>输出</strong></p><p>26</p><h4 id="测试数据3">测试数据3</h4><p><strong>输入</strong></p><p>375148206</p><p><strong>输出</strong></p><p>21</p><h4 id="测试数据4">测试数据4</h4><p><strong>输入</strong></p><p>512768340</p><p><strong>输出</strong></p><p>26</p><h4 id="测试数据5">测试数据5</h4><p><strong>输入</strong></p><p>123804765</p><p><strong>输出</strong></p><p>0</p><h2 id="问题二小明爱跑步">问题二：小明爱跑步</h2><h3 id="问题描述-1">问题描述</h3><p>众所周知，小明身材很好。但自从他博士毕业当老师后，他就自我感觉身体变差了，于是他就想锻炼了。为了不使自己太累，他提出一种从山顶跑步到山脚的锻炼方法。</p><p>千寻万觅，终于在郊区找到这样一座山，这座山有 <span class="math inline">\(N\)</span> 个地标，有先行者在这些地标之间开辟了 <span class="math inline">\(M\)</span> 条道路。并且这些地标按照海拔从低到高进行了编号，例如山脚是 <span class="math inline">\(1\)</span>，山顶是 <span class="math inline">\(N\)</span>。</p><p>小明这个人对跑步的方式很挑：</p><ul><li>只跑最短路径。但一条最短路径跑久了会烦，需要帮他设计 <span class="math inline">\(K\)</span> 条最短路径。</li><li>不想太累，每次选道路的时候只从（海拔的）高处到低处。</li></ul><p>现在问题来了，给你一份这座山地标间道路的列表，每条道路用 <span class="math inline">\((X_i, Y_i, D_i)\)</span> 表示，表示地标 <span class="math inline">\(X_i\)</span> 和地标 <span class="math inline">\(Y_i\)</span> 之间有一条长度为 <span class="math inline">\(D_i\)</span> 的下坡道路。你来计算下小明这 <span class="math inline">\(K\)</span> 条路径的对应长度，看看小明的锻炼强度大不大？</p><p><strong>要求只能用<span class="math inline">\(A^*\)</span>算法。</strong></p><p><strong>输入格式</strong></p><p>第一行三个用空格分开的整数 <span class="math inline">\(N, M, K\)</span>。 第二行到第 <span class="math inline">\(M+1\)</span> 行，每行有三个空格分开的整数 <span class="math inline">\(X_i, Y_i, D_i\)</span>，描述了一条下坡的路。</p><p><strong>输出格式</strong></p><p>共 <span class="math inline">\(K\)</span> 行。</p><p>在第 <span class="math inline">\(i\)</span> 行输出第 <span class="math inline">\(i\)</span> 短的路线长度，如果不存在就输出 <span class="math inline">\(-1\)</span>。</p><p>如果出现多条相同长度的路线，务必全部依次输出。</p><p><strong>输入样例</strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">5 </span><span class="hljs-number">8</span> <span class="hljs-number">7</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">4</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">3</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">4 </span><span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">2 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>输出样例</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">6</span><br><span class="hljs-number">7</span><br><span class="hljs-number">-1</span><br></code></pre></td></tr></table></figure><p><strong>结果解释</strong></p><p>这些路线分别为(5-1)、(5-3-1)、(5-2-1)、(5-3-2-1)、(5-4-3-1)和(5-4-3-2-1)。只有6条路线，所以最后一行（第7行）为-1。</p><h3 id="问题求解-1">问题求解</h3><h4 id="启发函数-1">启发函数</h4><p>和上一题类似，我们首先定义各个状态所对应的启发代价。由于整张图的结点关系、边权和目标结点是确定的，因此我们可以求出各个结点到目标结点的实际最小代价并以此作为各个结点的启发代价，也即对于状态 <span class="math inline">\(i\)</span>，其启发代价为 <span class="math display">\[h(i) = dist(v_i, v_t)\]</span> 其中 <span class="math inline">\(v_i\)</span> 为状态 <span class="math inline">\(i\)</span> 对应的结点，<span class="math inline">\(v_t\)</span> 为目标状态对应的结点。</p><p>以样例图为例，其各个结点的启发代价如下图所示：</p><figure><img src="q2_dijkstra.png" alt="q2_dijkstra" /><figcaption aria-hidden="true">q2_dijkstra</figcaption></figure><p>由于该代价为当前结点到目标结点的实际最小代价，因此必然为一个可接受启发。</p><h4 id="搜索过程-1">搜索过程</h4><p>通过题目描述可以发现，该问题是一个经典的<strong>K短路（K-Shortest Path）</strong>问题。对于一个一般的K短路问题，我们有如下定理成立：</p><blockquote><p><strong>Theorem 3：</strong>一张有向图的K短路问题是NP-Hard的。</p><p><strong>Proof：</strong>这里仅证明K条路径均为简单路径时的情况。由于一般路径包含简单路径，因此其求解难度必不小于简单路径时的情况。</p><p>对于一张包含 <span class="math inline">\(n\)</span> 个节点的有向图，其最多包含 <span class="math inline">\(n!\)</span> 条简单路径。</p><p>若存在一个算法 <span class="math inline">\(A\)</span> 可以在多项式时间内求解K短路问题，则对于一个初始结点和目标结点，我们可以使用二分搜索法通过调用 <span class="math inline">\(\mathcal{O}(n \log n)\)</span> 次 <span class="math inline">\(A\)</span> 来找到一条长度为 <span class="math inline">\(n\)</span> 的路径。由于整张图共有 <span class="math inline">\(n\)</span> 个结点，因此我们只需要通过调用 <span class="math inline">\(\mathcal{O}(n^3 \log n)\)</span> 次 <span class="math inline">\(A\)</span> 即可找到所有结点对的长度为 <span class="math inline">\(n\)</span> 的路径，也即在多项式时间内求解了<strong>哈密顿路径问题（Hamiltonian Path Problem）</strong>。</p><p>由于哈密顿路径问题是NP-Hard的，因此若该算法存在，则 <span class="math inline">\(P=NP\)</span>。也即K短路问题是NP-Hard的。</p></blockquote><p>根据上面的定理我们可以发现，我们很难找到一个高效的算法来求解K短路问题。因此，若使用<span class="math inline">\(A^*\)</span>算法求解该问题，我们仍然需要枚举结点的指数级跳路径才能找到前K短路径。</p><p>在<span class="math inline">\(A^*\)</span>算法中，由于开集中的元素按照代价估计值从小到大排序，因此我们可以通过<strong>选中目标状态的次数</strong>来依次找到第 <span class="math inline">\(2,3,\cdots,K\)</span> 短的路径。由于前K短的路径可能包含重叠部分，因此我们不再记录已经搜索过的状态。在一般的图中，这样做可能导致算法重复探索一条路径且无法终止。不过由于本题为一张有向无环图，且其边的数量有限，因此我们可以<strong>枚举所有可能的状态</strong>，也即算法最终能够终止。</p><h3 id="算法实现-1">算法实现</h3><p>由于本题的搜索空间为一张有向图，因此我们使用邻接表的方式来对输入的图进行存储。由于要计算终点到其他各个结点的距离，因此我们在对图进行存储时还需同时存储一张<strong>反向图</strong>。输入和结构化过程实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-keyword">int</span> n, m, k;<br>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt;&gt;&gt; graph, reverse_graph;<br>    <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d %d %d&quot;</span>, &amp;n, &amp;m, &amp;k);<br>    graph.resize(n);<br>    reverse_graph.resize(n);<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;<br>        <span class="hljs-keyword">int</span> from, to, weight;<br>        <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d %d %d&quot;</span>, &amp;from, &amp;to, &amp;weight);<br>        from -= <span class="hljs-number">1</span>;<br>        to -= <span class="hljs-number">1</span>;<br>        <span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; edge&#123;to, weight&#125;;<br>        <span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; reverse_edge&#123;from, weight&#125;;<br>        graph[from].push_back(edge);<br>        reverse_graph[to].push_back(reverse_edge);<br>    &#125;<br>    <span class="hljs-comment">//Irrelevant codes</span><br>&#125;<br></code></pre></td></tr></table></figure><p>根据上面的算法分析，我们使用终点到其他各个结点的实际最短路作为该结点的启发代价。对于单源最短路问题，一个经典的算法便是<strong>Dijkstra算法</strong>。由于本题无环状路径，因此可以保证这一算法结果的正确性。具体实现如下： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">get_heuristic</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt;&gt;&gt;&amp; _graph, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; _cost, <span class="hljs-keyword">int</span> _n)</span></span>&#123;<br>    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">vis</span><span class="hljs-params">(_n, <span class="hljs-number">0</span>)</span></span>;<br>    <span class="hljs-keyword">int</span> vis_cnt;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; _n; i++)&#123;<br>        _cost[i] = <span class="hljs-number">10000007</span>;<br>    &#125;<br>    _cost[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br>    vis_cnt = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span> (vis_cnt &lt; _n) &#123;<br>        <span class="hljs-keyword">int</span> candidate_index = <span class="hljs-number">0</span>, candidate_cost = <span class="hljs-number">10000007</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; _n; i++) &#123;<br>            <span class="hljs-keyword">if</span> (_cost[i] &lt; candidate_cost &amp;&amp; vis[i] == <span class="hljs-number">0</span>) &#123;<br>                candidate_index = i;<br>                candidate_cost = _cost[i];<br>            &#125;<br>        &#125;<br>        vis[candidate_index] = <span class="hljs-number">1</span>;<br>        vis_cnt += <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; _graph[candidate_index].size(); i++) &#123;<br>            <span class="hljs-keyword">int</span> edge_to, edge_cost;<br>            edge_to = _graph[candidate_index][i].first;<br>            edge_cost = _graph[candidate_index][i].second;<br>            <span class="hljs-keyword">if</span> (_cost[candidate_index] + edge_cost &lt; _cost[edge_to]) &#123;<br>                _cost[edge_to] = _cost[candidate_index] + edge_cost;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>随后我们来实现搜索过程中的开集。与上题类似，我们同样使用优先队列在存储开集中的各个状态。为了方便起见，我们同样为状态搜索树中的结点定义一个新的结构，其中存储了该状态对应的图结点号、从初始状态到当前状态的实际代价以及启发代价。随后由于队列中为自定义结构，我们需要覆写序关系的判定函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">node</span>&#123;</span><br>    <span class="hljs-keyword">int</span> index;<br>    <span class="hljs-keyword">int</span> g;<br>    <span class="hljs-keyword">int</span> h;<br>&#125;;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">compare_open</span>&#123;</span><br>    <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">operator</span><span class="hljs-params">()</span> <span class="hljs-params">(node a, node b)</span></span>&#123;<br>        <span class="hljs-keyword">return</span> (a.g + a.h) &gt; (b.g + b.h);<br>    &#125;<br>&#125;;<br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-comment">//Irrelevant codes</span><br>    <span class="hljs-built_in">priority_queue</span>&lt;node, <span class="hljs-built_in">vector</span>&lt;node&gt;, compare_open&gt; open_set;<br>&#125;<br></code></pre></td></tr></table></figure><p>之后我们使用<span class="math inline">\(A^*\)</span>算法的一般搜索流程实现求解过程即可。当每次目标结点作为最小估计代价结点被弹出开集时，也就意味着找到了一条新的路径，而<span class="math inline">\(A^*\)</span>的路径选择过程保证了这些路径必定是从小到大依次返回的。算法的终止条件为已经找到K条路径或图中所有满足条件的路径均已被探索完毕（也即开集为空）。具体实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-comment">//Irrelevant codes</span><br>    <span class="hljs-keyword">while</span>(path_cnt &lt; k &amp;&amp; !open_set.empty())&#123;<br>        node current_node = open_set.top();<br>        open_set.pop();<br>        <span class="hljs-keyword">int</span> current_index = current_node.index;<br>        <span class="hljs-keyword">int</span> current_cost = current_node.g;<br>        <span class="hljs-keyword">if</span>(current_index == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, current_cost);<br>            path_cnt += <span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; graph[current_index].size(); i++)&#123;<br>            <span class="hljs-keyword">int</span> candidate_index = graph[current_index][i].first;<br>            <span class="hljs-keyword">int</span> candidate_cost = current_cost + graph[current_index][i].second;<br>            <span class="hljs-keyword">int</span> candidate_heuristic = heuristic_cost[candidate_index];<br>            node candidate_node&#123;candidate_index, candidate_cost, candidate_heuristic&#125;;<br>            open_set.push(candidate_node);<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">//Irrelevant codes</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="测试数据结果-1">测试数据结果</h3><h4 id="测试数据1-1">测试数据1</h4><p><strong>输入</strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">5 </span><span class="hljs-number">8</span> <span class="hljs-number">3</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">4</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">3</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">4 </span><span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">2 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>输出</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h4 id="测试数据2-1">测试数据2</h4><p><strong>输入</strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">6 </span><span class="hljs-number">10</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">3</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">5</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">4</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">3</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">4 </span><span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">2 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>输出</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">3</span><br><span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><h4 id="测试数据3-1">测试数据3</h4><p><strong>输入</strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">6 </span><span class="hljs-number">10</span> <span class="hljs-number">12</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">3</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">5</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">4</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">3</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">4 </span><span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">2 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>输出</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">3</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br><span class="hljs-number">4</span><br><span class="hljs-number">7</span><br><span class="hljs-number">8</span><br><span class="hljs-number">-1</span><br><span class="hljs-number">-1</span><br><span class="hljs-number">-1</span><br><span class="hljs-number">-1</span><br></code></pre></td></tr></table></figure><h4 id="测试数据4-1">测试数据4</h4><p><strong>输入</strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">8 </span><span class="hljs-number">16</span> <span class="hljs-number">8</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">7</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">5</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">4</span> <span class="hljs-number">3</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">7 </span><span class="hljs-number">6</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">7 </span><span class="hljs-number">4</span> <span class="hljs-number">3</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">3</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">5</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">4</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">3</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">4 </span><span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">2 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>输出</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br><span class="hljs-number">4</span><br><span class="hljs-number">5</span><br><span class="hljs-number">6</span><br><span class="hljs-number">7</span><br><span class="hljs-number">7</span><br></code></pre></td></tr></table></figure><h4 id="测试数据5-1">测试数据5</h4><p><strong>输入</strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">8 </span><span class="hljs-number">16</span> <span class="hljs-number">16</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">7</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">5</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">4</span> <span class="hljs-number">3</span><br><span class="hljs-symbol">8 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">7 </span><span class="hljs-number">6</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">7 </span><span class="hljs-number">4</span> <span class="hljs-number">3</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">3</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">6 </span><span class="hljs-number">5</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">4</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">3</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">5 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">4 </span><span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">3 </span><span class="hljs-number">2</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">2 </span><span class="hljs-number">1</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>输出</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br><span class="hljs-number">4</span><br><span class="hljs-number">5</span><br><span class="hljs-number">6</span><br><span class="hljs-number">7</span><br><span class="hljs-number">7</span><br><span class="hljs-number">7</span><br><span class="hljs-number">8</span><br><span class="hljs-number">8</span><br><span class="hljs-number">8</span><br><span class="hljs-number">8</span><br><span class="hljs-number">9</span><br><span class="hljs-number">9</span><br><span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>在本实验中，我们探索了<span class="math inline">\(A^*\)</span>算法的一般性质，并使用<span class="math inline">\(A^*\)</span>算法及其变种解决了小明玩球（八数码问题）和小明爱跑步（K短路问题）两个问题。通过本实验，我们对启发式搜索算法及其相关应用有了更为深入的了解。</p><h2 id="references">References</h2><ol type="1"><li>Alexei.I.Kostrikin(张英伯译). 代数学引论(第一卷). 高等教育出版社, 2011.</li><li>amit. How can i use the a star algorithm to find the first 100 shortest paths? https://stackoverflow.com/questions/14088898/ how-can-i-use-the-a-star-algorithm-to-find-the-first-100-shortest-paths, 2012.</li><li>Mike Chiang. A* optimality proof, cycle checking. https://www.cs.ubc.ca/~hutter/ teaching/cpsc322/2-Search5.pdf, 2011.</li><li>Peter E. Hart, Nils J. Nilsson, and Bertram Raphael. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, 4(2):100–107, 1968.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(A^*\)&lt;/span&gt; 算法是一种经典的启发式搜索算法，其在路径规划、语意搜索和在线学习等任务中都有着极为广泛的应用。相比传统的遍历搜索，&lt;span class=&quot;math i</summary>
      
    
    
    
    <category term="当代人工智能" scheme="http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Artificial-Intelligence" scheme="http://gonggongjohn.me/tags/Artificial-Intelligence/"/>
    
  </entry>
  
  <entry>
    <title>当代人工智能 课程项目一 文本分类</title>
    <link href="http://gonggongjohn.me/2022/03/16/contemporary-ai/contemporary-ai-exp-1/"/>
    <id>http://gonggongjohn.me/2022/03/16/contemporary-ai/contemporary-ai-exp-1/</id>
    <published>2022-03-16T02:00:00.000Z</published>
    <updated>2022-12-05T11:56:31.321Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>文本分类是自然语言处理领域中一项十分基本的任务，其在多个领域都有着广泛的应用。在本文中，我们实现了基于 XLNet 预训练语言模型的文本分类模型，并使用微调(Fine-Tuning)的方法对给定数据集进行了文 本分类。通过对验证集的分类效果评估比较，我们得到了适用于当前数据集上最佳的模型超参数组合。随后，我们将模型与其他几种经典文本分类模型(支持向量机、MLP、TextCNN、Bert)的分类效果进行了比较，进一步验证了预训练语言模型和网络构架对文本分类效果的巨大影响。</p><p><strong>关键字：文本分类，支持向量机，多层感知机，TextCNN，Bert，XLNet</strong></p><h2 id="项目介绍">项目介绍</h2><h3 id="任务介绍">任务介绍</h3><p>在本项目中，我们需要实现一种机器学习模型，实现对文本的多分类任务。具体来说，给定一组文本集 <span class="math inline">\(\mathcal{D} = \{\boldsymbol{x}_1, \boldsymbol{x}_2, \cdots, \boldsymbol{x}_n \}\)</span> 和类别集 <span class="math inline">\(\mathcal{C} = \{c_1, c_2, \cdots, c_k \}\)</span>，我们需要让机器学习出一种映射 <span class="math inline">\(f: \mathcal{D} \to \mathcal{C}\)</span>，使得对于任意 <span class="math inline">\(\boldsymbol{x} \in \mathcal{C}\)</span>，存在一个 <span class="math inline">\(c \in \mathcal{C}\)</span>，使得 <span class="math inline">\(f(\boldsymbol{x}) = c\)</span>。</p><h3 id="数据集介绍">数据集介绍</h3><p>本实验的数据集共分为训练集和测试集两个部分。其中训练集包含了8000条各类别的带标签文本，测试集包含了2000条待预测的不含标签文本。训练集中各类别文本的词云如下图所示。通过词云我们可以大致推断出每个类别的主题，例如Class 0的主题可能为<strong>电视剧/电影</strong>，Class 1的主题可能为<strong>手机应用</strong>，Class 2的主题可能为<strong>汽车相关产品</strong>。这为我们后续的分类结果提供了一个人工的验证标准。</p><figure><img src="dataset_wordcloud.png" alt="dataset_wordcloud" /><figcaption aria-hidden="true">dataset_wordcloud</figcaption></figure><h2 id="基准模型">基准模型</h2><p>为了评估目标模型的文本分类效果，我们首先需要一组<strong>基准模型（Baseline Model）</strong>。在本实验中，我们使用了支持向量机、多层感知机、TextCNN以及Bert四种模型作为基准模型。</p><h3 id="支持向量机">支持向量机</h3><p><strong>支持向量机（Support Vector Machine）</strong>是一个经典的机器学习分类器，其通过计算最优分隔超平面来对向量空间中线性可分的点进行分类。通过使用<strong>核技巧（Kernel Trick）</strong>，其还可以进一步分隔线性不可分的数据集并取得不错的效果。</p><p>由于支持向量机仅作用于向量空间，要使得其能够对文本进行分类，我们就需要先对文本进行<strong>嵌入（Embedding）</strong>操作，使其能够在向量空间中表示。一个最朴素的方法便是使用<strong>计数方法</strong>，将词典中每个词在每句话中出现的次数作为句子的表示向量。然而，这样做并不能利用词和词之间的分布特征信息，因此分类效果并不好。一个更为合适的方法是使用所谓的<strong>TF-IDF嵌入法</strong>。</p><p>对于一个文本数据集，词项 <span class="math inline">\(t\)</span> 在文档 <span class="math inline">\(d\)</span> 中的TF-IDF值被定义为 <span class="math display">\[TF-IDF(t, d) = TF(t, d) \times IDF(t)\]</span> 其中 <span class="math inline">\(TF(t, d)\)</span> 为词项 <span class="math inline">\(t\)</span> 在文档 <span class="math inline">\(d\)</span> 中的<strong>词频（Term Frequency）</strong>，<span class="math inline">\(IDF(t)\)</span> 为词项 <span class="math inline">\(t\)</span> 在整个数据集中的<strong>逆文档频率（Inverse Document Frequency）</strong>。由于测试集中可能出现训练集中不存在的词项，我们对 <span class="math inline">\(IDF\)</span> 引入<strong>拉普拉斯平滑（Laplace Smoothing）</strong>来给这些不存在的词项一个默认的TF-IDF值，此时的 <span class="math inline">\(IDF\)</span> 计算公式可以写为 <span class="math display">\[IDF(t) = \log \frac{1 + n}{1 + DF(t)} + 1\]</span> 其中 <span class="math inline">\(n\)</span> 为文档个数，<span class="math inline">\(DF(t)\)</span> 为词项 <span class="math inline">\(t\)</span> 在数据集中出现的文档数。我们只要对句子中所有的词计算其在数据集中的TF-IDF值，即可得到该句子的TF-IDF向量表示。</p><p>在本实验中，我们使用了机器学习包<strong>Scikit-Learn</strong>提供的<strong>SVC（SVM Classifier）</strong>类实现了文本分类模型。对于核技巧，我们使用了<strong>高斯核（Gaussian Kernel）</strong>作为核函数，也即 <span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) =  = \exp \left( - \gamma || \boldsymbol{x} - \boldsymbol{y} ||^2 \right)\]</span> 该核函数被广泛地用于向量空间的特征分离任务中并通过能取得不错的效果。通常情况下，我们需要使用<strong>网格搜索（Grid Search）</strong>的方法来确定核函数中的超参数 <span class="math inline">\(\gamma\)</span>，然而当我们无法确定合理的参数范围时，搜索空间可能会变得十分庞大。由于从直观上看，高斯核中的参数 <span class="math inline">\(\gamma\)</span> 表征了数据集在向量空间中的分散程度，因此一个更为合理的方法便是使用数据集本身的方差来决定该超参数，也即 <span class="math display">\[\gamma = \frac{1}{n_{feature} \cdot Var(\boldsymbol{X})}\]</span> 其中 <span class="math inline">\(n_{feature}\)</span> 为数据集的特征维度，<span class="math inline">\(Var(\boldsymbol{X})\)</span> 为数据集的方差。这也是我们的实现中所使用的超参数决定方法。</p><h3 id="多层感知机">多层感知机</h3><p><strong>多层感知机（Multilayer Perceptron）</strong>又称为<strong>前向全连接神经网络（Feedforward Fully-Connected Neural Network）</strong>，是一种经典的深度学习网络构架。通过多个隐藏层对输入数据中不同粒度特征的提取，其就可以实现对数据的分类。感知机由一个个神经元构成，其单个神经元结构如下图所示。</p><figure><img src="fcnn_neuron.png" alt="fcnn_neuron" /><figcaption aria-hidden="true">fcnn_neuron</figcaption></figure><p>将多个神经元一层层地连接起来，便构成了多层感知机。对于当前数据集和任务，我们设计的神经网络结构如下图所示。对于输入层，我们同样使用上述SVM模型中提到的TF-IDF嵌入法得到句子的向量表示。经过统计，训练集中不同的词项个数共有 <span class="math inline">\(29999\)</span>个，因此我们将输入层的神经元个数设置为 <span class="math inline">\(29999\)</span>。随后，我们使用两层隐藏层结构来增加网络的非线性拟合能力，其神经元个数分别为 <span class="math inline">\(64\)</span> 和 <span class="math inline">\(32\)</span> 。最后，由于我们有 <span class="math inline">\(10\)</span> 个文本类别，因此输出神经元个数设置为 <span class="math inline">\(10\)</span>。</p><figure><img src="fcnn_structure.png" alt="fcnn_structure" /><figcaption aria-hidden="true">fcnn_structure</figcaption></figure><p>我们选择了<strong>ReLU（Rectified Linear Unit）</strong>作为当前网络的隐藏层激活函数。对于最后的分类结果，我们使用<strong>Softmax</strong>函数将其放缩为 <span class="math inline">\((0,1)\)</span> 之间的概率值，其定义如下： <span class="math display">\[\textrm{Softmax}(\boldsymbol{x}_i, \{\boldsymbol{x}_1, \cdots, \boldsymbol{x}_n \}) = \frac{e^{\boldsymbol{x}_i}}{\sum_{j = 1}^n e^{\boldsymbol{x}_j}}\]</span> 相应的，我们选择了<strong>交叉熵损失（CrossEntropyLoss）</strong>作为当前任务的损失函数，其定义为 <span class="math display">\[\mathcal{H}(\boldsymbol{y}^{pred}, \boldsymbol{y}^{true}) = - \sum_{i = 1}^n y^{true}_i \log y^{pred}_i\]</span> 。</p><p>神经网络通常使用<strong>反向传播（Backward Propagation）</strong>算法来对网络进行训练，其具体细节在此不再赘述。我们选择了<strong>AdamW</strong>优化器作为当前网络的优化器。AdamW作为Adam优化器的改进版本，相比<strong>随机梯度下降（Stochastic Gradient Descent）</strong>算法能够自适应地调整梯度下降的速率，并能够从一定程度上对抗网络落入<strong>局部最低点（Local Minima）</strong>的情况发生。而相比Adam，AdamW通过一种改进的实现方法解决了其正则化难以收敛的问题，使得网络参数能够更快地收敛到预期的位置。在超参数的设置上，我们通过网格搜索的方式对<strong>学习率（Learning Rate）</strong>进行了搜索，并最终确定学习率 <span class="math inline">\(lr = 0.01\)</span>。对于迭代次数，我们发现当网络迭代10次后 网络的损失不再出现明显的下降，因此我们设置迭代次数 <span class="math inline">\(epoch=10\)</span>。</p><h3 id="textcnn">TextCNN</h3><p>受到Word2Vec等词嵌入方法和图像处理任务中卷积方法的启发，Yoon Kim等人于2014年提出了用于文本分类的<strong>TextCNN</strong>方法。TextCNN方法本质上是一个<strong>N-Gram</strong>语言模型，这一方法将句子的词向量嵌入矩阵视为一个一维的<strong>特征图</strong>，通过使用多个不同大小的<strong>一维卷积核</strong>在词向量矩阵上做滑动，就可以获得句子中不同粒度上的语言特征。</p><figure><img src="textcnn_illustrate.png" alt="textcnn_illustrate" /><figcaption aria-hidden="true">textcnn_illustrate</figcaption></figure><p>通常来说，TextCNN由<strong>嵌入层（Embedding Layer）</strong>、<strong>卷积层（Convolutional Layer）</strong>、<strong>池化层（Max-Pooling Layer）</strong>和<strong>全连接层（Fully-Connected Layer）</strong>组成，其中所有的权重参数都会从数据集中学习得到。然而，由于当前任务中数据集规模并不大，网络可能会出现难以收敛或过拟合的问题。受到图像处理任务中<strong>迁移学习（Transfer Learning）</strong>方法的启发，我们使用一个经过预训练的词嵌入词典来直接作为嵌入层的输出，这样网络在初始化时，每个词的语义关系就能够被明确，网络也能够快速找出合适的分类特征。在当前项目中，我们使用了经过无监督预训练的<strong>GloVe</strong>通用词向量词典来对文本进行词嵌入。该词典使用<strong>Common Crawl</strong>数据集进行无监督训练，共包含了190万个词项，嵌入维度为300维，具有足够的通用性和较为合适的特征大小。</p><p>对于网络构架，我们参考了Ye Zhang等人的结果，使用了大小分别为<strong>2、3、4</strong>的卷积核，每种卷积核各有<strong>16</strong>个。随后，我们使用和多层感知机相同的<strong>ReLU</strong>作为激活函数，并通过池化核大小为 <span class="math inline">\(l_{sentence} - l_{kernel} + 1\)</span> 的池化层将其每个特征特征压缩至1个神经元内（其中 <span class="math inline">\(l_{sentence}\)</span> 为句子长度，<span class="math inline">\(l_{kernel}\)</span> 为卷积核大小）。最后，通过将这些特征神经元进行拼接并通过一层全连接层，网络即可输出文本的分类概率结果。</p><p>为了保证基准模型的公平性，我们将损失函数及优化器设置与上文中的多层感知机保持一致。对于迭代次数，我们发现当网络迭代20次后损失不再出现明显的下降，因此我们设置迭代次数 <span class="math inline">\(epoch=20\)</span>。</p><h3 id="bert">Bert</h3><p>随着<strong>语言模型（Language Model）</strong>和<strong>Transformer</strong>架构的提出，<strong>预训练（Pretrain）</strong>+<strong>微调（Finetune）</strong>方法逐渐成为了自然语言处理任务中的主流。其中最为经典的就是Google于2018年提出的<strong>Bert（Bidirectional Encoder Representation from Transformers）</strong>模型。</p><p>Bert模型是一个<strong>自编码语言模型（Autoencoder Language Model）</strong>，其网络构架如下图所示。Bert的主体由多个Transformer结构组成，网络首先接受一串由<strong>词项</strong>和<strong>特殊标识符（CLS、SEP）</strong>经过嵌入得到的句子向量，并使用Transformer构架计算句子的语言特征，得到一串同等长度的语言特征向量。通过将网络的输出与下游的网络结构相连接，我们就可以使用Bert模型进行各种自然语言处理任务。对于当前文本分类任务，我们只需要使用网络输出中的第一项（即CLS标识符的特征表示），并将其连接至一个全连接层即可得到文本的概率分类结果。</p><figure><img src="bert_classify.png" alt="bert_classify" /><figcaption aria-hidden="true">bert_classify</figcaption></figure><p>我们使用了Google提供的<strong>bert-base-uncased</strong>预训练模型作为网络构架及初始化参数，这一构架包含<strong>12</strong>个Transformer模块，每个Transformer模块中包含<strong>12</strong>个自注意力头以及一个维度为<strong>768</strong>的全连接层（共110万网络参数），并同样使用了AdamW作为网络的优化器。由于微调训练通常具有较小的网络梯度，我们将学习率设置为了 <span class="math inline">\(lr=5e-5\)</span>。</p><h2 id="xlnet文本分类器">XLNet文本分类器</h2><p>XLNet是Google于2019年提出的一种对Bert的改进模型。通过融合GPT中使用的<strong>自回归语言模型（Autoregressive Language Model）</strong>和Bert中使用的自编码语言模型并引入更多的构架改进，XLNet在许多下游任务中都获得了十分出色的表现，也是我们在当前实验中最终使用的文本分类模型。</p><h3 id="模型构架">模型构架</h3><p>XLNet的整体模型构架与Bert模型类似，其都由多组Transformer模块组成。然而，XLNet在进行预训练时的逻辑和Bert有很大的不同，其使用的自回归语言模型相比Bert可以解决其预训练/微调时的数据分布不一致的问题。而通过引入<strong>轮换语言模型（Permutation Language Modeling）</strong>，XLNet就能够在自回归语言模型中保留Bert中的双向语义视野的能力。为了在网络结构中实现这一点，XLNet在实现自注意力层时也使用了不同的方法，其基本构架如下图所示。可以看到，在实际实现过程中，XLNet并没有真正的对文本进行轮换，而是使用了<strong>掩盖（Masking）</strong>的方法来使得网络在预训练时无法得到目标词项的词义信息。</p><figure><img src="xlnet_architecture.png" alt="xlnet_architecture" /><figcaption aria-hidden="true">xlnet_architecture</figcaption></figure><h3 id="模型实现">模型实现</h3><p>由于该模型的实现细节较多且不是本文的重点，我们直接使用了<strong>HuggingFace</strong>提供的<strong>transformers</strong>工具包中所实现的XLNet模型。对于网络构架和参数，我们使用了HuggingFace提供的<strong>xlnet-large-cased</strong>进行初始化。相比<strong>xlnet-base-cased</strong>以及Bert的同级别模型，XLNet Large网络使用了更多的数据进行预训练，使得网络的语言特征捕捉能力得到了进一步的提升，其更大的网络结构（340万网络参数）也保证了网络足够的泛化能力，使得其不会出现过拟合的情况。</p><p>与使用Pytorch训练其他模型时一致，我们需要定义一个<strong>数据集对象（Dataset）</strong>来作为训练及测试时的数据源。在数据集初始化中，我们首先使用封装好的<strong>XLNetTokenizer</strong>对象对文本进行词条化及文本嵌入。通过对数据集的检查，我们发现当前数据集中文本的最大长度约为<strong>257</strong>个词项，因此我们将文本<strong>截断/补全长度</strong>设置为了<strong>256</strong>，这也作为了网络的输入尺寸。随后，通过覆写相应的数据集方法，我们就能得到一个可用的文本数据集对象。具体代码片段如下：<strong>（utils.py）</strong></p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, XLNetTokenizer<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TextDatasetForTrainer</span>(<span class="hljs-params">Dataset</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, source_df, model_type</span>):</span><br>        self.model_type = model_type<br>        <span class="hljs-keyword">if</span> model_type == <span class="hljs-string">&#x27;bert&#x27;</span>:<br>            self.tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&#x27;bert-base-uncased&#x27;</span>)<br>        <span class="hljs-keyword">elif</span> model_type == <span class="hljs-string">&#x27;xlnet&#x27;</span>:<br>            self.tokenizer = XLNetTokenizer.from_pretrained(<span class="hljs-string">&#x27;xlnet-large-cased&#x27;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;label&#x27;</span> <span class="hljs-keyword">in</span> source_df:<br>            self.mode = <span class="hljs-string">&#x27;paired&#x27;</span><br>            self.labels = [label <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> source_df[<span class="hljs-string">&#x27;label&#x27;</span>]]<br>        <span class="hljs-keyword">else</span>:<br>            self.mode = <span class="hljs-string">&#x27;unpaired&#x27;</span><br>        self.texts = [self.tokenizer(text, padding=<span class="hljs-string">&#x27;max_length&#x27;</span>, max_length=<span class="hljs-number">256</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>)<br>                      <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> source_df[<span class="hljs-string">&#x27;text&#x27;</span>]]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> len(self.texts)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span><br>        item_dict = self.texts[index]<br>        <span class="hljs-keyword">if</span> self.model_type == <span class="hljs-string">&#x27;xlnet&#x27;</span> <span class="hljs-keyword">or</span> self.model_type == <span class="hljs-string">&#x27;bert&#x27;</span>:<br>            item_dict[<span class="hljs-string">&#x27;attention_mask&#x27;</span>] = item_dict[<span class="hljs-string">&#x27;attention_mask&#x27;</span>].squeeze(<span class="hljs-number">0</span>)<br>            item_dict[<span class="hljs-string">&#x27;input_ids&#x27;</span>] = item_dict[<span class="hljs-string">&#x27;input_ids&#x27;</span>].squeeze(<span class="hljs-number">0</span>)<br>            item_dict[<span class="hljs-string">&#x27;token_type_ids&#x27;</span>] = item_dict[<span class="hljs-string">&#x27;token_type_ids&#x27;</span>].squeeze(<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">if</span> self.mode == <span class="hljs-string">&#x27;paired&#x27;</span>:<br>            item_dict[<span class="hljs-string">&#x27;labels&#x27;</span>] = torch.tensor(self.labels[index])<br>        <span class="hljs-keyword">return</span> item_dict<br></code></pre></td></tr></table></figure><p>transformers包中提供了一组统一的模型训练调度器，我们可以直接通过创建训练器对象并传入相关参数来对模型进行训练。在<strong>TrainingArguments</strong>对象中，我们可以定义网络训练时的各种属性及网络、优化器的各种超参数。我们只需要将配置好的TrainingArguments对象传递给<strong>Trainer</strong>对象，即可开始对网络进行训练、评估和预测操作。相关代码片段如下：<strong>（xlnet_train.py）</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer, TrainingArguments<br><br>train_args = TrainingArguments(<br>    output_dir=<span class="hljs-string">&#x27;output&#x27;</span>,<br>    evaluation_strategy=<span class="hljs-string">&#x27;epoch&#x27;</span>,<br>    save_strategy=<span class="hljs-string">&#x27;no&#x27;</span>,<br>    eval_steps=<span class="hljs-number">50</span>,<br>    per_device_train_batch_size=batch_size,<br>    per_device_eval_batch_size=batch_size,<br>    gradient_accumulation_steps=<span class="hljs-number">1</span>,<br>    num_train_epochs=epoch,<br>    seed=<span class="hljs-number">0</span>,<br>    logging_strategy=<span class="hljs-string">&#x27;step&#x27;</span>,<br>    logging_steps=<span class="hljs-number">64</span>,<br>    <span class="hljs-comment"># Other parameters to set</span><br>)<br>trainer = Trainer(<br>    model=model,<br>    args=train_args,<br>    train_dataset=train_dataset,<br>    eval_dataset=val_dataset,<br>    compute_metrics=compute_metrics<br>)<br>trainer.train()<br></code></pre></td></tr></table></figure><h3 id="超参调优">超参调优</h3><h4 id="batch-size">Batch Size</h4><p>首先我们来确定训练时的Batch Size。在使用随机梯度下降类算法对网络进行优化时，Batch Size往往决定了网络的<strong>收敛速度</strong>及<strong>泛化能力</strong>，过小的Batch Size可能导致网络难以收敛（Loss波动剧烈），而过大的Batch Size可能导致网络落入<strong>Sharp Minima</strong>，使其泛化能力降低（Loss无法降低）。在当前数据集上，不同Batch Size在训练时的Loss变化及在验证集上的正确率表现如下图所示。我们发现，当 <span class="math inline">\(Batch Size &gt; 16\)</span> 时，Training Loss就可以表现的较为稳定；而在相同的迭代次数下，<span class="math inline">\(Batch Size = 64\)</span> 时网络获得了最好的Training Loss表现。</p><figure><img src="batchsize_loss_acc.png" alt="batchsize_loss_acc" /><figcaption aria-hidden="true">batchsize_loss_acc</figcaption></figure><p>可以发现，由于XLNet模型本身的语言特征捕捉能力及预训练的存在，Batch Size本身对网络的表现影响并不明显。然而在实际应用场景下中，我们还需要考虑训练模型时的资源消耗情况。在使用了<strong>梯度累计（Gradient Accumulation）</strong>技巧时，显存占用随Batch Size的增长情况如下图所示。随着Batch Size的增长，训练XLNet时的显存占用急剧增长，在Batch Size=128时显存占用甚至达到了近50GB，这一资源消耗代价在平日的应用场景下显然是难以接受的。</p><figure><img src="gpu_mem.png" alt="gpu_mem" /><figcaption aria-hidden="true">gpu_mem</figcaption></figure><p>综合上面两种因素考虑，我们将训练时的Batch Size确定为<strong>64</strong>（或<strong>Batch Size=32 + Gradient Accumulation=2</strong>）。</p><h4 id="学习率">学习率</h4><p>由于我们使用了AdamW作为网络的优化器，因此每个参数的<strong>学习率（Learning Rate）</strong>会随着梯度的变化而不断发生变化。尽管如此，我们仍然需要决定一个整体学习率以确定各个参数学习率的变化尺度（由于后文所要介绍的学习率调度器的存在，这一学习率实际上为一个初始化学习率）。在当前数据集上，训练时的Loss随学习率的变化情况如下图所示（使用相同的学习率调度器）。可以看到，当学习率过大时，Loss的变化幅度巨大且难以收敛，而当学习率过小时，尽管Loss能够很快达到一个较低的水平，但由于每次优化幅度过小，使得其最终也难以收敛到一个较为合适的水平。</p><figure><img src="loss_lr.png" alt="loss_lr" /><figcaption aria-hidden="true">loss_lr</figcaption></figure><p>根据实验结果，最终我们将学习率设定为了<strong>5e-5</strong>。</p><h4 id="学习率调度器">学习率调度器</h4><p>在训练较为庞大的神经网络模型时，我们通常会在训练的不同阶段赋予优化器不同的基准学习率，这就需要一个较为合适的<strong>学习率调度器（Learning Rate Scheduler）</strong>。常用的学习率调度器包含恒定调度器、线性调度器、指数调度器、阶梯形调度器等，其对于学习率的影响如下图所示。可以看到，优化器的学习率在不同学习率调度器的控制下所表现出的变化情况呈现出不同的特征。</p><figure><img src="scheduler_lr.png" alt="scheduler_lr" /><figcaption aria-hidden="true">scheduler_lr</figcaption></figure><p>在实际的实验过程中，由于AdamW优化器本身的特性，学习率调度器对训练时Loss的变化影响及模型在验证集上的预测正确率并没有显著的影响。最终我们使用<strong>线形（Linear）调度器</strong>作为训练过程中的学习率调度器。</p><h4 id="迭代次数">迭代次数</h4><p>最后我们来确定训练时的<strong>迭代次数（Iterations）</strong>。通常来说，对于预训练语言模型的微调任务，我们会使用一个较小的迭代次数以防止其过拟合。在当前数据集上，训练时的Loss及模型在验证集上的分类正确率表现如下图所示。可以发现，当 <span class="math inline">\(epoch&lt;4\)</span> 时，网络在验证集上的正确率表现快速提升，而当 <span class="math inline">\(epoch &gt; 4\)</span>时，其正确率表现不再出现明显的提升，甚至开始出现下降。</p><figure><img src="epoch_loss_acc.png" alt="epoch_loss_acc" /><figcaption aria-hidden="true">epoch_loss_acc</figcaption></figure><p>因此，我们将训练时的迭代次数设定为<strong>4</strong>。</p><h2 id="交叉验证">交叉验证</h2><p>在验证机器学习模型时，模型的表现有很大一部分来自于数据集本身。若使用常规的方法固定的划分训练集和验证集，则可能会造成模型的表现带有<strong>偏向性（Bias）</strong>。因此，我们通常会使用<strong>交叉验证（Cross Validation）</strong>的方式来验证模型的性能。</p><p>交叉验证通常有两种方法。一种被称为<strong>留一法（Leave-one-out Cross Validation）</strong>，这种方法的问题在于每次验证集只有一个数据，若数据集规模很大，则需要循环迭代大量的次数。一个更常用的方法被称为<strong>K-折交叉验证（K-Fold Cross Validation）</strong>，其流程如下图所示（Figure ）。具体来说，我们将所有数据集分成K份，每次取其中一份作为验证集，其他的作为训练数据，依次对模型进行训练和测试，得到 <span class="math inline">\(K\)</span> 个验证集上的评价指标。</p><figure><img src="cross_val.png" alt="cross_val" /><figcaption aria-hidden="true">cross_val</figcaption></figure><p>随后，我们使用取平均值的方式得到最终的模型评价指标 <span class="math display">\[Score = \frac{1}{K} \sum_{i = 1}^K Score_i\]</span></p><p>Scikit-Learn提供了一个K-折交叉验证的数据集索引生成器，我们可以直接利用其来完成这一工作。这里我们选择 <span class="math inline">\(K = 5\)</span>。具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>kf = KFold(n_splits=<span class="hljs-number">5</span>, shuffle=<span class="hljs-literal">True</span>)<br>accuracy_list, precision_list, recall_list, f1_list = [], [], [], []<br>fold_cnt = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> kf.split(data_df):<br>    fold_cnt += <span class="hljs-number">1</span><br>    train_df = data_df.iloc[train_index]<br>    val_df = data_df.iloc[test_index]<br>    <span class="hljs-comment"># Irrelevant codes</span><br>    accuracy_list.append(eval_metrics[<span class="hljs-string">&#x27;eval_accuracy&#x27;</span>])<br>    precision_list.append(eval_metrics[<span class="hljs-string">&#x27;eval_precision&#x27;</span>])<br>    recall_list.append(eval_metrics[<span class="hljs-string">&#x27;eval_recall&#x27;</span>])<br>    f1_list.append(eval_metrics[<span class="hljs-string">&#x27;eval_f1&#x27;</span>])<br>accuracy_cross = np.array(accuracy_list).mean()<br>precision_cross = np.array(precision_list).mean()<br>recall_cross = np.array(recall_list).mean()<br>f1_cross = np.array(f1_list).mean()<br>print(<span class="hljs-string">&#x27;Average: Validation Accuracy: &#123;0&#125;, Precision: &#123;1&#125;, Recall: &#123;2&#125;, F1: &#123;3&#125;&#x27;</span>.format(accuracy_cross, precision_cross, recall_cross, f1_cross))<br></code></pre></td></tr></table></figure><h2 id="效果对比">效果对比</h2><p>我们使用<strong>Scikit-Learn</strong>及<strong>Pytorch</strong>工具包实现了本文中提到的各个模型，并使用上述的5折交叉验证方法对模型的分类效果进行了评估<strong>（具体代码请参考随附的README.md说明文档）</strong>。各个模型在训练集上的5折交叉验证结果如下表所示。可以看出，经过超参调优的XLNet模型在各个指标上均取得了所有模型中最好的分类表现，Bert和多层感知机模型的表现紧随其后，而传统的SVM分类器和TextCNN模型的表现则较为落后。</p><figure><img src="evaluation_score.png" alt="evaluation_score" /><figcaption aria-hidden="true">evaluation_score</figcaption></figure><p>进一步的，各个模型在各折验证结果中的正确率变化如下图所示。可以看出，基于传统机器学习和通用深度学习方法的分类模型在验证集上的正确率波动较大，而基于预训练+微调的语言模型分类方法则有着较好的稳定性。</p><figure><img src="models_acc_fold.png" alt="models_acc_fold" /><figcaption aria-hidden="true">models_acc_fold</figcaption></figure><p>最后，我们使用所有模型中效果最好的经过调优的XLNet模型对目标测试集进行了文本类别预测，其结果可见随附的<strong>test_output.txt</strong>文件。</p><h2 id="总结">总结</h2><p>在本实验中，我们实现了基于XLNet语言模型的文本分类器，并对其各个超参数进行了调优使其在验证集上得到较好的效果。随后，我们将其与其他几种经典文本分类模型的分类效果进行了对比，探索了几种不同的文本分类模型的特征及其在目标数据集上的表现。最后，我们使用训练完成的文本分类模型对目标测试集进行了标签预测，达到了预期的实验要求。</p><h2 id="references">References</h2><ol type="1"><li>Bernhard E. Boser, Isabelle M. Guyon, and Vladimir N. Vapnik. A training algorithm for optimal margin classifiers. In Proceedings of the Fifth Annual Workshop on Com- putational Learning Theory, COLT ’92, page 144–152, New York, NY, USA, 1992. Association for Computing Machinery.</li><li>Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning, 20(3):273–297, 1995.</li><li>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre- training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Com- putational Linguistics.</li><li>Ben Dickson. What are artificial neural networks (ann)? https://bdtechtalks. com/2019/08/05/what-is-artificial-neural-network-ann/, 2019.</li><li>Yoon Kim. Convolutional neural networks for sentence classification. In Proceed- ings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751, Doha, Qatar, October 2014. Association for Computa- tional Linguistics.</li><li>Scikit learn Developers. Cross-validation: evaluating estimator performance. https://scikit-learn.org/stable/modules/cross_validation.html, 2021.</li><li>Scikit learn Developers. Feature extraction. https://scikit-learn.org/stable/ modules/feature_extraction.html, 2021.</li><li>Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. ArXiv, abs/1711.05101, 2017.</li><li>Katherine (Yi) Li. How to choose a learning rate scheduler for neural networks. https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler, 2021.</li><li>Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, 2014.</li><li>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45, Online, October 2020. Association for Computational Linguistics.</li><li>Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. Xlnet: Generalized autoregressive pretraining for language understanding. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Gar- nett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.</li><li>Ye Zhang and Byron C. Wallace. A sensitivity analysis of (and practitioners’guide to) convolutional neural networks for sentence classification. In IJCNLP, 2017.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;文本分类是自然语言处理领域中一项十分基本的任务，其在多个领域都有着广泛的应用。在本文中，我们实现了基于 XLNet 预训练语言模型的文本分类模型，并使用微调(Fine-Tuning)的方法对给定数据集进行了文 本分类。通过对验证集的分</summary>
      
    
    
    
    <category term="当代人工智能" scheme="http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Artificial-Intelligence" scheme="http://gonggongjohn.me/tags/Artificial-Intelligence/"/>
    
  </entry>
  
  <entry>
    <title>当代数据管理系统项目二：书店（Bookstore）</title>
    <link href="http://gonggongjohn.me/2021/12/25/database/db-assignment-2/"/>
    <id>http://gonggongjohn.me/2021/12/25/database/db-assignment-2/</id>
    <published>2021-12-25T02:00:00.000Z</published>
    <updated>2022-12-07T11:49:41.956Z</updated>
    
    <content type="html"><![CDATA[<h2 id="实验要求">实验要求</h2><h3 id="功能">功能</h3><p>实现一个提供网上购书功能的网站后端。网站支持书商在上面开商店，购买者可能通过网站购买。买家和卖家都可以注册自己的账号。一个卖家可以开一个或多个网上商店，买家可以为自已的账户充值，在任意商店购买图书。支持下单 <span class="math inline">\(\to\)</span> 付款 <span class="math inline">\(\to\)</span> 发货 <span class="math inline">\(\to\)</span> 收货的流程。</p><ol type="1"><li><p><strong>实现对应接口的功能，见 doc 下面的 .md 文件描述（60% 分数）</strong></p><ol type="a"><li><p>用户权限接口，如注册、登录、登出、注销</p></li><li><p>买家用户接口，如充值、下单、付款</p></li><li><p>卖家用户接口，如创建店铺、填加书籍信息及描述、增加库存 通过对应的功能测试，所有test case都pass。测试下单及付款两个接口的性能（最好分离负载生成和后端），测出支持的每分钟交易数，延迟等</p></li></ol></li><li><p><strong>为项目添加其它功能：（40% 分数）</strong></p><ol type="a"><li><p>实现后续的流程发货 <span class="math inline">\(\to\)</span> 收货</p></li><li><p>搜索图书用户可以通过关键字搜索，参数化的搜索方式；如搜索范围包括，题目，标签，目录，内容；全站搜索或是当前店铺搜索。如果显示结果较大，需要分页（使用全文索引优化查找）</p></li><li><p>订单状态，订单查询和取消定单。 用户可以查自已的历史订单，用户也可以取消订单。</p></li></ol><p>取消定单（可选项，加分 +5 ∼ 10），买家主动地取消定单，如果买家下单经过一段时间超时后，如果买家未付款，定单也会自动取消。</p></li></ol><h3 id="要求">要求</h3><ol type="1"><li>允许向接口中增加或修改参数，允许修改 HTTP 方法，允许增加新的测试接口，请尽量不 要修改现有接口的 url 或删除现有接口，请根据设计合理的拓展接口（加分项 +2 ∼ 5 分）。 测试程序如果有问题可以提 bug（加分项，每提 1 个 BUG +2, 提 1 个 Pull Request +5）。</li><li>核心数据使用关系型数据库(PostgreSQL 或 MySQL 数据库)。blob 数据(如图片和大段 的文字描述)可以分离出来存其它 NoSQL 数据库或文件系统。</li><li>对所有的接口都要写 test case，通过测试并计算代码覆盖率（有较高的覆盖率是加分项 +2 ∼ 5）。</li><li>尽量使用正确的软件工程方法及工具，如:版本控制，测试驱动开发（利用版本控制是加分项 +2 ∼ 5）。</li><li>后端使用技术，实现语言不限；不要复制这个项目上的后端代码（不是正确的实践，减分项 − 2 ∼ 5 ）。</li><li>不需要实现页面。</li><li>最后评估分数时考虑以下要素：</li></ol><ol type="a"><li>实现完整度，全部测试通过，效率合理</li><li>正确地使用数据库和设计分析工具，ER 图，从 ER 图导出关系模式，规范化，事务处理，索引等 (c) 其它 · · ·</li></ol><ol start="8" type="1"><li>3个人一组，做好分工，量化每个人的贡献度</li></ol><h2 id="项目实现">项目实现</h2><h3 id="系统构架">系统构架</h3><p>作为一个经典的电商平台项目，我们采用了<strong>前后端分离</strong>和<strong>微服务</strong>的构架对整个系统进行了设计。整个系统的构架如下图所示（Figure 1）。其中，Nginx 支撑起一个前端维生容器，并向用户提供一个的由 Vue.js 搭建的前端服务<strong>（正向代理）</strong>。根据网页中的 UI 元素，用户可以根据通过配置好的请求方式向后端的对应接口发送 Http 请求（Axios）。请求会首先经过网关，并发送 到一个同样由 Nginx 维护的负载均衡服务器上<strong>（反向代理）</strong>。该服务器维护了当前系统内所有可 用的服务节点，并根据系统负载将所有的请求均摊到对应的服务上。在服务运行的过程中一共 涉及到 4 个数据库：<strong>PostgreSQL 主数据库</strong>、<strong>MongoDB 扩展数据库</strong>、<strong>Redis 缓存数据库</strong>和 <strong>ElasticSearch 搜索服务数据库</strong>，这些数据库通过分离部署的方式被所有服务容器所共享。此 外，一个由 Zookeeper 维护着的分布式 Kafka 消息队列连接着所有的组件，为所有微服务和数 据库间提供消息同步的机制。</p><img src="/2021/12/25/database/db-assignment-2/system_arch.png" class="" title="system_arch"><h3 id="数据库设计">数据库设计</h3><h4 id="entity-relation图">Entity-Relation图</h4><p>本项目的 Entity-Relation 图如下（Figure 2）。书店主要包含用户、商店、商品、订单和购物车五个实体。其中用户和商店构成经营的关系，用户和购物车构成操作的关系，用户与订单依据买家和卖家的角色构成下单和处理的关系；商品和商店构成出售的关系，商品和购物车构成包含的关系，商品和订单构成组成的关系。</p><img src="/2021/12/25/database/db-assignment-2/er_latest.png" class="" title="er_latest"><h4 id="关系数据库">关系数据库</h4><p>本项目的大部分数据存储在关系数据库中，一共包含 6 张表。</p><h5 id="用户表user">用户表（user）</h5><p>user 表存储用户的基本信息，包括<strong>用户名（name）</strong>、<strong>地址（address）</strong>、<strong>余额（money）</strong>、<strong>昵称（nickname）</strong>、<strong>密码（password）</strong>和<strong>手机号（phone）</strong>。</p><p>以用户名为主键，不额外设置自增主键，简化表结构，易于维护。</p><img src="/2021/12/25/database/db-assignment-2/pg_user.png" class="" title="pg_user"><h5 id="商品表book">商品表（book）</h5><p>book 表存储商品信息，包括商品 id(id)、详细信息的 id(info_id)、价格 (price)、销量 (sale)、库存 (stock_level)、商店名 (store_name) 和上架时间戳 (time)。</p><p>以自增 id 为主键，唯一确定一件商品，同时 store_name 与 info_id 的组合也可以唯一确定 一件商品，在 store_name 与 info_id 上建立联合索引，该索引和主键索引可以分别用于不同的 场景以提高查询效率。在 sale、price 和 time 上分别建立普通索引，用于提高带有对销量、价格或者时间字段排序的查询的效率。</p><img src="/2021/12/25/database/db-assignment-2/pg_book.png" class="" title="pg_book"><h5 id="商店表store">商店表（store）</h5><p>store 表存储商店信息，包括商店名 (name)、销量 (sale) 和卖家名 (seller_name)。</p><p>以商店名为主键，同时在 sale 和 seller_name 上分别建立普通索引，以提高相关查询的效率。</p><img src="/2021/12/25/database/db-assignment-2/pg_store.png" class="" title="pg_store"><h5 id="订单表order">订单表（order）</h5><p>order 表存储订单信息，包括订单号 (uuid，使用雪花算法生成)、买家用户名 (buyer_name)、发 货地址 (from_address)、物流单号 (logistic_id)、价格 (price)、状态 (status)、商店名 (store_name)、 下单时间戳 (time) 和收货地址 (to_address)。</p><p>以 uuid 为主键，同时在 buyer_name 和 store_name 分别建立普通索引，以提高相关查询的 效率。在 time 上建立普通索引，提高需要对时间排序的查询的效率。</p><img src="/2021/12/25/database/db-assignment-2/pg_order.png" class="" title="pg_order"><h5 id="订单商品表order_book">订单商品表（order_book）</h5><p>order_book 表存储订单里的商品信息，order 与 order_book 是一对多的关系。order_book 表包括订单 id(order_id)、图书详情 id(book_info_id)、数量 (count) 和单价 (single_price)。</p><p>以 order_id 和 book_info_id 作为联合主键，唯一确定某一订单里的某件商品。</p><img src="/2021/12/25/database/db-assignment-2/pg_order_book.png" class="" title="pg_order_book"><h5 id="购物车商品表shopping_cart_book">购物车商品表（shopping_cart_book）</h5><p>shopping_cart_book 表存储用户购物车里的商品信息，这里不单独设置购物车表，因为 用户和购物车存在一对一的关系，购物车与购物车中的商品存在一对多的关系，因此可以 把用户名作为购物车商品表的一个属性，这样即可确定某一商品是在哪个用户购物车里的。 shopping_cart_book 表包括用户名 (buyer_name)、商品 id(book_id)、数量 (count)、单价 (single_price)、商店名 (store_name)。</p><p>以 buyer_name 和 book_id 作为联合主键，唯一确定某一用户购物车里的某件商品。</p><img src="/2021/12/25/database/db-assignment-2/pg_shopping_cart_book.png" class="" title="pg_shopping_cart_book"><h4 id="文档数据库">文档数据库</h4><p>本项目中，文档数据库主要用于存储大段的文字信息和图片信息。</p><h5 id="图书详细信息集合-book_info">图书详细信息集合 (book_info)</h5><p>book_info 集合存储图书的详细信息，所有对该集合的访问都通过 id 来进行，因此除了 id 之外不再单独构建索引。</p><img src="/2021/12/25/database/db-assignment-2/mongo_book_info.png" class="" title="mongo_book_info"><h5 id="图书详细信息索引集合book_info_index">图书详细信息索引集合（book_info_index）</h5><p>这一部分存储在 Elastic Search 数据库中，关于 Elastic Search，详见本文的2.5.8节。</p><h5 id="评论集合comment">评论集合（comment）</h5><p>comment 集合存储商品的评价信息，所有对该集合的访问都通过 id 来进行，因此除了 id 之 外不再单独构建索引。</p><img src="/2021/12/25/database/db-assignment-2/mongo_comment.png" class="" title="mongo_comment"><h4 id="键值对数据库">键值对数据库</h4><p>本项目采用 redis 这一键值对缓存数据库，将一部分查询频率较高的数据存储到 redis 中，以提升查询效率。关于 redis，详见本文的2.6.1节。</p><h4 id="冗余">冗余</h4><p>在本项目中，redis 可以看作是关系数据库中某些数据的冗余，当一个查询到来时，如果在 redis 的缓存中命中，便可不用访问关系数据库，直接返回 redis 缓存中的结果，以此来提高查询效率。</p><p>Elastic Search 中存储的图书详细信息索引集合可以看作是 mongDB 中图书详细信息集合的 冗余，这里采用冗余是因为 Elastic Search 能够更好地进行搜索操作，提高搜索效率。</p><p>从 2.2.2 节可以看出，在关系数据库内部的表之间也存在一些冗余信息，这些冗余都是为了 提高查询效率。</p><h4 id="事务处理">事务处理</h4><p>本项目对某些操作采用了“事务处理”，如下单操作和付款操作等，以保证数据的一致性和 完整性。</p><p>在 SpringBoot 中，我们可以在方法上添加 <span class="citation" data-cites="Transactional">@Transactional</span> 注解来表明该方法为需要进行 “事务处理”的方法。当外部调用带有 <span class="citation" data-cites="Transactional">@Transactional</span> 注解的方法时，其访问数据库的过程会 当作一个事务来完成。当在方法执行过程中抛出 RunTimeException 异常时，会触发事务回滚(Rollback), 以保证数据的一致性，具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/* BuyerServiceImpl.java */</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-meta">@Transactional</span> <span class="hljs-comment">// 事务注解</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> ResponseEntity&lt;OrderMessage&gt; <span class="hljs-title">newOrder</span><span class="hljs-params">(NewOrderBody newOrderBody)</span> </span>&#123;<br>    String buyerName = newOrderBody.getBuyerName();<br>    String storeName = newOrderBody.getStoreName();<br>    <span class="hljs-comment">//Irrelevant codes</span><br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-meta">@Transactional</span> <span class="hljs-comment">// 事务注解</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> ResponseEntity&lt;Message&gt; <span class="hljs-title">payment</span><span class="hljs-params">(PayBody payBody)</span> </span>&#123;<br>    String md5Password = DigestUtils.md5DigestAsHex(payBody.getPassword().getBytes());<br>    String userRedisKey = <span class="hljs-string">&quot;user_&quot;</span> + payBody.getBuyerName();<br>    <span class="hljs-comment">//Irrelevant codes</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="数据库选型">数据库选型</h4><p>本实验要求我们使用关系型数据库作为系统的核心数据库。现阶段，市面上两大主流的传 统关系型数据库即为 MySQL 和 PostgreSQL(SQL Server 主要服务于 Windows 及其衍生系 统，而本项目设计的目标系统为 Linux 相关系统，故不作考虑)。下面我们来对这两大关系型数 据库进行分析，以确定在该项目中所要选用的核心数据库。</p><p>作为 Oracle 旗下的老牌关系型数据库，MySQL 已经在无数的应用上发挥出了其威力。然而， 作为一个以商用为主的软件，MySQL 分为免费的 Community(社区版)和收费的 Enterprise (商业版)，这就导致了其社区版本在许多功能上都受到了限制。此外，尽管 MySQL 的社区版本 开放了源代码，但其使用的 GPL 协议使得二次开发受到了许多的限制。相比之下，PostgreSQL 是一款完全由社区(PostgreSQL Global Development Group)维护的开源关系型数据库，这就 意味着其开发和改进相比 MySQL 更为方便和敏捷。其使用的类 BSD/MIT 协议也使得二次开发变得容易。</p><p>PostgreSQL 的宣传标语就是“世界上最先进的开源关系型数据库”，这也意味着其拥有着更新的特性。从功能上来说，PostgreSQL 相比 MySQL 增加了大量的数据类型，如 Array 和 JSON，且在部分原始数据类型上相比 MySQL 也有更小的限制(如 TEXT 类型)。这一特性使 得 PostgreSQL 甚至可以作为 NoSQL 来使用。此外，从运维上来说，PostgreSQL 拥有许多实用 的特性，如:DDL 操作能够放入事务中、能够并发地创建或删除索引、多样化的复制和提交方 式等。这些特性能够帮助我们快速完成对数据库中结构的修改，这对于类似本实验这样的小型项 目是十分重要的。</p><p>从 DB Engines 网站上我们可以看到近几年几大关系型数据库的流行程度(Figure 11)。可以 发现，尽管 MySQL 仍然占据着主导的数据库比例，但其市场占比已经开始有下降的趋势;而 PostgreSQL 作为一款新兴的关系型数据库，其市场占有率自 2014 年起就始终以一个极高的速 度增长着，这也充分表明了 PostgreSQL 在实际使用场景下的优势。</p><img src="/2021/12/25/database/db-assignment-2/db_ranking.png" class="" title="db_ranking"><p>MySQL 使用了 InnoDB 作为其主要存储引擎(新版本下的 MySQL 支持如 MyISAM 等其 他存储，但由于其不支持完整的事务处理功能，故不常被使用)，尽管自起发明以来已经取得了 长足的进步，但仍然有不少案例报告系统在运行过程中出现了服务器级别的数据库丢失现象。相 比较之下，在实际使用过程中，PostgreSQL 的稳定性更强。从性能上来说，MySQL 使用多线 程技术来提升系统性能的利用率，而 PostgreSQL 使用了多进程技术。在现代处理器上，后者相 比前者有着更好的优化空间。在实际的使用过程中，PostgreSQL 在面对高并发访问请求时相比 MySQL 也的确拥有着更好的表现。除此之外，当数据库负载逼近极限下，PostgreSQL 的性能指 标仍可以维持双曲线甚至对数曲线，到顶峰之后不再下降，而 MySQL 会明显出现一个波峰后下滑。</p><p>为了实际测试 MySQL 和 PostgreSQL 的性能表现，我们使用 Sysbench 基准测试工具分别 对同一台部署了 MySQL 和 PostgreSQL 的服务器进行了性能测试，如下图所示(Figure 12)。 测试结果表明，同等配置下，PostgreSQL 的综合性能表现达到了 MySQL 的近两倍。</p><img src="/2021/12/25/database/db-assignment-2/mysql_postgresql_compare.png" class="" title="mysql_postgresql_compare"><p>综合上面的结果，在本项目中，我们使用了 PostgreSQL 作为系统的核心数据库。</p><p>除此之外，在书店系统中，一本书本商品通常还会带有大量的 BLOB 数据，如图书简介、作 者简介、图书照片等。若直接这些数据放在关系型数据库中，会导致一个字段过长，且不方便存 储和扩展。对于这些数据，文档型数据库(Document Database)是一种极好的存储方式。在 本应用中，我们使用 MongoDB 来作为系统的扩展数据存储数据库。</p><h4 id="数据库调优">数据库调优</h4><p>除了前文中所讨论的如索引、冗余、事务处理等数据访问优化，对于数据库本身而言，其当前配 置也是一个需要考虑的问题。通常来说，一个数据库的默认配置是较为保守的，在很多场景下无 法完全利用系统中的资源。为了提升设备利用效率，我们需要对数据库的相关配置进行调优。由 于 MongoDB 等 NoSQL 本身已经具有了极强的性能分配机制，因此我们主要针对传统关系型数 据库进行调优。</p><p>对于 PostgreSQL 数据库，我们使用如下配置对参数进行了优化(Table 1)：</p><table><thead><tr class="header"><th>参数名</th><th>默认值</th><th>参数说明</th><th>优化值</th></tr></thead><tbody><tr class="odd"><td>max_connections</td><td>100</td><td>允许客户端连接的最大数目</td><td>10000</td></tr><tr class="even"><td>fsync</td><td>on</td><td>强制把数据同步更新到磁盘</td><td>off</td></tr><tr class="odd"><td>shared_buffers</td><td>24MB</td><td>PostgreSQL 能够用于缓存数据的内存大小</td><td>1024MB</td></tr><tr class="even"><td>work_mem</td><td>1MB</td><td>内部排序和一些复杂的查询在这个 Buffer 中完成</td><td>10MB</td></tr><tr class="odd"><td>wal_buffer</td><td>768KB</td><td>日志缓存区的大小</td><td>4096KB</td></tr><tr class="even"><td>checkpoint_segments</td><td>3</td><td>设置 Wal Log 的最大数量(一个 Log 的大小为 16M)</td><td>10</td></tr><tr class="odd"><td>commit_delay</td><td>0</td><td>事务提交后，日志写到 Wal Log 上到 wal_buffer写入到磁盘的时间间隔</td><td>2</td></tr><tr class="even"><td>commit_siblings</td><td>5</td><td>设置触发 commit_delay 的并发事务数</td><td>20</td></tr></tbody></table><h3 id="接口设计">接口设计</h3><p>本实验共设计并实现了 33 个接口，其中包括 11 个基础接口以及 22 个额外接口。额外接口 一部分用于给前端提供必要的展示数据，对数量较大的数据进行了分页处理，另一部分则用于用 户信息修改、购物车、订单的后续处理 (发货、收货、评价及取消)、商品搜索和商品评论等功能。</p><h4 id="基础接口">基础接口</h4><h5 id="用户注册">用户注册</h5><p><strong>URL:</strong> http://[address]/auth/register</p><p><strong>Method:</strong> POST</p><p><strong>Request Body</strong></p><table><thead><tr class="header"><th>变量名</th><th>类型</th><th>描述</th><th>是否可空</th></tr></thead><tbody><tr class="odd"><td>user_id</td><td>string</td><td>用户名</td><td>N</td></tr><tr class="even"><td>password</td><td>string</td><td>密码</td><td>N</td></tr></tbody></table><p><strong>Response Status Code</strong></p><table><thead><tr class="header"><th>状态码</th><th>描述</th></tr></thead><tbody><tr class="odd"><td>200</td><td>ok</td></tr><tr class="even"><td>512</td><td>注册失败，用户名已存在</td></tr></tbody></table><p><strong>Response Body</strong></p><table><thead><tr class="header"><th>变量名</th><th>类型</th><th>描述</th><th>是否可空</th></tr></thead><tbody><tr class="odd"><td>message</td><td>string</td><td>错误消息，成功时为“ok”</td><td>N</td></tr></tbody></table><h5 id="用户注销">用户注销</h5><h5 id="用户登录">用户登录</h5><h5 id="用户修改密码">用户修改密码</h5><h5 id="用户登出">用户登出</h5><h5 id="卖家创建商铺">卖家创建商铺</h5><h5 id="卖家添加书籍信息">卖家添加书籍信息</h5><h5 id="卖家添加书籍库存">卖家添加书籍库存</h5><h5 id="买家下单">买家下单</h5><h5 id="买家付款">买家付款</h5><h5 id="买家充值">买家充值</h5><h4 id="额外接口">额外接口</h4><h5 id="用户获取个人信息">用户获取个人信息</h5><h5 id="用户提现">用户提现</h5><h5 id="用户修改昵称手机号地址">用户修改昵称、手机号、地址</h5><h5 id="卖家删除商店">卖家删除商店</h5><h5 id="卖家获得自己的商店列表">卖家获得自己的商店列表</h5><h5 id="卖家下架商品">卖家下架商品</h5><h5 id="获得商品详细信息">获得商品详细信息</h5><h5 id="买家伙的购物车列表">买家伙的购物车列表</h5><h5 id="买家把商品加入到购物车">买家把商品加入到购物车</h5><h5 id="买家秀改购物车中商品的数量">买家秀改购物车中商品的数量</h5><h5 id="买家从购物车下单">买家从购物车下单</h5><h5 id="分页获取订单列表">分页获取订单列表</h5><h5 id="卖家发货">卖家发货</h5><h5 id="买家收获">买家收获</h5><h5 id="买家评价">买家评价</h5><h5 id="分页获取商品评论">分页获取商品评论</h5><h5 id="获取商品星级">获取商品星级</h5><h5 id="取消订单">取消订单</h5><h5 id="查看商店详情">查看商店详情</h5><h5 id="获取商店列表">获取商店列表</h5><h5 id="搜索商品分页返回">搜索商品，分页返回</h5><h3 id="前端实现">前端实现</h3><h4 id="前端技术介绍">前端技术介绍</h4><h5 id="vue.js-3">Vue.js 3</h5><p>渐进式 JavaScript 框架</p><ul><li>Vue.js是一套构建用户界面的渐进式框架。</li><li>Vue只关注视图层，被设计为可以自底向上逐层应用。</li><li>Vue的目标是通过尽可能简单的API实现响应数据的绑定以及视图组件的组合使用。</li><li>另外，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页 应用提供驱动。</li></ul><h5 id="quasar-v2">Quasar v2</h5><p>高性能高质量的 Vue.js 3 用户界面框架</p><ul><li>Quasar是一个高性能的Vue.js前端用户界面设计框架。</li><li>Quasar CLI 模式，对每种构建模式(SPA、SSR、PWA、移动应用程序、桌面应用程序和 浏览器扩展)提供了一流的支持，并提供了最佳的开发人员体验，可以高效、灵活地进行 高级开发者设计。</li><li>Quasar v2 基于 Vue3，提供高性能的响应式前端组件，可以对页面的风格特性、布局网络、 静态和动态组件进行高效的设计。</li><li>Quasar是最注重性能的框架之一。</li></ul><h5 id="axios">Axios</h5><p>易用、简洁且高效的 http 库</p><ul><li><p>Axios是一个基于promise的HTTP库，可以用在浏览器和node.js中.</p></li><li><p>Axios从浏览器中创建XMLHttpRequests，从node.js创建http请求，并且支持Promise API</p></li><li><p>Axios可以高效地处理或拦截请求和响应，转换请求数据和响应数据。</p></li><li><p>我们将 Axios 进行封装成为 api，简化调用过程、突出功能代码、便捷接口使用</p></li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">// Axios请求使用例</span><br><span class="hljs-keyword">let</span> url = location.protocol + <span class="hljs-string">&quot;//&quot;</span> + ( testurl || location.hostname ) + <span class="hljs-string">&quot;:&quot;</span> +<br>backend_port + <span class="hljs-string">&quot;/buyer/order_cancel&quot;</span>;<br><span class="hljs-keyword">let</span> body = &#123;<br><span class="hljs-string">&quot;buyer_id&quot;</span>: objData.user_id,<br><span class="hljs-string">&quot;uuid&quot;</span>: order_id, &#125;;<br>api.post(url, body).then(<span class="hljs-function">(<span class="hljs-params">response</span>) =&gt;</span> &#123; <span class="hljs-keyword">if</span>(response.status == <span class="hljs-number">200</span>)&#123;<br>alert(<span class="hljs-string">&quot;取 消 成 功!&quot;</span>)<br>&#125; &#125;)<br>.catch(<span class="hljs-function">(<span class="hljs-params">error</span>) =&gt;</span> &#123; alert(error.response.data.message);<br>&#125;);<br></code></pre></td></tr></table></figure><h4 id="前端结构设计">前端结构设计</h4><h4 id="前端接口设计">前端接口设计</h4><h4 id="开发流程">开发流程</h4><h4 id="页面展示">页面展示</h4><h4 id="特点">特点</h4><ul><li>数据响应式绑定，一方面简化开发人员对页面内容的操作方式，另一方面使用户实时直观地看到自己正在修改的内容对页面其他数据的影响。</li><li>采用高性能框架，减少前端页面内容对用户设备的页面渲染开销，并降低带宽压力。</li><li>网页模块化设计，有利于前端框架的维护工作，简化对前端进行进一步开发的流程。</li></ul><h4 id="后续开发方向">后续开发方向</h4><ul><li>优化功能:调整页面布局和浏览器本地存储策略，优化用户的信息获取方式，减少用户重复填入信息的操作。</li><li>响应式支持:进一优化响应式布局设计，构建 PC、平板电脑、手机端都能获得优秀使用体 验的前端设计。</li></ul><h3 id="后端实现">后端实现</h3><h4 id="springboot服务构架">Springboot服务构架</h4><p>为了实现一个完整的电商服务平台并能够应对各种可能的情况，我们必须使用一个足够方便 且功能全面的后端开发框架。作为当前世界上最流行的后端服务框架，Spring 拥有着后端开发 中最全的生态系统。为了方便开发，在本项目中，我们使用了 Springboot 作为后端开发框架。</p><p>书店系统的后端构架如下图所示(Figure 30)。整个系统共分为 5 层，拦截层(Interceptor) 负责验证请求的 Token 信息是否合法，控制层(Controller)负责接口的声明和参数传递，服 务层(Service)负责各种服务的实现，持久化层(DAO，Data Access Operator)负责与数 据库的 CRUD 及其他各种操作，模型层(Model)用于声明各种应用中存在的数据实体。</p><img src="/2021/12/25/database/db-assignment-2/backend_layer.png" class="" title="backend_layer"><p>为了方便开发和统一接口，我们使用了 ORM(Object Relational Mapping)和 ODM (Object Document Mapping)的方式将 Java 对象和数据库中的实体建立联系。这一功能是 由 Spring 生态中强大的驱动器(Driver)组件所保证的。具体来说，本项目用到的全部模块依赖如下表所示(Table 2)。</p><table><thead><tr class="header"><th>模块名</th><th>版本</th><th>功能</th></tr></thead><tbody><tr class="odd"><td>Spring Boot Starter Web</td><td></td><td></td></tr><tr class="even"><td>Mybatis Plus Boot Starter</td><td></td><td></td></tr><tr class="odd"><td>Spring Boot Start Data Redis</td><td></td><td></td></tr><tr class="even"><td>Redisson</td><td></td><td></td></tr><tr class="odd"><td>Spring Kafka</td><td></td><td></td></tr><tr class="even"><td>Caffeine</td><td></td><td></td></tr><tr class="odd"><td>PostgreSQL</td><td></td><td></td></tr><tr class="even"><td>Hystrix Core</td><td></td><td></td></tr><tr class="odd"><td>Lombok</td><td></td><td></td></tr><tr class="even"><td>Spring Boot Starter Test</td><td></td><td></td></tr><tr class="odd"><td>JAVA JWT</td><td></td><td></td></tr><tr class="even"><td>Spring Boot Starter Data MongoDB</td><td></td><td></td></tr><tr class="odd"><td>Spring Data ElasticSearch</td><td></td><td></td></tr></tbody></table><p>在实际处理请求的过程中，各功能层会被逐层调用，以做到业务的隔离。以买家服务控制器 (BuyerController)为例，其加载流程如下图所示(Figure 31)。可以看到，控制器层首先调用 各服务接口层(Service Interface)，并由服务实现层(Service Implementation)完成所有的请求处理逻辑。对于其中的数据库操作，服务层再接着调用持久化层和模型层完成相应的操作。</p><img src="/2021/12/25/database/db-assignment-2/buyer_controller_uml.png" class="" title="buyer_controller_uml"><h4 id="jwt与登录验证">JWT与登录验证</h4><h5 id="jwt介绍">JWT介绍</h5><p>JSON Web Token (JWT) 是一个开放标准 (RFC7519)，它定义了一种紧凑的、自包含的方 式，用于作为 JSON 对象在各方之间安全地传输信息。该信息可以被验证和信任，因为它是数 字签名的。</p><h5 id="jwt组成">JWT组成</h5><p>JWT 由三部分组成。第一部分为头部 (header)，第二部分为载荷 (payload)，第三部分是签 名 (signature)。头部包含 token 的类型 (“JWT”) 和加密算法名称 (如 SHA256)，载荷包含用 户的有效信息 (不能是敏感信息)，签名用于验证消息在传递过程中是否被更改，要得到签名，需 要仅存在于服务端的密钥 (secret)。</p><h5 id="jwt工作流程">JWT工作流程</h5><h5 id="jwt优点">JWT优点</h5><ul><li><p>由于 JSON 的通用性，JWT 是跨语言支持的。</p></li><li><p>便于传输，JWT 的构成简单，字节占用小。</p></li><li><p>不需要在服务端保存会话信息, 易于应用的扩展。</p></li></ul><h5 id="jwt应用">JWT应用</h5><p>配置 JWT 拦截器 (JWT Interceptor)，编写 JWT 生成和验证方法，除了特定接口直接放 行之外 (如登录、注册不需要 token 验证)，其余接口的请求都需要通过 JWT 验证才能继续进 行。具体代码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/* JWTInterceptor.java */</span><br><span class="hljs-comment">// JWT拦 截 器</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JWTInterceptor</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">HandlerInterceptor</span> </span>&#123;<br><span class="hljs-meta">@Override</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">preHandle</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse</span></span><br><span class="hljs-function"><span class="hljs-params">response, Object handler)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123; String token=request.getHeader(<span class="hljs-string">&quot;token&quot;</span>); Message message=<span class="hljs-keyword">new</span> Message();<br><span class="hljs-keyword">try</span>&#123;<br>JWTUtils.verify(token); message.setMessage(<span class="hljs-string">&quot;ok&quot;</span>); <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;<br>&#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>message.setMessage(<span class="hljs-string">&quot;token错 误&quot;</span>); response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); response.setContentType(<span class="hljs-string">&quot;application/json;charset=UTF-8&quot;</span>); response.getWriter().write(<span class="hljs-keyword">new</span> ObjectMapper().writeValueAsString(<br>&#125; &#125;<br>&#125;<br>message)); <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;<br><span class="hljs-comment">/* JWTInterceptorConfig.class */</span><br><span class="hljs-comment">// JWT拦 截 器 配 置</span><br><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JWTInterceptorConfig</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">WebMvcConfigurer</span> </span>&#123;<br><span class="hljs-meta">@Override</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">addInterceptors</span><span class="hljs-params">(InterceptorRegistry registry)</span> </span>&#123;<br>registry.addInterceptor(<span class="hljs-keyword">new</span> JWTInterceptor()) .addPathPatterns(<span class="hljs-string">&quot;/**&quot;</span>)<br>.excludePathPatterns( <span class="hljs-comment">// 不 需 要JWT验 证 直 接 放 行 的 接 口 &quot;/auth/register&quot;,</span><br><span class="hljs-string">&quot;/auth/unregister&quot;</span>, <span class="hljs-string">&quot;/auth/login&quot;</span>, <span class="hljs-string">&quot;/auth/password&quot;</span>, <span class="hljs-string">&quot;/buyer/payment&quot;</span>, <span class="hljs-string">&quot;/buyer/add_funds&quot;</span><br>  );<br>&#125;<br>&#125;<br>  <br><span class="hljs-comment">/* JWTUtils.class */</span><br><span class="hljs-comment">// JWT工 具 类</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JWTUtils</span> </span>&#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String SECRET=<span class="hljs-string">&quot;gld-bookstore-*%#@*!&amp;&quot;</span>; <span class="hljs-comment">// 密 钥</span><br><span class="hljs-comment">// JWT生 成</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title">generateToken</span><span class="hljs-params">(LoginBody loginBody)</span></span>&#123;<br>JWTCreator.Builder builder= JWT.create(); builder.withClaim(<span class="hljs-string">&quot;name&quot;</span>,loginBody.getName()); builder.withClaim(<span class="hljs-string">&quot;terminal&quot;</span>,loginBody.getTerminal()); Calendar instance=Calendar.getInstance(); instance.add(Calendar.HOUR,<span class="hljs-number">24</span>); builder.withExpiresAt(instance.getTime());<br><span class="hljs-keyword">return</span> builder.sign(Algorithm.HMAC256(SECRET)); &#125;<br><span class="hljs-comment">// JWT验 证</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">verify</span><span class="hljs-params">(String token)</span> </span>&#123;<br>JWT.require(Algorithm.HMAC256(SECRET)).build().verify(token); &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="orm框架的使用">ORM框架的使用</h4><p>在 SpringBoot 中，常用的 ORM 框架有两个，一个是 JPA，另一个是 MyBatis。JPA 可以 实现自动创建数据库表结构，而 Mybatis 却不行。但 Mybatis Plus 封装的 CURD 接口要比 JPA 的接口使用起来更加方便，因此本项目即使用了 JPA 用于自动建表，又使用了 Mybatis Plus 的 CURD 接口。</p><h5 id="jpa自动建表">JPA自动建表</h5><p>JPA 的自动建表功能十分方便，只需在实体类及其属性上加上相应的注解即可，具体代码如下。</p><h5 id="基于-mybatis-plus-的-curd">基于 Mybatis Plus 的 CURD</h5><p>使用 Mybatis Plus 封装的 CURD 接口可以方便地操作数据库，几乎不用写 SQL 语句。本项目中用到的 mapper 层接口如下。</p><h4 id="用户服务">用户服务</h4><h4 id="买家服务">买家服务</h4><h4 id="卖家服务">卖家服务</h4><h4 id="搜索服务">搜索服务</h4><h4 id="elasticsearch与全文搜索">ElasticSearch与全文搜索</h4><p>Elasticsearch 是一款基于 Apache Lucene 的分布式文档型数据库。Elasticsearch 的开发目的就 是实现一个能够实时高效的对非结构化数据进行各种检索操作的搜索引擎，因此其被大量的用 于各种 OLAP(Online Analytical Processing)场景。</p><p>ElasticSearch 中使用了倒排索引(Inverted Index)技术为加入的每一个文档建立了倒排索 引，这也是其能够实现高效全文搜索的重要基础之一。倒排索引的基本原理如下图所示(Figure 34)。对于每一个加入的文档，系统会使用分词器对其进行分词。随后，系统会建立一个词项 → 文档编号的映射表。如此，当用户发起一个对应词项的文档查询请求时，系统就能快速查询出包 含该词项的文档。</p><p>Elasticsearch 默认的分词器对中文的支持并不理想，对于一个中文语句，其往往会将其逐 字拆开作为词项，这显然是不合适的。为此，社区开发者 medcl 基于 Lucene IK analyzer 为 ElasticSearch 提供了一个名为 Analyze IK 的第三方分词。两种分词器对同一个中文语句的分 词结果如下图所示(Figure 35)。可以看到，使用 Analyze IK 对中文语句的分词效果远好于默 认分词器。</p><p>在本项目中，Elasticsearch 索引文档的结构如下表所示(Table 3)。其中，Elasticsearch 会对文 本(Text)类型进行分词，并将词项以倒排索引的形式存储在数据库中;而对关键字(Keyword) 类型，ES 直接将其视作一个整体存入数据库。这一区分也符合我们日常过程中对关键字的查询 结果预期。</p><p>与访问其他数据库类似，我们同样使用了 ODM 模式将 JAVA 对象与 ElasticSearch 文档相 关联，并使用映射器(Mapper)的方式对其进行访问。除了基本的 CRUD 操作外，Elasticsearch 为我们提供了强大的全文索引功能。我们只需要在 Mapper 中加入相关字段的接口，就可以实现 对对应字段的模糊查询操作:</p><p>将测试给定的书本数据插入 Elasticsearch 后的存储情况如下图所示(Figure 36)。可以看到， ES 以分片的方式在不同的空间中管理插入的数据，并为每组数据标记了其索引的位置和各种信 息。</p><p>对于一个关键字查询请求，我们首先通过上面的接口方法在各个字段中查询出满足条件的书 籍信息实体。随后，我们通过其对应的 BookinfoID 在书籍实体中查询出出售该种书籍的全部 商店，并根据用户给定的请求参数对结果进行编排后返回给用户。相关实现代码如下:</p><h3 id="高可用">高可用</h3><p>高可用性(High Availability)是指系统无中断地执行其功能的能力超过其同级别的系统， 代表系统的可用性程度，是进行系统设计时的准则之一 [Wik21a]。</p><p>造成服务不可用的原因有很多，其中一个十分重要的原因便是过多的并发请求(Concurrent Request)。在 WEB 服务中，并发请求是指一个或多个用户在同一时刻或相隔极短的时刻内发 送至目标服务器，并使得服务器需要同时处理并响应的请求。随着互联网规模的高速发展，这一 现象在一些热门服务供应商中体现的越来越明显。近年来，因为短时间内收到大量请求使得服务 器崩溃导致无法提供正常服务的事故屡次发生(Figure 37, 38)，这些事故严重影响了用户的体 验和服务的质量，也使得学术界和工业界加强了对高可用系统设计的重视。</p><p>一个高可用系统的设计通常具有以下三条原则：</p><ul><li>消除单点故障(Elimination of single points of failure)</li><li>可靠的交叉点服务(Reliable crossover)</li><li>提前检测故障并快速恢复(Detection of failures as they occur)</li></ul><p>在本实验中，我们需要测出书店系统中下单和付款接口的吞吐量，这正是一个极好的高并发 场景的实例。根据上述的三条原则，我们实现了一系列策略来提升这两个接口的吞吐量，并使得 整个书店系统在各种情况下都能够保持较高的可用性。</p><h4 id="redis与缓存数据库">Redis与缓存数据库</h4><p>由于需要管理的数据量通常十分庞大(GB 甚至 TB 级)，且需要支持完整的事务处理能力，常 规的关系性数据库通常使用磁盘来对数据进行维护，并使用页(Page)为单位对数据进行存取。 因此，对数据库中的内容进行一次访问通常具有很高的 I/O 代价。通过实际的测试我们也发现， 在整个服务的响应逻辑中，对数据库的访问代价占据了整个请求处理过程中绝大部分的耗时。在 高并发场景下，这一时间开销使得数据库系统很快就会遇到性能瓶颈，并使得后续的请求难以得 到正确的响应。</p><p>Redis(Remote Dictionary Server，远程字典服务) 是一款开源的、基于内存存储的分布 式 Key-Value 型数据库 [Wik21b]。作为 NoSQL 的一种，Redis 设计的宗旨就是为了在面对大量 随机读写请求时能够以尽可能高的效率存取数据，因此其天然地拥有极高的并发处理能力。经验 值表明，在一台常规的小型笔记本上，Redis 能够支持约 110000 次/秒的写操作和 81000 次/秒 的读操作 [Jai19]，这一数值几乎是传统关系型数据库吞吐量的近 100 倍。因此，使用 Redis 作 为主数据库的缓存数据库来提升整个服务的响应能力是一个十分合适的选择。</p><p>我们使用 JMeter 接口压测工具，分别向直接访问 Postgresql 数据库和使用了 Redis 缓存的 两个测试接口发送了 10000 次并发请求，其响应结果如下图所示(Figure 39, 40)。可以看到，使 用了 Redis 缓存的接口吞吐量几乎是直接访问 Postgresql 数据库接口的两倍，前者的平均响应 时间更是比后者快了整整 5 倍。</p><img src="/2021/12/25/database/db-assignment-2/db_concur_test2.png" class="" title="db_concur_test2"><img src="/2021/12/25/database/db-assignment-2/redis_concur_test2.png" class="" title="redis_concur_test2"><p>要使用 Redis 作为缓存，我们就需要分析在当前业务中哪些数据是经常被访问的数据，即所 谓的热点数据。在当前应用中，热点数据的访问主要发生在下单和付款两个接口请求的处理上。 对于下单操作，系统需要读取商品的库存、价格;对于付款操作，系统需要读取用户的密码、账 户余额及订单的总价。</p><p>书店系统的 Redis 缓存结构如下表所示(Table 4)。其中，user 键和 store 键分别维护当前系 统中所有的用户 ID 和商店 ID，用于快速判断下单和付款请求是否合法;stock_{图书 ID}<em>{商店 ID} 和 price</em>{图书 ID}<em>{商店 ID} 键分别用于维护热点商品的库存和价格信息(分开存储 是为了支持 Redis 的原子级自增(Increment)和自减(Decrement)操作);user</em>{用户名} 键用于存放已登录用户当前的密码及账户余额，用于在付款请求中快速确认用户身份并判断用 户账户是否有足够的足额支付当前订单;order_{订单号} 键用于临时存放下单成功的订单总价(若订单创建后的 T 时刻内仍没有被付款接口更新，则该 Redis 键自动过期，也即订单自动取 消)。</p><p>使用 Redis 作为缓存后，高并发接口的数据查询流程如下图所示(Figure 41)。对于一个下 单/付款请求，服务会先查看 Redis 中是否存在相应的缓存，若缓存存在，则直接进行判断和处 理操作;若缓存不存在，则服务从主数据库中查询数据，并将查询到的数据放入 Redis 缓存中。 如此，当收到大量对热点数据的操作请求时，服务就可以快速响应用户的请求，极大的提高了接 口的吞吐能力。</p><h4 id="布隆过滤器与缓存防穿透">布隆过滤器与缓存防穿透</h4><p>从上面的实现过程我们可以发现，当用户对高并发接口发起一个请求时，服务会先查询 Redis 缓 存，若缓存不命中，再访问数据库进行查询。然而，若用户查询的值并不存在于系统中(也即数 据库中不存在)，则服务必然会对数据库发起查询请求。当这一查询数量增加时，就会有大量的 查询请求直接打在数据库上，导致数据库服务崩溃。此时，缓存起不到任何流量分摊的作用，就 如同不存在一样，也即产生所谓的缓存穿透(Cache Penetration)问题。</p><p>在实际应用场景中，要解决缓存穿透问题，通常具有如下三种方法 [kkl21]:</p><ul><li>增加校验层，让用户请求频率降低</li><li>当数据库查询不到目标值时将对应的缓存键设置为空值</li><li>维护一张系统中所有书本的 ID 值的集合，在收到请求时过滤无效查询</li></ul><p>在这里我们使用第三种方法。</p><p>要维护系统中所有的书本 ID 集合，我们首先能够想到的就是在 Redis 缓存中增加一个类型 为集合的 bookID 键来存放所有的书本 ID。然而，当书本数量增长时，这一空间开销将逐渐变 得难以接受。注意到，对于每一个书本 ID，我们只需要记录其是否存在于系统中，因此我们可 以使用位图(Bitmap)技术来存放所有的 ID。事实上，我们无需精准的过滤每一个无效请求， 只需要将请求数量降低到一个数据库能够承受的范围即可。此时，我们完全可以使用一种概率型 数据结构来对请求的 ID 进行判断，以减少维护全部书本集合所需要的空间开销。</p><p>布隆过滤器(Bloom Filter)是一种概率型数据存储结构，其工作原理如下图所示(Figure 43)。系统首先设置一个固定长度的位数组，随后对于每一个给定的元素，系统会通过确定的 k 个哈希函数将其映射到对应的位上。于是，对于一个待查询元素，系统只需要判断其以同样 的方式映射后的位置上是否已被置为 1 即可。具体来说，布隆过滤器可以在上界确定的空间 O(m), m ∈ N + 内对请求的元素给出如下的应答:</p><ul><li><p>可能存在于集合中</p></li><li><p>一定不存在于集合中</p></li></ul><p>布隆过滤器可以保证给出第二种应答时一定正确;而对于第一种应答，对于一个由 k 个哈希 函数组成的长度为 m 的布隆过滤器，其面对 n 个总数据时的误判率约为 (1 − exp{− kn })k，这一结果在我们的场景下是完全可以接受的。</p><p>通过将布隆过滤器继承到 Redis 缓存中，用户在请求下单/付款接口时服务的数据查询流程 如下图所示(Figure 44)。在系统启动时，服务会从主数据库中获取当前系统中所有存在的书本 ID，并设置布隆过滤器中的响应位。这样，当接收到一个请求时，系统会首先通过布隆过滤器判 断书本 ID 是否可能存在于系统中，若判断结果为一定不存在则直接返回。如此，最终到达缓存 和主数据库的请求量就会被大大降低，减少了系统被恶意攻击时可能的宕机事故发生。</p><p>在 Springboot 中，我们可以使用 Google 的 Guava 模块或 Redis 原生的 Redisson 模块来实现布隆过滤器的继承，这里我们使用了后者。</p><h4 id="caffeine与多级缓存">Caffeine与多级缓存</h4><p>通过 Redis 缓存，我们已经可以使得系统在面对相对较高的并发请求时保证响应的效率。那 么我们是否又可能进一步的优化，让请求能够更快的得到应答呢?答案是肯定的。</p><p>注意到，在秒杀活动时，用户对一件商品的请求量与该商品本身的库存数往往是严重不匹配 的(例如一件商品的库存只有 100 件，而在秒杀活动瞬间服务器收到了 10000 次下单请求)，我 们希望能够在请求达到服务器时就能提前过滤掉这些多余的无效请求，让尽可能合理的请求数 到达之后的服务。</p><p>在绝大多数使用虚拟内存技术的现代操作系统上，进程内数据通讯只需要引用同一段虚拟 内存地址即可，而进程间数据通讯通常要涉及内存拷贝 [TB15]。尽管相比传统关系型数据库， Redis 已经能够提供较高的吞吐效率，但在面对如此大量的请求时，服务进程每次都要与其交互 仍然具有不小的代价(若 Redis 服务器与主服务器部署在不同的服务器主机上，交互过程还涉及 到 RPC 调用)。因此，我们希望能够在服务内的缓存中就完成对某些请求的判断操作，这也就 引出了多级缓存(Multi-Level Cache)的概念。</p><p>要过滤掉库存数量以外的请求，一个朴素的想法就是在缓存中对于每一个热点商品维护一个 “商品是否已售完”的标识符，当检测到库存降低到 0 时，就将缓存中的标识符设为 1。然而，由 于此时的请求是并发的，普通的 HashMap 并不能保证在面对如此大量的设置操作时的进程安全 性。幸运的是，社区开发者 ben-manes 提供了一个名为 Caffeine 的高性能缓存库，其可以支持以下的一些特性:</p><ul><li><p>异步的自动缓存项加载</p></li><li><p>当缓存大小达到上限时可根据访问频率和最近访问时间替换缓存</p></li><li><p>可根据最近访问时间对缓存项设置过期时间</p></li><li><p>检测到过期请求时自动刷新缓存项</p></li><li><p>弱引用时缓存键自动打包</p></li><li><p>弱引用或软引用时值自动打包</p></li><li><p>替换缓存事件通知</p></li><li><p>支持双写操作(一份写入缓存，一份写入外部空间)</p></li><li><p>可对缓存访问的特征进行聚合统计</p></li></ul><p>这些特性使得其可以很好的应对短时间内的高并发请求并保证数据的进程安全性。因此，我 们使用 Caffeine 来建立多级缓存机制。</p><p>集成了多级缓存后，一个下单请求的处理流程如下图所示(Figure 45)。当接口收到请求后， 系统会首先检查请求的 BookID 是否在 Caffeine 缓存中已经被标记为售空，若标记存在，则服 务直接返回;若不存在，再使用前文中提到的流程继续处理下单请求。</p><h4 id="kafka与消息队列">Kafka与消息队列</h4><p>在微服务构架中，我们通常会将服务分拆到多个服务器上，以方便运维和负载分离。此时， 不同服务器间的通讯和协同工作就成为了一个重要的问题。由于不同服务的处理速率差异，对于 一个特定的请求，不同服务能够接受并开始处理的时刻也各不相同。若直接让上一个服务访问下 一个服务，则会造成大量的等待时间。更进一步的，若请求响应链中的其中一个服务宕机，则 会造成整个响应过程卡死，造成请求响应失败。这时候，我们便可以使用消息队列(Message Queue)机制来解决这一问题。消息队列提供了一个公共的状态空间，使得与其关联的每个服务 都能够向其中发送/从其中获取消息。当响应链中的每个服务完成处理后，便向消息队列发送一 条消息，并标识需要接受这条消息的服务。当下游服务完成了其他请求后，便可以从消息队列中 拉取相应的消息并继续完成请求处理。这样，整个响应就可以以异步的方式完成，减少服务处理 的等待时间。</p><p>Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，其基于 Zookeeper 实现的分片 式中介服务可以很好的作为一个消息队列来使用。Kafka 的工作原理如下图所示(Figure 46)。 在一个带有 Kafka 消息队列的系统中，服务被分为生产者和消费者。生产者通过 Push 操作向 Kafka 的特定话题(Topic)发送消息，消费者通过 Pull 操作从对应的话题中拉取消息。其中， 每个 Kafka 协调器都被维护在一个 Kafka 容器中，并被统一注册到一个 Zookeeper 集群中。这 样分布式的管理方式使得 Kafka 拥有很强的伸缩性和极高的消息吞吐能力。</p><p>集成了消息队列后，一个下单请求的完整处理流程如下图所示(Figure 47)，这也是本项目最 终所采用的下单请求处理逻辑(付款请求使用了同样的逻辑)。请求到达后，系统会通过多级缓 存对请求进行一系列判断，并将无效请求快速过滤。随后，对于缓存命中的合法请求，系统会利 用 Redis 缓存中的信息快速创建订单，并将订单的信息放置到 Kafka 消息队列中。至此，下单 请求的处理已全部完成，服务会直接将订单号快速返回给用户。与此同时，一个异步的后台进程 会从消息队列中抽取下单成功的消息，并继续接管这一处理流程，将订单信息写入主数据库中。 这一分离式的服务处理流程构成了本系统能够应对高并发请求的重要基础。</p><h4 id="nginx与负载均衡">Nginx与负载均衡</h4><p>通过上面的各种缓存和优化技术，我们已经基本解决了高并发请求处理中数据库访问的性 能瓶颈。然而，由于服务本身也依托于服务器主机的性能之上，当请求规模扩大到一定数量时， 服务本身的处理性能就会成为瓶颈。对于服务的性能瓶颈问题，我们通常有两种处理方法:向上 扩展(Scale Up)和向外扩展(Scale Out)。其中，前者意味着通过升级硬件等方式提升单台 主机的性能，而后者则采用增加处理节点的方式来提升整个系统的处理能力。在当前技术工艺的 限制下，我们很难通过 Scale Up 来从根本上提升系统的性能潜能，因此我们往往会采用 Scale Out 的方式来对服务进行扩展。</p><p>当我们在多个节点上部署同一个服务后，我们就可以将接受到的请求君叹道这些节点上进行并行处理。为此，我们就需要引出所谓的负载均衡(Load Balancing)技术。</p><p>当前，学术界和工业界都提出了一系列负载均衡的实现方式，其中最常用的便是同样被我们 用作前端维生容器的 Nginx。Nginx 可以通过一种名为反向代理(Reverse Proxy)的方式来实现负载均衡，其基本原理如下图所示(Figure 49)。</p><h2 id="项目部署">项目部署</h2><p>本项目采用了前后端分离架构进行开发。要在生产环境部署本项目，目标系统上至少需要安装的依赖环境及其版本如下表所示(Table 5)。</p><p>若要从源码部署前端项目，你至少需要一个包含 quasar/cli@1.2.1 模块的 NodeJS 开发 环境。首先进入仓库的 frontend 目录，使用 quasar build 对项目进行打包。随后，前端项目的 静态资源会生成在项目的 frontend/dist/spa 目录下。之后，你需要一个能够支持前端资源的 服务容器，在这里我们使用了 Nginx 作为前端维生容器。一个部署完成的 Nginx 前端环境运行 状态如下图所示(Figure 50)。Nginx 的默认服务端口为 8080(可能与后端冲突，可自由更改)， 我们只需使用浏览器访问该地址即可。</p><p>后端的部署方式分为 JAR 包部署和 WAR 包部署两种方式。Springboot 本身包含了一个 Tomcat 服务容器，若使用前一种方式部署，框架就会自动将一个 Tomcat 容器集成至最终的 JAR 包中。此时，我们只需要在生产环境安装相应的 JAVA 运行环境即可。若想要在生产环境 下使用自定义的 Tomcat 或其他服务容器，则可以选择使用 WAR 包的方式进行部署。</p><p>就参数而言，后端服务的默认端口为 8080;PostgreSQL 连接地址为 127.0.01:5432，用 户名和密码均为 postgres，系统中应存在名称为 bookstore 的数据库;MongoDB 连接地址 为 127.0.0.1:27017;Redis 连接地址为 127.0.0.1:6379;Kafka 连接地址为 127.0.0.1:9092; ElasticSearch 连接地址为 127.0.0.1:9200。如对其中任意参数进行修改，则需要重编译后端项目。</p><h2 id="项目测试">项目测试</h2><h3 id="接口测试">接口测试</h3><h4 id="单元测试规范">单元测试规范</h4><h4 id="junit5">JUnit5</h4><h4 id="基础接口测试代码移植">基础接口测试代码移植</h4><h4 id="基础接口测试">基础接口测试</h4><h4 id="额外接口测试">额外接口测试</h4><h3 id="代码覆盖率">代码覆盖率</h3><p>我们使用了 Intellij IDEA 开发工具中自带的 Run with Coverage 功能记录了运行全部测 试时项目代码的覆盖率，结果如下图所示(Figure 53)。可以看到，我们编写的全部测试可以使 得类覆盖率达到 98.7%，方法覆盖率达到 91.7%，行覆盖率达到 90.3%。经过分析我们还可以 发现，绝大多数未覆盖的代码均为构造函数和形如 try...catch... 这样的异常处理函数，这些函 数保证了我们的系统能够应对各种突发状况和边界情况，因此其存在于代码中是必要的。若只考 虑实际功能段的代码，覆盖率将可得到进一步的提升。</p><h3 id="吞吐量测试">吞吐量测试</h3><p>我们使用实验要求中给出的测试工具对所实现的系统进行吞吐量测试(fe/test/test_bench.py)。 在 2020 版 13 英寸 Macbook Pro 上(2GHz 4 核 Intel Core i5 + 16GB LPDDR4X)上，下单和 付款接口吞吐量的测试结果如下图所示(Figure 54)。可以看到，系统的吞吐量可以达到 83000 左右，延迟可以维持在 0.008 左右。</p><p>然而，在测试过程中我们发现，实验要求中给出的这一测试程序实际上并不能正确给出两个 接口的真实吞吐量。通过修改配置文件中 Request_Per_Session(fe/conf.py)的值，我们甚至可 以测出超过 130 万的吞吐量(Figure 55)。作为对比，2020 年天猫双 11 购物节达到的最大流量 洪峰也仅达到了 583000 笔交易/秒，这一吞吐量已经给全面云原生化的阿里云造成了极大的压 力，因此测试程序给出的这一测试结果显然是不合理的。</p><p>为了得到更为可信的结果，我们还是使用 JMeter 接口压测工具对系统进行多线程压测。测 试的相关设置如下图所示(Figure 56, 57)。我们使用 1000 个线程来模拟 1000 个用户同时下单 时的场景，其中每个用户对同一本书进行 10 次下单操作，共 10000 次并发请求操作。</p><p>我们分别将请求的书本库存设置为 10000 和 100，用于分别模拟平日里普通下单场景下(商 品库存足够时)和活动促销时秒杀场景下(商品库存远小于请求量)的下单操作。经过测试，在 普通场景下，系统的下单接口吞吐量可以达到 1142 笔交易/秒(68562 笔交易/分钟)(Figure 58);在秒杀场景下，系统的吞吐量可以达到 1972 笔交易/秒(118320 笔交易/分钟)(Figure 59)。这一结果远高于直接对数据库进行访问的朴素服务响应流程(约 300 ∼ 500 笔交易/秒)， 极有力的表明了我们设计的一系列负载平衡措施起到了预期的效果。</p><h2 id="开发说明">开发说明</h2><h3 id="版本控制">版本控制</h3><p>本项目的全部工作均在水杉码源提供的 GitLab 平台上完成，并使用了 Git 工具进行版本控 制。开发过程中，项目成员共进行了 43 次提交，部分提交图如下图所示(Figure 60)。</p><img src="/2021/12/25/database/db-assignment-2/commit.png" class="" title="commit"><p>除此之外，我们还根据分工在项目仓库中建立了三个分支:master、frontend、backend (Figure 61)，方便成员集中开发自己模块上的功能。通过 Merge Request 功能，我们就能将分支中的更新合并到主分支上(Figure 62)。</p><img src="/2021/12/25/database/db-assignment-2/branch.png" class="" title="branch"><h3 id="项目分工">项目分工</h3><p>本项目共有 3 位成员，其中gxx为项目组长，dxx和lxx为项目成员。三位成员均摊了本项目的全部工作量，对本项目的贡 献相当。具体的，三位项目成员在本项目中的主要贡献及负责的任务如下表所示(Table 6)。</p><table><tbody><tr class="odd"><td>gxx</td><td>1/3</td><td>系统构架设计、数据库选型与调优、全文搜索、高可用设计与实现</td></tr><tr class="even"><td>dxx</td><td>1/3</td><td>ER 图与关系模式设计，接口设计，前端设计与开发</td></tr><tr class="odd"><td>lxx</td><td>1/3</td><td>系统功能设计、后端设计与开发、接口测试</td></tr></tbody></table><h2 id="后记">后记</h2><p>至此，本项目的全部功能和实现过程已叙述完毕。本项目从设计、构思到完成全部开发周期 超过两个月时间，仅后端源代码就超过 5000 行(Figure 63)，合计源代码更是达到了超过 70 万行(Figure 64)。项目的部分构架参考了淘宝、当当网、Bilibili 等知名电商及多媒体服务平 台的现役及历史构架，也使得我们得以对当今工业界一个完整电商平台的全开发流程有了一个 全景式的了解。</p><img src="/2021/12/25/database/db-assignment-2/line_count_java.png" class="" title="line_count_java"><img src="/2021/12/25/database/db-assignment-2/line_count_all.png" class="" title="line_count_all">]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;实验要求&quot;&gt;实验要求&lt;/h2&gt;
&lt;h3 id=&quot;功能&quot;&gt;功能&lt;/h3&gt;
&lt;p&gt;实现一个提供网上购书功能的网站后端。网站支持书商在上面开商店，购买者可能通过网站购买。买家和卖家都可以注册自己的账号。一个卖家可以开一个或多个网上商店，买家可以为自已的账户充值，在任意商</summary>
      
    
    
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Database" scheme="http://gonggongjohn.me/tags/Database/"/>
    
  </entry>
  
  <entry>
    <title>数据科学与工程算法基础 文本摘要实验</title>
    <link href="http://gonggongjohn.me/2021/12/24/machine-learning/dase-alg-exp-summary/"/>
    <id>http://gonggongjohn.me/2021/12/24/machine-learning/dase-alg-exp-summary/</id>
    <published>2021-12-24T03:00:00.000Z</published>
    <updated>2022-03-06T15:03:20.128Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>文本摘要是自然语言处理中一个十分重要的任务，一个好的摘要可以通过少量的文字很好地概括一段长文的核心内容，帮助读者快速理解文章的意思。当前，对于文本摘要任务，其方法大致可分为抽取式（Extractive）和生成式（Generative）两种，而其中前者由于拥有语句级的语法完整性，已经被广泛的应用于各种应用场景下。在抽取式文本摘要中，一种经典的方法是将其转化为最大集合覆盖问题，并采用子模函数（Submodular Function）的方法进行求解。本文详细推导并实现了基于爬山算法的文本抽取方法，讨论了一系列优化及其变体算法，并用其对同一主题下的20段论文语料进行了抽取式文本摘要。随后，我们还将其与另一种经典的抽取式文本摘要方法TextRank进行了对比，比较了两者的适用场景和异同。</p><p><strong>关键字：文本摘要，集合覆盖，子模函数，爬山算法，TextRank</strong></p><p>Text summarization is an important task in natural language processing. A good summary can summarize the crucial content of a long article with a small amount of text and help readers quickly understand the meaning of the article. Currently, the methods for text summarization task can be roughly divided into two types: Extractive and Generative. The former has been widely used in various application scenarios due to its sentence-level grammatical integrity. A classic method in extractive text summarization is to convert it into a maximum coverage problem and use the submodular function method to solve it. In this paper, we derived and implemented the extractive text summarization method based on hill climbing algorithm in detail, discussed a series of optimization and its variant algorithms, and used it to extract text summaries from a corpus of 20 papers under the same topic. Moreover, we compared it with another classic extractive text summarization method —— TextRank, and compared the application scenarios and similarities and differences of the two.</p><p><strong>Keywords: Text summarization, Set coverage, Submodular function, Hill-climbing algorithm, TextRank</strong></p><h2 id="项目概述">项目概述</h2><p>自动文本摘要是自然语言中一个十分重要的任务。这项任务要求我们从一个给定的文本语料（通常拥有较大的文本长度）中生成一段短文本，并使得其能够最大程度上表达原文本的含义。现阶段的文本摘要方法主要分为抽取式和生成式两类。其中，固定长度的抽取式文本摘要可以看作是一个<strong>最大K-子覆盖（Maximum K-Coverage Problem）</strong>，因此我们可以使用组合优化的方法来对其进行求解。本项目要求我们实现一种基于最大K-子覆盖问题的抽取式文本摘要算法，通过其一个从互联网上爬取的语料库中抽取100句话作为其文本摘要，并对摘要的性能进行分析。</p><h2 id="问题描述">问题描述</h2><p>使用最大集合子覆盖问题的语言对抽取式文本摘要问题的描述如下：</p><p>给定一个语料库 <span class="math inline">\(D = \{s_1, s_2, \cdots, s_n \}\)</span>，其中 <span class="math inline">\(s_i(i \in \{1,2,\cdots, n\})\)</span> 为单个句子，我们设其概念单元为 <span class="math inline">\(C = \{c_1, c_2, \cdots, c_m\}\)</span>，其中 <span class="math inline">\(c_i (i \in \{1,2,\cdots, m\}\)</span> 为关键词。抽取式文本摘要的目标是寻找一个子集 <span class="math inline">\(S \subset D\)</span>（其中 <span class="math inline">\(|S| \leq K\)</span>），使其能够覆盖的概念单元 <span class="math inline">\(|C&#39;|(C&#39; \subset C)\)</span> 尽可能的多。若使用优化的语言，则该问题可以写为 <span class="math display">\[\begin{aligned}&amp;\textbf{maximize} &amp;|C&#39;| \\&amp;\textbf{s.t} &amp;|S| \leq K\end{aligned}\]</span> 事实上，我们可以通过<strong>指示器变量（Indicator Variable）</strong>更具体的刻画这一问题。若设 <span class="math inline">\(x_i(i \in \{1, \cdots, n\})\)</span> 为语句选择的指示器变量，<span class="math inline">\(a_{ij}(j \in \{1, \cdots, m\})\)</span> 为关键词选择的指示器变量，也即 <span class="math display">\[\begin{aligned}&amp;x_i = \left\{\begin{aligned}1, s_i \in S \\0, s_i \notin S\end{aligned}\right., \quad&amp;a_{ij} = \left\{\begin{aligned}1, c_j \in s_i \\0, c_j \notin s_i\end{aligned}\right.\end{aligned}\]</span> 则原问题还可以写为 <span class="math display">\[\begin{aligned}&amp;\textbf{maximize} &amp;\left|\left\{j \Big| \sum_{i = 1}^n a_{ij} x_i \geq 1\right\}\right| \\&amp;\textbf{s.t} &amp; \sum_{i = 1}^n x_i \leq K, x_i \in \{0, 1\}\end{aligned}\]</span></p><p>可以看出，这是一个<strong>带有背包限制的最大集合子覆盖问题（MCKP，Maximum Coverage Problem with Knapsack Constraint）</strong>。</p><h2 id="数据集描述">数据集描述</h2><p>为了比较文本摘要算法的性能和效果，我们需要一个相应的语料库。在本文中，我们使用了同一主题下的论文文本作为语料库，论文摘要作为单文档文本摘要的关键词集合，并将一篇同主题下的综述性论文作为多文档文本摘要的关键词集合。具体的，我们爬取了预印本网站<strong>Arxiv</strong>中<strong>计算机视觉和模式识别（Computer Vision and Pattern Recognition, cs.CV）</strong>主题下的20篇有关<strong>目标检测（Object Detection）</strong>的论文，并将其作为目标语料库。此外，我们使用了发表于期刊<strong>Computer Science Review</strong>上的一篇关于目标检测的综述性论文作为多文档文本摘要的目标关键词集。</p><h3 id="数据集获取">数据集获取</h3><p>我们首先来对论文数据进行爬取。论文爬取的过程分为两步，第一步我们搜索所有满足条件的候选论文的相关信息（标题、类别、论文编号等），第二步我们下载论文的实际数据（PDF源码等资源）。</p><p>Arxiv提供了一个可以按主题查看最近一周论文的网页界面（https://arxiv.org/list/cs.CV/pastweek），因此我们首先对该网页进行分析。论文列表网页的HTML元素布局如下图所示：</p><img src="/2021/12/24/machine-learning/dase-alg-exp-summary/overview_html_aspect.png" class="" title="overview_html_aspect"><p>可以看到，对于一个论文信息显示块，其论文编号、论文标题、作者、主题分类被分别放置在标记为<strong>Abstract</strong>、<strong>list-title mathjax</strong>、<strong>list-authors</strong>和<strong>list-subjects</strong>的HTML元素块里。</p><p>我们使用Python自带的<strong>requests</strong>模块对网站发起请求，拉取其页面的HTML字符串，并使用社区开发者提供的<strong>BeautifulSoup</strong>模块对HTML的DOM结构进行解析，取出上述的元素。随后，我们将标题中带有“Object”和“Detection”两个关键词（不区分大小写）的论文取出，作为我们候选语料库文档。筛选的部分结果如下图所示：</p><img src="/2021/12/24/machine-learning/dase-alg-exp-summary/scrap_selected.png" class="" title="scrap_selected"><p>得到了论文编号后，我们就可以对论文的各种元数据（MetaData）进行获取。我们可以通过解析https://arxiv.org/abs/{arXiv_ID}获得论文的摘要，通过{https://arxiv.org/pdf/{arXiv_ID}下载其PDF文档，通过https://arxiv.org/e-print/{arXiv_ID}下载其原始资源，在此不再赘述。</p><p>事实上，Arxiv本身提供了一个可供程序访问的论文资源获取的API（实现完才发现QAQ）。我们只需要使用<strong>布尔查询表达式（Boolean Query Expression）</strong>即可获得相应的论文结果。社区开发者对其接口请求和数据格式进行了封装，因此在Python我们只需直接引入arxiv包即可发起查询并获得论文的<strong>标题</strong>、<strong>摘要</strong>、<strong>PDF文档</strong>及<strong>原始文档（Latex文本及图片等源文件）</strong>等资源。</p><p>同样的，我们使用该API实现了自动爬取论文源数据的相关代码，并获得了最终的语料库。</p><h3 id="文本预处理">文本预处理</h3><h4 id="文本提取">文本提取</h4><p>得到了原始的论文文档后，我们需要对文档集进行整理和清洗，抽取出语料库，并对文本进行预处理。</p><p>我们首先尝试使用<strong>Pdfminer</strong>模块直接对论文的PDF文档进行分析，通过关键字的方式对文本进行抽取，结果如下图所示：</p><img src="/2021/12/24/machine-learning/dase-alg-exp-summary/pdfminer_success.png" class="" title="pdfminer_success"><img src="/2021/12/24/machine-learning/dase-alg-exp-summary/pdfminer_fail.png" class="" title="pdfminer_fail"><p>。可以看到，由于PDF是以矢量图的方式对元素进行排布，其排布并不完全按照视觉上的排布顺序，因此该方法并不能准确的抽取出文档中的相应文本。</p><p>事实上，我们可以通过对PDF文档进行<strong>版面分析（Layout Analysis）</strong>的方式提取论文的原始文本，但这一做法就导致不确定因素更多，使问题变得更为复杂，因此我们不做考虑。</p><p>幸运的是，Arxiv提供了论文源文件的下载地址，这也就意味着我们可以直接获取到论文的Latex源代码。因此，我们只需要直接从Latex文档中对纯文本进行抽取即可。Latex是一种标准化的排版工具，我们可以通过声明式的代码语言在一个Latex文档中插入各种元素。由于我们只需要对其中的纯文本进行分析，因此这些元素在当前的任务下是多余的。这时，我们就需要使用正则表达式对其进行替换。例如，对于<strong>\cite{}</strong>，我们就可以使用正则表达式 \\cite\{(.*?)\}将其匹配出来。</p><h2 id="方法">方法</h2><h3 id="朴素枚举法">朴素枚举法</h3><h3 id="贪心算法爬山算法">贪心算法（爬山算法）</h3><h3 id="带权的贪心算法">带权的贪心算法</h3><h3 id="stack-encoding">Stack Encoding</h3><h3 id="textrank">TextRank</h3><h2 id="实验结果">实验结果</h2><p>最后，我们从摘要质量和摘要推理时间两个方面来对上面的方法进行分析。</p><p>对于摘要质量，我们自然的可以想到使用关键词覆盖率作为其评价指标。沿用上面的记号，若我们将抽取出的概括文本 <span class="math inline">\(S\)</span> 看作词项的集合，则覆盖率被定义为 <span class="math display">\[Coverage = S \cap C\]</span> 。对于文本摘要任务，一个常用的评价指标被称为<strong>ROUGE-N（Recall-Oriented Understudy for Gisting Evaluation-N）</strong>，其定义为 <span class="math display">\[ROUGE-N = \frac{|N-Gram_{Extracted} \cap N-Gram_{Reference}|}{|N-Gram_{Reference}|}\]</span> ，也即抽取的摘要中匹配的N-Gram数除以标准摘要中的N-Gram总数。从定义中我们可以发现，ROUGE-N通常需要一个参考的摘要文本才能计算，而这里我们并没有这样的文本。不过，由于我们有目标关键字，而这可以视作一种1-Gram，因此我们仍然可以计算ROUGE-1的值。</p><h2 id="结论">结论</h2><p>在本实验中，我们首先从集合覆盖的角度分析了抽取式文本摘要问题，并将其转化了为了一个MCKP问题。由于该问题是一个NP-Hard问题，我们无法在可接受的时间内用朴素搜索算法求解出精确解。随后，我们实现了基于贪心算法的最大子覆盖算法，并用其实现了抽取式文本摘要。进一步的，我们对贪心算法实现了一系列的改进，包括考虑文本的权重，以及使用队列的方式进行聚合搜索。最后，我们实现了经典的TextRank算法，并将其与前面的算法进行了比较。</p><p>我们可以很容易的发现，基于最大子覆盖的文本摘要算法能够更好的贴合目标关键字，但其语义连贯性明显不如TextRank算法。这就意味着当我们有一个好的关键词集合或面对多文档摘要场景时，我们可以使用基于最大子覆盖问题的文本摘要算法。而在实际应用场景或单文本的摘要场景下，我们更倾向于使用TextRank等基于语义的文本摘要算法。</p><p>通过本实验，我们对抽取式文本摘要任务和子模函数、最大K-子覆盖问题有了更深入的了解。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;文本摘要是自然语言处理中一个十分重要的任务，一个好的摘要可以通过少量的文字很好地概括一段长文的核心内容，帮助读者快速理解文章的意思。当前，对于文本摘要任务，其方法大致可分为抽取式（Extractive）和生成式（Generative）</summary>
      
    
    
    
    <category term="数据科学算法基础" scheme="http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Machine-Learning" scheme="http://gonggongjohn.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>数据科学与工程算法基础 PCA实验</title>
    <link href="http://gonggongjohn.me/2021/11/29/machine-learning/dase-alg-exp-pca/"/>
    <id>http://gonggongjohn.me/2021/11/29/machine-learning/dase-alg-exp-pca/</id>
    <published>2021-11-29T02:00:00.000Z</published>
    <updated>2022-02-12T10:16:50.056Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>图像压缩一直是图像处理中一个重要的任务，一个好的图像压缩算法可以大大降低存储和传输代价。主成分分析（Principal Component Analysis）作为一个经典的降维方法，已经在图像压缩领域得到了极为广泛的运用。在本文中，我们从主成分分析的原理出发，导出并实现了基于特征分解的朴素PCA算法，并使用奇异值分解方法对其计算进行了优化。随后，我们实现了更适合图像处理的2DPCA、其改进方法2D-2DPCA。此外，我们还实现了基于核方法的Kernel PCA来进一步提升主成分的表达能力，并对比了多种不同的核函数下图像的压缩效果。进一步的，我们尝试使用了较为现代的基于神经网络的GHA（Generalized Hebbian Algorithm）算法来迭代得到主成分。最后，我们将实现的结果与时下较为常用的基于离散余弦变换的JPEG图像压缩算法进行了对比。</p><p><strong>关键字：图像压缩，主成分分析，核方法，感知机，余弦变换</strong></p><p>Image compression has long be a fundamental task in image processing, a good image compression algorithm can massively reduce the cost of storage and transmission. As a classic dimension reduction algorithm, Principle Component Analysis has been widely used in the field of image compression. In this article, we derive and implement the naive PCA algorithm based on eigenvalue decomposition, and use the singular value decomposition method to optimize its calculation. Subsequently, we implemented 2DPCA and its improvement version 2D-2DPCA, which is more suitable for image processing. In addition, we implemented Kernel PCA based on the kernel method to further improve the expression ability of principal components, and compared the compression effects of images under a variety of different kernel functions. Further, we tried to use a more modern neural network-based GHA (Generalized Hebbian Algorithm) algorithm to iteratively obtain the principal components. Finally, we compared the achieved results with the contemporary mainstream JPEG image compression algorithm which is based on discrete cosine transform.</p><p><strong>Keywords: Image compression, Principle component analysis, Perceptron, Cosine transformation</strong></p><h2 id="项目概述">项目概述</h2><p>主成分分析（Principal Component Analysis）可以用来减少矩阵（图像）的维度，并将这些新的维度投射到图像上，使其保留质量。本项目要求我们使用PCA方法及其变体，对3组图像（每组包含100张图像）进行压缩，并对图像压缩的性能进行分析。</p><h2 id="问题描述">问题描述</h2><p>一张<span class="math inline">\(8\)</span>位三通道（RGB）正方形彩色图片可视为三个 <span class="math inline">\(N\)</span> 维矩阵 <span class="math inline">\(\boldsymbol{X}\)</span>，其中 <span class="math inline">\(x_{ij} \in \{0,1, \cdots, 255\}\)</span>，其存储代价为 <span class="math inline">\(b\)</span>。图像压缩的目标即为寻找一个映射 <span class="math inline">\(\mathcal{Q}\)</span>，使得 <span class="math inline">\(\mathcal{Q}(\boldsymbol{X}) \in \mathbb{R}^{k \times n}(k \ll n), \mathcal{Q}^{-1} (\mathcal{Q}(\boldsymbol{X})) \approx X\)</span>，且存储 <span class="math inline">\(\mathcal{Q} (\boldsymbol{X})\)</span> 和 <span class="math inline">\(\mathcal{Q}^{-1}\)</span> 所需的空间 <span class="math inline">\(\tilde{b} \ll b\)</span>。</p><h2 id="方法">方法</h2><h3 id="朴素pca">朴素PCA</h3><p>PCA的主要思想是通过将一个高维样本 <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^n\)</span> 左乘一个正交矩阵 <span class="math inline">\(\boldsymbol{Q} \in \mathbb{R}^{k \times n}(k \ll n)\)</span>，使得其映射到一个较低维的超平面 <span class="math inline">\(\boldsymbol{Q x} \in \mathbb{R}^k\)</span> 上，同时又保证多个数据点映射后的统计性质保持不变。具体来说，这样的超平面要具有如下的性质：</p><ul><li><strong>最近重构性：</strong>样本点到这个超平面的距离足够近</li><li><strong>最大可分性：</strong>样本点在这个超平面上的投影尽可能分开</li></ul><p>由此，我们就有两种角度来求解这一正交矩阵。事实上，在中心化条件下，这两者是等价的。这是由于有如下定理保证：</p><blockquote><p><strong>Theorem:</strong> 对于中心化数据集 <span class="math inline">\(\{\boldsymbol{x}^{(i)}\}_{i = 1}^N\)</span>，最小化重构距离等价于最大化投影方差</p><p><strong>Proof:</strong> 这里仅证明投影到一维时的情形，高维时的情况可自然推广</p><p>设投影直线的方向向量为 <span class="math inline">\(\boldsymbol{v}\)</span>，其中 <span class="math inline">\(||\boldsymbol{v}||^2 = 1\)</span></p><p>则由勾股定理可知，<span class="math inline">\(||\boldsymbol{x}^{(i)} - \boldsymbol{v^T} \boldsymbol{x}^{(i)}\boldsymbol{v}||^2 = ||\boldsymbol{x}^{(i)}||^2 - \left(\boldsymbol{v}^T \boldsymbol{x}^{(i)}\right)^2\)</span></p><p>于是 <span class="math inline">\(\boldsymbol{v}\)</span> 的最优解 <span class="math display">\[\begin{aligned}\boldsymbol{v}^* &amp;= \mathop{\arg\min}_{\boldsymbol{v}: ||\boldsymbol{v}||^2 = 1} \frac{1}{N} \sum_{i = 1}^N ||\boldsymbol{x}^{(i)} - \boldsymbol{v^T} \boldsymbol{x}^{(i)}\boldsymbol{v}||^2 \\&amp;= \mathop{\arg\min}_{\boldsymbol{v}: ||\boldsymbol{v}||^2 = 1} \frac{1}{N} \sum_{i = 1}^N \left( ||\boldsymbol{x}^{(i)}||^2 - \left(\boldsymbol{v}^T \boldsymbol{x}^{(i)}\right)^2 \right) \\&amp;= \mathop{\arg\max}_{\boldsymbol{v}: ||\boldsymbol{v}||^2 = 1} \frac{1}{N} \sum_{i = 1}^N \left(\boldsymbol{v}^T \boldsymbol{x}^{(i)}\right)^2\end{aligned}\]</span> 也即最小化重构距离与最大化投影方差等价</p></blockquote><p>这里我们通过最大化投影方差的方法来求解。 我们知道，对于一个中心化矩阵 <span class="math inline">\(\boldsymbol{X}\)</span>（即 <span class="math inline">\(E(\boldsymbol{X}) = \boldsymbol{0}\)</span>），其协方差矩阵 <span class="math display">\[\begin{aligned}\Sigma (\boldsymbol{X}) &amp;= E \left[ (\boldsymbol{X} - E(\boldsymbol{X})) (\boldsymbol{X} - E(\boldsymbol{X}))^T \right] \\&amp;= \begin{pmatrix}\textrm{Cov}(\boldsymbol{X}_1, \boldsymbol{X}_1) &amp; \textrm{Cov}(\boldsymbol{X}_1, \boldsymbol{X}_2) &amp;\cdots &amp;\textrm{Cov}(\boldsymbol{X}_1, \boldsymbol{X}_n) \\\textrm{Cov}(\boldsymbol{X}_2, \boldsymbol{X}_1) &amp; \textrm{Cov}(\boldsymbol{X}_2, \boldsymbol{X}_2) &amp;\cdots &amp;\textrm{Cov}(\boldsymbol{X}_2, \boldsymbol{X}_n) \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\\textrm{Cov}(\boldsymbol{X}_n, \boldsymbol{X}_1) &amp; \textrm{Cov}(\boldsymbol{X}_n, \boldsymbol{X}_2) &amp;\cdots &amp;\textrm{Cov}(\boldsymbol{X}_n, \boldsymbol{X}_n)\end{pmatrix} \\&amp;= \frac{1}{N} \boldsymbol{X} \boldsymbol{X}^T\end{aligned}\]</span> 若将投影矩阵 <span class="math inline">\(\boldsymbol{Q}\)</span> 按行划分为向量组，也即设 <span class="math display">\[\boldsymbol{Q} = \begin{pmatrix}\boldsymbol{q}_1 \\\boldsymbol{q}_2 \\\vdots \\\boldsymbol{q}_k\end{pmatrix}\]</span> ，则要使得投影方差和最大，也即求解 <span class="math display">\[\begin{aligned}\mathop{\arg\max}_{\boldsymbol{Q}: \boldsymbol{Q}\boldsymbol{Q}^T = \boldsymbol{I}} \sum_{i = 1}^k || \boldsymbol{q}_i \boldsymbol{X} ||_2^2 &amp;= \mathop{\arg\max}_{\boldsymbol{Q}: \boldsymbol{Q}\boldsymbol{Q}^T = \boldsymbol{I}} ||\boldsymbol{QX}||_F^2 \\&amp;=\mathop{\arg\max}_{\boldsymbol{Q}: \boldsymbol{Q}\boldsymbol{Q}^T = \boldsymbol{I}} \textrm{tr} \left( \boldsymbol{X}^T \boldsymbol{Q}^T \boldsymbol{Q} \boldsymbol {X} \right)\end{aligned}\]</span> 由此可得优化问题 <span class="math display">\[\begin{aligned}\min \quad &amp; - \textrm{tr} \left( \boldsymbol{X}^T \boldsymbol{Q}^T \boldsymbol{Q} \boldsymbol {X} \right) \\\textbf{s.t} \quad &amp; \boldsymbol{Q} \boldsymbol{Q}^T = \boldsymbol{I}_{k \times k}\end{aligned}\]</span> 利用拉格朗日乘子法，我们可得当目标函数取到最小值时，有 <span class="math display">\[\boldsymbol{Q} \boldsymbol{X} \boldsymbol{X}^T = \boldsymbol{Q} \boldsymbol{\lambda}\]</span> 也即 <span class="math inline">\(\boldsymbol{Q}\)</span> 中的第 <span class="math inline">\(i\)</span> 行为 <span class="math inline">\(\boldsymbol{X} \boldsymbol{X}^T\)</span> 的第 <span class="math inline">\(i\)</span> 个特征值 <span class="math inline">\(\lambda_i\)</span> 对应的特征向量。进一步的，将结果代回原式我们可以发现，由于 <span class="math inline">\(\boldsymbol{Q}\)</span> 为一个 <span class="math inline">\(k \times n\)</span> 的矩阵，因此若要使得目标函数取到最小值，<span class="math inline">\(\boldsymbol{Q}\)</span> 中的行向量应取前 <span class="math inline">\(k\)</span> 大的特征值所对应的特征向量。</p><p>在图像压缩任务中，当将数据集映射到低维空间后，我们还需要将其重构回原来的图像空间以保证图像的可用性。对于使用正交变换的PCA方法，这一重构任务是容易的。由于 <span class="math inline">\(\boldsymbol{Q}\)</span> 为一正交矩阵，其逆矩阵 <span class="math inline">\(\boldsymbol{Q}^{-1} = \boldsymbol{Q}^T\)</span>。因此要重构压缩后的图像，进行我们只需要对降维数据进行逆变换，即左乘 <span class="math inline">\(\boldsymbol{Q}^T\)</span> 即可。</p><p>由此，我们导出了使用朴素PCA方法进行图像压缩的一般过程。需要注意的是，要使用基于特征分解的PCA方法对图像进行分析和处理，我们需要将图像矩阵划分为向量组并进行中心化操作，这里我们采用按列划分的方法。算法的具体流程如下：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/naive_pca_alg.png" class="" title="naive_pca_alg"><p>在选择了不同主成分个数时，使用朴素PCA算法进行图像压缩的效果结果如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/naive_pca_pic.png" class="" title="naive_pca_pic"><p>可以看到，仅使用前10个主成分已经能还原出整体的图像轮廓，当 <span class="math inline">\(k=50\)</span> 时，图像的细节已基本得到恢复。</p><h3 id="基于奇异值分解的pca">基于奇异值分解的PCA</h3><p>可以看到，基于特征值分解的PCA算法中计算开销最大的部分为计算协方差矩阵 <span class="math inline">\(\boldsymbol{X} \boldsymbol{X}^T\)</span> 的特征值与特征向量。事实上，我们可以使用奇异值分解来避免这一高开销计算，一个 <span class="math inline">\(m \times n\)</span> 的矩阵 <span class="math inline">\(\boldsymbol{A}\)</span> 的奇异值分解是指将其分解为三个特殊矩阵乘积的形式 <span class="math inline">\(\boldsymbol{A} = \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^T\)</span>，其中 <span class="math inline">\(\boldsymbol{U}\)</span> 为 <span class="math inline">\(m\)</span> 阶正交矩阵，<span class="math inline">\(\boldsymbol{V}\)</span> 为 <span class="math inline">\(n\)</span> 阶正交矩阵，<span class="math inline">\(\Sigma\)</span> 是由降序排列的非负的对角线元素组成的 <span class="math inline">\(m \times n\)</span> 对角矩阵。</p><p>对于任意实矩阵，我们都能找到它的奇异值分解。这是由于有如下定理保证：</p><blockquote><p><strong>Theorem:</strong> 若 <span class="math inline">\(\boldsymbol{A}\)</span> 为一 <span class="math inline">\(m \times n\)</span> 实矩阵，<span class="math inline">\(\boldsymbol{A} \in \mathbb{R}^{m \times n}\)</span>，则 <span class="math inline">\(\boldsymbol{A}\)</span> 的奇异值分解存在 <span class="math inline">\(\boldsymbol{A} = \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^T\)</span>其中 <span class="math inline">\(\boldsymbol{U}\)</span> 是 <span class="math inline">\(m\)</span> 阶正交矩阵，<span class="math inline">\(\boldsymbol{V}\)</span> 是 <span class="math inline">\(n\)</span> 阶正交矩阵，<span class="math inline">\(\boldsymbol{\Sigma}\)</span> 是 <span class="math inline">\(m \times n\)</span> 对角矩阵，其前 <span class="math inline">\(r\)</span> 个对角元素 <span class="math inline">\((\sigma_1, \cdots, \sigma_r)\)</span> 为正，且按降序排列，其余均为 <span class="math inline">\(0\)</span>。</p><p><strong>Proof:</strong> 由于 <span class="math inline">\(\boldsymbol{A}^T \boldsymbol{A}\)</span> 为对称半正定矩阵，因此可以对其进行特征分解 <span class="math inline">\(\boldsymbol{A}^T \boldsymbol{A} = \boldsymbol{V} \boldsymbol{\Lambda}_n \boldsymbol{V}^T\)</span>，其中 <span class="math inline">\(V \in \mathbb{R}^{n \times n}\)</span> 是正交矩阵，<span class="math inline">\(\boldsymbol{\Lambda}_n\)</span> 是对称矩阵，并且对角线元素是 <span class="math inline">\(\boldsymbol{A}^T \boldsymbol{A}\)</span> 的特征值 <span class="math inline">\(\lambda_i \geq 0, i = 1, \cdots, n\)</span>，并且是按降序排列的。因为 <span class="math inline">\(\textrm{rank} (\boldsymbol{A}) = \textrm{rank}(\boldsymbol{A}^T \boldsymbol{A}) = r\)</span>，所以前 <span class="math inline">\(r\)</span> 个特征值是正的。</p><p>注意到 <span class="math inline">\(\boldsymbol{A} \boldsymbol{A}^T\)</span> 和 <span class="math inline">\(\boldsymbol{A}^T \boldsymbol{A}\)</span> 有相同的非零特征值，因此他们的秩是相等的。我们定义 <span class="math display">\[\sigma_i = \sqrt{\lambda_i} &gt; 0, i = 1, \cdots, r\]</span> ，记 <span class="math inline">\(\boldsymbol{v}_1, \cdots,\boldsymbol{v}_r\)</span> 是 <span class="math inline">\(\boldsymbol{V}\)</span> 的前 <span class="math inline">\(r\)</span> 列，它们同时也是 <span class="math inline">\(\boldsymbol{A}^T \boldsymbol{A}\)</span> 前 <span class="math inline">\(r\)</span> 个特征值对应的特征向量。即有 <span class="math display">\[\boldsymbol{A}^T \boldsymbol{A} \boldsymbol{v}_i = \lambda_i \boldsymbol{v}_i, i = 1, \cdots, r\]</span> 。因此同时在两边左乘上 <span class="math inline">\(\boldsymbol{A}\)</span> 就有 <span class="math display">\[(\boldsymbol{A} \boldsymbol{A}^T) \boldsymbol{A} \boldsymbol{v}_i = \lambda_i \boldsymbol{A} \boldsymbol{v}_i,i = 1, \cdots, r\]</span> 。这就意味着 <span class="math inline">\(\boldsymbol{A} \boldsymbol{v}_i\)</span> 是 <span class="math inline">\(\boldsymbol{A} \boldsymbol{A}^T\)</span> 的特征向量，因为 <span class="math inline">\(\boldsymbol{v}_i^T \boldsymbol{A}^T \boldsymbol{A} \boldsymbol{v}_j = \lambda_j \boldsymbol{v}_i^T \boldsymbol{v}_j\)</span> 所以这些特征向量也是正交的。所以将他们标准化则有</p><p><span class="math display">\[\boldsymbol{u}_i = \frac{\boldsymbol{A} \boldsymbol{v}_i}{\sqrt{\lambda_i}} = \frac{\boldsymbol{A} \boldsymbol{v}_i}{\sigma_i}, i = 1, \cdots, r\]</span> 这些 <span class="math inline">\(\boldsymbol{u}_1, \cdots, \boldsymbol{u}_r\)</span> 是 <span class="math inline">\(r\)</span> 个 <span class="math inline">\(\boldsymbol{A} \boldsymbol{A}^T\)</span> 关于非零特征值 <span class="math inline">\(\lambda_1, \cdots, \lambda_r\)</span> 的特征向量。因此 <span class="math display">\[\boldsymbol{u}_i^T \boldsymbol{A} \boldsymbol{v}_j = \frac{1}{\sigma_i} \boldsymbol{v}_i^T \boldsymbol{A}^T \boldsymbol{A} \boldsymbol{v}_j = \frac{\lambda_j}{\sigma_i} \boldsymbol{v}_i^T \boldsymbol{v}_j = \left\{\begin{aligned}\sigma_i, &amp; i = j \\0, 其他\end{aligned}\right.\]</span> 以矩阵的方式重写即有</p><p><span class="math display">\[\begin{pmatrix}\boldsymbol{u}_1^T \\\vdots \\\boldsymbol{u}_r^T\end{pmatrix}\boldsymbol{A}(\boldsymbol{v}_1, \cdots, \boldsymbol{v}_r)= \textrm{diag} (\sigma_1, \cdots, \sigma_r) = \boldsymbol{\Sigma}_r\]</span></p><p>注意到根据定义 <span class="math display">\[\boldsymbol{A}^T \boldsymbol{A} \boldsymbol{v}_i = 0, i = r + 1, \cdots, n\]</span> 即有 <span class="math display">\[\boldsymbol{A} \boldsymbol{v}_i = 0, i = r + 1, \cdots, n\]</span> 取相互正交的单位向量 <span class="math inline">\(\boldsymbol{u}_{r+1}, \cdots, \boldsymbol{u}_m\)</span> 均与 <span class="math inline">\(\boldsymbol{u}_1, \cdots, \boldsymbol{u}_r\)</span> 正交，即有 <span class="math display">\[\boldsymbol{u}_i^T \boldsymbol{A} \boldsymbol{v}_j = 0. i = 1, \cdots, m; j = r + 1, \cdots, n\]</span> 它们共同构成了 <span class="math inline">\(\mathbb{R}^m\)</span> 的一组标准正交基。因此，扩展前述奇异值分解式即有 <span class="math display">\[\begin{pmatrix}\boldsymbol{u}_1^T \\\vdots \\\boldsymbol{u}_m^T\end{pmatrix}\boldsymbol{A}(\boldsymbol{v}_1, \cdots, \boldsymbol{v}_n)= \begin{pmatrix}\boldsymbol{\Sigma}_r &amp; \boldsymbol{0}^T \\\boldsymbol{0} &amp; \boldsymbol{O}\end{pmatrix}= \boldsymbol{\Sigma}\]</span> 令 <span class="math inline">\(\boldsymbol{U} = (\boldsymbol{u}_1, \cdots, \boldsymbol{u}_m)\)</span>，<span class="math inline">\(\boldsymbol{V} = (\boldsymbol{v}_1, \cdots, \boldsymbol{v}_n)\)</span>，即有 <span class="math inline">\(\boldsymbol{A} = \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^T\)</span>。 由此可知，矩阵 <span class="math inline">\(\boldsymbol{A}\)</span> 必存在奇异值分解。</p></blockquote><p>根据矩阵的奇异值分解定理，对于中心化图像矩阵 <span class="math inline">\(\boldsymbol{X}\)</span>，我们有 <span class="math display">\[\begin{aligned}\boldsymbol{X}^T \boldsymbol{X} &amp;= \left( \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^T \right)^T \left( \boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^T \right) \\&amp;= \boldsymbol{V} \boldsymbol{\Sigma} \boldsymbol{V}^T\end{aligned}\]</span> 也即 <span class="math inline">\(\boldsymbol{X}^T \boldsymbol{X} \boldsymbol{V} = \boldsymbol{V} \boldsymbol{\Sigma}\)</span>。由此我们得知协方差矩阵的第 <span class="math inline">\(i\)</span> 个特征向量也即右奇异值矩阵 <span class="math inline">\(\boldsymbol{V}\)</span> 的第 <span class="math inline">\(i\)</span> 列。</p><p>基于奇异值分解的PCA图像压缩算法具体流程如下：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/svd_pca_alg.png" class="" title="svd_pca_alg"><p>同样的，我们使用Python实现了上述算法。对于奇异值分解操作，我们使用Numpy模块中提供的<strong>svd()</strong>函数来完成。Numpy模块使用了LAPACK科学计算包来完成矩阵分解的相关操作。其中，SVD分解采用了<strong>Householder变换</strong>的方式来完成，这一操作的时间开销远低于一般的采用<strong>Gram-Schimdt正交化</strong>的求解方式，也远低于对协方差矩阵作特征值分解的时间开销。</p><h3 id="dpca">2DPCA</h3><p>由于常规的PCA方法是对向量组进行操作，因此当我们使用该方法对图像进行压缩时，需要先将其划分为列向量组再进行处理。由此得到的协方差矩阵规模十分巨大，需要极大的时间开销来完成计算。此外，由于图像压缩通常被作为其他图像处理任务的上游任务，如此操作会导致图像的特征信息出现大量的丢失。因此，之后的研究者提出了另一种简单的图像投影技术，称为<strong>二维主成分分析(2DPCA)</strong>，专门用于图像特征提取。与传统的PCA方法不同，2DPCA基于2D矩阵直接构建图像的协方差矩阵。与PCA的协方差矩阵相比，使用2DPCA的图像协方差矩阵的大小要小得多，这就意味着确定相应的特征向量所需的时间更少。此外，由于其更多的利用了图像的空间信息，对图像的特征也能够更好的保留。</p><p>2DPCA的主要思想是直接利用一个 <span class="math inline">\(n \times k\)</span> 维矩阵对整张图像进行投影。这里我们先考虑投影矩阵为一维时的情况，再将其推广到 <span class="math inline">\(k\)</span> 维上去。</p><p>若设图像矩阵为 <span class="math inline">\(\boldsymbol{A}\)</span>，<span class="math inline">\(\boldsymbol{X}\)</span> 为投影向量，<span class="math inline">\(\boldsymbol{Y} = \boldsymbol{AX}\)</span> 为投影后的特征。则 <span class="math inline">\(\boldsymbol{Y}\)</span> 的协方差矩阵 <span class="math inline">\(\boldsymbol{S}_x\)</span> 可以写为 <span class="math display">\[\begin{aligned}\boldsymbol{S}_x &amp;= E \left[(\boldsymbol{Y} - E[\boldsymbol{Y}])(\boldsymbol{Y} - E[\boldsymbol{Y}])^T \right] \\&amp;=E \left[(\boldsymbol{AX} - E[\boldsymbol{AX}])(\boldsymbol{AX} - E[\boldsymbol{AX}])^T \right] \\&amp;= E \left[((\boldsymbol{A} - E[\boldsymbol{A}]) \boldsymbol{X})((\boldsymbol{A} - E[\boldsymbol{A}]) \boldsymbol{X})^T \right]\end{aligned}\]</span> 与一般的PCA方法类似，我们定义判断投影好坏的评价指标为 <span class="math inline">\(J(\boldsymbol{X}) = \textrm{tr} (\boldsymbol{S}_x)\)</span>，则代入上面的式子就可以写为 <span class="math display">\[\begin{aligned}J(\boldsymbol{X}) &amp;= \textrm{tr} (\boldsymbol{S}_x) \\&amp;= \boldsymbol{X}^T E \left[ (\boldsymbol{A} - E[\boldsymbol{A}])^T (\boldsymbol{A} - E[\boldsymbol{A}]) \right] \boldsymbol{X}\end{aligned}\]</span> 。从上面的式子我们可以看出，2DPCA通常是同时作用于多张图像矩阵上的，这也是其协方差矩阵维度相对较小的原因。若设图像集合为 <span class="math inline">\(\boldsymbol{A}_1, \cdots, \boldsymbol{A}_M\)</span>，则 <span class="math display">\[\begin{aligned}\boldsymbol{G} &amp;\overset{def}{=} E \left[ (\boldsymbol{A} - E[\boldsymbol{A}])^T (\boldsymbol{A} - E[\boldsymbol{A}]) \right] \\&amp;= \frac{1}{M} \sum_{i = 1}^M \left( \boldsymbol{A}_i - \bar{\boldsymbol{A}} \right)^T \left( \boldsymbol{A}_i - \bar{\boldsymbol{A}} \right)\end{aligned}\]</span> 现在我们将投影矩阵推广为 <span class="math inline">\(k\)</span> 维，也即设投影矩阵为 <span class="math inline">\(\boldsymbol{X} = \{\boldsymbol{X}_1, \cdots, \boldsymbol{X}_d \}\)</span>，则优化问题为 <span class="math display">\[\begin{aligned}\min \quad &amp; - J(\boldsymbol{X}) \\\textbf{s.t} \quad &amp; \boldsymbol{X}_i^T \boldsymbol{X}_j = 0, i \neq j\end{aligned}\]</span> 由拉格朗日乘子法我们可以得知，要提取前 <span class="math inline">\(k\)</span> 个特征，投影矩阵的最优解即为 <span class="math inline">\(\boldsymbol{G}\)</span> 前 <span class="math inline">\(k\)</span> 大个特征值对应的特征向量所组成的矩阵。</p><p>由此我们就得到了使用2DPCA进行图像压缩的一般算法：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/2d_pca_alg.png" class="" title="2d_pca_alg"><p>在选择了不同主成分个数时，使用2DPCA算法进行图像压缩的效果结果如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/2d_pca_pic.png" class="" title="2d_pca_pic"><h3 id="d-2dpca">2D-2DPCA</h3><p>在上述介绍的2DPCA中，若我们用 <span class="math inline">\(\boldsymbol{A}^{(t)}\)</span> 来表示矩阵 <span class="math inline">\(\boldsymbol{A}\)</span> 的第 <span class="math inline">\(t\)</span> 行，则 <span class="math display">\[\begin{aligned}\boldsymbol{A}_i &amp;= \left( \left( \boldsymbol{A}_i^{(1)} \right)^T,  \cdots, \left( \boldsymbol{A}_i^{(n)} \right)^T \right)^T \\\bar{\boldsymbol{A}} &amp;= \left( \left( \bar{\boldsymbol{A}}^{(1)} \right)^T,  \cdots, \left( \bar{\boldsymbol{A}}^{(n)} \right)^T \right)^T\end{aligned}\]</span> ，于是协方差矩阵 <span class="math inline">\(\boldsymbol{G}\)</span> 就可以被写为 <span class="math display">\[\boldsymbol{G} = \frac{1}{M} \sum_{i = 1}^M \sum_{k = 1}^n \left( \boldsymbol{A}_i^{(k)} - \bar{\boldsymbol{A}}^{(k)}\right)^T \left( \boldsymbol{A}_i^{(k)} - \bar{\boldsymbol{A}}^{(k)}\right)\]</span> 。通过该式我们可以发现，<span class="math inline">\(\boldsymbol{G}\)</span> 可以通过图像集合中行向量的外积得到，这也就意味着2DPCA实际上仅按行提取了图像之间的联系。自然的，我们可以想到是否可以用类似的方法提取图像列之间的联系并将它们结合在一起，从而挖掘出图像更多的特征联系。这一想法也就形成了所谓的<strong>双方向二维主成分分析（2D-2DPCA）</strong>。</p><p>我们设 <span class="math inline">\(\boldsymbol{Z} \in \mathbb{R}^{n \times k}\)</span> 为另一投影矩阵，其作用即为对图像矩阵 <span class="math inline">\(\boldsymbol{A}\)</span> 的列进行投影。于是与2DPCA的做法类似，我们设矩阵 <span class="math inline">\(\boldsymbol{A}\)</span> 投影得到的特征为 <span class="math display">\[\boldsymbol{B} = \boldsymbol{Z}^T \boldsymbol{A}\]</span> 。于是投影得到的协方差矩阵即为 <span class="math display">\[J(\boldsymbol{Z}) = \boldsymbol{Z}^T E \left[ (\boldsymbol{A} - E[\boldsymbol{A}]) (\boldsymbol{A} - E[\boldsymbol{A}])^T \right] \boldsymbol{Z}\]</span> 我们定义 <span class="math display">\[\begin{aligned}\boldsymbol{G}&#39; &amp;\overset{def}{=} E \left[ (\boldsymbol{A} - E[\boldsymbol{A}]) (\boldsymbol{A} - E[\boldsymbol{A}])^T \right] \\&amp;= \frac{1}{M} \sum_{i = 1}^M  \left( \boldsymbol{A}_i - \bar{\boldsymbol{A}} \right) \left( \boldsymbol{A}_i - \bar{\boldsymbol{A}} \right)^T \\&amp;= \frac{1}{M} \sum_{i = 1}^M \sum_{k = 1}^n \left( \boldsymbol{A}_i^{(k)} - \bar{\boldsymbol{A}}^{(k)}\right) \left( \boldsymbol{A}_i^{(k)} - \bar{\boldsymbol{A}}^{(k)}\right)^T\end{aligned}\]</span> 其中 <span class="math inline">\(\boldsymbol{A}^{(t)}\)</span> 为矩阵 <span class="math inline">\(\boldsymbol{A}\)</span> 的第 <span class="math inline">\(t\)</span> 列。</p><p>与上面类似，我们最大化 <span class="math inline">\(J(\boldsymbol{Z})\)</span>，同样可以得到 <span class="math inline">\(\boldsymbol{Z}\)</span> 的最优解即为 <span class="math inline">\(\boldsymbol{G}\)</span> 的前 <span class="math inline">\(k\)</span> 大个特征值对应的特征向量所组成的矩阵。</p><p>将行投影和列投影结合，我们就能得到图像集合中的任一图像 <span class="math inline">\(\boldsymbol{A}\)</span> 经过投影后的特征为 <span class="math display">\[\boldsymbol{C} = \boldsymbol{Z}^T \boldsymbol{A} \boldsymbol{Z}\]</span> ，其重构图像为 <span class="math display">\[\tilde{\boldsymbol{A}} = \boldsymbol{Z} \boldsymbol{C} \boldsymbol{X}^T\]</span> 。由此我们就得到了使用2D-2DPCA进行图像压缩的一般算法：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/2d_2d_pca_alg.png" class="" title="2d_2d_pca_alg"><p>在选择了不同主成分个数时，使用2D-2DPCA算法进行图像压缩的效果结果如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/2d2d_pca_pic.png" class="" title="2d2d_pca_pic"><h3 id="generalized-hebbian-algorithm">Generalized Hebbian Algorithm</h3><p>可以看到，上面几种PCA方法均为基于矩阵分解的求解方法。近年来随着机器学习和神经网络模型的提出，研究者也提出了基于学习的方法来快速提取数据集的主成分。其中较为典型的即为基于Gram-Schmidt正交化方法的<strong>扩展Hebbian算法（Generalized Hebbian Algorithm）</strong>。GHA算法是一种无监督的学习算法，我们可以将其看作Oja方法的一种推广。</p><p>首先我们构建一个单层全连接神经网络（Single-layer Feed Forward Neural Network），如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/gha_network.png" class="" title="gha_network"><p>可以证明，通过GHA算法对该神经网络进行权重调整，则训练完成后，连接每个输出神经元的权重向量即为一个主成分向量。</p><p>首先我们考虑输出层只有 <span class="math inline">\(1\)</span> 个神经元的情况。若设第 <span class="math inline">\(t\)</span> 次迭代的输入向量为 <span class="math inline">\(\boldsymbol{x}_t \in \mathbb{R}\)</span>，网络的权重向量为 <span class="math inline">\(\boldsymbol{w}_t \in \mathbb{R}^n\)</span>，输出 <span class="math inline">\(y_t = \boldsymbol{w}_t^T \boldsymbol{x}_t\)</span>，<span class="math inline">\(\eta\)</span> 为学习率。则根据Oja方法，权重更新公式为 <span class="math display">\[\boldsymbol{w}_{t + 1} = \boldsymbol{w}_{t} + \eta \boldsymbol{y}_{t} (\boldsymbol{x}_{t} - \boldsymbol{y}_{t} \boldsymbol{w}_{t})\]</span> 。现在我们将其推广到 <span class="math inline">\(k\)</span> 个输出时的情况，即求解前 <span class="math inline">\(k\)</span> 个主成分。设 <span class="math inline">\(\boldsymbol{W}_t \in \mathbb{R}^{k \times n}\)</span>，输出 <span class="math inline">\(\boldsymbol{y}_t = \boldsymbol{W}_t \boldsymbol{x}_t\)</span>，则 <span class="math display">\[\boldsymbol{W}_{t + 1} = \eta \left( \boldsymbol{y}_t \boldsymbol{x}_t^T - \textrm{LOWER}(\boldsymbol{y}_t \boldsymbol{y}_t^T) \boldsymbol{W}_t \right)\]</span> ，其中 <span class="math inline">\(\textrm{LOWER}(\boldsymbol{A})\)</span> 为取矩阵 <span class="math inline">\(\boldsymbol{A}\)</span> 的下三角操作（上三角部分置为 <span class="math inline">\(0\)</span>）。</p><p>于是，使用GHA进行图像压缩的算法流程如下：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/gha_alg.png" class="" title="gha_alg"><p>对于训练结果的评价指标，我们定义损失函数 <span class="math display">\[\mathcal{L}(\boldsymbol{W}, \boldsymbol{Q}) = \sum_{i = 1}^k ||\boldsymbol{w}_i - \boldsymbol{q}_i||^2 = ||\boldsymbol{W} - \boldsymbol{Q}||_F^2\]</span> 及向量夹角 <span class="math display">\[\mathcal{A}(\boldsymbol{w}_i, \boldsymbol{q}_i) = \arccos \left(  \frac{\boldsymbol{w}_i \cdot \boldsymbol{q}_i}{|| \boldsymbol{w}_i ||_2 \cdot ||\boldsymbol{q}_i||_2} \right)\]</span> 由于该算法的收敛速度较为不可控，因此这里我们仅使用网络提取前两个主成分。我们使用正态分布 <span class="math inline">\(\mathcal{N}(0, 0.5)\)</span> 随机初始化了权重矩阵，并设置学习率 <span class="math inline">\(\eta = 10^{-4}\)</span> 进行了两次模拟，每次对网络进行了 <span class="math inline">\(20000\)</span> 次训练迭代。两次迭代过程中Loss和向量夹角的变化情况如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/gha_pca_exp1.png" class="" title="gha_pca_exp1"><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/gha_pca_exp2.png" class="" title="gha_pca_exp2"><p>可以发现，随着权重矩阵初始值的不同，网络的收敛特征也会随之发生变化。</p><p>使用神经网络算法进行模型训练时一个经典的问题即为学习率过大。事实上，在训练该模型的过程中，我们同样遇到了这一问题，并且固定的学习率很难保证适合整个损失超平面。为此，研究者提出了适用于GHA的自适应学习率优化方法。由于该方法实现过于复杂，在此仅作为了解。</p><h3 id="kernel-pca">Kernel PCA</h3><p>由PCA的推导过程我们可以看出，要对一个数据集使用PCA方法进行降维的一大前提即为数据集必须在当前维度下线性可分，而类似图像这样高度紧凑的数据集通常会出现线性不可分的问题。在这种情况下，我们通常会尝试使用一个映射 <span class="math inline">\(\phi: \mathbb{R}^n \to \mathbb{R}^d, d &gt; n\)</span> 将数据集映射到更高维度的特征空间，使得其在该空间下线性可分，该方法被称为<strong>核方法（Kernel Method）</strong>。利用核方法，我们可以对朴素的PCA方法进行改进，使其能够表达更多的原始特征，这就形成了所谓的<strong>核主成分分析（Kernel PCA）</strong>。</p><p>若设图像矩阵为 <span class="math inline">\(\boldsymbol{X}\)</span>，非线性映射 <span class="math inline">\(\phi(\boldsymbol{X})\)</span> 对应的核函数 <span class="math inline">\(\boldsymbol{K} = \phi(\boldsymbol{X})^T \phi(\boldsymbol{X})\)</span>，特征空间为 <span class="math inline">\(\mathcal{F}\)</span>，则特征空间中的协方差矩阵就可以写为 <span class="math display">\[\boldsymbol{C}_{\mathcal{F}} = \frac{1}{N} \phi(\boldsymbol{X}) (\phi(\boldsymbol{X}))^T\]</span> 其特征值问题的方程 <span class="math inline">\(\boldsymbol{C}_{\mathcal{F}} \boldsymbol{v} = \lambda \boldsymbol{v}\)</span> 就可以写为 <span class="math display">\[\sum_{i = 1}^N \phi(\boldsymbol{x}_i) \phi(\boldsymbol{x}_i)^T \boldsymbol{v} = \lambda \boldsymbol{v}\]</span> 由此我们发现其每一个特征向量 <span class="math inline">\(\boldsymbol{v}_j\)</span> 都可以表示为 <span class="math inline">\(\phi(\boldsymbol{x}_i)\)</span> 的线性组合 <span class="math display">\[\boldsymbol{v} = \sum_{i = 1}^N a_i \phi(\boldsymbol{x}_i) = \phi (\boldsymbol{X}) \boldsymbol{a}\]</span> ，其中 <span class="math inline">\(\boldsymbol{a} = (a_1, \cdots, a_N)^T\)</span>。 引入核函数，化简即可得到 <span class="math display">\[\boldsymbol{K}(\boldsymbol{X}) \boldsymbol{a} = \lambda \boldsymbol{a}\]</span> ，也即经过特征空间所得的降维变换向量即为矩阵 <span class="math inline">\(\boldsymbol{K}\)</span> 的特征向量。</p><p>使用Kernel PCA进行图像压缩时所涉及的变换如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/kernel_pca.png" class="" title="kernel_pca"><p>通常来说，核函数要求矩阵为正定矩阵。在本文中，我们实现了以下几种核函数：</p><ul><li><strong>线性核（Linear Kernel）</strong></li></ul><p><span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) = \boldsymbol{x}^T \boldsymbol{y}\]</span></p><ul><li><strong>多项式核（Polynomial Kernel）</strong></li></ul><p><span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) = \left( \boldsymbol{x}^T \boldsymbol{y} + c \right)^d\]</span></p><ul><li><strong>高斯核（Gaussian Kernel/Radial Basis Function Kernel）</strong></li></ul><p><span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) = \exp \left( - \frac{|| \boldsymbol{x} - \boldsymbol{y} ||^2}{2 \sigma^2} \right) = \exp \left( - \gamma || \boldsymbol{x} - \boldsymbol{y} ||^2 \right)\]</span></p><ul><li><strong>指数核（Exponential Kernel）</strong></li></ul><p><span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) = \exp \left( - \frac{|| \boldsymbol{x} - \boldsymbol{y} ||}{2 \sigma^2} \right) = \exp \left( - \gamma || \boldsymbol{x} - \boldsymbol{y} || \right)\]</span></p><ul><li><strong>ANOVA核</strong></li></ul><p><span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) = \exp \left( -\sigma \left( \boldsymbol{x}^k - \boldsymbol{y}^k \right)^2 \right)^d\]</span></p><ul><li><strong>Sigmoid核</strong></li></ul><p><span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) = \tanh \left( a \boldsymbol{x}^T \boldsymbol{y} + r \right)\]</span></p><p>对于部分核函数，我们还需要给定合适的超参数以达到最好的特征提前效果。以高斯核为例，我们采用网格搜索的方式来选取合适的超参数 <span class="math inline">\(\gamma\)</span>。图像的重构误差随 <span class="math inline">\(\gamma\)</span> 的变化如下图所示：（左一）</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/rbf_param.png" class="" title="rbf_param"><p>可以看到，随着 <span class="math inline">\(\gamma\)</span> 值的增大，图像的重构误差逐渐减少。然而这并不意味着 <span class="math inline">\(\gamma\)</span> 值越大越好，这是由于当 <span class="math inline">\(\gamma\)</span> 值过大时，模型会出现<strong>过拟合（overfitting）</strong>的问题。具体来说，当 <span class="math inline">\(\gamma\)</span> 值过大时，核函数 <span class="math display">\[\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y}) \approx\left\{\begin{aligned}&amp;e^0 = 1 &amp;,\boldsymbol{x} = \boldsymbol{y} \\&amp;e^{-\infty} = 0 &amp;,\boldsymbol{x} \neq \boldsymbol{y}\end{aligned}\right.\]</span> ，此时核矩阵退化为 <span class="math inline">\(\boldsymbol{I}_n\)</span>，也即单位变换。这就导致了降维空间成为原空间的一个子空间，自然就失去了特征提取的功能。</p><p>若设核矩阵 <span class="math inline">\(\boldsymbol{K}\)</span> 的前 <span class="math inline">\(k\)</span> 个特征值为 <span class="math inline">\(\lambda_1, \cdots, \lambda_k\)</span>，我们定义其方差（该指标衡量了特征值的分散程度）为 <span class="math display">\[Var(\lambda_1, \cdots, \lambda_k) = \frac{1}{k} \sum_{i = 1}^k \left(\lambda_i - \bar{\lambda} \right)^2\]</span> ，则核矩阵方差及核矩阵行列式的值如图所示（上图左二、左三）。易见当 <span class="math inline">\(\gamma \gg 10^{-3}\)</span> 时，核矩阵的方差趋近于 <span class="math inline">\(0\)</span>，其行列式趋近于 <span class="math inline">\(1\)</span>，这也印证了上述的理论论述，表明模型确实出现了过拟合。</p><p>可以看到，由于核函数基本都为非线性函数，其逆变换通常难以求得。因此使用核方法对数据集进行降维的一个很大的问题在于对数据集进行重构，这对于图像压缩问题来说是十分不友好的。</p><p>若设 <span class="math inline">\(\mathcal{H}_K\)</span> 为核 <span class="math inline">\(\boldsymbol{K}(\boldsymbol{x}, \boldsymbol{y})\)</span> 所生成的再生希尔伯特核空间，其对应的特征变换 <span class="math inline">\(\phi(\boldsymbol{x}): \mathbb{R}^n \to \mathcal{H}_k\)</span>，则图像重构问题即为给定 <span class="math inline">\(\mathcal{H}_K\)</span> 中的一点 <span class="math inline">\(\boldsymbol{\Psi}\)</span>，求输入空间中的一点 <span class="math inline">\(\boldsymbol{z} \in \mathbb{R}^n\)</span>，使得 <span class="math display">\[\boldsymbol{z} = \mathop{\arg\min}_{\boldsymbol{z}} || \boldsymbol{\Psi} - \phi (\boldsymbol{z}) ||^2\]</span> 事实上自Kernel PCA被提出以来，已经有大量的研究提出了一系列对KPCA降维后数据进行重构的方法，这些方法大多都是基于近似拟合的方法。其中，基于<strong>梯度下降（Gradient Descent）</strong>的方法和基于<strong>回归（Regression）</strong>的方法是两大较为有代表性的求解方法。由于这一过程实现过于复杂，我们直接使用了Scikit-Learn工具包中提供的<strong>inverse_transform()</strong>函数来完成。</p><p>使用Kernel PCA进行图像压缩的算法流程如下：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/kpca_alg.png" class="" title="kpca_alg"><p>以高斯核为例，在选择了不同主成分个数时，使用Kernel PCA算法进行图像压缩的效果结果如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/kernel_pca_pic.png" class="" title="kernel_pca_pic"><p>可以发现，与朴素PCA方法不同，当选择的主成分个数为10时图像的主要特征仍然没有得到恢复，而当 <span class="math inline">\(k=50\)</span> 时，图像的质量得到了极大的改善。这也表明经过变换后的数据集在核空间下的特征分离方式与原空间下是不同的。</p><h3 id="jpeg">JPEG</h3><p>上面使用的几种图像压缩算法均为即为基于PCA的方法。事实上，在日常场景下，人们更常使用基于信号处理和特殊编码的方法来对图像进行压缩。其中较为典型的代表即为基于离散余弦变换的<strong>JPEG（JFIF）算法</strong>。</p><p>JPEG图像压缩算法的具体流程如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/jpeg_pipeline.png" class="" title="jpeg_pipeline"><p>压缩算法主要分为如下几个步骤：</p><ul><li><p><span class="math inline">\(RGB \to YC_bC_r\)</span> <strong>空间转换</strong></p></li><li><p><strong>下采样</strong></p></li><li><p><strong>图像分割</strong></p></li><li><p><strong>离散余弦变换</strong></p></li><li><p><strong>数据量化</strong></p></li><li><p><strong>Huffman编码</strong></p></li></ul><p>使用JPEG算法进行图像压缩的效果结果如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/jpeg_pic.png" class="" title="jpeg_pic"><p>可以看到，尽管JPEG为有损压缩算法，重构后的图片与原图几乎看不到可见的差异，这也从一定程度上解释了该算法流行的原因。</p><p>事实上，近年来的许多压缩方法还会将JPEG算法及其变体JPEG2000与PCA方法相结合，从而进一步提高压缩率及重构的准确率。例如在高光谱成像领域，由于原始图像通常还会附带许多频谱信息，将这两种方法相结合可以极大的压缩存储图像所需的空间，从而减少数据传输的开销。</p><h2 id="实验结果">实验结果</h2><p>前文中我们提及了一系列图像压缩的方法，现在我们从<strong>压缩率</strong>、<strong>重构质量</strong>和压缩耗时三个维度来对上述提及的所有方法进行分析和比较。</p><p>图像的压缩率被定义为 <span class="math display">\[\eta = 1 - \frac{\textrm{Size}(\tilde{\boldsymbol{X}}) + \textrm{Size}(\boldsymbol{Q})}{\textrm{Size}(\boldsymbol{X})}\]</span> ，其中 <span class="math inline">\(\textrm{Size}(\boldsymbol{A})\)</span> 为 <span class="math inline">\(\boldsymbol{A}\)</span> 的空间度量，<span class="math inline">\(\boldsymbol{X}\)</span> 为原始图像，<span class="math inline">\(\tilde{\boldsymbol{X}}\)</span> 为重构图像，<span class="math inline">\(\boldsymbol{Q}\)</span> 为重构变换矩阵。</p><p>以 <span class="math inline">\(k = 50\)</span> 为例，本文中实现的不同算法的压缩率如下表所示：</p><table><thead><tr class="header"><th>压缩算法</th><th>单张图片压缩率</th><th>100张图片压缩率</th><th>300张图片压缩率</th></tr></thead><tbody><tr class="odd"><td>PCA</td><td><span class="math inline">\(60.94\%\)</span></td><td><span class="math inline">\(60.94\%\)</span></td><td><span class="math inline">\(60.94\%\)</span></td></tr><tr class="even"><td>2DPCA</td><td><span class="math inline">\(60.94\%\)</span></td><td><span class="math inline">\(80.27\%\)</span></td><td><span class="math inline">\(80.40\%\)</span></td></tr><tr class="odd"><td>2D-2DPCA</td><td><span class="math inline">\(41.41\%\)</span></td><td><span class="math inline">\(80.08\%\)</span></td><td><span class="math inline">\(80.34\%\)</span></td></tr><tr class="even"><td>Kernel PCA</td><td><span class="math inline">\(60.94\%\)</span></td><td><span class="math inline">\(60.94\%\)</span></td><td><span class="math inline">\(60.94\%\)</span></td></tr><tr class="odd"><td>JPEG</td><td><span class="math inline">\(84.54\%\)</span></td><td><span class="math inline">\(86.09\%\)</span></td><td><span class="math inline">\(87.22\%\)</span></td></tr></tbody></table><p>可以发现，朴素PCA和Kernel PCA对单张图片计算主成分，因此其在单张图片和多张图片上的压缩率相同；而2DPCA和2D-2DPCA由于对整个数据集计算特征，因此随着数据集的增长，总体的图像压缩率逐渐增长。JPEG在所有算法中拥有最高的压缩率。</p><p>对于重构质量，我们使用<strong>均方误差（Mean Square Error）</strong>和<strong>峰值信噪比（Peak Signal-to-Noise Ratio）</strong>来进行评估。其中，原始图像 <span class="math inline">\(\boldsymbol{X}\)</span> 和重构图像 <span class="math inline">\(\tilde{\boldsymbol{X}}\)</span> 间的均方误差被定义为 <span class="math display">\[\textrm{MSE}(\boldsymbol{X}, \tilde{\boldsymbol{X}}) = \frac{1}{N^2} \sum_{i = 1}^N \sum_{j = 1}^N (x_{ij} - \tilde{x}_{ij})^2\]</span> 其之间的峰值信噪比被定义为 <span class="math display">\[\textrm{PSNR}(\boldsymbol{X}, \tilde{\boldsymbol{X}}) = 10 \cdot \log_{10} \left( \frac{\textrm{MAX}_{\boldsymbol{X}}^2}{\textrm{MSE}(\boldsymbol{X}, \tilde{\boldsymbol{X}})}\right)\]</span> ，其中 <span class="math inline">\(\textrm{MAX}_{\boldsymbol{X}}\)</span> 为矩阵 <span class="math inline">\(\boldsymbol{X}\)</span> 每个元素可能的最大值（对于一张 <span class="math inline">\(8\)</span> 位图像即为 <span class="math inline">\(255\)</span>）。</p><p>当 <span class="math inline">\(k\)</span> 为 <span class="math inline">\(50\)</span> 时，使用不同算法进行压缩重构后得到的MSE和PSNR值由下表给出：</p><table><thead><tr class="header"><th>压缩算法</th><th>MSE</th><th>PSNR</th></tr></thead><tbody><tr class="odd"><td>PCA</td><td><span class="math inline">\(47.8774\)</span></td><td><span class="math inline">\(31.3295\)</span></td></tr><tr class="even"><td>2DPCA</td><td><span class="math inline">\(76.1444\)</span></td><td><span class="math inline">\(29.3144\)</span></td></tr><tr class="odd"><td>2D-2DPCA</td><td><span class="math inline">\(90.1605\)</span></td><td><span class="math inline">\(28.5806\)</span></td></tr><tr class="even"><td>Kernel PCA</td><td><span class="math inline">\(11.1868\)</span></td><td><span class="math inline">\(37.6437\)</span></td></tr><tr class="odd"><td>JPEG</td><td><span class="math inline">\(53.2189\)</span></td><td><span class="math inline">\(30.8701\)</span></td></tr></tbody></table><p>更进一步的，当主成分选择数 <span class="math inline">\(k\)</span> 从 <span class="math inline">\(1\)</span> 上升到 <span class="math inline">\(200\)</span> 的过程中，不同算法的重构质量如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/reconstruct_quality.png" class="" title="reconstruct_quality"><p>可以看到，在所有实现的方法中，Kernel PCA在两项指标中均获得了最好的结果。然而，由于其重构变换使用了近似的方法，这一过程并不稳定，因此其误差曲线出现了一定程度的波动。相比较而言，一般的PCA方法两项评价指标随主成分选择数增加的变化十分稳定。</p><p>最后我们来考察不同压缩算法的压缩耗时。压缩耗时的计算公式被定义为 <span class="math display">\[\mathcal{T} = \mathcal{T}_{Compress} + \mathcal{T}_{Reconstruct}\]</span> 其中 <span class="math inline">\(\mathcal{T}_{Compress}\)</span> 为编码耗时，<span class="math inline">\(\mathcal{T}_{Reconstruct}\)</span> 重构耗时。</p><p>不同算法随着待压缩的图片总量从单张到 <span class="math inline">\(100\)</span> 张所用的时间如下图所示：</p><img src="/2021/11/29/machine-learning/dase-alg-exp-pca/time.png" class="" title="time"><p>可以发现，基于特征分解的朴素PCA算法随着数据集的增长进行压缩所用的时间迅速的增大，这是由于其计算协方差矩阵的特征值和特征向量的巨额时间开销。基于奇异值分解的PCA算法由于使用了更为高效的Householder变换算法，其耗时相比特征值分解得到了显著的下降。在我们的实现中，Kernel PCA同样使用了SVD方法进行优化，但其时间开销仍然十分巨大，表明其主要耗时在图像重构上。2DPCA和2D-2DPCA由于对整个数据集进行统一变换，因此在多张图像数据集上拥有极高的压缩效率。</p><h2 id="结论">结论</h2><p>在本实验中，我们完整推导并实现了<strong>基于特征值分解的 PCA 算法</strong>、基于奇异值分解的 PCA 算法、<strong>基于 GHA 的 PCA 算法</strong>、<strong>2DPCA 算法</strong>、<strong>2D-2DPCA 算法</strong>、<strong>Kernel PCA 算法</strong>及 <strong>JPEG 算法</strong>，并将它们应用于图像压缩任务中。经过比较我们可以发现，在不同的度量标准下， 不同的算法均有着相应的优势和劣势。一般的 PCA 算法具有较好的稳定性和可解释性，2DPCA 和 2D-2DPCA 算法拥有较高的压缩效率，Kernel PCA 算法拥有较高的重构精度。这也表明这些 方法没有严格的好坏之分，在不同任务下需要根据实际情况选择合适的方法。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>Daniel Báscones, Carlos González, and Daniel Mozos. Hyperspectral image compression using vector quantization, pca and jpeg2000. Remote sensing, 10(6):907, 2018.</li><li>Liang-Hwa Chen and Shyang Chang. An adaptive learning algorithm for principal component analysis. IEEE Transactions on Neural Networks, 6(5):1255–1263, 1995.</li><li>COMP-652 and ECSE-608. Dimensionality reduction. pca. kernel pca. https://www.cs.mcgill.ca/~dprecup/courses/ML/Lectures/ml-lecture13.pdf, 2016.</li><li>Alberto García-González, Antonio Huerta, Sergio Zlotnik, and Pedro Díez. A kernel principal component analysis (kpca) digest with a new backward mapping (pre-image reconstruction) strategy, 2021.</li><li>Matt Gormley. Deriving principal component analysis (pca). https://www.cs.cmu. edu/~mgormley/courses/606-607-f18/slides606/lecture11-pca.pdf, October 2018.</li><li>R.B. Lehoucq. The computation of elementary unitary matrices. Technical report, University of Tennessee, 1994.</li><li>Graphics Mill. Working with jpeg. https://www.graphicsmill.com/docs/gm/ working-with-jpeg.htm.</li><li>Sebastian Mika, Bernhard Schölkopf, Alex Smola, Klaus-Robert Müller, Matthias Scholz, and Gunnar Rätsch. Kernel pca and de-noising in feature spaces. In M. Kearns, S. Solla, and D. Cohn, editors, Advances in Neural Information Processing Systems, volume 11. MIT Press, 1999.</li><li>Erkki Oja. Simplified neuron model as a principal component analyzer. Journal of mathematical biology, 15(3):267–273, 1982.</li><li>Terence D. Sanger. Optimal unsupervised learning in a single-layer linear feedforward neural network, 1989.</li><li>Bernhard Schölkopf, Alexander Smola, and Klaus-Robert Müller. Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation, 10(5):1299–1319, 1998.</li><li>Wikipedia contributors. Jpeg — Wikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=JPEG&amp;oldid=1056557277, 2021. [Online; accessed 23-November-2021].</li><li>Wikipedia contributors. Singular value decomposition — Wikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=Singular_value_decomposition&amp;oldid=1055826758, 2021. [Online; accessed 24-November-2021].</li><li>Chih-Wen Wang and Jyh-Horng Jeng. Image compression using pca with clustering. In 2012 International Symposium on Intelligent Signal Processing and Communications Systems, pages 458–462, 2012.</li><li>Frank Wood. http://www.stat.columbia.edu/~fwood/Teaching/w4315/Fall2009/pca.pdf, December 2009.</li><li>Jason Weston, Bernhard Schölkopf, and Gökhan Bakir. Learning to find pre-images. In S. Thrun, L. Saul, and B. Schölkopf, editors, Advances in Neural Information Processing Systems, volume 16. MIT Press, 2004.</li><li>Jian Yang, D. Zhang, A.F. Frangi, and Jing yu Yang. Two-dimensional pca: a new approach to appearance-based face representation and recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(1):131–137, 2004.</li><li>Daoqiang Zhang and Zhi-Hua Zhou. (2d)2pca: Two-directional two-dimensional pca for eﬀicient face representation and recognition. Neurocomputing, 69(1):224–231, 2005. Neural Networks in Signal Processing.</li><li>周志华. 机器学习. 清华大学出版社, 2016.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;图像压缩一直是图像处理中一个重要的任务，一个好的图像压缩算法可以大大降低存储和传输代价。主成分分析（Principal Component Analysis）作为一个经典的降维方法，已经在图像压缩领域得到了极为广泛的运用。在本文中，我</summary>
      
    
    
    
    <category term="数据科学算法基础" scheme="http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Machine-Learning" scheme="http://gonggongjohn.me/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>寻宝游戏(MongoDB)</title>
    <link href="http://gonggongjohn.me/2021/10/08/database/db-assignment-1/"/>
    <id>http://gonggongjohn.me/2021/10/08/database/db-assignment-1/</id>
    <published>2021-10-08T02:00:00.000Z</published>
    <updated>2021-12-10T05:51:04.111Z</updated>
    
    <content type="html"><![CDATA[<h2 id="实验要求">实验要求</h2><p>考虑以下游戏场景：</p><p>每个游戏玩家都有一定数量的金币、宝物。有一个市场供玩家们买卖宝物。玩家可以将宝物放到市场上挂牌，自己确定价格。其他玩家支付足够的金币，可购买宝物。</p><p>宝物分为两类:一类为工具，它决定持有玩家的工作能力;一类为配饰，它决定持有玩家的运气。</p><p>每位玩家每天可以通过寻宝获得一件宝物，宝物的价值由玩家的运气决定。每位玩家每天可以通过劳动赚取金币，赚得多少由玩家的工作能力决定。（游戏中的一天可以是现实中的 1 分钟、5 分钟、10 分钟，自主设定。）</p><p>每个宝物都有一个自己的名字（尽量不重复）。每位玩家能够佩戴的宝物是有限的（比如一个玩家只能佩戴一个工具和两个配饰）。多余的宝物被放在存储箱中，不起作用，但可以拿到市场出售。</p><p>在市场上挂牌的宝物必须在存储箱中并仍然在存储箱中，直到宝物被卖出。挂牌的宝物可以被收回，并以新的价格重新挂牌。当存储箱装不下时，运气或工作能力值最低的宝物将被系统自动回收。</p><p>假设游戏永不停止而玩家的最终目的是获得最好的宝物。</p><p>请根据以上场景构建一个假想的 Web 游戏，可供多人在线上玩耍。后台的数据库使用 MongoDB。对游戏玩家提供以下几种操作：寻宝（可以自动每天一次）、赚钱（可以自动每天一 次）、佩戴宝物、浏览市场、买宝物、挂牌宝物、收回宝物。</p><h2 id="实验过程">实验过程</h2><h3 id="网站构架">网站构架</h3><p>本次寻宝游戏网站的整体构架如下图所示。</p><figure><img src="system_structure.png" alt="system_structure" /><figcaption aria-hidden="true">system_structure</figcaption></figure><p>由于游戏平台通常会由多个不同的模块构成，且需要不断的迭代和集成，因此我们采用了前后端分离的架构来设计网站。整个网站分为 四个部分，分别为前端维生服务器、前端页面、后端请求服务器及服务器数据库。</p><p>对于前端维生服务器，我们使用了基于 NodeJS 的经典 Web 服务器维持框架 Express。这一 框架提供了一个快速的 Web 应用搭建流程，我们只需要直接将前端页面框架生成的相关资源统 一放在相应的位置，Express 就会帮我们自动托管之后的服务器维持事务。</p><p>对于前端页面，我们使用了经典的 Vue 3 框架来进行搭建。这一框架提供了一整套完善的 UI 及前后端交互流程，可以十分清晰的梳理出各个模块之间的继承及通信关系，方便后续维护。对于 UI 样式，我们使用了基于 Vue 3 的 Quasar Framework 2 框架，这一框架支持流式数据加载 及响应式的交互访问，可以吸引用户访问并使用该平台。</p><p>由于需要应对各种不同的情况，后端服务器由多个模块联合构成。首先，我们使用了 Flask 作为容器实现框架，并通过蓝图（Blueprint）功能将接口分摊至五个子接口集合上以实现业务隔离。随后，由于我们使用了前后端分离架构，自然会涉及到跨域问题。因此我们在请求处理接口 上加上了一层 CORS 包装器。最后，为了应对高并发请求，我们使用了 Gunicorn 网关容器对全 应用进行了封装，并对 Flask 开启了多线程支持。这样在面对高并发请求时系统可以较为均衡的分摊整个负载。</p><p>本次实验使用了 MongoDB 作为服务器存储数据库。作为一个文档型数据库，其类 Json 格 式的数据管理模型更贴近 Web 交互时的数据格式，这使得我们在后续在设计接口数据协议时更为方便。</p><h3 id="数据库设计">数据库设计</h3><h4 id="内嵌存储-v.s-归一化存储">内嵌存储 v.s 归一化存储</h4><p>对于当前应用，我们主要需要存储以下几种数据:系统中可用的宝物及其价值、用户的各种 基本信息、用户正在佩戴的物品、用户当前拥有的物品、市场上正在出售的宝物。</p><p>对于文档型数据库，一个最直接的想法便是将所有的用户数据全部存储在同一个集合中。因此，对于当前应用，一个可能的数据库设计如下图所示。</p><figure><img src="embed_db.png" alt="embed_db" /><figcaption aria-hidden="true">embed_db</figcaption></figure><p>其中，用户已佩戴的物品及储物箱中的物品被以数组的形式嵌入用户集合中。这样做的好处是在每次用户访问其拥有物品 时，我们始终能够以 <span class="math inline">\(O(1)\)</span> 的代价（获取到用户文档之后）完成对用户物品查询。然而，当用户想要变更物品的状态时，系统就需要遍历整个数组以找到对应的物品，此时其时间开销便会变得极为糟糕，在最坏情况下甚至能达到 <span class="math inline">\(O(n)\)</span>（获取到用户文档之后），且索引功能很难帮助优化这 一查询代价。此外，这一存储方式会带来大量的数据冗余，且由于宝物的全部信息均被存储在了用户表中，当系统要对宝物信息进行更新时，就需要对所有集合中的所有玩家的每一条宝物数据进行遍历，当用户规模较大时，这一代价将变得十分巨大，且此时可能出现数据不一致的问题， 破坏了数据库的 ACID 原则。</p><p>在数据库设计中，我们通常还会尽可能的让同一数据在所有集合中尽可能只保留一份以减少数据冗余，即所谓的存储归一化（Storage Normalization）。在这种模式下，数据库可以以下图所示的方式设计。</p><figure><img src="normalize_db.png" alt="normalize_db" /><figcaption aria-hidden="true">normalize_db</figcaption></figure><p>这样做的好处是极大的减少了数据冗余，且从灾备的角度来看， 即使发生了数据丢失，由于宝物和用户的信息是单独存储的，其数据损失的概率也相对较小。此外，当宝物状态需要发生改变时，我们只需要移动其唯一标识即可进行更改，数据移动的开销较小。然而，由于宝物与用户的信息发生了分离，对于用户的每一件物品，我们都需要至少访问两个集合才能获取到所有需要的数据，而访问不同的集合对于 MongoDB 而言开销是巨大的，因此对于本应用来说仍然不是一个合适的选择。</p><h4 id="缓存型存储">缓存型存储</h4><p>为了解决上面两种方式的问题，对于本应用，我们采用了一种称为缓存型存储（或存储反归一化， Storage Denormalization）的思想来设计本应用的数据库结构。与直接存储不同的是，缓存 型存储是先将数据进行归一化，随后再将数据以最适合访问的方式进行冗余缓存，这样既保证了数据修改时的数据一致性，又使得数据能以较高的效率被访问。 本应用的数据库集合设计如下图所示。</p><figure><img src="denormalize_db.png" alt="denormalize_db" /><figcaption aria-hidden="true">denormalize_db</figcaption></figure><p>其中，用户集合包含了用户的全部基本信息，而宝物集合则维护了当前系统中能够被提供的全部宝物信息。持有物品集合中存储了所有玩家所拥有的物品及其相关状态，其在本应用中既用作玩家存储箱信息的维护，也用作市场上物品信息的维护。此外，根据实际的查询需求，我们对宝物集合的 gain 键建立了索引，对持有物品集合的 owner 和 status 两个键分别建立了索引。</p><p>更具体的，每个集合中各个键的数据类型定义如下表所示。</p><figure><img src="table_db_structure.png" alt="table_db_structure" /><figcaption aria-hidden="true">table_db_structure</figcaption></figure><p>这里需要注意的是，对于用户的头像，我们使用了一个对象标识符类型将其指向一个外部的位置。由于 MongoDB 采用了 BSON 作为其文档存储实现，其最大单个文档的大小限制为 4MB。而若要将用户头像这样的二进制数据直接存储在单个文档中，则很容易超过这一限制导致无法存储。为了解决这一问题，MongoDB 提供了一个名为 GridFS 的存储方案。通过将二进制文件拆分为多 个小块（Chunk，通常为 256KB/个），我们便可以将图片等媒体数据存储在数据库中。因此事实上该应用一共有 5 个集合，额外的两个集合（分别名为 fs.chunks 和 fs.files）分别用于存储 大文件的二进制数据及其块索引。</p><p>作为归一化集合，当数据进行更新时，用户集合和宝物集合拥有最高的更新优先级。持有物品集合作为本应用的缓存集合，包含了玩家可能频繁访问的全部物品数据。因此无论玩家是在访问自己的装备物品、存储箱还是市场上正在出售的物品时，我们都只需要访问持有物品这一个集合，极大地提高了数据查询的效率。</p><p>此外，为了保证数据一致性，在每一次应用启动时，系统都会对缓存集合中的数据进行检查。 由于缓存集合中记录了其他集合相关条目的唯一标识符，因此这一同步是可行的。当管理员需要进行某些更新(例如对某件宝物的属性进行调整时)，系统也会先更新宝物和用户集合，再将数据同步至持有物品集合中。</p><p>可以注意到，这里我们没有单独为市场设计一个缓存集合，这是由于用户查询市场上的物品就等价于查询所有玩家中 status=3 的物品，而我们已经对持有物品集合中的 status 键建立了索引，这一查询的效率是极高的，因此无需再另设一个集合专门对市场上的物品进行缓存。此外， 若再设一个缓存集合，则需要花费更高的代价去解决数据不一致的问题，得不偿失，可见这样做是并不合适的。</p><h4 id="odm-与数据库交互实现">ODM 与数据库交互实现</h4><p>MongoDB 提供了对 Python 的原生访问接口模块 pymongo。通过这一模块，我们可以使用和 命令行中类似的类 JSON 方式对数据库中的对象进行 CRUD（Create-Retrieve-Update-Delete）操作。然而，由于其没有与 Python 中对象的直接映射关系，我们无法快速获知当前操作对数据库及 Python 对象进行了怎样的数据变化，这样很容易使得操作逻辑变得不可控（尤其是考虑到文档型数据库中可以动态加入键值的特性）。</p><p>受到 MySQL 等关系型数据库中 ORM 概念的启发，对于对象型编程语言与数据库间的交互，一个极好的办法便是实用所谓的对象-文档映射（ODM，Object Document Mapping）模型。 通过将数据库中的对象映射为 Python 中的类，我们便可以直接使用 Python 中的类操作方法对数据库中的对象进行操作。由于每一个数据库文档中的键都与对象中的一个变量有一一对应关系，我们便可以随时掌握当前操作的内容及其可能的行为，这样就使得整个系统更易于维护。</p><p>幸运的是，对于 MongoDB，Python 中已经存在了一款十分完善的 ODM 实现模块 Mongo-Engine。对于本应用，我们直接使用专门针对 Flask 框架封装的 Flask-MongoEngine 来实现对应的 ODM 模型。对于上述提出的集合结构，其 ODM 模型申明代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">User</span>(<span class="hljs-params">db.Document</span>):</span><br>username = db.StringField(required=<span class="hljs-literal">True</span>)<br>password = db.StringField(required=<span class="hljs-literal">True</span>)<br>nickname = db.StringField()<br>permission = db.IntField(default=<span class="hljs-number">1</span>) <span class="hljs-comment"># 1 - Player; 2 - Admin</span><br>  avatar = db.FileField()<br>coin = db.IntField(default=<span class="hljs-number">10</span>)<br>power = db.IntField(default=<span class="hljs-number">1</span>)<br>luck = db.IntField(default=<span class="hljs-number">1</span>)<br>regtime = db.DateTimeField(default=datetime.now()) tool_equipped = db.IntField(default=<span class="hljs-number">0</span>)<br>accessory_equipped = db.IntField(default=<span class="hljs-number">0</span>)<br>container_usage = db.IntField(default=<span class="hljs-number">0</span>)<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Treasure</span>(<span class="hljs-params">db.Document</span>):</span><br>name = db.StringField(required=<span class="hljs-literal">True</span>)<br>type = db.IntField(required=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 1 - Tools; 2 - Accessories</span><br>  gain = db.IntField()<br>meta = &#123;<br><span class="hljs-string">&#x27;indexes&#x27;</span>: [ <span class="hljs-string">&#x27;gain&#x27;</span><br>] &#125;<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Container</span>(<span class="hljs-params">db.Document</span>):</span><br>treasure_id = db.ObjectIdField(required=<span class="hljs-literal">True</span>)<br>treasure_name = db.StringField()<br>treasure_type = db.IntField()<br>treasure_gain = db.IntField()<br>owner = db.ObjectIdField(required=<span class="hljs-literal">True</span>)<br>owner_name = db.StringField()<br>status = db.IntField() <span class="hljs-comment"># 1 - Equipped; 2 - In inventory; 3 - On sale</span><br>  price = db.IntField() <span class="hljs-comment"># Only exists when status = 3</span><br>meta = &#123;<br><span class="hljs-string">&#x27;indexes&#x27;</span>: [ <span class="hljs-string">&#x27;owner&#x27;</span>, <span class="hljs-string">&#x27;status&#x27;</span><br>] &#125;<br></code></pre></td></tr></table></figure><p>在该种映射模型下，数据库的 CRUD 操作变得异常简单。下面以用户表的一次 CRUD 操作 代码为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">user_create = User(username=username, password=password) <span class="hljs-comment"># Create</span><br>user_item = User.objects(username=username).first() <span class="hljs-comment"># Retrieve</span><br>user_item.nickname = abc <span class="hljs-comment"># Update</span><br>user_item.delete() <span class="hljs-comment"># Delete</span><br>user_create.save() <span class="hljs-comment"># Save</span><br></code></pre></td></tr></table></figure><h3 id="业务实现">业务实现</h3><h4 id="账户管理">账户管理</h4><p>对于玩家来说，一款游戏的账户管理系统主要涉及用户注册及用户登录两个功能，因此我们分别设计两个接口/register 及/login 来完成这一交互逻辑。</p><p>首先我们来设计注册接口。当用户发起注册请求时，我们首先从请求中拿到用户所要注册的用户名和密码，随后使用 MongoEngine 提供的查询语句查询数据库中用户名是否已经存在。若用户名不存在，则向数据库的 User 文档集合中插入一条新的用户文档，否则则报错。为了方便后续维护，我们约定/register 接口的返回状态码如下：</p><figure><img src="register_status.png" alt="register_status" /><figcaption aria-hidden="true">register_status</figcaption></figure><p>对于登录接口，我们首先从 request 请求体中获得用户名及密码，随后使用 MongoEngine 查询数据库中用户名符合的第一条记录（由于在注册时对数据库中是否存在重名用户进行了检查， 因此这里可以保证获得的第一条记录是整个数据库中唯一符合条件的记录）。得到记录后，我们只需要对其密码进行比对，并将判断结果返回给用户（前端）即可。</p><p>同样的，这里我们约定/login 接口的返回状态码如下：</p><figure><img src="login_status.png" alt="login_status" /><figcaption aria-hidden="true">login_status</figcaption></figure><p>对于账户管理页面的前端设计，我们使用了 Layout+Page 的模式对其进行了样式统一，并使 界面尽可能的保持简洁。其效果如下图所示。</p><figure><img src="login_page.png" alt="login_page" /><figcaption aria-hidden="true">login_page</figcaption></figure><figure><img src="register_page.png" alt="register_page" /><figcaption aria-hidden="true">register_page</figcaption></figure><h4 id="session-与用户组">Session 与用户组</h4><p>由于后续的请求中大量涉及到用户验证，若每次都需要在请求体中加入用户名和密码，则后续操作将会变得十分复杂，且由于用户信息始终在端与端之间传输，会造成极大的安全隐患。因此这里我们使用会话（Session）技术来保持用户的登录状态。同时，为了保证请求安全性，我们还需要对 Session 进行加密。</p><p>Flask原生提供了对Session的支持，我们可以直接使用键值对的方式对一个应用中的Session 进行操作。对于本应用，我们对除登录注册外的所有接口都设置了 Session 验证，当检测到用户发来的请求头中没有 Session 信息的话，则会直接返回 100 状态码告诉用户无权访问。</p><p>在实际场景下，有时我们需要对游戏中的内容进行更新操作（如添加新的可用宝物），为了方便这一操作，我们将其引入前端的交互界面中。然而一旦将修改全局数据库的操作暴露在公开接口中，我们就需要开始考虑操作的权限验证问题，否则就有可能产生安全问题。得益于 Session 用户验证机制，我们可以通过设置用户组来对用户的访问权限进行限制。</p><p>对于当前应用，我们进行如下的权限组约定：</p><figure><img src="permission_table.png" alt="permission_table" /><figcaption aria-hidden="true">permission_table</figcaption></figure><p>可以看到，在前面的数据库结构设计中，我们在用户集合中设置了一个 permission 键用于标识用户所在的组。当用户注册完成后，该键默认被设置为 1，且不可通过接口请求的方式进行更改。为了方便统一管理，我们将所有的管理员操作专门放到一个/admin 蓝图中。该蓝图中的所有接口均进行了用户组认证。当用户发起请求时，系统会首先检查请求头 Session 中包含的用户信息，若用户的权限组高于 2，则继续处理用户所请求的操作，否则直接返回用户码 2 告诉用户无权修改服务器。</p><p>对于不同的用户组，前端界面的呈现也进行了一定的区分。其中当用户为管理员时，菜单中会多出一栏管理员界面可供用户进行操作，这与常规游戏中的设计也基本吻合。</p><figure><img src="normal_player_navigate.png" alt="normal_player_navigate" /><figcaption aria-hidden="true">normal_player_navigate</figcaption></figure><figure><img src="command_player_navigate.png" alt="command_player_navigate" /><figcaption aria-hidden="true">command_player_navigate</figcaption></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;实验要求&quot;&gt;实验要求&lt;/h2&gt;
&lt;p&gt;考虑以下游戏场景：&lt;/p&gt;
&lt;p&gt;每个游戏玩家都有一定数量的金币、宝物。有一个市场供玩家们买卖宝物。玩家可以将宝物放到市场上挂牌，自己确定价格。其他玩家支付足够的金币，可购买宝物。&lt;/p&gt;
&lt;p&gt;宝物分为两类:一类为工具，它决</summary>
      
    
    
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Database" scheme="http://gonggongjohn.me/tags/Database/"/>
    
  </entry>
  
  <entry>
    <title>数据科学与工程数学基础 作业7</title>
    <link href="http://gonggongjohn.me/2021/06/30/dase-math/dase-math-assignment-7/"/>
    <id>http://gonggongjohn.me/2021/06/30/dase-math/dase-math-assignment-7/</id>
    <published>2021-06-30T02:00:00.000Z</published>
    <updated>2022-02-10T14:38:31.914Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一">一</h2><blockquote><p>下面的集合哪些是凸集？</p><ol type="1"><li>平板， 即形如 <span class="math inline">\(\left\{ x \in \mathbb{R}^n | \alpha \leq a^T x \leq \beta \right\}\)</span> 的集合。</li><li>矩形， 即形如 <span class="math inline">\(\left\{ x \in \mathbb{R}^n | \alpha_i \leq x_i \leq \beta_i, i = 1, \cdots, n \right\}\)</span> 的集合。当 <span class="math inline">\(n &gt; 2\)</span> 使，矩形有时也称为超矩形。</li><li>楔形，即 <span class="math inline">\(\left\{ x \in \mathbb{R}^n | a_1^T x \leq b_1, a_2^T x \leq b_2 \right\}\)</span>。</li><li>距离给定点比距离给定集合近的点构成的集合，即</li></ol><p><span class="math display">\[\left\{ x | || x - x_0 ||_2 \leq || x - y ||_2, \forall y \in S \right\}\]</span></p><p>，其中 <span class="math inline">\(S \subseteq \mathbb{R}^n\)</span></p></blockquote><p><strong>(a)</strong> 该集合可写为 <span class="math inline">\(\{x \in \mathbb{R}^n | a^Tx \leq \beta \} \cap \{x \in \mathbb{R}^n | a^Tx &gt; \alpha \}\)</span>，故为一个凸集</p><p><strong>(b)</strong> 该集合可写为一组半空间的交集，故为一个凸集</p><p><strong>(c)</strong> 该集合可写为 <span class="math inline">\(\{x \in \mathbb{R}^n | a_1^T x \leq b_1\} \cap \{x \in \mathbb{R}^n | a_2^T x \leq b_2\}\)</span>，故为一个凸集</p><p><strong>(d)</strong> 该集合可写为 <span class="math display">\[\bigcap_{y \in S} \{x | ||x - x_0||_2 \leq ||x-y||_2 \}\]</span> 故为一个凸集</p><h2 id="二">二</h2><blockquote><p>下面的函数哪些是凸函数? 请说明理由：</p><ol type="1"><li><span class="math inline">\(f(x)=e^{x}+1, x \in \mathbb{R}\)</span></li><li><span class="math inline">\(f(x)=\max \left(\|A x+b\|_{2},\left\|x^{T} A x\right\|_{1}\right), A \in \mathbb{R}^{m \times n} x \in \mathbb{R}^{n} b \in \mathbb{R}^{m}\)</span></li><li><span class="math inline">\(f(x)=-\cos x, x \in[-\pi / 2, \pi / 2]\)</span></li></ol></blockquote><p><strong>(a)</strong> <span class="math display">\[f&#39;(x) = e^x, f&#39;&#39;(x) = e^x &gt; 0, x \in \mathbb{R}\]</span> 故 <span class="math inline">\(f(x)\)</span> 为凸函数</p><p><strong>(b)</strong> 由于仿射映射、仿射函数取范数、取最大值为保凸运算，故 <span class="math inline">\(f(x)\)</span> 为凸函数</p><p><strong>(c)</strong> <span class="math display">\[f&#39;(x) = \sin x, f&#39;&#39;(x) = \cos x \geq 0, x \in [-\frac{\pi}{2}, \frac{\pi}{2}]\]</span> 故 <span class="math inline">\(f(x)\)</span> 为凸函数</p><h2 id="三">三</h2><blockquote><p>证明 <span class="math inline">\(x^* = (1, 0.5, -1)\)</span> 是如下优化问题的最优解： <span class="math display">\[\begin{aligned}&amp;\min &amp;\frac{1}{2} x^T P x + q^T x + r \\&amp;\textrm{s.t} &amp; -1 \leq x_i \leq 1, i = 1,2,3\end{aligned}\]</span> 其中 <span class="math display">\[P = \begin{pmatrix}13 &amp; 12 &amp; -2 \\12 &amp; 17 &amp; 6 \\-2 &amp; 6 &amp; 12\end{pmatrix},q = \begin{pmatrix}-22 \\-14.5 \\13\end{pmatrix},r = 1\]</span></p></blockquote><p>由于 <span class="math inline">\(\nabla f_0 = \frac{1}{2} (P+P^T) x +q = px+q\)</span></p><p>故 <span class="math inline">\(\nabla f_0(x^*) = (-1,0,2)^T\)</span></p><p>因此 <span class="math inline">\(\forall y \in [-1,1]^n\)</span>，<span class="math inline">\(\nabla f_0(x^*)^T(y-x) \geq 0\)</span></p><p>即 <span class="math inline">\(x^*\)</span> 满足最优性条件，也即目标函数的最优点</p><h2 id="四">四</h2><blockquote><p>计算函数 <span class="math inline">\(f(x)\)</span> 的共轭函数，以及共轭函数的定义域：</p><ol type="1"><li><span class="math inline">\(f(x) = - \log x\)</span></li><li><span class="math inline">\(f(x) = e^x\)</span></li></ol></blockquote><p><strong>(a)</strong> 由 <span class="math inline">\(f(x)=- \log x\)</span> 可知 <span class="math inline">\(domf = \{x|x&gt;0\}\)</span></p><p>令 <span class="math inline">\(g(x,y) = xy + \log x\)</span></p><p>当 <span class="math inline">\(y \geq 0\)</span> 时，<span class="math inline">\(\sup g(x,y) = +\infty\)</span></p><p>当 <span class="math inline">\(y &lt; 0\)</span> 时，<span class="math inline">\(\sup g(x,y) = -1- \log(-y)\)</span> 当且仅当 <span class="math inline">\(x = -\frac{1}{y}\)</span></p><p>故 <span class="math inline">\(f^*(y) = -1-\log(-y),y &lt; 0\)</span></p><p><strong>(b)</strong> <span class="math inline">\(domf = \mathbb{R}\)</span></p><p>令 <span class="math inline">\(g(x,y) = xy- e^x\)</span></p><p>当 <span class="math inline">\(y&gt;0\)</span> 时，<span class="math inline">\(\sup g(x,y) = y \log y - y\)</span> 当且仅当 <span class="math inline">\(x = \log y\)</span></p><p>当 <span class="math inline">\(y = 0\)</span> 时，<span class="math inline">\(\sup g(x,y) = \sup (-e^x) = 0\)</span></p><p>当 <span class="math inline">\(y &lt;0\)</span> 时，<span class="math inline">\(\sup g(x,y) = +\infty\)</span></p><p>故 <span class="math display">\[f^*(y) = \left\{\begin{aligned}y \log y - y, y &gt; 0 \\0, y = 0\end{aligned}\right.\]</span></p><h2 id="五">五</h2><blockquote><p>求解线性规划 <span class="math display">\[\begin{aligned}&amp;\min &amp;e^T x \\&amp;\textrm{s.t} &amp;G x \leq h \\&amp; &amp;Ax = b\end{aligned}\]</span> 的对偶函数，给出对偶问题。</p></blockquote><p>拉格朗日函数 <span class="math display">\[\begin{aligned}L(x, \lambda, \mu) &amp;= e^T x + \lambda^T (Gx-h) + \mu^T(Ax-b) \\&amp;= (e^T + \lambda G+\mu^T A)x - \lambda^T h - \mu^T b\end{aligned}\]</span> 故 <span class="math display">\[g(\lambda, \mu) = \left\{\begin{aligned}-\lambda^T h - \mu^T b &amp;,&amp; e + G^T \lambda + A^T \mu = 0 \\-\infty&amp;,&amp; otherwise\end{aligned}\right.\]</span> 因此其对偶问题为 <span class="math display">\[\max_{\lambda, \mu} \left( -\lambda^Th-\mu^Tb \right) \\s.t. \ \ e + G^T \lambda + A^T \mu = 0, \lambda \geq 0\]</span></p><h2 id="六">六</h2><blockquote><p>证明：Gauss概率密度函数的累积分布函数 <span class="math display">\[\Phi(x) = \frac{1}{\sqrt{2 \pi}} \int_{- \infty}^x e^{-\frac{u^2}{2}} du\]</span> 是对数-凹函数。即 <span class="math inline">\(\log(\Phi(x))\)</span> 是凹函数。</p></blockquote><p>由于 <span class="math display">\[\Phi&#39;(x) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} \\\Phi&#39;&#39;(x) = -\frac{x}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}}\]</span> 故 <span class="math display">\[(\Phi&#39;(x))^2 = \frac{1}{2 \pi} e^{-\frac{x^2}{2}} \\\Phi(x) \Phi&#39;&#39;(x) = -\frac{x}{2 \pi} e^{-\frac{x^2}{2}} \int_{-\infty}^x e^{-\frac{u^2}{2}} du\]</span> 当 <span class="math inline">\(x \geq 0\)</span> 时，易见 <span class="math inline">\(\Phi(x) \Phi&#39;&#39;(x) \leq (\Phi&#39;(x))^2\)</span></p><p>当 <span class="math inline">\(x &lt; 0\)</span> 时，由 <span class="math inline">\(\frac{u^2}{2}\)</span> 的凸性可知 <span class="math display">\[\begin{aligned}\Phi(x) \Phi&#39;&#39;(x) &amp;= -\frac{x}{2 \pi} e^{-\frac{x^2}{2}} \int_{-\infty}^x e^{-\frac{u^2}{2}} du \\&amp;\leq -\frac{x}{2 \pi} e^{-\frac{x^2}{2}} \int_{-\infty}^x e^{-\frac{x^2}{2}-(u-x)x} du \\&amp;=\frac{1}{2\pi} e^{-\frac{x^2}{2}} \\&amp;= \left(\Phi&#39;(x)\right)^2\end{aligned}\]</span> 由此可知 <span class="math inline">\(\Phi(x)\)</span> 时对数凸函数</p><h2 id="七">七</h2><blockquote><p>求优化问题 <span class="math inline">\(\arg\min_{x_1, x_2, x_3} x_1x_2x_3\)</span> 当 <span class="math inline">\(x_1,x_2,x_3\)</span> 满足 <span class="math inline">\(x_1^2 + x_2^2 + x_3^2 = 1\)</span> 的解</p></blockquote><p>拉格朗日函数 <span class="math inline">\(L = x_1x_2x_3 + \lambda (x_1^2 + x_2^2+x_3^2 - 1)\)</span></p><p>令 <span class="math inline">\(\nabla L = 0\)</span>，即 <span class="math display">\[\left\{\begin{aligned}&amp;\frac{\partial L}{\partial x_1} = x_2 x_3 + 2\lambda x_1 = 0 \\&amp;\frac{\partial L}{\partial x_2} = x_1 x_3 + 2\lambda x_2 = 0 \\&amp;\frac{\partial L}{\partial x_3} = x_1 x_2 + 2\lambda x_3 = 0 \\&amp;\frac{\partial L}{\partial \lambda} = x_1^2 + x_2^2 + x_3^2 - 1 = 0 \\\end{aligned}\right.\]</span> 解得 <span class="math inline">\(|x_1| = |x_2| = |x_3| = \frac{1}{\sqrt{3}}\)</span></p><p>故 <span class="math inline">\(|x_1x_2x_3| = \frac{\sqrt{3}}{9}\)</span></p><p>代入原方程可知 <span class="math inline">\(x_1x_2x_3 = -\frac{\sqrt{3}}{9}\)</span></p><h2 id="八">八</h2><blockquote><p>已知矩阵 <span class="math inline">\(A \in \mathbb{R}^{p \times q}, B \in \mathbb{R}^{p \times r}, \textrm{rank}(A) = \min (p,q)\)</span>，未知矩阵 <span class="math inline">\(X \in \mathbb{R}^{q \times r}\)</span>，求以下优化问题：</p><p>若 <span class="math inline">\(p &lt; q\)</span>，求Frobenius范数最小的矩阵 <span class="math inline">\(X\)</span>，使得 <span class="math inline">\(AX = B\)</span>，也即优化问题为 <span class="math display">\[\begin{aligned}&amp;\min &amp;f(X) = \frac{1}{2} ||X||_F^2 \\&amp;\textrm{s.t} &amp;AX = B\end{aligned}\]</span></p></blockquote><p>拉格朗日函数 <span class="math inline">\(L = Tr(\frac{1}{2} X^T X) - Tr(\Lambda^T(AX-B))\)</span></p><p>令 <span class="math inline">\(\nabla L = 0\)</span>，即 <span class="math display">\[\left\{\begin{aligned}&amp;\frac{\partial L}{\partial X} = X-A^T \Lambda = 0 \\&amp;\frac{\partial L}{\partial \Lambda} = AX-B = 0\end{aligned}\right.\]</span> 由于 <span class="math inline">\(A\)</span> 行满秩，故 <span class="math inline">\(AA^T\)</span> 可逆</p><p>故 <span class="math inline">\(AX = B = AA^T(AA^T)^{-1}B\)</span></p><p>即 <span class="math inline">\(X = A^T(AA^T)^{-1} B\)</span></p><h2 id="九">九</h2><blockquote><p>给出优化问题 <span class="math inline">\(\min_x (x^3 - ax)\)</span> 使用牛顿法时的迭代格式。</p></blockquote><p><span class="math display">\[f&#39;(x) = 3x^2-a, f&#39;&#39;(x) = 6x\]</span></p><p>故 <span class="math display">\[x_n = x_{n-1} - \frac{f&#39;(x_n)}{f&#39;&#39;(x_n)} = x_{n-1} - \frac{3x_n^2-a}{6x_n}\]</span></p><h2 id="十">十</h2><blockquote><p>梯度下降法是最常用的优化方法之一。考虑优化问题 <span class="math display">\[\min f(x) = x_1^2 + x_2^2 + 2x_3^2\]</span> 证明:在点 <span class="math inline">\(x_0 = (x_1, x_2, x_3)\)</span> 处沿负梯度方向迭代的最佳步⻓为 <span class="math display">\[\lambda = \frac{x_1^2 + x_2^2 + 4x_3^2}{2x_1^2 + 2x_2^2 + 16 x_3^2}\]</span></p></blockquote><p>令 <span class="math inline">\(x&#39; = x - \lambda \nabla f(x)\)</span></p><p>故 <span class="math display">\[\begin{aligned}g(\lambda) &amp;= f(x&#39;) \\&amp;= f(x - \lambda \nabla f(x)) \\&amp;= (1-2\lambda)^2 x_1^2 + (1-2\lambda)^2 x_2^2 + 2 (1-4\lambda)^2 x_3^2\end{aligned}\]</span> 于是 <span class="math display">\[g&#39;(\lambda) = -4(1-2\lambda)^2 x_1^2 - 4 (1-2\lambda)^2x_2^2 - 16(1-4\lambda)x_3^2\]</span> 令 <span class="math inline">\(g&#39;(\lambda) = 0\)</span></p><p>解得 <span class="math display">\[\lambda = \frac{x_1^2+x_2^2+4x_3^2}{2x_1^2+2x_2^2+16x_3^2}\]</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一&quot;&gt;一&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;下面的集合哪些是凸集？&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;平板， 即形如 &lt;span class=&quot;math inline&quot;&gt;\(\left\{ x \in \mathbb{R}^n | \alpha </summary>
      
    
    
    
    <category term="数据科学数学基础" scheme="http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Mathematics" scheme="http://gonggongjohn.me/tags/Mathematics/"/>
    
    <category term="DataScience" scheme="http://gonggongjohn.me/tags/DataScience/"/>
    
  </entry>
  
  <entry>
    <title>数据科学与工程数学基础 作业6</title>
    <link href="http://gonggongjohn.me/2021/06/30/dase-math/dase-math-assignment-6/"/>
    <id>http://gonggongjohn.me/2021/06/30/dase-math/dase-math-assignment-6/</id>
    <published>2021-06-30T01:00:00.000Z</published>
    <updated>2022-02-10T14:36:32.120Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一">一</h2><blockquote><p>证明：若 <span class="math inline">\(H(Y|X) = 0\)</span> 则 <span class="math inline">\(Y\)</span> 是 <span class="math inline">\(X\)</span> 的函数（即对于满足 <span class="math inline">\(p(x) &gt; 0\)</span> 的任意 <span class="math inline">\(x\)</span>，仅存在一个可能的取值 <span class="math inline">\(y\)</span>，使得 <span class="math inline">\(p(x,y) &gt; 0\)</span>）</p></blockquote><p>由 <span class="math inline">\(H(Y|X) = 0\)</span> 可知，对任意 <span class="math inline">\(x_i\)</span>，存在唯一的 <span class="math inline">\(y_j\)</span> 使得 <span class="math inline">\(P(Y=y_j|X=x_i) = 1\)</span></p><p>故 <span class="math display">\[\begin{aligned}p(x_i, y_j) &amp;= p(y_j|x_i) \cdot p(x_i) \\&amp;=p(x_i), X=x_i \land Y=y_j\end{aligned}\]</span> 也即 <span class="math inline">\(Y\)</span> 是 <span class="math inline">\(X\)</span> 的函数</p><h2 id="二">二</h2><blockquote><p>一个容器里面装有 <span class="math inline">\(a\)</span> 个红球和 <span class="math inline">\(b\)</span> 个白球，若从容器中取出 <span class="math inline">\(k(k \geq 2)\)</span> 个球。对于有放回和无放回两种情况，哪种情况的熵更大?请回答并给予说明。</p></blockquote><p>有放回时，第 <span class="math inline">\(i\)</span> 次摸出红球和白球的概率是相同的</p><p>无放回时， 第 <span class="math inline">\(i\)</span> 次摸出红球和白球的概率与前 <span class="math inline">\(i-1\)</span> 次的结果有关</p><p>于是由熵的极值性可知，有放回的熵更大。</p><h2 id="三">三</h2><blockquote><p>投掷一枚均匀的硬币。硬币出现正面和反面的互信息是多少？</p></blockquote><p><span class="math display">\[I(H,T) = \log \frac{P(H|T)}{P(H)} = -\infty\]</span></p><h2 id="四">四</h2><blockquote><p>投掷一颗 <span class="math inline">\(6\)</span> 面均匀的骰子，出现顶面和前面的互信息是多少？</p></blockquote><p><span class="math display">\[I(Top, Front) = \log \frac{P(Top|Front)}{P(Top)} = -\infty\]</span></p><h2 id="五">五</h2><blockquote><p>求均匀分布 <span class="math inline">\(X \sim U(a,b)\)</span> 的微分熵</p></blockquote><p><span class="math display">\[\begin{aligned}h(X) &amp;= -\int_a^b \frac{1}{b-a} \log \frac{1}{b-a} dx \\&amp;=\log(b-a)\end{aligned}\]</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一&quot;&gt;一&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;证明：若 &lt;span class=&quot;math inline&quot;&gt;\(H(Y|X) = 0\)&lt;/span&gt; 则 &lt;span class=&quot;math inline&quot;&gt;\(Y\)&lt;/span&gt; 是 &lt;span clas</summary>
      
    
    
    
    <category term="数据科学数学基础" scheme="http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Mathematics" scheme="http://gonggongjohn.me/tags/Mathematics/"/>
    
    <category term="DataScience" scheme="http://gonggongjohn.me/tags/DataScience/"/>
    
  </entry>
  
  <entry>
    <title>树莓派在线教学系统</title>
    <link href="http://gonggongjohn.me/2021/06/29/web/remote-teaching/"/>
    <id>http://gonggongjohn.me/2021/06/29/web/remote-teaching/</id>
    <published>2021-06-29T03:28:35.000Z</published>
    <updated>2021-07-02T16:20:12.083Z</updated>
    
    <content type="html"><![CDATA[<h2 id="树莓派部署">树莓派部署</h2><p>​ <strong>树莓派（Raspberry Pi）</strong>是由英国慈善组织“Raspberry Pi基金会”开发的一款ARM微型单片机，其具备了一台标准计算机的绝大部分功能，常被用于提供各类小型服务类应用及嵌入式产品驱动。本项目基于Raspberry Pi 4B型号进行开发。</p><p>​ 树莓派官方提供了一个基于Linux内核的专为树莓派硬件设计的<strong>Raspberry Pi OS</strong>操作系统，可以直接在其官网进行镜像的下载。这里我们使用当前最新版<strong>（Kernel Version: 5.10）</strong>进行开发。</p><a id="more"></a><p><img src="raspberry_os.png" alt="raspberry_os" style="zoom:50%;" /></p><p>​ 将系统烧录至SD卡并引导进入系统后，我们首先打开系统的SSH及VNC服务，使得其可以通过远程访问：</p><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">&gt; sudo raspi-config<br></code></pre></td></tr></table></figure><p>在弹出的GUI界面中选择<strong>Interfacing Options</strong>，依次打开SSH及VNC配置项即可。</p><p>​ 接下来我们来为树莓派创建一个热点，使得其他设备可以连接到树莓派的WIFI网络中以通过局域网访问后续的教学网站页面。首先我们安装在系统中安装<strong>hostapd</strong>（一个类Unix系统下可以提供热点访问的服务端工具）和<strong>dnsmasq</strong>（一个用于配置DNS和DHCP的工具）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; sudo apt-get install hostapd<br>&gt; sudo apt install dnsmasq<br></code></pre></td></tr></table></figure><p>在<strong>/etc/hostapd/</strong>目录下创建一个<strong>hostapd.conf</strong>配置文件，并在其中指定要创建热点的相关信息：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">interface</span>=wlan0<br><span class="hljs-attr">driver</span>=nl80211<br><span class="hljs-attr">ssid</span>=graspberry<br><span class="hljs-attr">hw_mode</span>=g<br><span class="hljs-attr">channel</span>=<span class="hljs-number">7</span><br><span class="hljs-attr">wmm_enabled</span>=<span class="hljs-number">0</span><br><span class="hljs-attr">macaddr_acl</span>=<span class="hljs-number">0</span><br><span class="hljs-attr">auth_algs</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">ignore_broadcast_ssid</span>=<span class="hljs-number">0</span><br><span class="hljs-attr">wpa</span>=<span class="hljs-number">2</span><br><span class="hljs-attr">wpa_passphrase</span>=<span class="hljs-number">1029384756</span><br><span class="hljs-attr">wpa_key_mgmt</span>=WPA-PSK<br><span class="hljs-attr">wpa_pairwise</span>=TKIP<br><span class="hljs-attr">rsn_pairwise</span>=CCMP<br></code></pre></td></tr></table></figure><p>随后我们将这一配置文件添加到<strong>/etc/default/hostapd</strong>中：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">DAEMON_CONF</span>=<span class="hljs-string">&quot;/etc/hostapd/hostapd.conf&quot;</span><br></code></pre></td></tr></table></figure><p>重启系统后，我们打开hostapd服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; sudo systemctl unmask hostapd<br>&gt; sudo systemctl <span class="hljs-built_in">enable</span> hostapd<br>&gt; sudo systemctl start hostapd<br></code></pre></td></tr></table></figure><p>现在，我们便可以在其他设备上搜索到树莓派的热点信号了：</p><p><img src="raspberry_hotspot.png" alt="raspberry_hotspot" style="zoom:50%;" /></p><p>连接热点后，我们只需要使用SSH工具，便可以远程访问树莓派：</p><p><img src="raspberry_ssh.png" alt="raspberry_ssh" style="zoom:50%;" /></p><p>​ 由于Raspberry Pi OS是Linux系统的一种，我们可以使用与开发环境类似的方式部署网站。首先我们从官网下载并安装Node运行环境包（https://nodejs.org/zh-cn/download/），并配置相应的环境变量：<strong>（.bash_profile）</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> NODE_HOME=/home/pi/ node-v14.17.2-linux-armv7l<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$NODE_HOME</span>/bin <br><span class="hljs-built_in">export</span> NODE_PATH=<span class="hljs-variable">$NODE_HOME</span>/lib/node_modules<br></code></pre></td></tr></table></figure><p>随后我们使用apt-get安装<strong>MariaDB-Server</strong>作为服务端数据库环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; sudo apt-get install mariadb-server-10.0<br></code></pre></td></tr></table></figure><p>以安全模式进入数据库并修改数据库默认密码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; sudo service mysql stop<br>&gt; sudo mysqld_safe --skip-grant-tables &amp;<br>&gt; mysql -u root<br>MariaDB&gt; update mysql.user <span class="hljs-built_in">set</span> authentication_string=PASSWORD(<span class="hljs-string">&#x27;1029384756&#x27;</span>), plugin=<span class="hljs-string">&#x27;mysql_native_password&#x27;</span> <span class="hljs-built_in">where</span> user=<span class="hljs-string">&#x27;root&#x27;</span>;<br>&gt; sudo service mysql stop<br>&gt; sudo service mysql start<br></code></pre></td></tr></table></figure><p>现在我们的树莓派系统已经可以支持网页应用的部署了。</p><h2 id="系统构架">系统构架</h2><p>​ 整个树莓派在线教学系统分为<strong>用户端（前端）</strong>及<strong>服务端（后端）</strong>，其中用户端又分为<strong>学生端</strong>和<strong>教师端</strong>，其基本系统构架如下图所示：</p><figure><img src="structure.png" alt="structure" /><figcaption aria-hidden="true">structure</figcaption></figure><p>​ 可以看到，整个系统的构架是十分清晰的。用户首先通过用户管理系统登录在线教学系统，系统会根据教师或学生身份分别跳转到教师端的课程路由界面或学生端课程路由界面。随后，系统通过请求后端的课程数据库来返回用户当前参与或教授的所有课程，用户可根据界面提示进入到相应的课程界面中。对于一个课程界面，系统提供了签到、实时聊天、文件下载、在线答题及视频推流5个基本模块，每个模块经过后端路由再传递给服务器文件系统或另一学生/教师客户端。对于学生签到机制，后端会通过深度学习模型对前端传入的照片进行人脸识别，并将相应的签到结果传给教师客户端；而对于在线答题机制，则由教师端先上传一定格式的题目描述及答题限制，再由后端的试题结构解析器进行解析分发给学生客户端，当学生完成答题后，再通过路由送到后端进行结果统计，并将统计结果发送回教师端展示。</p><p>​ 以用户视角来看，教学系统的主体界面效果如下：</p><p><img src="lesson.png" alt="lesson" style="zoom:50%;" /></p><h2 id="quasar-framework与前端整合">Quasar Framework与前端整合</h2><p>​ 由于该网站的前端元素较为繁杂，我们需要一个合适易用的前端框架来避免大量不必要的重复编码。Quasar Framework是一款基于Vue.js的前端UI框架，其开箱即用和跨平台的属性使得我们可以快速的对各类UI元素进行整合。要构架Quasar Framework开发环境是容易的，Quasar官方提供了一个基于Vuex的脚手架，我们以此为起点来进行网站前端的构建。</p><p>​ 首先我们使用npm工具全局安装Quasar-CLI最新版：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; npm install -g @quasar/cli<br></code></pre></td></tr></table></figure><p>系统会自动安装相关的必要的组建，包括Vue-CLI脚手架（如果没有自动安装的话，可以手动安装Vue-CLI最新版本）。</p><p>随后，我们在目标位置使用Quasar-CLI生成一个前端开发环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; quasar create frontend<br></code></pre></td></tr></table></figure><p>系统会自动解析并生成所需的相应配置文件，并会在其中询问我们若干次相关参数的设置值，这里我们直接使用默认选项即可。</p><p><img src="quasar_create.png" alt="quasar_create" style="zoom:50%;" /></p><p>生成完成后，我们进入目录安装相应的Node依赖包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; npm install<br></code></pre></td></tr></table></figure><p>现在，我们的前端开发环境就配置完成了。我们可以使用如下命令即时查看开发效果，也可以对整个应用进行打包送至后端进行整合：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; quasar dev <span class="hljs-comment"># 开发环境测试</span><br>&gt; quasar build <span class="hljs-comment"># 打包至生产环境</span><br></code></pre></td></tr></table></figure><p><img src="quasar_build.png" alt="quasar_build" style="zoom:50%;" /></p><p>​ Vue将<strong>布局（Layout）</strong>和<strong>页面（Page）</strong>进行了分离，使得在同种布局下网站中的内容可以进行缺省替换，这正是本项目所需要的。对于本项目，我们设计了两种不同的界面布局，分别用于用户管理和授课窗口。网站的前端路由结构如下图所示：</p><p><img src="frontend_structure.png" alt="frontend_structure" style="zoom:80%;" /></p><h2 id="express与后端路由">Express与后端路由</h2><p>​ 为了与前端达到最佳的适配，我们使用<strong>NodeJS+Express框架</strong>作为服务端的实现基础。与Quasar类似，Express同样提供了一个官方脚手架用于搭建后端的开发环境。我们只需使用npm工具全局安装即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; npm install -g express<br>&gt; npm install -g express-generator<br></code></pre></td></tr></table></figure><p>安装完成后，我们在目标位置生成一个新的后端项目：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; express backend<br></code></pre></td></tr></table></figure><p>Express脚手架会在目标位置自动生成相关的依赖文件：</p><p><img src="express_create.png" alt="express_create" style="zoom:50%;" /></p><p>生成完后端环境后，我们进入目录，使用npm安装相应的依赖包，即可使用如下命令进行后端的测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&gt; node bin/www<br></code></pre></td></tr></table></figure><p>​ 本项目后端路由的整体结构如图所示：</p><p><img src="backend_structure.png" alt="backend_structure" style="zoom:80%;" /></p><p>可以发现，除了根目录为网页推送接口，其他接口均为前端请求响应接口，故这些接口可以向用户隐去。此外，本项目还需要额外创建一个WebSocket服务器来响应实时的前后端数据交互请求。</p><h2 id="用户管理">用户管理</h2><p>​ 我们在数据库中创建一张表<strong>user</strong>来管理用户的基本信息。对于一个用户而言，我们需要记录其<strong>用户名（username）</strong>、<strong>密码（password）</strong>、<strong>邮箱（email）</strong>和<strong>身份（identity）</strong>。此外，我们还需要记录其<strong>参加/开设的课程编号（lessons）</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE user(<br>    &#96;id&#96; INT NOT NULL AUTO_INCREMENT,<br>    &#96;username&#96; TEXT NOT NULL,<br>    &#96;password&#96; TEXT NOT NULL,<br>    &#96;email&#96; TEXT,<br>    &#96;identity&#96; INT NOT NULL,<br>    &#96;lessons&#96; TEXT,<br>    PRIMARY KEY (&#96;id&#96;)<br>);<br></code></pre></td></tr></table></figure><p>​ 用户的基本管理逻辑分为注册和登录。我们将两个逻辑分别封装在两个独立的函数中，并采用<strong>回调函数</strong>的方式让路由调用。对于用户登录，我们只需要查询表中是否存在对应username键和password键的行即可。由于Node.JS中的Mysql插件为<strong>异步</strong>访问的，这里我们需要使用<strong>Promise</strong>函数来确保其执行顺序。为了向回调函数提供统一的接口，我们使用<strong>status</strong>状态字来指示查询的结果和状态：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> login = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">username, password, callback</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> sql_str = <span class="hljs-string">&quot;SELECT username,password FROM user WHERE username=?&quot;</span>;<br>    <span class="hljs-keyword">var</span> sql_param = [username];<br>    <span class="hljs-keyword">var</span> promise = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve, reject</span>)</span>&#123;<br>        mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>            <span class="hljs-keyword">if</span>(err)&#123;<br>                reject(err);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                resolve(result);<br>            &#125;<br>        &#125;);<br>    &#125;);<br>    promise.then(<span class="hljs-function">(<span class="hljs-params">result</span>) =&gt;</span> &#123;<br>        <span class="hljs-keyword">var</span> status = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 0 - 未确定; 1 - 成功; 2 - 用户名不存在; 3 - 密码错误 */</span><br>        <span class="hljs-keyword">if</span>(result == <span class="hljs-literal">undefined</span> || result.length == <span class="hljs-number">0</span>)&#123;<br>            status = <span class="hljs-number">2</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(result[<span class="hljs-number">0</span>].password == password)&#123;<br>            status = <span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            status = <span class="hljs-number">3</span>;<br>        &#125;<br>        callback(status);<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><p>​ 注册的逻辑同登录类似，只需将Mysql查询语句改为插入语句即可。这里需要注意的是，为了确保用户名的唯一性，我们在插入数据之前需首先查询表中是否已经存在对应的username键值，如果存在相同用户名，我们需要返回用户一个“用户名已存在”的错误：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> register = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">username, password, email, identity, callback</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> sql_str = <span class="hljs-string">&quot;SELECT username FROM user WHERE username=?&quot;</span>;<br>    <span class="hljs-keyword">var</span> sql_param = [username];<br>    <span class="hljs-keyword">var</span> promise_query = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve, reject</span>)</span>&#123;<br>        mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>            <span class="hljs-keyword">if</span>(err)&#123;<br>                reject(err);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                resolve(result);<br>            &#125;<br>        &#125;);<br>    &#125;);<br>    promise_query.then(<span class="hljs-function">(<span class="hljs-params">result</span>) =&gt;</span> &#123;<br>        <span class="hljs-keyword">var</span> status = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 0 - 未确定; 1 - 成功; 2 - 用户名已存在 */</span><br>        <span class="hljs-keyword">if</span>(result.length &gt; <span class="hljs-number">0</span>)&#123;<br>            status = <span class="hljs-number">2</span>;<br>            callback(status);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            sql_str = <span class="hljs-string">&quot;INSERT INTO user(username, password, email, identity) VALUES (?,?,?,?)&quot;</span>;<br>            sql_param = [username, password, email, identity];<br>            <span class="hljs-keyword">var</span> promise_insert = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve, reject</span>)</span>&#123;<br>                mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>                    <span class="hljs-keyword">if</span>(err)&#123;<br>                        reject(err);<br>                    &#125;<br>                    <span class="hljs-keyword">else</span>&#123;<br>                        resolve(result);<br>                    &#125;<br>                &#125;);<br>            &#125;);<br>            promise_insert.then(<span class="hljs-function">(<span class="hljs-params">result</span>) =&gt;</span> &#123;<br>                status = <span class="hljs-number">1</span>;<br>                callback(status);<br>            &#125;)<br>        &#125;<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="课程管理">课程管理</h2><p>​ 为了提高整个系统的可扩展性，我们希望能够并行的同时进行多个课程的在线教学。要做到这一点，我们需要将每个课程的工作环境隔离开来。幸运的是，在Mysql数据库中，我们可以创建一个唯一的ID使得其在每次插入数据的时候进行自增，因此我们可以直接使用这一ID作为课程的唯一标识。</p><p>​ 我们首先创建一张<strong>lesson</strong>表用于维护整个系统中的全局课程信息，这张表中应当维护<strong>课程名（name）</strong>、<strong>授课教师ID（teacher）</strong>及<strong>学生列表（students）</strong>三个关键字：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE lesson(<br>    &#96;id&#96; INT NOT NULL AUTO_INCREMENT,<br>    &#96;name&#96; TEXT NOT NULL,<br>    &#96;teacher&#96; TEXT,<br>    &#96;students&#96; TEXT,<br>    PRIMARY KEY (&#96;id&#96;)<br>);<br></code></pre></td></tr></table></figure><p>​ 随后，我们需要封装一系列函数来对这一表格内容进行维护。当教师新创建一门课程时，前端会向教师询问课程名，并请求后端的<strong>/lesson_create</strong>口进行课程创建：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">template</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">q-page</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;flex flex-top-left&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;width: 100%; margin-top: 2%&quot;</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">q-btn</span> <span class="hljs-attr">color</span>=<span class="hljs-string">&quot;secondary&quot;</span> <span class="hljs-attr">hidden</span>=<span class="hljs-string">&quot;false&quot;</span> <span class="hljs-attr">padding</span>=<span class="hljs-string">&quot;sm xl&quot;</span> <span class="hljs-attr">ref</span>=<span class="hljs-string">&quot;create_btn&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;margin-left: 3%&quot;</span> <span class="hljs-attr">label</span>=<span class="hljs-string">&quot;创建课程&quot;</span> @<span class="hljs-attr">click</span>=<span class="hljs-string">&quot;createLesson = true&quot;</span> /&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">q-dialog</span> <span class="hljs-attr">v-model</span>=<span class="hljs-string">&quot;createLesson&quot;</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">q-card</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">q-card-section</span> <span class="hljs-attr">align</span>=<span class="hljs-string">&quot;center&quot;</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">q-input</span> <span class="hljs-attr">outlined</span> <span class="hljs-attr">v-model</span>=<span class="hljs-string">&quot;lesson_name&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;q-pa-sm&quot;</span> <span class="hljs-attr">:rules</span>=<span class="hljs-string">&quot;[val =&gt; !!val || &#x27;课程名称不能为空！&#x27;]&quot;</span> <span class="hljs-attr">label</span>=<span class="hljs-string">&quot;课程名称&quot;</span> /&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">q-btn</span> <span class="hljs-attr">color</span>=<span class="hljs-string">&quot;secondary&quot;</span> <span class="hljs-attr">padding</span>=<span class="hljs-string">&quot;sm xl&quot;</span> <span class="hljs-attr">label</span>=<span class="hljs-string">&quot;创建课程&quot;</span> @<span class="hljs-attr">click</span>=<span class="hljs-string">&quot;onCreateLesson&quot;</span> <span class="hljs-attr">v-close-popup</span> /&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">q-card-section</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">q-card</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">q-dialog</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">q-page</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">template</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><br><span class="javascript">    <span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> &#123;</span><br><span class="javascript">        name: <span class="hljs-string">&#x27;lessonList&#x27;</span>,</span><br>        data()&#123;<br><span class="javascript">            <span class="hljs-keyword">return</span>&#123;</span><br><span class="javascript">                username: <span class="hljs-string">&quot;&quot;</span>,</span><br><span class="javascript">                createLesson: <span class="hljs-literal">false</span>,</span><br><span class="javascript">                lesson_name: <span class="hljs-string">&quot;&quot;</span>,</span><br>            &#125;<br>        &#125;,<br>        methods: &#123;<br>            onCreateLesson()&#123;<br><span class="javascript">                <span class="hljs-keyword">var</span> full_url = <span class="hljs-string">&#x27;lesson_create?name=&#x27;</span> + <span class="hljs-built_in">this</span>.lesson_name + <span class="hljs-string">&#x27;&amp;teacher=&#x27;</span> + <span class="hljs-built_in">this</span>.username;</span><br><span class="javascript">                <span class="hljs-built_in">this</span>.axios.get(full_url).then(<span class="hljs-function">(<span class="hljs-params">response</span>) =&gt;</span> &#123;</span><br><span class="javascript">                    <span class="hljs-keyword">var</span> status = response.data.status;</span><br>                    if(status == 1)&#123;<br><span class="javascript">                        alert(<span class="hljs-string">&quot;创建成功！&quot;</span>);</span><br>                    &#125;<br><span class="javascript">                    <span class="hljs-keyword">else</span> &#123;</span><br><span class="javascript">                        <span class="hljs-built_in">console</span>.log(<span class="hljs-string">&quot;Error occurred!&quot;</span>);</span><br>                    &#125;<br><span class="javascript">                &#125;).catch(<span class="hljs-function">(<span class="hljs-params">response</span>) =&gt;</span> &#123;</span><br><span class="javascript">                    <span class="hljs-built_in">console</span>.log(response);</span><br>                &#125;);<br>            &#125;<br>        &#125;<br>    &#125;<br><br><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br></code></pre></td></tr></table></figure><p>创建课程的基本逻辑为<strong>无重名确认-&gt;创建课程-&gt;查询课程ID-&gt;将课程信息添加到教师授课列表中</strong>，我们可以快速写出相应的实现代码：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> createLesson = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">name, teacher, callback</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> sql_str = <span class="hljs-string">&quot;SELECT name FROM lesson WHERE name=? AND teacher=?&quot;</span>;<br>    <span class="hljs-keyword">var</span> sql_param = [name, teacher];<br>    <span class="hljs-keyword">var</span> promise_check = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_check, reject_check</span>)</span>&#123;<br>        mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>            <span class="hljs-keyword">if</span>(err)&#123;<br>                reject_check(err);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                resolve_check(result);<br>            &#125;<br>        &#125;);<br>    &#125;);<br>    promise_check.then(<span class="hljs-function">(<span class="hljs-params">result_check</span>) =&gt;</span> &#123;<br>        <span class="hljs-keyword">var</span> status = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 1 - 成功; 2 - 课程重名; 3 - 内部错误 */</span><br>        <span class="hljs-keyword">if</span>(result_check.length &gt; <span class="hljs-number">0</span>)&#123;<br>            status = <span class="hljs-number">2</span>;<br>            callback(status);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            sql_str = <span class="hljs-string">&quot;INSERT INTO lesson(name, teacher) VALUES (?,?)&quot;</span>;<br>            sql_param = [name, teacher];<br>            <span class="hljs-keyword">var</span> promise_create = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_create, reject_create</span>)</span>&#123;<br>                mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>                    <span class="hljs-keyword">if</span>(err)&#123;<br>                        reject_create(err);<br>                    &#125;<br>                    <span class="hljs-keyword">else</span>&#123;<br>                        resolve_create(result);<br>                    &#125;<br>                &#125;);<br>            &#125;);<br>            promise_create.then(<span class="hljs-function">(<span class="hljs-params">result_create</span>) =&gt;</span> &#123;<br>                sql_str = <span class="hljs-string">&quot;SELECT id FROM lesson WHERE name=? AND teacher=?&quot;</span>;<br>                sql_param = [name, teacher];<br>                <span class="hljs-keyword">var</span> promise_getid = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_getid, reject_getid</span>)</span>&#123;<br>                    mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>                        <span class="hljs-keyword">if</span>(err)&#123;<br>                            reject_getid(err);<br>                        &#125;<br>                        <span class="hljs-keyword">else</span>&#123;<br>                            resolve_getid(result);<br>                        &#125;<br>                    &#125;);<br>                &#125;);<br>                promise_getid.then(<span class="hljs-function">(<span class="hljs-params">result_getid</span>) =&gt;</span> &#123;<br>                    <span class="hljs-keyword">if</span>(result_getid == <span class="hljs-literal">undefined</span> || result_getid.length == <span class="hljs-number">0</span>)&#123;<br>                        status = <span class="hljs-number">3</span>;<br>                        callback(status);<br>                    &#125;<br>                    <span class="hljs-keyword">else</span>&#123;<br>                        appendLesson(teacher, result_getid[<span class="hljs-number">0</span>].id, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">status_append</span>)</span>&#123;<br>                            <span class="hljs-keyword">if</span>(status_append != <span class="hljs-number">1</span>)&#123;<br>                                status = <span class="hljs-number">3</span>;<br>                            &#125;<br>                            <span class="hljs-keyword">else</span>&#123;<br>                                status = <span class="hljs-number">1</span>;<br>                                callback(status);<br>                            &#125;<br>                        &#125;);<br>                    &#125;<br>                &#125;);<br>            &#125;);<br>        &#125;<br>    &#125;);<br>&#125;<br><br><span class="hljs-keyword">var</span> appendLesson = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">username, lesson_id, callback</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> sql_str = <span class="hljs-string">&quot;SELECT lessons FROM user WHERE username=?&quot;</span>;<br>    <span class="hljs-keyword">var</span> sql_param = [username];<br>    <span class="hljs-keyword">var</span> status = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 1 - 成功; 2 - 用户名不存在 */</span><br>    <span class="hljs-keyword">var</span> promise_showlist = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_showlist, reject_showlist</span>)</span>&#123;<br>        mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>            <span class="hljs-keyword">if</span>(err)&#123;<br>                reject_showlist(err);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                resolve_showlist(result);<br>            &#125;<br>        &#125;);<br>    &#125;);<br>    promise_showlist.then(<span class="hljs-function">(<span class="hljs-params">result_showlist</span>) =&gt;</span> &#123;<br>        <span class="hljs-keyword">if</span>(result_showlist == <span class="hljs-literal">undefined</span> || result_showlist.length == <span class="hljs-number">0</span>)&#123;<br>            status = <span class="hljs-number">2</span>;<br>            callback(status);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">var</span> lesson_str = result_showlist[<span class="hljs-number">0</span>].lessons;<br>            <span class="hljs-keyword">if</span>(lesson_str == <span class="hljs-literal">undefined</span> || lesson_str == <span class="hljs-literal">null</span>)&#123;<br>                lesson_str = <span class="hljs-built_in">String</span>(lesson_id);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                lesson_str = lesson_str + <span class="hljs-string">&quot;,&quot;</span> + lesson_id;<br>            &#125;<br>            sql_str = <span class="hljs-string">&quot;UPDATE user SET lessons=? WHERE username=?&quot;</span>;<br>            sql_param = [lesson_str, username];<br>            <span class="hljs-keyword">var</span> promise_update = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_update, reject_update</span>)</span>&#123;<br>                mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>                    <span class="hljs-keyword">if</span>(err)&#123;<br>                        reject_update(err);<br>                    &#125;<br>                    <span class="hljs-keyword">else</span>&#123;<br>                        resolve_update(result);<br>                    &#125;<br>                &#125;);<br>            &#125;);<br>            promise_update.then(<span class="hljs-function">(<span class="hljs-params">resule_update</span>) =&gt;</span> &#123;<br>                status = <span class="hljs-number">1</span>;<br>                callback(status);<br>            &#125;);<br>        &#125;<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><p>这里需要注意的是，由于MySQL中没有“数组”这一基本数据类型，因此我们使用字符串拼接的方式将课程ID以字符串的形式存储到用户的lessons字段中，当需要查询用户的课程列表时，再通过字符串拆分的方式将其还原为ID列表。</p><p>参与已有的课程与查询用户参与的课程列表的逻辑也基本类似，基本都是对通过课程ID作为唯一的键桥梁分别在user和lesson中进行查询操作：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> getLessons = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">username, callback</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> sql_str = <span class="hljs-string">&quot;SELECT lessons FROM user WHERE username=?&quot;</span>;<br>    <span class="hljs-keyword">var</span> sql_param = [username];<br>    <span class="hljs-keyword">var</span> promise_showlist = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_showlist, reject_showlist</span>)</span>&#123;<br>        mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>            <span class="hljs-keyword">if</span>(err)&#123;<br>                reject_showlist(err);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                resolve_showlist(result);<br>            &#125;<br>        &#125;);<br>    &#125;);<br>    promise_showlist.then(<span class="hljs-function">(<span class="hljs-params">result_showlist</span>) =&gt;</span> &#123;<br>        <span class="hljs-keyword">var</span> errno = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 0 - 无错误; 1 - 用户名不存在; 2 - 课程不存在 */</span><br>        <span class="hljs-keyword">if</span>(result_showlist == <span class="hljs-literal">undefined</span> || result_showlist.length == <span class="hljs-number">0</span>)&#123;<br>            errno = <span class="hljs-number">1</span>;<br>            callback(errno, <span class="hljs-literal">undefined</span>);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">var</span> lesson_str = result_showlist[<span class="hljs-number">0</span>].lessons;<br>            <span class="hljs-keyword">if</span>(lesson_str == <span class="hljs-literal">null</span>)&#123;<br>                callback(errno, []);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                <span class="hljs-keyword">var</span> lesson_list = lesson_str.split(<span class="hljs-string">&quot;,&quot;</span>);<br>                <span class="hljs-keyword">var</span> fetch_total = lesson_list.length;<br>                <span class="hljs-keyword">var</span> fetched_num = <span class="hljs-number">0</span>;<br>                <span class="hljs-keyword">var</span> promise_loop = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_loop, reject_loop</span>)</span>&#123;<br>                    <span class="hljs-keyword">var</span> detail_list = [];<br>                    lesson_list.forEach(<span class="hljs-function">(<span class="hljs-params">lesson</span>) =&gt;</span> &#123;<br>                        sql_str = <span class="hljs-string">&quot;SELECT name,teacher FROM lesson where id=?&quot;</span>;<br>                        sql_param = [lesson];<br>                        <span class="hljs-keyword">var</span> promise_detail = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_detail, reject_detail</span>)</span>&#123;<br>                            mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>                                <span class="hljs-keyword">if</span>(err)&#123;<br>                                    reject_detail(err);<br>                                &#125;<br>                                <span class="hljs-keyword">else</span>&#123;<br>                                    resolve_detail(result);<br>                                &#125;<br>                            &#125;);<br>                        &#125;);<br>                        promise_detail.then(<span class="hljs-function">(<span class="hljs-params">result_detail</span>) =&gt;</span> &#123;<br>                            <span class="hljs-keyword">if</span>(result_detail == <span class="hljs-literal">undefined</span> || result_detail.length == <span class="hljs-number">0</span>)&#123;<br>                                errno = <span class="hljs-number">2</span>;<br>                                reject_loop(<span class="hljs-string">&quot;Lesson doesn&#x27;t exist!&quot;</span>);<br>                            &#125;<br>                            <span class="hljs-keyword">else</span>&#123;<br>                                detail_list.push(&#123;<span class="hljs-attr">id</span>: lesson, <span class="hljs-attr">name</span>: result_detail[<span class="hljs-number">0</span>].name, <span class="hljs-attr">teacher</span>: result_detail[<span class="hljs-number">0</span>].teacher&#125;);<br>                                fetched_num += <span class="hljs-number">1</span>;<br>                                <span class="hljs-keyword">if</span>(fetched_num == fetch_total)&#123;<br>                                    resolve_loop(detail_list);<br>                                &#125;<br>                            &#125;<br>                        &#125;);<br>                    &#125;);<br>                &#125;);<br>                promise_loop.then(<span class="hljs-function">(<span class="hljs-params">result_loop</span>) =&gt;</span> &#123;<br>                    callback(errno, result_loop);<br>                &#125;);<br>            &#125;<br>        &#125;<br>    &#125;);<br>&#125;<br><br><span class="hljs-keyword">var</span> appendLesson = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">username, lesson_id, callback</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> sql_str = <span class="hljs-string">&quot;SELECT lessons FROM user WHERE username=?&quot;</span>;<br>    <span class="hljs-keyword">var</span> sql_param = [username];<br>    <span class="hljs-keyword">var</span> status = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 1 - 成功; 2 - 用户名不存在 */</span><br>    <span class="hljs-keyword">var</span> promise_showlist = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_showlist, reject_showlist</span>)</span>&#123;<br>        mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>            <span class="hljs-keyword">if</span>(err)&#123;<br>                reject_showlist(err);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                resolve_showlist(result);<br>            &#125;<br>        &#125;);<br>    &#125;);<br>    promise_showlist.then(<span class="hljs-function">(<span class="hljs-params">result_showlist</span>) =&gt;</span> &#123;<br>        <span class="hljs-keyword">if</span>(result_showlist == <span class="hljs-literal">undefined</span> || result_showlist.length == <span class="hljs-number">0</span>)&#123;<br>            status = <span class="hljs-number">2</span>;<br>            callback(status);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">var</span> lesson_str = result_showlist[<span class="hljs-number">0</span>].lessons;<br>            <span class="hljs-keyword">if</span>(lesson_str == <span class="hljs-literal">undefined</span> || lesson_str == <span class="hljs-literal">null</span>)&#123;<br>                lesson_str = <span class="hljs-built_in">String</span>(lesson_id);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                lesson_str = lesson_str + <span class="hljs-string">&quot;,&quot;</span> + lesson_id;<br>            &#125;<br>            sql_str = <span class="hljs-string">&quot;UPDATE user SET lessons=? WHERE username=?&quot;</span>;<br>            sql_param = [lesson_str, username];<br>            <span class="hljs-keyword">var</span> promise_update = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">resolve_update, reject_update</span>)</span>&#123;<br>                mysql.query(sql_str, sql_param, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, result</span>)</span>&#123;<br>                    <span class="hljs-keyword">if</span>(err)&#123;<br>                        reject_update(err);<br>                    &#125;<br>                    <span class="hljs-keyword">else</span>&#123;<br>                        resolve_update(result);<br>                    &#125;<br>                &#125;);<br>            &#125;);<br>            promise_update.then(<span class="hljs-function">(<span class="hljs-params">resule_update</span>) =&gt;</span> &#123;<br>                status = <span class="hljs-number">1</span>;<br>                callback(status);<br>            &#125;);<br>        &#125;<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><p>现在，我们可以在界面中自由创建/加入并随时查看当前参与的课程了：</p><p><img src="lesson_list_page.png" alt="lesson_list_page" style="zoom:50%;" /></p><h2 id="文件管理">文件管理</h2><p>​ 接下来我们来实现文件共享的功能。Quasar Framework提供了一个用于文件上传的UI组件，我们可以直接通过调用它来提示用户选择文件并发送至后端：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">template</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">q-page</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;flex flex-center&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">q-uploader</span></span><br><span class="hljs-tag">            <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;file_upload&quot;</span></span><br><span class="hljs-tag">            <span class="hljs-attr">:headers</span>=<span class="hljs-string">&quot;[&#123;name: &#x27;lesson_id&#x27;, value: this.lesson_id &#125;]&quot;</span></span><br><span class="hljs-tag">            <span class="hljs-attr">field-name</span>=<span class="hljs-string">&quot;file&quot;</span></span><br><span class="hljs-tag">        /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">q-page</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">template</span>&gt;</span><br></code></pre></td></tr></table></figure><p>这里为了方便后续的资源隔离，我们在其发送的请求头中加入了课程ID号。</p><p>​ Quasar文件上传器使用了HTTP协议进行文件上传，因此我们需要在后端实现符合这一协议的文件接受通道。这里我们使用了一个名为<strong>multer</strong>的NodeJS插件，它可以以极高的效率处理前端发来的文件数据。我们先在服务端文件系统上新建一个file_upload目录，用于专门管理课堂中的共享资源。随后，我们在后端路由中附上这一组件，并将接收到的文件统一保存至file_upload目录：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> multer = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;multer&#x27;</span>);<br><span class="hljs-keyword">var</span> file_upload = multer(&#123;<span class="hljs-attr">dest</span>: <span class="hljs-string">&#x27;file_upload/&#x27;</span>&#125;);<br><br>router.post(<span class="hljs-string">&#x27;/file_upload&#x27;</span>, file_upload.single(<span class="hljs-string">&#x27;file&#x27;</span>), <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">request, response</span>)</span>&#123;<br>  file.file_redirect(request.file.destination, request.file.path, request.headers.lesson_id, request.file.originalname, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)</span>&#123;<br>    response.writeHead(<span class="hljs-number">200</span>, &#123;<br>      <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span><br>    &#125;);<br>    response.write(<span class="hljs-built_in">JSON</span>.stringify(&#123;<span class="hljs-string">&#x27;status&#x27;</span>: <span class="hljs-number">1</span>&#125;));<br>    response.end();<br>  &#125;);<br>&#125;);<br></code></pre></td></tr></table></figure><p>由于需要支持多个课堂同时进行，我们需要将每个课程的资源隔离。为此，我们在创建课程时，为每个课程创建一个相应的子目录，以课程ID作为目录名。随后，我们封装一个文件重定位函数，当multer将前端发来的文件保存到目标位置后，随即将其移动至相应的子文件夹下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> file_redirect = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">origin_path, origin_fullname, lesson_id, target_name, callback</span>)</span>&#123;<br>    <span class="hljs-built_in">console</span>.log(origin_path, origin_fullname, lesson_id, target_name);<br>    fs.exists(origin_path + lesson_id + <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">exists</span>)</span>&#123;<br>        <span class="hljs-keyword">if</span>(!exists)&#123;<br>          fs.mkdir(origin_path + lesson_id + <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err</span>)</span>&#123;<br>            <span class="hljs-keyword">if</span>(err)&#123;<br>              <span class="hljs-built_in">console</span>.log(err);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>              fs.rename(origin_fullname, origin_path + lesson_id + <span class="hljs-string">&quot;/&quot;</span> + target_name, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err</span>)</span>&#123;<br>                <span class="hljs-keyword">if</span>(err)&#123;<br>                  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">&quot;Rename error!&quot;</span>);<br>                &#125;<br>                <span class="hljs-keyword">else</span>&#123;<br>                    callback();<br>                &#125;<br>              &#125;);<br>            &#125;<br>          &#125;);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            fs.rename(origin_fullname, origin_path + lesson_id + <span class="hljs-string">&quot;/&quot;</span> + target_name, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err</span>)</span>&#123;<br>              <span class="hljs-keyword">if</span>(err)&#123;<br>                  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">&quot;Rename error!&quot;</span>);<br>              &#125;<br>              <span class="hljs-keyword">else</span>&#123;<br>                  callback();<br>              &#125;<br>            &#125;);<br>        &#125;<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><p>​ 现在，我们可以正常将文件上传至服务端并共享给其他用户了：</p><p><img src="file_upload.png" alt="file_upload" style="zoom:50%;" /></p><p>​ 对于学生端而言，每当学生用户进入课程时，我们只需要列出对应文件夹下的文件名，并将其发回给前端，就可以让用户随时看到课堂中的所有共享文件：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> list_files = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">base_path, lesson_id, callback</span>)</span>&#123;<br>    fs.exists(base_path + lesson_id + <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">exists</span>)</span>&#123;<br>        <span class="hljs-keyword">if</span>(!exists)&#123;<br>            callback([]);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            fs.readdir(base_path + lesson_id + <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, data</span>)</span>&#123;<br>                <span class="hljs-keyword">if</span>(err)&#123;<br>                    <span class="hljs-built_in">console</span>.log(err);<br>                &#125;<br>                <span class="hljs-keyword">else</span>&#123;<br>                    callback(data);<br>                &#125;<br>            &#125;);<br>        &#125;<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><p>​ 当一个客户端请求下载某个课堂中的文件时，我们可以使用NodeJS自带的fs插件中的流式传输功能，将其输出管道重定向到请求回应流中即可：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs javascript">router.get(<span class="hljs-string">&#x27;/file_download&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">request, response</span>)</span>&#123;<br>  <span class="hljs-keyword">var</span> lesson_id = request.query.id;<br>  <span class="hljs-keyword">var</span> filename = request.query.filename;<br>  <span class="hljs-keyword">if</span>(lesson_id == <span class="hljs-literal">undefined</span> || filename == <span class="hljs-literal">undefined</span>)&#123;<br>    response.end();<br>  &#125;<br>  <span class="hljs-keyword">else</span>&#123;<br>    response.writeHead(<span class="hljs-number">200</span>, &#123;<br>      <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/octet-stream&#x27;</span>,<br>      <span class="hljs-string">&#x27;Content-Disposition&#x27;</span>: <span class="hljs-string">&#x27;attachment; filename=&#x27;</span> + <span class="hljs-built_in">encodeURI</span>(filename)<br>    &#125;);<br>    fs.createReadStream(<span class="hljs-string">&#x27;file_upload/&#x27;</span> + lesson_id + <span class="hljs-string">&#x27;/&#x27;</span> + filename).pipe(response);<br>  &#125;<br>&#125;);<br></code></pre></td></tr></table></figure><p>至此，我们已经实现了一个基本的文件共享功能，效果如下：</p><p><img src="file_download.png" alt="file_download" style="zoom:50%;" /></p><h2 id="实时做题">实时做题</h2><p>​ 在在线课堂系统中，有时教师希望能够即时给学生分发一道课堂练习，并实时看到学生的答题状况，这就需要我们实现一套在线做题系统。</p><p>​ 在线做题首先需要教师端上传一道指定的题目。以选择题为例，为了方便结构化解析，我们要求教师上传一个固定格式的json文件作为题目（当然也可使用深度学习技术自动解析非结构化的题目信息，不过这一工程量将大幅度增长，在此我们不做讨论）：</p><p><img src="problem_upload.png" alt="problem_upload" style="zoom:50%;" /></p><p>​ 题目共享功能实现的主体思路与文件共享类似，我们只需要让教师端将题目以文件的形式发送给服务端，再通过服务端将题目分发给学生端即可。不过，为了让用户即时看到可阅读的题目信息，我们还需要在后端将题目文件解析为格式化信息，并通过json字符串的方式将结构化的题目发送给前端：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> get_problem = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">problem_base, lesson_id, callback</span>)</span>&#123;<br>    fs.exists(problem_base + lesson_id + <span class="hljs-string">&#x27;/question.json&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">exists</span>)</span>&#123;<br>        <span class="hljs-keyword">var</span> status = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 1 - 读取成功; 2 - 文件不存在; 3 - 读取错误 ;*/</span><br>        <span class="hljs-keyword">if</span>(!exists)&#123;<br>            status = <span class="hljs-number">2</span>;<br>            callback(status, <span class="hljs-literal">undefined</span>);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">var</span> data = fs.readFileSync(problem_base + lesson_id + <span class="hljs-string">&#x27;/question.json&#x27;</span>, <span class="hljs-string">&#x27;utf8&#x27;</span>);<br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">typeof</span> data == <span class="hljs-string">&#x27;string&#x27;</span>)&#123;<br>                status = <span class="hljs-number">1</span>;<br>                callback(status, data);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                status = <span class="hljs-number">3</span>;<br>                callback(status, <span class="hljs-literal">undefined</span>);<br>            &#125;<br>        &#125;<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><p>前端展示实现：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">template</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">q-page</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;flex flex-top-left&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;margin-top: 3%; margin-left: 3%&quot;</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">q-btn</span> <span class="hljs-attr">color</span>=<span class="hljs-string">&quot;secondary&quot;</span> <span class="hljs-attr">padding</span>=<span class="hljs-string">&quot;sm xl&quot;</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;margin-bottom: 5%&quot;</span> <span class="hljs-attr">label</span>=<span class="hljs-string">&quot;上传题目&quot;</span> @<span class="hljs-attr">click</span>=<span class="hljs-string">&quot;onProblemUpload&quot;</span> /&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">q-form</span> @<span class="hljs-attr">submit</span>=<span class="hljs-string">&quot;onSubmitAnswer&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;q-gutter-md&quot;</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">h5</span>&gt;</span> 实时题目 <span class="hljs-tag">&lt;/<span class="hljs-name">h5</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span> &#123;&#123;problem_description&#125;&#125; <span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">q-option-group</span> <span class="hljs-attr">v-model</span>=<span class="hljs-string">&quot;chosen_answer&quot;</span> <span class="hljs-attr">:options</span>=<span class="hljs-string">&quot;answer_options&quot;</span> <span class="hljs-attr">color</span>=<span class="hljs-string">&quot;primary&quot;</span> /&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">q-btn</span> <span class="hljs-attr">label</span>=<span class="hljs-string">&quot;提交答案&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;submit&quot;</span> <span class="hljs-attr">color</span>=<span class="hljs-string">&quot;primary&quot;</span>/&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">q-form</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">q-page</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">template</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><br><span class="javascript">    <span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> &#123;</span><br><span class="javascript">        name: <span class="hljs-string">&#x27;lesson&#x27;</span>,</span><br>        data()&#123;<br><span class="javascript">            <span class="hljs-keyword">return</span>&#123;</span><br><span class="javascript">                username: <span class="hljs-string">&quot;&quot;</span>,</span><br>                lesson_id: 0,<br><span class="javascript">                problem_description: <span class="hljs-string">&quot;3466645r15&quot;</span>,</span><br><span class="javascript">                chosen_answer: <span class="hljs-string">&quot;&quot;</span>,</span><br>                answer_options: [<br>                    &#123;<br><span class="javascript">                        label: <span class="hljs-string">&quot;Answer1&quot;</span>,</span><br><span class="javascript">                        value: <span class="hljs-string">&quot;A&quot;</span></span><br>                    &#125;<br>                ]<br>            &#125;<br>        &#125;,<br><span class="javascript">        mounted: <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>&#123;</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.onInitLesson();</span><br>        &#125;,<br>        methods: &#123;<br>            onInitLesson()&#123;<br><span class="javascript">                <span class="hljs-built_in">this</span>.username = <span class="hljs-built_in">this</span>.$route.query.username;</span><br><span class="javascript">                <span class="hljs-built_in">this</span>.lesson_id = <span class="hljs-built_in">this</span>.$route.query.lesson_id;</span><br><span class="javascript">                <span class="hljs-built_in">this</span>.getProblem();</span><br>            &#125;,<br>            getProblem()&#123;<br><span class="javascript">                <span class="hljs-keyword">var</span> full_url = <span class="hljs-string">&#x27;problem_get?id=&#x27;</span> + <span class="hljs-built_in">this</span>.lesson_id;</span><br><span class="javascript">                <span class="hljs-built_in">this</span>.axios.get(full_url).then(<span class="hljs-function">(<span class="hljs-params">response</span>) =&gt;</span> &#123;</span><br><span class="javascript">                    <span class="hljs-keyword">var</span> problem_json = response.data;</span><br><span class="javascript">                    <span class="hljs-keyword">if</span>(problem_json != <span class="hljs-literal">undefined</span>)&#123;</span><br><span class="javascript">                        <span class="hljs-built_in">this</span>.problem_description = problem_json.description;</span><br><span class="javascript">                        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> key <span class="hljs-keyword">in</span> problem_json.options)&#123;</span><br><span class="javascript">                            <span class="hljs-built_in">this</span>.answer_options.push(&#123;</span><br>                                label: problem_json.options[key],<br>                                value: key<br>                            &#125;);<br>                        &#125;<br><span class="javascript">                        <span class="hljs-built_in">console</span>.log(<span class="hljs-built_in">this</span>.answer_options);</span><br>                    &#125;<br><span class="javascript">                &#125;).catch(<span class="hljs-function">(<span class="hljs-params">response</span>) =&gt;</span> &#123;</span><br><span class="javascript">                    <span class="hljs-built_in">console</span>.log(response);</span><br>                &#125;);<br>            &#125;<br>        &#125;<br>    &#125;<br><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br></code></pre></td></tr></table></figure><p>​ 现在，学生用户已经可以随时接受教师下发的课堂练习并做答了。接下来，我们需要让教师端能够实时得到学生的做题反馈。为了实现这一功能，我们需要让前端实时监听后端的数据变化，并在后端产生数据变化时发送消息给前端。在NodeJS中，我们可以使用WebSocket插件来实现。</p><p>​ 首先，我们在服务端创建一个WebSocket服务器，并监听8000端口：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> ws = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;nodejs-websocket&#x27;</span>);<br><br><span class="hljs-keyword">var</span> ws_server = ws.createServer(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">socket</span>)</span>&#123;<br>  <span class="hljs-comment">//Irrelevant codes</span><br>&#125;).listen(<span class="hljs-number">8000</span>);<br></code></pre></td></tr></table></figure><p>当学生前端点击提交答案按钮时，我们通过这一端口将回答信息通知给后端：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">template</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">q-page</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;flex flex-top-left&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;margin-top: 3%; margin-left: 3%&quot;</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">q-form</span> @<span class="hljs-attr">submit</span>=<span class="hljs-string">&quot;onSubmitAnswer&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;q-gutter-md&quot;</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">h5</span>&gt;</span> 实时题目 <span class="hljs-tag">&lt;/<span class="hljs-name">h5</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span> &#123;&#123;problem_description&#125;&#125; <span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">q-option-group</span> <span class="hljs-attr">v-model</span>=<span class="hljs-string">&quot;chosen_answer&quot;</span> <span class="hljs-attr">:options</span>=<span class="hljs-string">&quot;answer_options&quot;</span> <span class="hljs-attr">color</span>=<span class="hljs-string">&quot;primary&quot;</span> /&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">q-btn</span> <span class="hljs-attr">label</span>=<span class="hljs-string">&quot;提交答案&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;submit&quot;</span> <span class="hljs-attr">color</span>=<span class="hljs-string">&quot;primary&quot;</span>/&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">q-form</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">q-page</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">template</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><br><span class="javascript">    <span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> &#123;</span><br><span class="javascript">        name: <span class="hljs-string">&#x27;lesson&#x27;</span>,</span><br>        data()&#123;<br><span class="javascript">            <span class="hljs-keyword">return</span>&#123;</span><br><span class="javascript">                username: <span class="hljs-string">&quot;&quot;</span>,</span><br>                lesson_id: 0,<br><span class="javascript">                chosen_answer: <span class="hljs-string">&quot;&quot;</span></span><br>            &#125;<br>        &#125;,<br><span class="javascript">        mounted: <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>&#123;</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.onInitLesson();</span><br><span class="javascript">            <span class="hljs-keyword">var</span> full_path = <span class="hljs-built_in">window</span>.document.location.href;</span><br><span class="javascript">            <span class="hljs-keyword">var</span> route_path = <span class="hljs-built_in">this</span>.$route.path;</span><br><span class="javascript">            <span class="hljs-keyword">var</span> base_path = full_path.substring(<span class="hljs-number">7</span>, full_path.indexOf(route_path));</span><br><span class="javascript">            <span class="hljs-keyword">var</span> base_path_stripped = base_path.substring(<span class="hljs-number">0</span>, base_path.indexOf(<span class="hljs-string">&#x27;:&#x27;</span>));</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.web_socket = <span class="hljs-keyword">new</span> WebSocket(<span class="hljs-string">&quot;ws://&quot;</span> + base_path_stripped + <span class="hljs-string">&quot;:8000&quot;</span>);</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.web_socket.onopen = <span class="hljs-function">() =&gt;</span> &#123;</span><br><span class="javascript">                <span class="hljs-built_in">console</span>.log(<span class="hljs-string">&quot;Websocket连接成功！&quot;</span>)</span><br>            &#125;<br><span class="javascript">            <span class="hljs-built_in">this</span>.web_socket.onmessage = <span class="hljs-function">(<span class="hljs-params">event</span>) =&gt;</span> &#123;</span><br><span class="javascript">                <span class="hljs-built_in">console</span>.log(event.data);</span><br>            &#125;<br>        &#125;,<br><span class="javascript">        destroyed: <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)</span>&#123;</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.web_socket.close();</span><br>        &#125;,<br>        methods: &#123;<br>            onSubmitAnswer()&#123;<br><span class="javascript">                <span class="hljs-built_in">this</span>.web_socket.send(<span class="hljs-built_in">JSON</span>.stringify(&#123;<span class="hljs-attr">type</span>: <span class="hljs-string">&quot;problem_answer&quot;</span>, <span class="hljs-attr">username</span>: <span class="hljs-built_in">this</span>.username, <span class="hljs-attr">lesson_id</span>: <span class="hljs-built_in">this</span>.lesson_id, <span class="hljs-attr">answer</span>: <span class="hljs-built_in">this</span>.chosen_answer&#125;));</span><br>            &#125;<br>        &#125;<br>    &#125;<br><br><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br></code></pre></td></tr></table></figure><p>对于每一个课程实例，服务端维护着一个当前题目的回答列表，每当后端收到前端发来的回答通知时，便将对应的计数器加一。随后，服务端会通知教师客户端更新实时统计信息：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> ws_server = ws.createServer(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">socket</span>)</span>&#123;<br>  <span class="hljs-keyword">var</span> answer_status = &#123;<br>    <span class="hljs-string">&quot;6&quot;</span>: &#123;<br>      <span class="hljs-string">&quot;A&quot;</span>: <span class="hljs-number">0</span>,<br>      <span class="hljs-string">&quot;B&quot;</span>: <span class="hljs-number">0</span>,<br>      <span class="hljs-string">&quot;C&quot;</span>: <span class="hljs-number">0</span>,<br>      <span class="hljs-string">&quot;D&quot;</span>: <span class="hljs-number">0</span><br>    &#125;<br>  &#125;<br>  socket.on(<span class="hljs-string">&#x27;text&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">str</span>)</span>&#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>      <span class="hljs-keyword">var</span> obj=<span class="hljs-built_in">JSON</span>.parse(str);<br>      <span class="hljs-keyword">if</span>(<span class="hljs-keyword">typeof</span> obj == <span class="hljs-string">&#x27;object&#x27;</span> &amp;&amp; obj )&#123;<br>          <span class="hljs-keyword">if</span>(obj.type == <span class="hljs-string">&quot;problem_answer&quot;</span>)&#123;<br>            <span class="hljs-keyword">var</span> lesson_id = obj.lesson_id;<br>            <span class="hljs-keyword">var</span> answer = obj.answer;<br>            <span class="hljs-keyword">if</span>(lesson_id != <span class="hljs-literal">undefined</span> &amp;&amp; answer != <span class="hljs-literal">undefined</span>)&#123;<br>              answer_status[lesson_id][answer] += <span class="hljs-number">1</span>;<br>              ws_server.connections.forEach(<span class="hljs-function">(<span class="hljs-params">connection</span>) =&gt;</span> &#123;<br>                connection.sendText(<span class="hljs-built_in">JSON</span>.stringify(answer_status));<br>              &#125;);<br>            &#125;<br>          &#125;<br>      &#125;<span class="hljs-keyword">else</span>&#123;<br>          <span class="hljs-built_in">console</span>.log(<span class="hljs-string">&quot;Error phasing json!&quot;</span>);<br>      &#125;<br>    &#125; <span class="hljs-keyword">catch</span>(e) &#123;<br>        <span class="hljs-built_in">console</span>.log(e);<br>    &#125;<br>  &#125;);<br>&#125;).listen(<span class="hljs-number">8000</span>);<br></code></pre></td></tr></table></figure><p>对于前端统计信息，这里我们使用Echarts图表的形式将答题的即时情况展现给教师：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">template</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">q-page</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;flex flex-center&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;answer_chart&quot;</span> <span class="hljs-attr">:style</span>=<span class="hljs-string">&quot;&#123;width: &#x27;300px&#x27;, height: &#x27;300px&#x27;&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">q-page</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">template</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><br><span class="javascript">    <span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> &#123;</span><br><span class="javascript">        name: <span class="hljs-string">&#x27;problemStatistics&#x27;</span>,</span><br>        data()&#123;<br><span class="javascript">            <span class="hljs-keyword">return</span>&#123;</span><br><span class="javascript">                username: <span class="hljs-string">&quot;&quot;</span>,</span><br>                lesson_id: 0,<br><span class="javascript">                web_socket: <span class="hljs-literal">null</span>,</span><br><span class="javascript">                chart: <span class="hljs-literal">null</span></span><br>            &#125;<br>        &#125;,<br><span class="javascript">        mounted: <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>&#123;</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.onInitLesson();</span><br><span class="javascript">            <span class="hljs-keyword">var</span> echarts = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;echarts&#x27;</span>);</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.chart = echarts.init(<span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">&#x27;answer_chart&#x27;</span>));</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.chart.setOption(&#123;</span><br><span class="javascript">                title: &#123; <span class="hljs-attr">text</span>: <span class="hljs-string">&#x27;学生实时答题情况统计&#x27;</span> &#125;,</span><br>                tooltip: &#123;&#125;,<br>                xAxis: &#123;<br><span class="javascript">                    data: [<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>, <span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;D&quot;</span>]</span><br>                &#125;,<br>                yAxis: &#123;&#125;,<br>                series: [&#123;<br><span class="javascript">                    name: <span class="hljs-string">&#x27;选择人数&#x27;</span>,</span><br><span class="javascript">                    type: <span class="hljs-string">&#x27;bar&#x27;</span>,</span><br>                    data: [0, 0, 0, 0]<br>                &#125;]<br>            &#125;);<br><span class="javascript">            <span class="hljs-keyword">var</span> full_path = <span class="hljs-built_in">window</span>.document.location.href;</span><br><span class="javascript">            <span class="hljs-keyword">var</span> route_path = <span class="hljs-built_in">this</span>.$route.path;</span><br><span class="javascript">            <span class="hljs-keyword">var</span> base_path = full_path.substring(<span class="hljs-number">7</span>, full_path.indexOf(route_path));</span><br><span class="javascript">            <span class="hljs-keyword">var</span> base_path_stripped = base_path.substring(<span class="hljs-number">0</span>, base_path.indexOf(<span class="hljs-string">&#x27;:&#x27;</span>));</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.web_socket = <span class="hljs-keyword">new</span> WebSocket(<span class="hljs-string">&quot;ws://&quot;</span> + base_path_stripped + <span class="hljs-string">&quot;:8000&quot;</span>);</span><br><span class="javascript">            <span class="hljs-built_in">this</span>.web_socket.onopen = <span class="hljs-function">() =&gt;</span> &#123;</span><br><span class="javascript">                <span class="hljs-built_in">console</span>.log(<span class="hljs-string">&quot;Websocket连接成功！&quot;</span>)</span><br>            &#125;<br><span class="javascript">            <span class="hljs-built_in">this</span>.web_socket.onmessage = <span class="hljs-function">(<span class="hljs-params">event</span>) =&gt;</span> &#123;</span><br><span class="javascript">                <span class="hljs-keyword">var</span> latest_data = <span class="hljs-built_in">JSON</span>.parse(event.data);</span><br><span class="javascript">                <span class="hljs-keyword">if</span>(latest_data != <span class="hljs-literal">undefined</span>)&#123;</span><br><span class="javascript">                    <span class="hljs-keyword">var</span> stat_dict = latest_data[<span class="hljs-built_in">this</span>.lesson_id];</span><br><span class="javascript">                    <span class="hljs-keyword">var</span> x_tags = [];</span><br><span class="javascript">                    <span class="hljs-keyword">var</span> y_values = [];</span><br><span class="javascript">                    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> key <span class="hljs-keyword">in</span> stat_dict)&#123;</span><br>                        x_tags.push(key);<br>                        y_values.push(stat_dict[key]);<br>                    &#125;<br><span class="javascript">                    <span class="hljs-built_in">this</span>.refreshChart(x_tags, y_values);</span><br>                &#125;<br>            &#125;<br>        &#125;,<br>        methods: &#123;<br>            onInitLesson()&#123;<br><span class="javascript">                <span class="hljs-built_in">this</span>.username = <span class="hljs-built_in">this</span>.$route.query.username;</span><br><span class="javascript">                <span class="hljs-built_in">this</span>.lesson_id = <span class="hljs-built_in">this</span>.$route.query.lesson_id;</span><br>            &#125;,<br>            refreshChart(x, y)&#123;<br><span class="javascript">                <span class="hljs-built_in">this</span>.chart.setOption(&#123;</span><br><span class="javascript">                title: &#123; <span class="hljs-attr">text</span>: <span class="hljs-string">&#x27;学生实时答题情况统计&#x27;</span> &#125;,</span><br>                tooltip: &#123;&#125;,<br>                xAxis: &#123;<br>                    data: x<br>                &#125;,<br>                yAxis: &#123;&#125;,<br>                series: [&#123;<br><span class="javascript">                    name: <span class="hljs-string">&#x27;选择数&#x27;</span>,</span><br><span class="javascript">                    type: <span class="hljs-string">&#x27;bar&#x27;</span>,</span><br>                    data: y<br>                &#125;]<br>            &#125;);<br>            &#125;<br>        &#125;<br>    &#125;<br><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br></code></pre></td></tr></table></figure><p>页面效果如下：</p><p><img src="problem_stat.png" alt="problem_stat" style="zoom:50%;" /></p><h2 id="快速签到">快速签到</h2><h2 id="视频推流">视频推流</h2><h2 id="远程访问">远程访问</h2><p>​ 至此，我们已经实现了树莓派在线教学系统的绝大部分基本功能。我们将其通过SFTP上传至树莓派中的目标目录下，并启动服务。通过树莓派提供的热点，我们在另一台设备上远程访问树莓派的网站接口，发现其已经可以正常工作：</p><p><img src="remote_comp.png" alt="remote_comp" style="zoom:50%;" /></p><p>同样的，我们也可以使用移动端访问树莓派上的教学服务：</p><p><img src="remote_phone.PNG" alt="remote_phone" style="zoom:30%;" /></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;树莓派部署&quot;&gt;树莓派部署&lt;/h2&gt;
&lt;p&gt;​ &lt;strong&gt;树莓派（Raspberry Pi）&lt;/strong&gt;是由英国慈善组织“Raspberry Pi基金会”开发的一款ARM微型单片机，其具备了一台标准计算机的绝大部分功能，常被用于提供各类小型服务类应用及嵌入式产品驱动。本项目基于Raspberry Pi 4B型号进行开发。&lt;/p&gt;
&lt;p&gt;​ 树莓派官方提供了一个基于Linux内核的专为树莓派硬件设计的&lt;strong&gt;Raspberry Pi OS&lt;/strong&gt;操作系统，可以直接在其官网进行镜像的下载。这里我们使用当前最新版&lt;strong&gt;（Kernel Version: 5.10）&lt;/strong&gt;进行开发。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Web" scheme="http://gonggongjohn.me/tags/Web/"/>
    
    <category term="Frontend" scheme="http://gonggongjohn.me/tags/Frontend/"/>
    
  </entry>
  
  <entry>
    <title>数据科学与工程数学基础 作业5</title>
    <link href="http://gonggongjohn.me/2021/06/12/dase-math/dase-math-assignment-5/"/>
    <id>http://gonggongjohn.me/2021/06/12/dase-math/dase-math-assignment-5/</id>
    <published>2021-06-12T02:00:00.000Z</published>
    <updated>2022-02-10T14:31:28.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一">一</h2><blockquote><p>求随机变量 <span class="math inline">\(X \sim b(n,p)\)</span> 的期望与方差。</p></blockquote><p>由 <span class="math inline">\(X \sim b(n, p)\)</span> 可知 <span class="math display">\[P(X=k) = \binom{n}{k} p^k (1-p)^{1-k}, k \in \{0,1,2,\cdots,n\}\]</span> 故其期望为 <span class="math display">\[\begin{aligned}E(X) &amp;= \sum_\limits{k = 0}^n k \binom{n}{k} p^k (1-p)^{n-k} \\&amp;= \sum_\limits{k = 1}^n k \binom{n}{k} p^k (1-p)^{n-k} \\&amp;= \sum_\limits{k = 1}^n n \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;=np \sum_\limits{k = 1}^n \binom{n-1}{k-1} p^{k-1} (1-p)^{n-k} \\&amp;=np \sum_\limits{m = 0}^{n-1} \binom{n-1}{m} p^m (1-p)^{n-1-m} \\&amp;=np \cdot (p+1-p)^{n-1} \\&amp;=np\end{aligned}\]</span> 又由 <span class="math display">\[\begin{aligned}E(X^2) &amp;= \sum_\limits{k = 0}^n k^2 \binom{n}{k} p^k (1-p)^{n-k} \\&amp;= n \cdot \sum_\limits{k = 1}^n k \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;= n \cdot \sum_\limits{k = 1}^n (k - 1 + 1) \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;= n \cdot \left[ \sum_\limits{k = 1}^n (k - 1) \binom{n-1}{k-1} p^k (1-p)^{n-k} + \sum_\limits{k = 1}^n  \binom{n-1}{k-1} p^k (1-p)^{n-k} \right] \\&amp;=n \cdot \sum_\limits{k = 2}^n (n - 1) \binom{n-2}{k-2} p^k (1-p)^{n-k} + n \cdot \sum_\limits{k = 1}^n  \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;= n(n-1)p^2 + np\end{aligned}\]</span> 可知其方差为 <span class="math display">\[\begin{aligned}Var(X) &amp;= E(X^2) - E^2(X) \\&amp;=n(n-1)p^2 + np - n^2p^2 \\&amp;=n^2p^2-np^2+ np - n^2p^2 \\&amp;=np(1-p)\end{aligned}\]</span></p><h2 id="二">二</h2><blockquote><p>设连续性随机变量 <span class="math inline">\(X\)</span> 的分布函数为 <span class="math display">\[F_X(x) = \left\{\begin{aligned}&amp;0 ,&amp; x &lt; 1 \\&amp;\ln x ,&amp; 1 \leq x &lt; e \\&amp;1 ,&amp; x \geq e\end{aligned}\right.\]</span></p><ol type="1"><li>求 <span class="math inline">\(P(X &lt; 2), P(0 &lt; X &lt;3)\)</span></li><li>求概率密度函数 <span class="math inline">\(f_X(x)\)</span></li></ol></blockquote><ol type="1"><li></li></ol><p><span class="math display">\[P(X&lt;2) = F_X(2)= \ln 2 \\P(0&lt;X&lt;3) = F_X(3)-F_X(0)=1-0=1\]</span></p><ol start="2" type="1"><li></li></ol><p>由 <span class="math display">\[f_X(x) = \frac{d}{dx}F_X(x)\]</span> 可知</p><p>当 <span class="math inline">\(x&lt;1\)</span> 时，<span class="math inline">\(f_X(x) = 0\)</span></p><p>当 <span class="math inline">\(1&lt;x&lt;e\)</span> 时，<span class="math inline">\(f_X(x)=\frac{1}{x}\)</span></p><p>当 <span class="math inline">\(x&gt;e\)</span> 时，<span class="math inline">\(f_X(x) = 0\)</span></p><p>又 <span class="math display">\[F&#39;_-(1) = \lim_{x \to 1^-} \frac{f(1)-f(x)}{1-x}= 0 \neq 1 = F&#39;_+(1) \\F&#39;_-(e) = \lim_{x \to e^-} \frac{f(e)-f(x)}{e-x}= \frac{1}{e} \neq 0 = F&#39;_+(e)\]</span> 故 <span class="math inline">\(f_X(x)\)</span> 在 <span class="math inline">\(x=1\)</span> 和 <span class="math inline">\(x=e\)</span> 处不存在</p><p>因此 <span class="math display">\[f_X(x) = \left\{\begin{aligned}0 &amp;,&amp; x &lt; 1 \\\frac{1}{x} &amp;,&amp; 1 &lt; x &lt; e \\0 &amp;,&amp; x&gt;e\end{aligned}\right.\]</span></p><h2 id="三">三</h2><blockquote><p>下表为二维离散随机变量 <span class="math inline">\((X,Y)\)</span> 的联合分布列，其中最后一列为随机变量 <span class="math inline">\(Y\)</span> 的边缘分布列，最后一行为随机变量 <span class="math inline">\(X\)</span> 的边缘分布列，且 <span class="math inline">\(X,Y\)</span> 独立。试将下表补充完整，并给出 <span class="math inline">\(X,Y\)</span> 的协方差 <span class="math inline">\(\textrm{Cov}(X,Y)\)</span></p></blockquote><table><thead><tr class="header"><th></th><th><span class="math inline">\(X=1\)</span></th><th><span class="math inline">\(X=2\)</span></th><th><span class="math inline">\(X=3\)</span></th><th><span class="math inline">\(P_Y(Y)\)</span></th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(Y=1\)</span></td><td><span class="math inline">\(0.03\)</span></td><td><span class="math inline">\(0.15\)</span></td><td><span class="math inline">\(0.12\)</span></td><td><span class="math inline">\(0.3\)</span></td></tr><tr class="even"><td><span class="math inline">\(Y=2\)</span></td><td><span class="math inline">\(0.03\)</span></td><td><span class="math inline">\(0.15\)</span></td><td><span class="math inline">\(0.12\)</span></td><td><span class="math inline">\(0.3\)</span></td></tr><tr class="odd"><td><span class="math inline">\(Y=3\)</span></td><td><span class="math inline">\(0.02\)</span></td><td><span class="math inline">\(0.1\)</span></td><td><span class="math inline">\(0.08\)</span></td><td><span class="math inline">\(0.2\)</span></td></tr><tr class="even"><td><span class="math inline">\(Y=4\)</span></td><td><span class="math inline">\(0.02\)</span></td><td><span class="math inline">\(0.1\)</span></td><td><span class="math inline">\(0.08\)</span></td><td><span class="math inline">\(0.2\)</span></td></tr><tr class="odd"><td><span class="math inline">\(P_X(X)\)</span></td><td><span class="math inline">\(0.1\)</span></td><td><span class="math inline">\(0.5\)</span></td><td><span class="math inline">\(0.4\)</span></td><td><span class="math inline">\(/\)</span></td></tr></tbody></table><p>由于 <span class="math inline">\(X,Y\)</span> 独立，故 <span class="math inline">\(Cov(X,Y) = 0\)</span></p><h2 id="四">四</h2><blockquote><p>已知所有的胰腺癌患者都有某症状，若一个人有该症状的概率为万分之一，并且胰腺癌的发病概率也为万分之一。问若一个人有该症状，则他也是胰腺癌患者的概率为多少。</p></blockquote><p>设 <span class="math inline">\(A=\{有该症状\},B=\{有胰腺癌\}\)</span></p><p>由于 <span class="math inline">\(B \subset A\)</span></p><p>故 <span class="math display">\[P(B|A) = \frac{P(A \cap B)}{P(A)} = \frac{P(B)}{P(A)} = 1\]</span></p><h2 id="五">五</h2><blockquote><p>一个不透明的箱子中有一些红球和白球，有放回地在箱子中随机摸出5个球，分别为红、白、白、白、红，试估计箱子中红球与白球的比例。</p></blockquote><p>设箱子中摸出红球的概率为 <span class="math inline">\(p\)</span>， <span class="math display">\[X_i = \left\{\begin{aligned}1, 第i次摸出红球 \\0, 第i次摸出白球\end{aligned}\right.\]</span> 故 <span class="math inline">\(X_i \stackrel{i.i.d}{\sim} b(1,p) \ , i \in \{1,2,3,4,5\}\)</span></p><p>于是 <span class="math display">\[L(p) = p^{\sum_\limits{i = 1}^n x_i} (1-p)^{n-\sum_\limits{i = 1}^n x_i}\]</span> 故 <span class="math display">\[\frac{\partial \ln L(p)}{\partial p} = \frac{\sum_\limits{i = 1}^n x_i}{p} - \frac{n - \sum_\limits{i = 1}^n x_i}{1-p}\]</span> 于是 <span class="math inline">\(p\)</span> 的极大似然估计 <span class="math display">\[\hat{p} = \bar{x} = \frac{1+0+0+0+1}{5} = \frac{2}{5}\]</span> 故 <span class="math display">\[\frac{红球}{白球} = \frac{2}{3}\]</span></p><h2 id="六">六</h2><blockquote><p>随机地取8只活塞环，测得他们的直径为(以mm计)</p><figure class="highlight apache"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">74</span>.<span class="hljs-number">001</span> <span class="hljs-number">74</span>.<span class="hljs-number">005</span> <span class="hljs-number">74</span>.<span class="hljs-number">003</span> <span class="hljs-number">74</span>.<span class="hljs-number">001</span><br><span class="hljs-attribute">74</span>.<span class="hljs-number">000</span> <span class="hljs-number">73</span>.<span class="hljs-number">998</span> <span class="hljs-number">74</span>.<span class="hljs-number">006</span> <span class="hljs-number">74</span>.<span class="hljs-number">002</span><br></code></pre></td></tr></table></figure><p>试求总体均值 <span class="math inline">\(\mu\)</span> 以及方差 <span class="math inline">\(\sigma^2\)</span> 的矩估计值。</p></blockquote><p><span class="math display">\[\begin{aligned}\hat{\mu} &amp;= \bar{x} \\&amp;= \frac{74.001+74.005+74.003+74.001+74.000+73.998+74.006+74.002}{8} \\&amp;=74.002\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}\hat{\sigma^2} &amp;= s^2 \\&amp;=\frac{1}{7} \left[ (74.001 - 74.002)^2 + (74.005 - 74.002)^2 + (74.003 - 74.002)^2 + (74.001 - 74.002)^2 + (74.000 - 74.002)^2 + (73.998 - 74.002)^2 + (74.006 - 74.002)^2 + (74.002 - 74.002)^2 \right] \\&amp; \approx 6.8571 \times 10^{-6}\end{aligned}\]</span></p><h2 id="七">七</h2><blockquote><p>给定 <span class="math inline">\(N\)</span> 个独立同分布样本 <span class="math inline">\(x_t\)</span>，服从多元正态分布 <span class="math display">\[G(x_t) = \frac{1}{(2 \pi)^{\frac{d}{2}} |\Sigma|^{\frac{1}{2}}} \exp \left\{ -\frac{1}{2} (x_t - \mu)^T \Sigma^{-1} (x_t - \mu) \right\}\]</span> ，其中 <span class="math inline">\(\Sigma\)</span> 是可逆对称矩阵，<span class="math inline">\(x_t, \mu \in \mathbb{R}^d\)</span>。 利用极大似然估计(MLE)估计参数 <span class="math inline">\(\mu, \Sigma\)</span>。</p></blockquote><p>似然函数 <span class="math display">\[\begin{aligned}L(\mu, \Sigma) &amp;= \prod_{i = 1}^n \frac{1}{(2 \pi)^{\frac{d}{2}} |\Sigma|^{\frac{1}{2}}} e^{-\frac{1}{2} (x_i - \mu)^T \Sigma^{-1} (x_i - \mu)} \\&amp;=\frac{1}{(2\pi)^{\frac{nd}{2}} |\Sigma|^{\frac{n}{2}}} e^{-\frac{1}{2} \sum_\limits{i = 1}^n (x_i-\mu)^T \Sigma^{-1} (x_i - \mu)}\end{aligned}\]</span> 故其对数似然函数 <span class="math display">\[l(\mu, \Sigma) = -\frac{nd}{2} \ln(2\pi) - \frac{n}{2} \ln |\Sigma| - \frac{1}{2}\sum_{i = 1}^n (x_i - \mu)^T \Sigma^{-1} (x_i - \mu)\]</span> 由于 <span class="math display">\[\begin{aligned}dl &amp;= Tr\left[ d \left( -\frac{nd}{2} \ln(2\pi) - \frac{n}{2} \ln |\Sigma| - \frac{1}{2}\sum_{i = 1}^n (x_i - \mu)^T \Sigma^{-1} (x_i - \mu) \right) \right] \\&amp;=Tr \left[ -\frac{1}{2} \sum_{i = 1}^n \left( d (x_i- \mu)^T \cdot \Sigma^{-1} \cdot (x_i - \mu) + (x_i - \mu)^T \cdot \Sigma^{-1} \cdot d(x_i - \mu) \right)\right] \\&amp;=Tr \left[  \frac{1}{2} \sum_{i = 1}^n \left( d \mu^T \cdot \Sigma^{-1} \cdot (x_i - \mu) + (x_i - \mu)^T \cdot \Sigma^{-1} \cdot d \mu \right) \right] \\&amp;=Tr \left[  \frac{1}{2} \sum_{i = 1}^n \left( (x_i - \mu)^T \cdot \left( \Sigma^{-1} \right)^T \cdot d \mu + (x_i - \mu)^T \cdot \Sigma^{-1} \cdot d \mu \right) \right] \\&amp;=Tr \left[ \sum_{i = 1}^n  \left( (x_i - \mu)^T \cdot \Sigma^{-1}\right) d\mu \right]\end{aligned}\]</span> 故 <span class="math display">\[\frac{\partial l}{\partial \mu} = \Sigma^{-1} \sum_{i = 1}^n (x_i - \mu)\]</span> 因此 <span class="math display">\[\hat{\mu} = \frac{1}{n}\sum_{i = 1}^n x_i = \bar{x}\]</span> 又由于 <span class="math display">\[\begin{aligned}dl &amp;= Tr \left[ -\frac{n}{2} d \ln |\Sigma| -\frac{1}{2} \sum_{i = 1}^n (x_i - \mu)^T \cdot d \Sigma^{-1} \cdot (x_i - \mu) \right] \\&amp;=Tr \left[ -\frac{n}{2 |\Sigma|} |\Sigma|\Sigma^{-1} d \Sigma + \frac{1}{2}\sum_{i = 1}^n \left( (x_i - \mu)^T \cdot \Sigma^{-1} d\Sigma \cdot \Sigma^{-1} \cdot (x_i - \mu) \right)\right] \\&amp;=Tr \left[-\frac{n}{2}\Sigma^{-1} d \Sigma \right] + \frac{1}{2} \sum_{i = 1}^n Tr \left[ \Sigma^{-1} \cdot (x_i - \mu)(x_i - \mu)^T \cdot \Sigma^{-1} d \Sigma \right] \\&amp;=Tr \left[\left( -\frac{n}{2}\Sigma^{-1} + \frac{1}{2}\sum_{i = 1}^n \left( \Sigma^{-1} (x_i - \mu)(x_i - \mu)^T \Sigma^{-1} \right) \right) d \Sigma \right]\end{aligned}\]</span> 故 <span class="math display">\[\frac{\partial l}{\partial \Sigma} = \frac{1}{2} \sum_{i = 1}^n \left(\Sigma^{-1} (x_i - \mu)(x_i - \mu)^T \Sigma^{-1} \right) - \frac{n}{2}\Sigma^{-1}\]</span> 因此 <span class="math display">\[\begin{aligned}\hat{\Sigma} &amp;= \frac{1}{n}\sum_{i = 1}^n (x_i - \mu)(x_i - \mu)^T \\&amp;=\frac{1}{n}\sum_{i = 1}^n (x_i - \bar{x})(x_i - \bar{x})^T\end{aligned}\]</span></p><h2 id="八">八</h2><blockquote><p>证明：在多分类问题中，利用交叉熵函数作为损失函数和用KL散度作为损失函数是等价的。</p></blockquote><p>对于多分类问题，若设 <span class="math inline">\(p_i\)</span> 为第 <span class="math inline">\(i\)</span> 个数据的目标输出，<span class="math inline">\(q_i\)</span> 为第 <span class="math inline">\(i\)</span> 个数据的实际输出，则 <span class="math display">\[L_{CrossEntropy} = -\sum_{i = 1}^n p_i \ln q_i \\L_{KL} = \sum_{i = 1}^n p_i \ln p_i - \sum_{i = 1}^n p_i \ln q_i\]</span> 二者仅相差一个与 <span class="math inline">\(q_i\)</span> 无关的常数，即 <span class="math display">\[\frac{\partial L_{CrossEntropy}}{\partial q_i} = \frac{\partial L_{KL}}{\partial q_i} = -\frac{p_i}{q_i}\]</span> 故二者作为损失函数等价</p><h2 id="九">九</h2><blockquote><p>同时抛2颗骰子，事件 <span class="math inline">\(A,B,C\)</span> 分别表示为 <span class="math display">\[A: 仅有一个骰子是3 \\B: 至少一个骰子是4 \\C: 骰子上点数总和为偶数\]</span> 试计算事件 <span class="math inline">\(A,B,C\)</span> 发生后所提供的信息量</p></blockquote><p><span class="math display">\[\begin{aligned}I_1 &amp;= - \lg \frac{5}{18} \approx 1.8480 \\I_2 &amp;= -\lg \frac{11}{36} \approx 1.7105 \\I_3 &amp;= -\lg \frac{1}{2} = 1\end{aligned}\]</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一&quot;&gt;一&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;求随机变量 &lt;span class=&quot;math inline&quot;&gt;\(X \sim b(n,p)\)&lt;/span&gt; 的期望与方差。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;由 &lt;span class=&quot;math </summary>
      
    
    
    
    <category term="数据科学数学基础" scheme="http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Mathematics" scheme="http://gonggongjohn.me/tags/Mathematics/"/>
    
    <category term="DataScience" scheme="http://gonggongjohn.me/tags/DataScience/"/>
    
  </entry>
  
  <entry>
    <title>操作系统实验 内存管理</title>
    <link href="http://gonggongjohn.me/2021/06/08/os/os-exp-memory/"/>
    <id>http://gonggongjohn.me/2021/06/08/os/os-exp-memory/</id>
    <published>2021-06-08T03:54:46.000Z</published>
    <updated>2022-02-09T14:20:33.022Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的">目的</h2><p>修改Minix3.1.2a的内存分配机制，使得当调用brk系统调用时，系统重新给进程分配一块更大的空间并将数据复制至新空间中。</p><h2 id="内容与设计思想">内容与设计思想</h2><ol type="1"><li>将Minix系统中的内存分配机制由<strong>First-Fit</strong>修改为<strong>Best-Fit</strong>。</li><li>修改<strong>brk</strong>系统调用行为，使得当被调用时系统重新开辟空间并分配给进程。</li></ol><h2 id="实验过程">实验过程</h2><h3 id="minix3.1.2a的内存管理策略">Minix3.1.2a的内存管理策略</h3><p>在较早的Minix3版本中，内存管理机制是十分固定和清晰的（Minix3.1.4引入了页式存储管理，使得分配给进程的内存空间可能实际分布在内存地址的各个地方）。系统的<strong>进程管理器（Process Manager）</strong>维护一个空闲空间列表，根据内存地址从低到高排列：</p><img src="/2021/06/08/os/os-exp-memory/free_list.png" class="" title="free_list"><p>当一个进程请求内存时，进程管理器会采用最先匹配法在空闲列表中找到第一个符合要求的空闲区，并将其分配给该进程。一旦进程被装入内存后，该片内存空间就被固定了下来，不会再被扩展。</p><p>Minix3的程序大多被编译为进程的各个部分共用一个内存块的形式以方便作为一个整体进行加载，其中，栈和数据/代码段分别位于内存空间的顶部和底部，整体结构大体如下：</p><img src="/2021/06/08/os/os-exp-memory/minix_program.png" class="" title="minix_program"><h3 id="内存分配原则修改">内存分配原则修改</h3><p>Minix系统中的空闲块由一个链接来维护其元信息，其单元结构如下：<strong>（include/minix/type.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Memory allocation by PM. */</span>  <br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">hole</span> &#123;</span>  <br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">hole</span> *<span class="hljs-title">h_next</span>;</span>          <span class="hljs-comment">/* pointer to next entry on the list */</span>  <br>  phys_clicks h_base;           <span class="hljs-comment">/* where does the hole begin? */</span>  <br>  phys_clicks h_len;            <span class="hljs-comment">/* how big is the hole? */</span>  <br>&#125;;<br></code></pre></td></tr></table></figure><p>在Minix3.1.2a中，内存分配遵循首次<strong>适配原则（First-Fit）</strong>，即在遍历到第一个能够容纳该进程的空闲块时，便将这一空闲块分配给进程。</p><p>现在我们来将这一分配机制修改为<strong>最优适配原则（Best-Fit）</strong>。Best-Fit原则需要遍历整个空闲块链表，找出与进程所需空间最接近的空闲块。由于要保证空闲块大小大于进程所需内存大小，因此我们采用外部逼近的更新思路来实现。若在现有的空闲块中能够找到满足要求的空闲块，我们还需要更新空闲块的信息并将已被完全分配的空闲块从空闲链表中移出：<strong>（servers/pm/alloc.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function">PUBLIC phys_clicks <span class="hljs-title">alloc_mem</span><span class="hljs-params">(clicks)</span>  </span><br><span class="hljs-function">phys_clicks clicks</span>;     <span class="hljs-comment">/* amount of memory requested */</span>  <br>&#123;  <br>    <span class="hljs-keyword">register</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">hole</span> *<span class="hljs-title">hp</span>, *<span class="hljs-title">prev_ptr</span>,*<span class="hljs-title">best</span>,*<span class="hljs-title">prev_best</span>;</span>  <br>    phys_clicks old_base,best_clicks;  <br>    <span class="hljs-keyword">int</span> flag= <span class="hljs-number">0</span>;  <br>  <br>    <span class="hljs-keyword">do</span> &#123;  <br>        prev_ptr = NIL_HOLE;  <br>        hp = hole_head;  <br>        <span class="hljs-comment">//Procedure of finding the best-fit block  </span><br>        <span class="hljs-keyword">while</span> (hp != NIL_HOLE &amp;&amp; hp-&gt;h_base &lt; swap_base) &#123;   <br>            <span class="hljs-keyword">if</span> (hp-&gt;h_len &gt;= clicks) &#123;  <br>                <span class="hljs-keyword">if</span>(!flag)&#123;  <br>                    best = hp;  <br>                    prev_best=prev_ptr;  <br>                    flag=<span class="hljs-number">1</span>;  <br>                    best_clicks=best-&gt;h_len;  <br>                &#125;  <br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(flag &amp;&amp; hp-&gt;h_len&lt;best_clicks)&#123;    <br>                    best=hp;  <br>                    prev_best=prev_ptr;  <br>                    best_clicks=best-&gt;h_len;  <br>                &#125;  <br>            &#125;  <br>            prev_ptr = hp;  <br>            hp = hp-&gt;h_next;  <br>        &#125;  <br>    &#125; <span class="hljs-keyword">while</span> (swap_out());       <span class="hljs-comment">/* try to swap some other process out */</span>  <br>    <span class="hljs-comment">//Update the status of the hole  </span><br>    <span class="hljs-keyword">if</span> (flag)&#123;    <br>        old_base = best-&gt;h_base;    <br>        best-&gt;h_base += clicks;    <br>        best-&gt;h_len -= clicks;   <br>  <br>        <span class="hljs-keyword">if</span> (best-&gt;h_base &gt; high_watermark)    <br>        high_watermark = best-&gt;h_base;  <br>  <br>        <span class="hljs-keyword">if</span> (best-&gt;h_len == <span class="hljs-number">0</span>) del_slot(prev_best,best);    <br>  <br>        <span class="hljs-keyword">return</span>(old_base);  <br>  <br>    &#125;  <br>    <span class="hljs-keyword">return</span>(NO_MEM);  <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="内存申请行为修改">内存申请行为修改</h3><p>在Minix3.1.2中，系统为进程分配的内存空间是不可变的。一旦进程使用完了分配的空间，程序便将报错退出，这可以在系统代码中直观的体现出来：<strong>（servers/pm/break.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function">PUBLIC <span class="hljs-keyword">int</span> <span class="hljs-title">adjust</span><span class="hljs-params">(rmp, data_clicks, sp)</span>  </span><br><span class="hljs-function"><span class="hljs-keyword">register</span> struct mproc *rmp</span>; <span class="hljs-comment">/* whose memory is being adjusted? */</span>  <br>vir_clicks data_clicks;     <span class="hljs-comment">/* how big is data segment to become? */</span>  <br>vir_bytes sp;           <span class="hljs-comment">/* new value of sp */</span>  <br>&#123;  <br>  <span class="hljs-comment">//Irrelevant code  </span><br>  <span class="hljs-keyword">if</span> (lower &lt; gap_base) <span class="hljs-keyword">return</span>(ENOMEM);  <span class="hljs-comment">/* data and stack collided */</span>  <br>  <span class="hljs-comment">//Irrelevant code  </span><br>&#125;<br></code></pre></td></tr></table></figure><p>现在我们来修改这一行为。首先我们定义一个新的局部函数用于分配新的内存：<strong>（servers/pm/break.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function">PUBLIC <span class="hljs-keyword">int</span> <span class="hljs-title">allocate_new_mem</span><span class="hljs-params">(rmp,old_clicks)</span>  </span><br><span class="hljs-function"><span class="hljs-keyword">register</span> struct mproc *rmp</span>; <span class="hljs-comment">//Pointer of target process  </span><br>phys_clicks old_clicks; <span class="hljs-comment">//Original space size</span><br></code></pre></td></tr></table></figure><p>并在检测到程序空间不足时调用这一函数：<strong>（servers/pm/break.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> ERROR 0</span><br><br><span class="hljs-function">PUBLIC <span class="hljs-keyword">int</span> <span class="hljs-title">adjust</span><span class="hljs-params">(rmp, data_clicks, sp)</span>    </span><br><span class="hljs-function"><span class="hljs-keyword">register</span> struct mproc *rmp</span>; <span class="hljs-comment">/* whose memory is being adjusted? */</span>    <br>vir_clicks data_clicks;     <span class="hljs-comment">/* how big is data segment to become? */</span>    <br>vir_bytes sp;           <span class="hljs-comment">/* new value of sp */</span>    <br>&#123;    <br>    <span class="hljs-comment">//Irrelevant code    </span><br>    <span class="hljs-keyword">if</span> (lower &lt; gap_base) &#123;<span class="hljs-comment">/* data and stack collided */</span>  <br>      <span class="hljs-keyword">if</span> (allocate_new_mem(rmp, (phys_clicks)(mem_sp-&gt;mem_vir+mem_sp-&gt;mem_len-mem_dp-&gt;mem_vir)) == ERROR)  <br>            <span class="hljs-keyword">return</span>(ENOMEM);  <br>    &#125;     <br>    <span class="hljs-comment">//Irrelevant code    </span><br>&#125;<br></code></pre></td></tr></table></figure><p>现在我们来实现内存空间的更新。<strong>allocate_new_mem</strong>中需要完成以下几个任务：</p><p><strong>1)</strong> <strong>分配一块比原先更大的内存空间</strong></p><p><strong>2)</strong> <strong>将远数据段和栈段分别复制至新空间的对应位置</strong></p><p><strong>3)</strong> <strong>释放原内存空间</strong></p><p><strong>4)</strong> <strong>通知系统映射新内存段</strong></p><p>受<strong>动态表（Dynamic Table）</strong>的启发，我们在每次需要扩展空间时将空间大小扩展至原来的两倍。在Minix中，进程的栈段和数据段基地址均被存放在其进程管理表（Process Management Table）中：<strong>（servers/pm/mproc.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c">EXTERN <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mproc</span> &#123;</span>  <br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mem_map</span> <span class="hljs-title">mp_seg</span>[<span class="hljs-title">NR_LOCAL_SEGS</span>];</span> <span class="hljs-comment">/* points to text, data, stack */</span>  <br>  <span class="hljs-comment">//Irrelevant codes  </span><br>&#125;<br></code></pre></td></tr></table></figure><p>其中mp_seg[1]为数据段基地址，mp_seg[2]为栈段基地址，因此我们可以直接读取这一地址并根据新分配的空间大小计算出新的基地址。对于内存内容拷贝，Minix提供了一个现成的sys_abscopy函数可供我们使用：<strong>（include/minix/syslib.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> sys_abscopy(src_phys, dst_phys, bytes) \  </span><br>    sys_physcopy(NONE, PHYS_SEG, src_phys, NONE, PHYS_SEG, dst_phys, bytes)  <br>_PROTOTYPE(<span class="hljs-keyword">int</span> sys_physcopy, (<span class="hljs-keyword">int</span> src_proc, <span class="hljs-keyword">int</span> src_seg, vir_bytes src_vir,  <br>    <span class="hljs-keyword">int</span> dst_proc, <span class="hljs-keyword">int</span> dst_seg, vir_bytes dst_vir, phys_bytes bytes));<br></code></pre></td></tr></table></figure><p>同样，对于内存释放，系统也封装了相应的函数：<strong>（servers/pm/proto.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">_PROTOTYPE( <span class="hljs-keyword">void</span> free_mem, (phys_clicks base, phys_clicks clicks)   );<br></code></pre></td></tr></table></figure><p>于是我们便可以快速实现这一完整逻辑：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function">PUBLIC <span class="hljs-keyword">int</span> <span class="hljs-title">allocate_new_mem</span><span class="hljs-params">(rmp,old_clicks)</span>  </span><br><span class="hljs-function"><span class="hljs-keyword">register</span> struct mproc *rmp</span>;  <br>phys_clicks old_clicks;  <br>&#123;     <br>    <span class="hljs-keyword">register</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mem_map</span> *<span class="hljs-title">mem_sp</span>, *<span class="hljs-title">mem_dp</span>;</span>  <br>    phys_clicks new_clicks, old_base,new_base;  <br>    phys_clicks  old_stack_base,new_stack_base;  <br>     <br>      <br>    phys_bytes data_bytes,stak_bytes;  <br>    phys_bytes old_base_bytes,new_base_bytes;  <br>    phys_bytes old_stack_base_bytes,new_stack_base_bytes;  <br>      <br>    <span class="hljs-keyword">int</span> x;  <br>      <br>    mem_dp = &amp;rmp-&gt;mp_seg[D];    <span class="hljs-comment">/* Pointer to data segment */</span>  <br>    mem_sp = &amp;rmp-&gt;mp_seg[S];  <span class="hljs-comment">/* Pointer to stack segment */</span>  <br>      <br>    old_base=mem_dp-&gt;mem_phys;  <br>    old_stack_base=mem_sp-&gt;mem_phys;  <br>      <br>    data_bytes=(phys_bytes) mem_dp-&gt;mem_len &lt;&lt; CLICK_SHIFT;    <br>    stak_bytes=(phys_bytes) mem_sp-&gt;mem_len &lt;&lt; CLICK_SHIFT;    <br>    old_base_bytes=old_base &lt;&lt; CLICK_SHIFT;    <br>    old_stack_base_bytes=old_stack_base &lt;&lt; CLICK_SHIFT;    <br>      <br>    new_clicks=<span class="hljs-number">2</span>*old_clicks;  <br>    new_base=alloc_mem(new_clicks);  <br>    <span class="hljs-keyword">if</span>(new_base==NO_MEM)&#123;  <br>      <span class="hljs-keyword">return</span>(ERROR);  <br>    &#125;  <br>      <br>    new_base_bytes = (phys_bytes) new_base &lt;&lt; CLICK_SHIFT;  <br>      <br>    <span class="hljs-keyword">if</span> ((x=sys_memset(<span class="hljs-number">0</span>,new_base_bytes,(new_clicks&lt;&lt;CLICK_SHIFT)))!=OK)&#123;    <br>      panic(__FILE__,<span class="hljs-string">&quot;new mem can&#x27;t be zero&quot;</span>,x);  <br>    &#125;  <br>  <br>      <br>    new_stack_base=new_base+new_clicks-mem_sp-&gt;mem_len;  <br>    new_stack_base_bytes=new_stack_base &lt;&lt; CLICK_SHIFT;  <br>      <br>      <br>      <br>    x = sys_abscopy(old_base_bytes,new_base_bytes,data_bytes);  <br>    <span class="hljs-keyword">if</span> (x &lt; <span class="hljs-number">0</span> ) panic(__FILE__,<span class="hljs-string">&quot;allocate_new_mem can&#x27;t copy&quot;</span>,x);  <br>    x = sys_abscopy( old_stack_base_bytes,new_stack_base_bytes,stak_bytes);  <br>    <span class="hljs-keyword">if</span> ( x &lt; <span class="hljs-number">0</span> ) panic(__FILE__,<span class="hljs-string">&quot;allocate_new_mem can&#x27;t copy&quot;</span>,x);  <br>      <br>     <br>    rmp-&gt;mp_seg[D].mem_phys = new_base;  <br>    rmp-&gt;mp_seg[S].mem_phys = new_stack_base;  <br>    rmp-&gt;mp_seg[S].mem_vir = mem_dp-&gt;mem_vir+new_clicks-mem_sp-&gt;mem_len;  <br>    free_mem(old_base,old_clicks);  <br>  <span class="hljs-keyword">return</span> (<span class="hljs-number">1</span>);  <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="功能测试">功能测试</h3><p>现在我们可以来重编译系统并测试新实现的内存扩展功能了。由于Minix3.1.2a开发时间较早，需要手动安装新内核并将其加入开机菜单中：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c">/usr/src/servers&gt; make image  <br>/usr/src/tools&gt; make hdboot  <br>/usr/src/tools&gt; make install  <br>d0p0s0&gt; newminix(<span class="hljs-number">5</span>,start <span class="hljs-keyword">new</span> kernel) &#123;image=/boot/image/<span class="hljs-number">3.1</span><span class="hljs-number">.2</span>ar1;boot;&#125;<br></code></pre></td></tr></table></figure><p><strong>需要注意的是，Minix3.1.2a不支持VirtualBox的网卡配置，因此若使用VirtualBox进行调试，将无法通过主机使用SSH服务与Minix联通，需手动在虚拟机环境内修改代码。</strong></p><p>首先我们对使用sbrk调用对内存分配进行基本的测试，测试代码如下：<strong>（test1.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;unistd.h&gt;  </span></span><br><span class="hljs-keyword">int</span> inc = <span class="hljs-number">1</span>;  <br><span class="hljs-keyword">int</span> total = <span class="hljs-number">0</span>;  <br><span class="hljs-keyword">int</span> i;  <br><span class="hljs-function"><span class="hljs-keyword">char</span> *<span class="hljs-title">sbrk</span><span class="hljs-params">(<span class="hljs-keyword">int</span> incr)</span></span>;  <br><span class="hljs-keyword">char</span> *result;  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">int</span> **argv)</span>  </span><br><span class="hljs-function"></span>&#123;  <br>        <span class="hljs-keyword">while</span> (((<span class="hljs-keyword">int</span>)(result = sbrk(inc))) &gt; <span class="hljs-number">0</span>)  <br>        &#123;  <br>                total += inc;  <br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;incremented by %d, total %d\n&quot;</span>, inc, total);  <br>                inc += inc;  <br>        &#125;  <br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <br>&#125;<br></code></pre></td></tr></table></figure><p>随后，我们实际访问新分配的内存，验证其分配空间是否能够正常使用：<strong>（test2.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;unistd.h&gt;  </span></span><br><span class="hljs-keyword">int</span> inc = <span class="hljs-number">1</span>;  <br><span class="hljs-keyword">int</span> total = <span class="hljs-number">0</span>;  <br><span class="hljs-function"><span class="hljs-keyword">char</span> *<span class="hljs-title">sbrk</span><span class="hljs-params">(<span class="hljs-keyword">int</span> incr)</span></span>;  <br><span class="hljs-keyword">char</span> *result;  <br><span class="hljs-keyword">int</span> i;  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">int</span> **argv)</span>  </span><br><span class="hljs-function"></span>&#123;  <br>    <span class="hljs-keyword">while</span> (((<span class="hljs-keyword">int</span>)(result = sbrk(inc))) &gt; <span class="hljs-number">0</span>)  <br>    &#123;  <br>        <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; inc; i++)  <br>            result[i] = <span class="hljs-number">0x12</span>;  <br>        total += inc;  <br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;incremented by: %d, total: %d , result: %d\n&quot;</span>, inc, total,   (<span class="hljs-keyword">int</span>)result);  <br>        inc += inc;  <br>    &#125;  <br>    <span class="hljs-built_in">exit</span> (<span class="hljs-number">0</span>);  <br>&#125;<br></code></pre></td></tr></table></figure><p>经过测试可以发现，程序输出与预期相符，且两次分配内存大小相同，表明新实现的内存分配机制是有效的。程序输出结果如下：</p><img src="/2021/06/08/os/os-exp-memory/run_1.png" class="" title="run_1"><img src="/2021/06/08/os/os-exp-memory/run_2.png" class="" title="run_2"><h2 id="总结">总结</h2><p>在本实验中，我们在Minix3.1.2a系统下对内存分配机制进行了修改。将first-fit内存分配策略修改为best-fit策略，可以有效的提高内存的综合利用率，减少内存碎片的产生。通过对brk系统调用实现的修改，得以让程序能够得到的内存空间随着需求动态扩展，极大的增强了系统的通用性和可扩展性。这一实验也使得我们对进程内存管理和内存空间调度的相关知识有了更深刻的了解。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目的&quot;&gt;目的&lt;/h2&gt;
&lt;p&gt;修改Minix3.1.2a的内存分配机制，使得当调用brk系统调用时，系统重新给进程分配一块更大的空间并将数据复制至新空间中。&lt;/p&gt;
&lt;h2 id=&quot;内容与设计思想&quot;&gt;内容与设计思想&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;将</summary>
      
    
    
    
    <category term="操作系统" scheme="http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Operating-System" scheme="http://gonggongjohn.me/tags/Operating-System/"/>
    
  </entry>
  
  <entry>
    <title>数据科学与工程数学基础 作业4</title>
    <link href="http://gonggongjohn.me/2021/06/02/dase-math/dase-math-assignment-4/"/>
    <id>http://gonggongjohn.me/2021/06/02/dase-math/dase-math-assignment-4/</id>
    <published>2021-06-02T02:00:00.000Z</published>
    <updated>2022-02-10T09:00:53.615Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一">一</h2><blockquote><p>构建模型使得预测值与真实值的误差最小常用向量2-范数度量，求解模型过程中需要计算梯度，求梯度：</p><ul><li><p><span class="math inline">\(f(A) = \frac{1}{2} ||Ax + b - y ||_2^2\)</span>，求 <span class="math inline">\(\frac{\partial f}{\partial A}\)</span></p></li><li><p><span class="math inline">\(f(x) = \frac{1}{2} ||Ax + b - y ||_2^2\)</span>，求 <span class="math inline">\(\frac{\partial f}{\partial x}\)</span></p></li></ul><p>，其中 <span class="math inline">\(A \in \mathbb{R}^{m \times n}, x \in \mathbb{R}^n, b, y \in \mathbb{R}^m\)</span></p></blockquote><p>由 <span class="math display">\[\begin{aligned}f(\textbf{A}, x) &amp;= \frac{1}{2} || \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} ||_2^2 \\&amp;=\frac{1}{2} \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)\end{aligned}\]</span> 可知 <span class="math display">\[\begin{aligned}df &amp;= d \left[\ Tr \left(\frac{1}{2} \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)\right) \right] \\&amp;= \frac{1}{2} Tr \left[ d \left( \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right)\right] \\&amp;=\frac{1}{2} Tr \left[ d\left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] \\&amp;=\frac{1}{2} Tr \left[ \textbf{x}^T \cdot d \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \cdot \textbf{x} \right] \\&amp;=\frac{1}{2} \left\{ Tr \left[ \textbf{x}^T \cdot d \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] + Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \cdot \textbf{x} \right] \right\} \\&amp;= \frac{1}{2} \left\{ Tr \left[ d \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \cdot \textbf{x}^T \right] + Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] \right\} \\&amp;= \frac{1}{2} \left\{ Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] + Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] \right\} \\&amp;= \frac{1}{2} Tr \left[ 2 \cdot \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right] \\&amp;= Tr \left[ \textbf{x} \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \textbf{A} \right]\end{aligned}\]</span> 故 <span class="math display">\[\frac{\partial f}{\partial \textbf{A}} = \left(\textbf{x} \cdot (\textbf{A} \textbf{x}+\textbf{b}-\textbf{y})^T\right)^T = (\textbf{A} \textbf{x}+\textbf{b}-\textbf{y}) \cdot \textbf{x}^T\]</span> 又 <span class="math display">\[\begin{aligned}df &amp;=\frac{1}{2} Tr \left[ d\left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot d \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] \\&amp;=\frac{1}{2} Tr \left[ d\textbf{x}^T \cdot \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) + \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \\&amp;=\frac{1}{2} \left\{ Tr \left[ d\textbf{x}^T \cdot \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right) \right] + Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \right\} \\&amp;= \frac{1}{2} \left\{ Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] + Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \right\} \\&amp;= \frac{1}{2} Tr \left[ 2 \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right] \\&amp;= Tr \left[ \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \cdot d\textbf{x} \right]\end{aligned}\]</span> 故 <span class="math display">\[\frac{\partial f}{\partial \textbf{x}} = \left( \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)^T \cdot \textbf{A} \right)^T = \textbf{A}^T \cdot \left( \textbf{A} \textbf{x} + \textbf{b} - \textbf{y} \right)\]</span></p><h2 id="二">二</h2><blockquote><p>利用迹微分法求解 <span class="math display">\[\frac{\partial \tr (W^{-1})}{\partial W}\]</span> ，其中 <span class="math inline">\(W \in \mathbb{R}^{m \times m}\)</span></p></blockquote><p>由 <span class="math display">\[\begin{aligned}d \ Tr(\textbf{W}^{-1}) &amp;= Tr \left[ d  \left( \textbf{W}^{-1} \right) \right] \\&amp;=Tr \left[ - \textbf{W}^{-1} \cdot d\textbf{W} \cdot \textbf{W}^{-1} \right] \\&amp;=Tr \left[ -\left(\textbf{W}^{-1}\right)^2 \cdot d \textbf{W} \right]\end{aligned}\]</span> 可知 <span class="math display">\[\frac{\partial Tr(\textbf{W}^{-1})}{\partial \textbf{W}} = -\left( \textbf{W}^{-2} \right)^T\]</span></p><h2 id="三">三</h2><blockquote><p>二次型是数据分析中常用函数，求 <span class="math display">\[\frac{\partial x^T A x}{\partial x}, \frac{\partial x^T A x}{\partial A}\]</span> ，其中 <span class="math inline">\(A \in \mathbb{R}^{m \times m}, x \in \mathbb{R}^m\)</span></p></blockquote><p>由 <span class="math display">\[\begin{aligned}d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) &amp;= d \ Tr \left(\textbf{x}^T \textbf{A} \textbf{x} \right) \\&amp;=Tr \left[ d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) \right] \\&amp;=Tr \left[ d \textbf{x}^T \cdot \textbf{A} \textbf{x} + \textbf{x}^T \textbf{A} \cdot d\textbf{x}  \right] \\&amp;=Tr \left[\textbf{x}^T \textbf{A}^T d\textbf{x} \right] + Tr \left[ \textbf{x}^T \textbf{A} d\textbf{x}\right] \\&amp;=Tr \left[ \textbf{x}^T (\textbf{A}^T + \textbf{A}) d\textbf{x}\right]\end{aligned}\]</span> 故 <span class="math display">\[\frac{\partial \textbf{x}^T \textbf{A} \textbf{x}}{\partial \textbf{x}} = \left(\textbf{x}^T (\textbf{A}^T + \textbf{A})\right)^T = (\textbf{A}+\textbf{A}^T)\textbf{x}\]</span> 又 <span class="math display">\[\begin{aligned}d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) &amp;=Tr \left[ d \left(\textbf{x}^T \textbf{A} \textbf{x} \right) \right] \\&amp;=Tr \left[ \textbf{x}^T \cdot d \textbf{A} \cdot \textbf{x} \right] \\&amp;=Tr \left[\textbf{x} \textbf{x}^T d \textbf{A} \right] \\\end{aligned}\]</span> 故 <span class="math display">\[\frac{\partial \textbf{x}^T \textbf{A} \textbf{x}}{\partial \textbf{A}} = \left(\textbf{x}\textbf{x}^T \right)^T = \textbf{x}\textbf{x}^T\]</span></p><h2 id="四">四</h2><blockquote><p>定义 <span class="math inline">\((\exp(z))_i = \exp(z_i), (\ln (z))_i = \ln (z_i)\)</span>，则 <span class="math display">\[f(z) = \frac{\exp(z)}{\boldsymbol{1}^T \exp(z)}\]</span> 成为Softmax函数，如果 <span class="math inline">\(q = f(z), J = -p^T \ln (q)\)</span>，其中 <span class="math inline">\(p,q,z \in \mathbb{R}^n\)</span>，并且 <span class="math inline">\(\boldsymbol{1}^T p = 1\)</span>，则</p><ul><li>证明：<span class="math inline">\(\frac{\partial J}{\partial z} = q - p\)</span></li><li>若 <span class="math inline">\(z = Wx\)</span>，其中 <span class="math inline">\(W \in \mathbb{R}^{n \times m}, x \in \mathbb{R}^m, \frac{\partial J}{\partial W} = (q - p)x^T\)</span> 是否成立。</li></ul></blockquote><p><span class="math inline">\(\forall \textbf{x}, \textbf{y}, \textbf{z} \in \mathbb{R}^2, \lambda \in \mathbb{R}\)</span></p><p><strong>(1)</strong> 任取 <span class="math inline">\(i, j \in \{1,2,...,n\}\)</span></p><p>易得 <span class="math display">\[\frac{\partial J}{\partial q_j} = - \frac{p_j}{q_j}\]</span> 当 <span class="math inline">\(i \neq j\)</span> 时， <span class="math display">\[\frac{\partial q_j}{\partial z_i} = - \frac{e^{z_i + z_j}}{\left( \sum_\limits{k = 1}^n e^{z_k} \right)^2} = -q_i \cdot q_j\]</span> 当 <span class="math inline">\(i = j\)</span> 时， <span class="math display">\[\frac{\partial q_j}{\partial z_i} = \frac{e^{z_i} \cdot \left( \sum_\limits{k = 1}^n e^{z_k} \right) - e^{2z_i}}{\left( \sum_\limits{k = 1}^n e^{z_k} \right)^2} = q_i - q_i^2\]</span> 故 <span class="math display">\[\begin{aligned}\frac{\partial J}{\partial z_i} &amp;= \sum_{j = 1}^n \frac{\partial J}{\partial q_j} \cdot \frac{\partial q_j}{\partial z_i} \\&amp;=\sum_{j \neq i} \left( - \frac{p_j}{q_j} \right) (-q_i q_j) + \left(- \frac{p_i}{q_i} \right) (q_i - q_i^2) \\&amp;=q_i \cdot \sum_{j \neq i} p_j - p_i(1-q_i) \\\end{aligned}\]</span> 于是由 <span class="math inline">\(1^T p = \sum_\limits{i = 1}^n p_i = 1\)</span> 可知 <span class="math display">\[\frac{\partial J}{\partial z_i} = q_i (1 - p_i) - p_i(1-q_i) = q_i - p_i\]</span> 即 <span class="math display">\[\frac{\partial J}{\partial \textbf{z}} = \textbf{q} - \textbf{p}\]</span> <strong>(2)</strong> 由 <span class="math inline">\(d \ Tr (\textbf{W} \textbf{x}) = Tr \left( d \textbf{W} \cdot \textbf{x} \right) = Tr(\textbf{x} \cdot d \textbf{W})\)</span> 可知 <span class="math display">\[\frac{\partial J}{\partial \textbf{W}} = \textbf{x}^T\]</span> 故 <span class="math display">\[\frac{\partial J}{\partial \textbf{W}} = \frac{\partial J}{\partial \textbf{z}} \cdot \frac{\partial \textbf{z}}{\partial \textbf{W}} = (\textbf{q} - \textbf{p}) \textbf{x}^T\]</span> 成立</p><h2 id="五">五</h2><blockquote><p>以下内容是利用极大似然估计求解多元正态分布模型的关键步骤： <span class="math display">\[L = -\frac{Nd}{2} \ln (2 \pi) - \frac{N}{2} \ln |\Sigma| - \frac{1}{2} \sum_t (x_t - \mu)^T \Sigma^{-1} (x_t - \mu)\]</span> ，<span class="math inline">\(L\)</span> 是对数似然，<span class="math inline">\(N\)</span> 为样本数，<span class="math inline">\(d\)</span> 为样本维数，<span class="math inline">\(\Sigma \in \mathbb{R}^{d \times d}\)</span> 为协方差矩阵（对称矩阵），<span class="math inline">\(\mu \in \mathbb{R}^d\)</span> 为期望向量。</p><ul><li><p>求 <span class="math inline">\(\frac{\partial L}{\partial \mu}\)</span></p></li><li><p>当 <span class="math inline">\(\mu = \frac{1}{N} \sum_t x_t\)</span> 使，求 <span class="math inline">\(\frac{\partial L}{\partial \Sigma}\)</span>，并求使 <span class="math inline">\(\frac{\partial L}{\partial \Sigma} = 0\)</span> 成立的 <span class="math inline">\(\Sigma\)</span>。</p></li></ul></blockquote><p><strong>(1)</strong> <span class="math display">\[\begin{aligned}\frac{\partial L}{\partial \boldsymbol{\mu}} &amp;= -\frac{1}{2} \sum_{t = 1}^N \frac{\partial}{\partial \boldsymbol{\mu}} \left[ (\textbf{x}_t - \boldsymbol{\mu})^T \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu})\right] \\&amp;= -\frac{1}{2} \sum_{t = 1}^N \frac{\partial \left[(\textbf{x}_t - \boldsymbol{\mu})^T \right]}{\partial \boldsymbol{\mu}} \cdot \frac{\partial \left[ (\textbf{x}_t - \boldsymbol{\mu})^T \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu}) \right]}{\partial[\textbf{x}_t - \boldsymbol{\mu}]} \\&amp;=-\frac{1}{2} \sum_{t = 1}^N \left[ -2\Sigma^{-1}(\textbf{x}_t - \boldsymbol{\mu}) \right] \\&amp;=\Sigma^{-1} \cdot \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu})\end{aligned}\]</span> <strong>(2)</strong></p><p>由 <span class="math display">\[\begin{aligned}dL &amp;= Tr \left[ d \left( - \frac{Nd}{2} \ln (2 \pi) - \frac{N}{2} \ln |\Sigma| - \frac{1}{2} \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu})^T \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu}) \right) \right] \\&amp;= Tr \left[ - \frac{N}{2} d \left(  \ln |\Sigma| \right) - \frac{1}{2} \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu})^T \cdot d \left(\Sigma^{-1}\right) \cdot (\textbf{x}_t - \boldsymbol{\mu}) \right] \\&amp;= Tr \left[ - \frac{N}{2|\Sigma|}\cdot |\Sigma| \Sigma^{-1} d \Sigma + \frac{1}{2} \sum_{t = 1}^N (\textbf{x}_t - \boldsymbol{\mu}) (\textbf{x}_t - \boldsymbol{\mu})^T \cdot \Sigma^{-1} d \Sigma \cdot \Sigma^{-1} \right] \\&amp;= Tr \left[ \left(- \frac{N}{2}\cdot \Sigma^{-1} + \frac{1}{2} \sum_{t = 1}^N \Sigma^{-1} (\textbf{x}_t - \boldsymbol{\mu}) (\textbf{x}_t - \boldsymbol{\mu})^T \cdot \Sigma^{-1}\right) d \Sigma \right]\end{aligned}\]</span> 及 <span class="math inline">\(\Sigma\)</span> 为对称矩阵可知 <span class="math display">\[\frac{\partial L}{\partial \Sigma} = \frac{1}{2} \sum_{t = 1}^N \Sigma^{-1}(\textbf{x} - \boldsymbol{\mu})(\textbf{x} - \boldsymbol{\mu})^T \Sigma^{-1} - \frac{N}{2} \Sigma^{-1}\]</span> 故当 <span class="math inline">\(\Sigma = \frac{1}{N}(\textbf{x} - \boldsymbol{\mu})(\textbf{x} - \boldsymbol{\mu})^T\)</span> 时，<span class="math inline">\(\frac{\partial L}{\partial \Sigma} = 0\)</span></p><h2 id="六">六</h2><blockquote><p>求 <span class="math display">\[\frac{\partial |X_k|}{\partial X}\]</span> ，其中 <span class="math inline">\(X \in \mathbb{R}^{m \times m}\)</span> 为可逆矩阵。</p></blockquote><p>由 <span class="math inline">\(\textbf{X} \in \mathbb{R}^{m \times m}\)</span> 可逆可知 <span class="math display">\[\begin{aligned}\frac{\partial \left|\textbf{X}^k\right|}{\partial \textbf{X}} &amp;= \frac{\partial \left|\textbf{X}^k\right|}{\partial \textbf{|X|}} \cdot \frac{\partial \left|\textbf{X}\right|}{\partial \textbf{X}} \\&amp;=k |\textbf{X}|^{k - 1} \cdot |\textbf{X}| \cdot (\textbf{X}^{-1})^T \\&amp;= k |\textbf{X}|^k \left( \textbf{X}^{-1} \right)^T\end{aligned}\]</span></p><h2 id="七">七</h2><blockquote><p>求 <span class="math display">\[\frac{\partial \tr (AXBX^T C)}{\partial X}\]</span> ，其中 <span class="math inline">\(A \in \mathbb{R}^{m \times n}, X \in \mathbb{R}^{n \times k}, B \in \mathbb{R}^{k \times k}, C \in \mathbb{R}^{n \times m}\)</span></p></blockquote><p>由 <span class="math display">\[\begin{aligned}d \left( \textbf{A} \textbf{x} \textbf{B} \textbf{x}^T \textbf{C} \right) &amp;=Tr \left[d \left(\textbf{A} \textbf{x} \textbf{B} \textbf{x}^T \textbf{C} \right) \right] \\&amp;=Tr \left[\textbf{A} \cdot d \textbf{x} \cdot \textbf{B} \textbf{x}^T \textbf{C} + \textbf{A} \textbf{x} \textbf{B} \cdot d \textbf{x}^T \cdot \textbf{C} \right] \\&amp;=Tr \left[ \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} d \textbf{x} \right] + Tr \left[ d \textbf{x}^T \cdot \textbf{C}\textbf{A}\textbf{x}\textbf{B} \right] \\&amp;=Tr \left[ \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} d \textbf{x} \right] + Tr \left[ \textbf{B}^T\textbf{x}^T \textbf{A}^T \textbf{C}^T d \textbf{x} \right] \\&amp;=Tr \left[ \left( \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} + \textbf{B}^T\textbf{x}^T \textbf{A}^T \textbf{C}^T \right) d \textbf{x}\right]\end{aligned}\]</span> 可知 <span class="math display">\[\frac{\partial Tr \left(\textbf{A} \textbf{x} \textbf{B} \textbf{x}^T \textbf{C} \right)}{\partial \textbf{X}} = \left( \textbf{B}\textbf{x}^T \textbf{C}\textbf{A} + \textbf{B}^T\textbf{x}^T \textbf{A}^T \textbf{C}^T \right)^T = \textbf{A}^T \textbf{C}^T \textbf{x} \textbf{B}^T + \textbf{C} \textbf{A} \textbf{x} \textbf{B}\]</span></p><h2 id="八">八</h2><blockquote><p>求激活函数 <span class="math display">\[\sigma(x) = \frac{1}{1 + e^{-x}}\]</span> 的导数</p></blockquote><p><span class="math display">\[\frac{d \sigma}{d \textbf{x}} = \frac{d}{d \textbf{x}} \left( \frac{1}{1+e^{- \textbf{x}}} \right) = \frac{e^{- \textbf{x}}}{\left(1+e^{-\textbf{x}}\right)^2} = \sigma(\textbf{x}) \left(1-\sigma(\textbf{x}) \right)\]</span></p><h2 id="九">九</h2><blockquote><p>求 <span class="math display">\[\frac{\partial}{\partial x} \exp \left\{ - \frac{1}{2 ||\sigma||_2^2} ||x - \mu||_2^2 \right\}\]</span> ，其中 <span class="math inline">\(x, \mu, \sigma \in \mathbb{R}^n\)</span></p></blockquote><p>由 <span class="math display">\[\begin{aligned}d\left( e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \right) &amp;=Tr \left[ d \left( e^{-\frac{2}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \right)\right] \\&amp;=Tr \left[ -\frac{1}{2||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \cdot d \left( ||\textbf{x} - \boldsymbol{\mu}||_2^2\right) \right] \\&amp;=Tr \left[ -\frac{1}{2||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \cdot d \left( (\textbf{x} - \boldsymbol{\mu})^T (\textbf{x} - \boldsymbol{\mu}) \right) \right] \\&amp;=Tr \left[ -\frac{(\textbf{x} - \boldsymbol{\mu})^T}{||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} \cdot d\textbf{x} \right]\end{aligned}\]</span> 可知 <span class="math display">\[\frac{\partial}{\partial \textbf{x}} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2} = \left(-\frac{(\textbf{x} - \boldsymbol{\mu})^T}{||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2}\right)^T = -\frac{(\textbf{x} - \boldsymbol{\mu})}{||\boldsymbol{\sigma}||^2} e^{-\frac{1}{2||\boldsymbol{\sigma}||^2}||\textbf{x} - \boldsymbol{\mu}||_2^2}\]</span></p><h2 id="十">十</h2><blockquote><p>阅读以下代码，填写更新梯度部分的代码。（提交时，需要提交补全的代码，以及最后10次输出的截图）</p></blockquote><p><strong>实现代码：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>N, D_in, H, D_out = <span class="hljs-number">64</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">100</span>, <span class="hljs-number">10</span><br><span class="hljs-comment"># 随机创建一些训练数据</span><br>x = np.random.randn(N, D_in)<br>y = np.random.randn(N, D_out)<br>w1 = np.random.randn(D_in, H)<br>w2 = np.random.randn(H, D_out)<br>learning_rate = <span class="hljs-number">1e-6</span><br><span class="hljs-keyword">for</span> it <span class="hljs-keyword">in</span> range(<span class="hljs-number">500</span>):<br>    <span class="hljs-comment"># Forward pass</span><br>    h = x.dot(w1)  <span class="hljs-comment"># N * H</span><br>    h_relu = np.maximum(h, <span class="hljs-number">0</span>)  <span class="hljs-comment"># N * H</span><br>    y_pred = h_relu.dot(w2)  <span class="hljs-comment"># N * D_out</span><br>    <span class="hljs-comment"># compute loss</span><br>    loss = np.square(y_pred - y).sum()<br>    print(it, loss)<br>    <span class="hljs-comment"># Backward pass</span><br>    <span class="hljs-comment"># compute the gradient</span><br>    grad_y_pred = y_pred - y<br>    grad_w2 = h_relu.T.dot(grad_y_pred)<br>    grad_h_relu = grad_y_pred.dot(w2.T)<br>    grad_h = grad_h_relu.copy()<br>    grad_h[h &lt; <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    grad_w1 = x.T.dot(grad_h)<br>    w1 -= learning_rate * grad_w1<br>    w2 -= learning_rate * grad_w2<br></code></pre></td></tr></table></figure><p><strong>输出结果（最后10次循环）：</strong></p><img src="/2021/06/02/dase-math/dase-math-assignment-4/1.png" class="" width="1">]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一&quot;&gt;一&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;构建模型使得预测值与真实值的误差最小常用向量2-范数度量，求解模型过程中需要计算梯度，求梯度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(f(A) = \frac{1</summary>
      
    
    
    
    <category term="数据科学数学基础" scheme="http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Mathematics" scheme="http://gonggongjohn.me/tags/Mathematics/"/>
    
    <category term="DataScience" scheme="http://gonggongjohn.me/tags/DataScience/"/>
    
  </entry>
  
  <entry>
    <title>操作系统实验 I/O子系统</title>
    <link href="http://gonggongjohn.me/2021/06/01/os/os-exp-io/"/>
    <id>http://gonggongjohn.me/2021/06/01/os/os-exp-io/</id>
    <published>2021-06-01T03:54:46.000Z</published>
    <updated>2022-02-09T14:20:18.671Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的">目的</h2><p>在Minix3中创建一块可用的RAM盘，并比较其与DISK盘在各类存取方式下的速度。</p><h2 id="内容与设计思想">内容与设计思想</h2><ol type="1"><li>在Minix3中安装一块 X MB大小的RAM盘<strong>（Minix中已有6块用户可用RAM盘，7块系统保留RAM盘）</strong>，可以挂载并且存取文件操作。</li><li>测试RAM盘和DISK盘的文件读写速度，分析其读写速度差异原因。</li></ol><h2 id="实验过程">实验过程</h2><h3 id="minix3的存储管理策略">Minix3的存储管理策略</h3><p>与其整体系统构架类似，Minix3的I/O构架分为5层：用户进程层、资源调度层、设备驱动层、内核中断层及硬件层。</p><img src="/2021/06/01/os/os-exp-io/minix_io.png" class="" title="minix_io"><p>对于磁盘来说，其通常以块为单位进行存储。当一个用户程序要从一个文件读一个块时，操作系统首先在高速缓存中查找有关的块。如果需要的块不在其中，则调用设备驱动程序，向硬件发出一个请求，从磁盘读取该块，然后将进程阻塞。当磁盘操作完成时，硬件产生一个中断，中断处理器随即从设备读取状态并唤醒休眠的的用户进程使其能够继续运行。</p><h3 id="ram盘申请">RAM盘申请</h3><p>RAM盘是将主存中的部分空间当作普通磁盘来使用的一种存储模型。在许多场景下，这种使用方式是高效且重要的（尤其是在由外部设备引导的系统下）。Minix3系统中共有6块固有的RAM盘，其设备控制程序分别被挂载在<strong>/dev/ram</strong>，<strong>/dev/kmem</strong>，<strong>/dev/boot</strong>，<strong>/dev/mem</strong>，<strong>/dev/null</strong>和<strong>/dev/zero</strong>下。</p><p>为了增加一块RAM盘，我们首先修改这一RAM盘常量：<strong>（minix/drivers/storage/memory）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* ramdisks (/dev/ram*) */</span>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> RAMDISKS     7</span><br></code></pre></td></tr></table></figure><p>Minix本身提供了一个用于创建RAM盘的<strong>ramdisk</strong>指令，但其单位为<strong>KB</strong>。为了方便起见，我们实现一个单位为<strong>MB</strong>的<strong>buildmyram</strong>指令用于创建较大容量的RAM盘：<strong>（minix/commands/ramdisk）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;minix/paths.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/ioc_memory.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;fcntl.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdlib.h&gt;  </span></span><br>  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> *argv[])</span>  </span><br><span class="hljs-function"></span>&#123;  <br>    <span class="hljs-keyword">int</span> fd;  <br>    <span class="hljs-keyword">signed</span> <span class="hljs-keyword">long</span> size;  <br>    <span class="hljs-keyword">char</span> *d;  <br>  <br>    <span class="hljs-keyword">if</span>(argc &lt; <span class="hljs-number">2</span> || argc &gt; <span class="hljs-number">3</span>) &#123;  <br>        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;usage: %s &lt;size in MB&gt; [device]\n&quot;</span>,  <br>                argv[<span class="hljs-number">0</span>]);  <br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;  <br>    &#125;  <br>  <br>    d = argc == <span class="hljs-number">2</span> ? _PATH_RAMDISK : argv[<span class="hljs-number">2</span>];  <br>    <span class="hljs-keyword">if</span>((fd=open(d, O_RDONLY)) &lt; <span class="hljs-number">0</span>) &#123;  <br>        perror(d);  <br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;  <br>    &#125;  <br>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> KFACTOR 1024  </span><br>    size = atol(argv[<span class="hljs-number">1</span>])*KFACTOR*<span class="hljs-number">1024</span>;  <br>  <br>    <span class="hljs-keyword">if</span>(size &lt; <span class="hljs-number">0</span>) &#123;  <br>        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;size should be non-negative.\n&quot;</span>);  <br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;  <br>    &#125;  <br>  <br>    <span class="hljs-keyword">if</span>(ioctl(fd, MIOCRAMSIZE, &amp;size) &lt; <span class="hljs-number">0</span>) &#123;  <br>        perror(<span class="hljs-string">&quot;MIOCRAMSIZE&quot;</span>);  <br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;  <br>    &#125;  <br>  <br>    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;size on %s set to %ldMB\n&quot;</span>, d, size/KFACTOR/<span class="hljs-number">1024</span>);  <br>  <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <br>&#125;<br></code></pre></td></tr></table></figure><p>修改完必要的内核代码后，我们重新编译系统并重启进入。现在，我们就可以来实际在系统中申请RAM盘了。</p><p>与系统固有盘类似，我们首先使用<strong>mknod</strong>指令创建一个新申请RAM盘的设备控制节点：</p><img src="/2021/06/01/os/os-exp-io/mknod.png" class="" title="mknod"><p>随后，我们使用新实现的<strong>buildmyram</strong>指令申请一块大小为500MB的RAM盘：</p><img src="/2021/06/01/os/os-exp-io/buildmyram.png" class="" title="buildmyram"><p>最后，我们在新申请的RAM盘上创建相应的文件系统，并将其挂载到<strong>/root/myram</strong>目录下即可：</p><img src="/2021/06/01/os/os-exp-io/mkfs.png" class="" title="mkfs"><p>通过<strong>df</strong>指令可以看到，RAM盘已被成功创建。</p><h3 id="读写性能测试">读写性能测试</h3><p>接下来，我们需要编写一组用于测试和比较DISK盘和RAM盘读写性能的程序。由于DISK盘和RAM盘使用了同样的抽象模型，我们可以使用相同的逻辑来对其进行测试。</p><p>一块磁盘在使用过程中主要会遇到以下四种读写模式：<strong>顺序读取、随机读取、顺序写入、随机写入</strong>。对于读取操作，我们首先使用<strong>open</strong>系统调用打开相应的文件，随后使用<strong>read</strong>系统调用将文件中固定大小的内容读入缓存中。若为随机读取，则在读取完成后我还需要使用<strong>lseek</strong>和<strong>rand</strong>函数将文件指针重新指到一个随机的位置。此外，为了产生较为显著的运行时间以方便比较，我们在一次操作中重复读取1000轮：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> ROUND 1000  </span><br>  <br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">read_file</span><span class="hljs-params">(<span class="hljs-keyword">int</span> blocksize, <span class="hljs-keyword">bool</span> isrand, <span class="hljs-keyword">char</span> *filepath)</span></span>&#123;  <br>    <span class="hljs-keyword">int</span> fd = <span class="hljs-number">0</span>;  <br>    fd = open(filepath, O_CREAT | O_RDWR | O_SYNC, S_IRWXU);  <br>    <span class="hljs-keyword">if</span>(fd &lt; <span class="hljs-number">0</span>)&#123;  <br>        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stdout</span>, <span class="hljs-string">&quot;Error occurred when opening file!&quot;</span>);  <br>        <span class="hljs-keyword">return</span>;  <br>    &#125;  <br>    <span class="hljs-keyword">char</span> *buf_ext = (<span class="hljs-keyword">char</span> *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">char</span>) * blocksize);  <br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; ROUND; i++)&#123;  <br>        read(fd, buf_ext, blocksize);  <br>        <span class="hljs-keyword">if</span>(isrand)&#123;  <br>            lseek(fd, rand() % ((blocksize - <span class="hljs-number">1</span>) * ROUND), SEEK_SET);  <br>        &#125;  <br>    &#125;  <br>    <span class="hljs-built_in">free</span>(buf_ext);  <br>    lseek(fd, <span class="hljs-number">0</span>, SEEK_SET);  <br>    close(fd);  <br>&#125;<br></code></pre></td></tr></table></figure><p>写入操作与读取操作类似。我们首先构造一个64Bytes的字符串作为写入的最小单位，随后使用<strong>strcat</strong>函数将重复拼接到指定的写入大小，并通过<strong>write</strong>系统调用将其写入文件系统即可：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> BUFSIZE (64)  </span><br>  <br><span class="hljs-keyword">char</span> buffer[BUFSIZE] = <span class="hljs-string">&quot;This is a 6KB block!&quot;</span>;  <br>  <br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">write_file</span><span class="hljs-params">(<span class="hljs-keyword">int</span> blocksize, <span class="hljs-keyword">bool</span> isrand, <span class="hljs-keyword">char</span> *filepath)</span></span>&#123;  <br>    <span class="hljs-keyword">int</span> fd = <span class="hljs-number">0</span>;  <br>    fd = open(filepath, O_CREAT | O_RDWR | O_SYNC, S_IRWXU);  <br>    <span class="hljs-keyword">if</span>(fd &lt; <span class="hljs-number">0</span>)&#123;  <br>        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stdout</span>, <span class="hljs-string">&quot;Error occurred when opening file!&quot;</span>);  <br>        <span class="hljs-keyword">return</span>;  <br>    &#125;  <br>    <span class="hljs-keyword">char</span> *buf_ext = (<span class="hljs-keyword">char</span> *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">char</span>) * blocksize);  <br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; blocksize / BUFSIZE; i++)&#123;  <br>        <span class="hljs-built_in">strcat</span>(buf_ext, buffer);  <br>    &#125;  <br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; ROUND; i++)&#123;  <br>        write(fd, buf_ext, blocksize);  <br>        <span class="hljs-keyword">if</span>(isrand)&#123;  <br>            lseek(fd, rand() % ((blocksize - <span class="hljs-number">1</span>) * ROUND), SEEK_SET);  <br>        &#125;  <br>    &#125;  <br>    lseek(fd, <span class="hljs-number">0</span>, SEEK_SET);  <br>    close(fd);  <br>&#125;<br></code></pre></td></tr></table></figure><p>由于现代存储媒介大多已经可以应付较高的读写请求，为了最大程度测试DISK盘和RAM盘的性能，我们使用多线程并发读写的方式来尽可能地使磁盘吞吐达到饱和。经实测，在写入块大小为<strong>4KB</strong>时， RAM和DISK盘的吞吐在并发数为<strong>16～20</strong>左右时基本达到了饱和：</p><img src="/2021/06/01/os/os-exp-io/concur.png" class="" title="concur"><p>考虑到SSD磁盘的读写硬件特性，我们将并发数设置为<strong>15</strong>。对于读写块大小，我们以2倍为步长，以测试从64Bytes到8KB时的情况：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> MAXSTR 100  </span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> CONCURRENCY 15  </span><br>  <br><span class="hljs-keyword">char</span> *path_format[<span class="hljs-number">2</span>] = &#123;<span class="hljs-string">&quot;/root/myram/disk_%d.txt&quot;</span>, <span class="hljs-string">&quot;/usr/disk_%d.txt&quot;</span>&#125;;  <br>  <br><span class="hljs-comment">//Irrelevant code  </span><br>  <br><span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">get_time_left</span><span class="hljs-params">(struct timeval starttime, struct timeval endtime)</span></span>&#123;  <br>    <span class="hljs-keyword">return</span> ((endtime.tv_sec * <span class="hljs-number">1000</span> + endtime.tv_usec / <span class="hljs-number">1000</span>) - (starttime.tv_sec * <span class="hljs-number">1000</span> +  <br>                                                                starttime.tv_usec / <span class="hljs-number">1000</span>)) / <span class="hljs-number">1000.0</span>;  <br>&#125;  <br>  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;  <br>    srand(time(<span class="hljs-number">0</span>));  <br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">2</span>; j++) &#123;  <br>        <span class="hljs-keyword">if</span> (j == <span class="hljs-number">0</span>) <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;RAM:\n&quot;</span>);  <br>        <span class="hljs-keyword">else</span> <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Disk:\n&quot;</span>);  <br>        <span class="hljs-keyword">int</span> block_size = <span class="hljs-number">64</span>;  <br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> k = <span class="hljs-number">0</span>; k &lt; <span class="hljs-number">8</span>; k++) &#123;  <br>            <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">timeval</span> <span class="hljs-title">start_time</span>, <span class="hljs-title">end_time</span>;</span>  <br>            gettimeofday(&amp;start_time, <span class="hljs-literal">NULL</span>);  <br>            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; CONCURRENCY; i++) &#123;  <br>                <span class="hljs-keyword">char</span> *filepath = (<span class="hljs-keyword">char</span> *) <span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">char</span>) * MAXSTR);  <br>                <span class="hljs-built_in">sprintf</span>(filepath, path_format[j], i);  <br>                <span class="hljs-keyword">if</span> (fork() == <span class="hljs-number">0</span>) &#123;  <br>                    <span class="hljs-comment">/* 顺序读取 */</span>  <br>                    read_file(block_size, <span class="hljs-literal">false</span>, filepath);  <br>                     <span class="hljs-comment">/* 随机读取 */</span>  <br>                    <span class="hljs-comment">//read_file(block_size, true, filepath);  </span><br>                     <span class="hljs-comment">/* 顺序写入 */</span>  <br>                    <span class="hljs-comment">//write_file(block_size, false, filepath);  </span><br>                     <span class="hljs-comment">/* 随机写入 */</span>  <br>                    <span class="hljs-comment">//write_file(block_size, true, filepath);  </span><br>                    <span class="hljs-built_in">exit</span>(<span class="hljs-number">1</span>);  <br>                &#125;  <br>            &#125;  <br>            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; CONCURRENCY; i++) &#123;  <br>                wait(<span class="hljs-literal">NULL</span>);  <br>            &#125;  <br>            gettimeofday(&amp;end_time, <span class="hljs-literal">NULL</span>);  <br>            <span class="hljs-keyword">double</span> time_cost = get_time_left(start_time, end_time);  <br>            <span class="hljs-keyword">double</span> write_size = block_size * ROUND * CONCURRENCY / <span class="hljs-number">1024.0</span> / <span class="hljs-number">1024</span>;  <br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Blocksize: %d Bytes, Writesize: %f MB, Time: %f s\n&quot;</span>, block_size, write_size, time_cost);  <br>            block_size *= <span class="hljs-number">2</span>;  <br>        &#125;  <br>    &#125;  <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="测试结果分析">测试结果分析</h3><p>将测试程序编译并多次运行后，我们得到了一组RAM盘和DISK盘在不同块大小下各种读写情况时的运行时间。通过<strong>数据大小/运行时间</strong>，我们就可大致得到磁盘的平均读写速度。结果如下：</p><img src="/2021/06/01/os/os-exp-io/chart_1.png" class="" title="chart_1"><img src="/2021/06/01/os/os-exp-io/chart_2.png" class="" title="chart_2"><img src="/2021/06/01/os/os-exp-io/chart_3.png" class="" title="chart_3"><img src="/2021/06/01/os/os-exp-io/chart_4.png" class="" title="chart_4"><img src="/2021/06/01/os/os-exp-io/chart_aggregate.png" class="" title="chart_aggregate"><p>可以发现，随着操作块大小的增加，RAM盘和DISK盘的吞吐量也逐渐增加。在各种读写场景下，RAM盘的读写速度显著高于Disk盘，这与其实现原理及在计算机体系结构中的层级位置相一致：</p><img src="/2021/06/01/os/os-exp-io/hierarchy.png" class="" title="hierarchy"><p>此外，由于我们使用了SSD（PCI-Express协议）作为磁盘存储媒介，可以看到当块大小为4KB时，DISK盘的吞吐量激增。这是由于在使用SSD磁盘时，系统通常会对其进行4K对齐优化以延长磁盘使用寿命，而4KB的读写块大小正好为一个磁盘块大小，因此磁盘控制器可以快速响应所需的请求。</p><img src="/2021/06/01/os/os-exp-io/4k-alignment.png" class="" title="4k-alignment"><h2 id="总结">总结</h2><p>在本实验中，我们在Minix3系统下分别划分了一块DISK盘空间与RAM盘空间，并通过一系列不同读写方式的组合测试了DISK盘和RAM盘的读写速度与特性，更加直观的认识了系统对于RAM和DISK存储媒介的不同管理方式及其在系统构架中的巨大传输速度差异，从而感受到了现代计算机系统构架的合理性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目的&quot;&gt;目的&lt;/h2&gt;
&lt;p&gt;在Minix3中创建一块可用的RAM盘，并比较其与DISK盘在各类存取方式下的速度。&lt;/p&gt;
&lt;h2 id=&quot;内容与设计思想&quot;&gt;内容与设计思想&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;在Minix3中安装一块 X MB大小的RA</summary>
      
    
    
    
    <category term="操作系统" scheme="http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Operating-System" scheme="http://gonggongjohn.me/tags/Operating-System/"/>
    
  </entry>
  
  <entry>
    <title>操作系统实验 进程调度EDF</title>
    <link href="http://gonggongjohn.me/2021/04/27/os/os-exp-chrt/"/>
    <id>http://gonggongjohn.me/2021/04/27/os/os-exp-chrt/</id>
    <published>2021-04-27T03:54:46.000Z</published>
    <updated>2022-03-06T14:13:47.592Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的">目的</h2><p>修改MINIX3系统内核，增加一个系统调用<strong>chrt</strong>，并在其中实现<strong>EDF(Earlist-Deadline-First)</strong>进程调度算法。</p><h2 id="内容与设计思想">内容与设计思想</h2><ol type="1"><li>提供设置进程执行期限的系统调度<code>chrt(long deadline)</code>，用于将调用该系统调用的进程设为实时进程，其执行的期限为：从调用处开始deadline秒。例如：</li></ol><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;unistd.h&gt;  </span></span><br>...<br>chrt(<span class="hljs-number">10</span>); <span class="hljs-comment">/* 该程序将可以运行的最长时间为10秒，若没有运行结束，则强制结束 */</span>  <br>...<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li><p>在内核进程表中需要增加一个条目，用于表示进程的实时属性；修改相关代码，新增一个系统调用<strong>chrt</strong>，用于设置其进程表中的实时属性。</p></li><li><p>修改<strong>proc.c</strong>和<strong>proc.h</strong>中相关的调度代码，实现最早deadline的用户进程相对于其它用户进程具有更高的优先级，从而被优先调度运行。</p></li><li><p>在用户程序中，可以在不同位置调用多次chrt系统调用，在未到deadline之前，调用chrt将会改变该程序的deadline。</p></li><li><p>未调用chrt的程序将以普通的用户进程(非实时进程)在系统中运行。</p></li></ol><h2 id="实验过程">实验过程</h2><h3 id="minix系统构架">MINIX系统构架</h3><p>作为一个微内核构架系统，Minix将系统进程分为了4层：<strong>内核层</strong>、<strong>驱动管理层</strong>、<strong>服务器进程层</strong>、<strong>用户进程层</strong>，其中内核层运行在系统内核态，而后三层均运行在用户态。</p><p>在Minix中，层与层之间的消息传递通过系统调用来完成，而这又分为了<strong>System Call</strong>和<strong>Kernel Call</strong>。<strong>System Call</strong>用于应用层向服务层的消息传递，<strong>Kernel Call</strong>则用于服务层向内核层的消息传递。</p><img src="/2021/04/27/os/os-exp-chrt/minix_msgpass.png" class="" title="minix_msgpass"><p>消息传递本质上是进程间通讯，从内存角度看即为内存地址间的内容拷贝。幸运的是，Minix已经帮我们封装好了这些调用的底层实现，我们只需要传入正确的参数，系统会自动托管底层内存拷贝的相关事务：<strong>（minix/lib/libc/sys/syscall.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">int</span> _syscall(<span class="hljs-keyword">endpoint_t</span> who, <span class="hljs-keyword">int</span> syscallnr, message *msgptr)  <br>&#123;  <br>  <span class="hljs-keyword">int</span> status;  <br>  <br>  msgptr-&gt;m_type = syscallnr;  <br>  status = ipc_sendrec(who, msgptr);  <br>  <span class="hljs-keyword">if</span> (status != <span class="hljs-number">0</span>) &#123;  <br>    <span class="hljs-comment">/* &#x27;ipc_sendrec&#x27; itself failed. */</span>  <br>    <span class="hljs-comment">/* XXX - strerror doesn&#x27;t know all the codes */</span>  <br>    msgptr-&gt;m_type = status;  <br>  &#125;  <br>  <span class="hljs-keyword">if</span> (msgptr-&gt;m_type &lt; <span class="hljs-number">0</span>) &#123;  <br>    errno = -msgptr-&gt;m_type;  <br>    <span class="hljs-keyword">return</span>(<span class="hljs-number">-1</span>);  <br>  &#125;  <br>  <span class="hljs-keyword">return</span>(msgptr-&gt;m_type);  <br>&#125;<br></code></pre></td></tr></table></figure><p><strong>（minix/lib/libsys/kernel_call.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">int</span> _kernel_call(<span class="hljs-keyword">int</span> syscallnr, message *msgptr)  <br>&#123;  <br>  msgptr-&gt;m_type = syscallnr;  <br>  do_kernel_call(msgptr);  <br>  <span class="hljs-keyword">return</span>(msgptr-&gt;m_type);  <br>&#125;<br></code></pre></td></tr></table></figure><p>Minix系统采用了一种多级调度算法，通过维护16个进程队列并赋予其不同的队列优先级来实现进程的分级。其中，0号队列用于放置时钟及系统任务，系统会允许其持续运行直到阻塞（但如果其运行时间过长，系统会设置一个罚时将其暂时移出队列以防止其他进程发生饥饿），7号队列用于放置用户进程，15号队列用于放置闲置进程。在每个进程队列内部，系统采用了时间片轮转的方式使得进程可以公平的分配到运行时间。</p><img src="/2021/04/27/os/os-exp-chrt/proc_queue.png" class="" title="proc_queue"><h3 id="edf调度实现">EDF调度实现</h3><p>要实现EDF调度算法，需要记录每个进程的截止时间。为此，我们在<strong>进程控制块（Process Control Block）</strong>的结构定义中新增一个<strong>p_deadline</strong>项：<strong>（minix/kernel/proc.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">proc</span> &#123;</span>  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>  <br>    <span class="hljs-keyword">long</span> p_deadline;  <span class="hljs-comment">/* Deadline of the process */</span>  <br>  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>&#125;;<br></code></pre></td></tr></table></figure><p>由于Minix采用多级进程队列，我们可以选择其中的一个进程队列，并在其中使用EDF算法进行调度。由于要保证所有调用chrt系统调用的进程都使用该调度规则，所选择的进程队列的整体优先级要高于用户进程所在的队列，但同时又不能影响系统进程的运作。这里我们选择优先级为5的队列作为EDF调度队列（事实上，4号队列也可以作为要替换的目标队列，但为了防止驱动或系统进程临时调度到这一队列，在此我们将其留出作为缓冲）。</p><p>对于一般的进程，我们在进程初始化时将<strong>p_deadline</strong>置为0。这样在进程调度时，若检测到<strong>p_deadline&gt;0</strong>，即可得知其为调用了<strong>chrt</strong>系统调用的进程，我们便将其加入优先级为5的队列中：<strong>（minix/kernel/proc.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">enqueue</span><span class="hljs-params">(    </span></span><br><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">register</span> struct proc *rp  <span class="hljs-comment">/* this process is now runnable */</span>    </span></span><br><span class="hljs-function"><span class="hljs-params">)</span>    </span><br><span class="hljs-function"></span>&#123;    <br>    <span class="hljs-comment">//Unrelated codes   </span><br>    <span class="hljs-keyword">if</span>(rp-&gt;p_deadline &gt; <span class="hljs-number">0</span>)&#123;    <br>        rp-&gt;p_priority = <span class="hljs-number">5</span>;    <br>    &#125;    <br>    <span class="hljs-comment">//Unrelated codes    </span><br>&#125;   <br>  <br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">enqueue_head</span><span class="hljs-params">(struct proc *rp)</span>  </span><br><span class="hljs-function"></span>&#123;  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>    <span class="hljs-keyword">if</span>(rp-&gt;p_deadline &gt; <span class="hljs-number">0</span>)&#123;  <br>        rp-&gt;p_priority = <span class="hljs-number">5</span>;  <br>    &#125;  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>&#125;<br></code></pre></td></tr></table></figure><p>在调度时，我们要找出队列中<strong>p_deadline</strong>最小的进程并返回。一个可行的办法是维护一个优先队列，按照<strong>p_deadline</strong>对进程控制结构建立小根堆，其可以在 <span class="math inline">\(\mathcal{O}(\lg n)\)</span> 的时间内返回目标进程，但这样做需要修改整个进程队列的数据结构，操作起来过于复杂，也不符合Minix3的原始设计风格。由于进入该队列的进程是由用户指定的，其规模通常较小，因此我们可以直接遍历整个队列，其效率仍然是可以接受的。实现代码如下：<strong>（minix/kernel/proc.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">static</span> struct proc * <span class="hljs-title">pick_proc</span><span class="hljs-params">(<span class="hljs-keyword">void</span>)</span>  </span><br><span class="hljs-function"></span>&#123;  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>    <span class="hljs-keyword">for</span> (q=<span class="hljs-number">0</span>; q &lt; NR_SCHED_QUEUES; q++) &#123;      <br>        <span class="hljs-comment">//Unrelated codes  </span><br>        <span class="hljs-comment">//EDF algorithm  </span><br>        <span class="hljs-keyword">if</span>(q == <span class="hljs-number">5</span>)&#123;  <br>            rp = rdy_head[q];  <br>            <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">proc</span> *<span class="hljs-title">cur</span> = <span class="hljs-title">rp</span>-&gt;<span class="hljs-title">p_nextready</span>;</span>  <br>            <span class="hljs-comment">//Traverse the queue  </span><br>            <span class="hljs-keyword">while</span>(cur != <span class="hljs-literal">NULL</span>) &#123;  <br>                <span class="hljs-keyword">if</span>(proc_is_runnable(cur) &amp;&amp; (cur-&gt;p_deadline &gt; <span class="hljs-number">0</span>)) &#123;  <br>                    <span class="hljs-keyword">if</span> (rp-&gt;p_deadline &gt; cur-&gt;p_deadline) &#123;  <br>                        rp = cur;  <br>                    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (rp-&gt;p_deadline == <span class="hljs-number">0</span>)&#123;  <br>                        rp = cur;  <br>                    &#125;  <br>                &#125;  <br>                cur = cur-&gt;p_nextready;  <br>            &#125;  <br>        &#125;  <br>        <span class="hljs-comment">//Unrelated codes  </span><br>        <span class="hljs-keyword">return</span> rp;  <br>    &#125;  <br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;  <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="应用层实现">应用层实现</h3><p>在应用层中，我们需要实现面向用户的<strong>chrt函数</strong>，并将用户指定的进程和截止时间传入服务层。</p><p>首先我们在POSIX规定的操作系统API头文件中定义chrt的函数原型：<strong>（include/unistd.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">chrt</span><span class="hljs-params">(<span class="hljs-keyword">long</span> deadline)</span></span>; <span class="hljs-comment">// 0 - Normal process; &gt;0 - Realtime process; &lt;0 - Unsuccessful</span><br></code></pre></td></tr></table></figure><p>用户指定的截止时间是一个相对时间，即从该语句执行时刻向后deadline秒，因此我们需要将其转为绝对时间（事实上是相对系统时钟当前时刻的时间）。Minix系统提供了一个<strong>clock_gettime</strong>函数用于获取系统的时间戳，因此我们可以直接调用该函数来算出当前进程所指定deadline对应的绝对时刻：<strong>（minix/lib/libc/sys/chrt.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/cdefs.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;namespace.h&quot;</span>  </span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;lib.h&gt;  </span></span><br>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;string.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;unistd.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;time.h&gt;  </span></span><br>  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">chrt</span><span class="hljs-params">(<span class="hljs-keyword">long</span> deadline)</span></span>&#123;  <br>    message m;  <br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">timespec</span> <span class="hljs-title">now</span>;</span>  <br>    <span class="hljs-built_in">memset</span>(&amp;m, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span>(m));  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>    <span class="hljs-keyword">if</span>(deadline &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(deadline &gt; <span class="hljs-number">0</span>)&#123;  <br>        clock_gettime(CLOCK_REALTIME, &amp;now);  <br>        deadline = now.tv_sec + deadline;  <br>    &#125;  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>&#125;<br></code></pre></td></tr></table></figure><p>此外，我们还需要对传入的deadline参数做一些边界处理，并通过<strong>alarm</strong>系统调用将超时响应的应用提前结束。随后我们便可以将其放入一个消息结构体中，并通过 **System Call（_syscall函数）** 将消息传入服务层中：<strong>（minix/lib/libc/sys/chrt.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">chrt</span><span class="hljs-params">(<span class="hljs-keyword">long</span> deadline)</span></span>&#123;  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>    alarm((<span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span>) deadline);  <br>    <span class="hljs-comment">//Unrelated codes  </span><br>    m.m2_l1 = deadline;  <br>    <span class="hljs-keyword">return</span> _syscall(PM_PROC_NR, PM_CHRT, &amp;m);  <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="服务层实现">服务层实现</h3><p>对于要实现的chrt系统调用来说，服务层起到了消息传递的作用。在Minix3系统中，这需要两步来完成，先接受应用层传来的消息，再将消息重新打包并通过<strong>Kernel Call</strong>传入内核中。</p><p>首先我们来实现消息接受的功能。在应用层中，我们通过调用标识符为<strong>PM_CHRT</strong>的System Call将消息发到了服务层中，于是我们需要在服务层中申明这一System Call并将其与消息接收函数相关联：<strong>（minix/include/minix/callnr.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PM_CHRT     (PM_BASE + 48)  </span><br>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> NR_PM_CALLS     49  <span class="hljs-comment">/* highest number from base plus one */</span>  </span><br></code></pre></td></tr></table></figure><p><strong>（minix/servers/pm/table.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">int</span> (* <span class="hljs-keyword">const</span> call_vec[NR_PM_CALLS])(<span class="hljs-keyword">void</span>) = &#123;  <br>    CALL(PM_CHRT)       = do_chrt,      <span class="hljs-comment">/* chrt */</span>  <br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>（minix/servers/pm/proto.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* chrt.c */</span>  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">do_chrt</span><span class="hljs-params">()</span></span>;<br></code></pre></td></tr></table></figure><p>至于消息接收函数的实现，我们只需要将发来消息的进程号和发来的消息传递给承接服务层向内核进行消息传递的函数即可：<strong>（minix/servers/pm/chrt.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;pm.h&quot;</span>  </span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;signal.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/time.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;minix/com.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;minix/callnr.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;mproc.h&quot;</span>  </span><br>  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">do_chrt</span><span class="hljs-params">()</span></span>&#123;  <br>    sys_chrt(who_p, m_in.m2_l1);  <br>    <span class="hljs-keyword">return</span> OK;  <br>&#125;<br></code></pre></td></tr></table></figure><p>随后我们来实现服务层向内核层的消息传递。首先我们定义消息传递函数的原型：<strong>（minix/include/minix/syslib.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">sys_chrt</span><span class="hljs-params">(<span class="hljs-keyword">endpoint_t</span> proc_ep, <span class="hljs-keyword">long</span> deadline)</span></span>;<br></code></pre></td></tr></table></figure><p>对于该函数我们只需要将传入的函数重新打包为一个新的消息，并通过**Kernel Call（_kernel_call函数）<strong>将其传入内核即可：</strong>（minix/lib/libsys/sys_chrt.c）**</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;syslib.h&quot;</span>  </span><br>  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">sys_chrt</span><span class="hljs-params">(<span class="hljs-keyword">endpoint_t</span> proc_ep, <span class="hljs-keyword">long</span> deadline)</span>  </span><br><span class="hljs-function"></span>&#123;  <br>    message m;  <br>    m.m2_i1 = proc_ep;  <br>    m.m2_l1 = deadline;  <br>    <span class="hljs-keyword">return</span> _kernel_call(SYS_CHRT, &amp;m);  <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="内核层实现">内核层实现</h3><p>首先我们定义服务层中调用的<strong>SYS_CHRT</strong>内核调用，并将其与内核实现函数相关联：<strong>（minix/include/minix/com.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#  <span class="hljs-meta-keyword">define</span> SYS_CHRT (KERNEL_CALL + 58) <span class="hljs-comment">/* sys_chrt() */</span>  </span><br>  <br><span class="hljs-comment">/* Total */</span>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> NR_SYS_CALLS    59  <span class="hljs-comment">/* number of kernel calls */</span></span><br></code></pre></td></tr></table></figure><p><strong>（minix/kernel/system.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-built_in">map</span>(SYS_CHRT, do_chrt);       <span class="hljs-comment">/* chrt */</span><br></code></pre></td></tr></table></figure><p>随后我们定义实现函数的原型，并在内核中默认启用它：<strong>（minix/kernel/config.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> USE_CHRT           1    <span class="hljs-comment">/* chrt */</span></span><br></code></pre></td></tr></table></figure><p><strong>（minix/kernel/system.h）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">do_chrt</span><span class="hljs-params">(struct proc * caller, message *m_ptr)</span></span>;  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> ! USE_CHRT  </span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> do_chrt NULL  </span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>内核的任务就是把上层传递下来的消息解包，并将目标进程的截止时间设置为用户所指定的时间：<strong>（minix/kernel/system/do_chrt.c）</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;kernel/system.h&quot;</span>  </span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;kernel/vm.h&quot;</span>  </span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;signal.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;string.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;assert.h&gt;  </span></span><br>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;minix/endpoint.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;minix/u64.h&gt;  </span></span><br>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> USE_CHRT  </span><br>  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">do_chrt</span><span class="hljs-params">(struct proc *caller, message *m_ptr)</span></span>&#123;  <br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">proc</span> *<span class="hljs-title">rp</span>;</span>  <br>    <span class="hljs-keyword">long</span> deadline;  <br>    deadline = m_ptr-&gt;m2_l1;  <br>    rp = proc_addr(m_ptr-&gt;m2_i1);  <br>    rp-&gt;p_deadline = deadline;  <br>    <span class="hljs-keyword">return</span> OK;  <br>&#125;  <br>  <br><span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">/* USE_FORK */</span></span><br></code></pre></td></tr></table></figure><h3 id="功能测试">功能测试</h3><p>我们使用以下代码来对实现的功能进行测试：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdlib.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;unistd.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;string.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;signal.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/wait.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/types.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;lib.h&gt;  </span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;time.h&gt;  </span></span><br>  <br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">proc</span><span class="hljs-params">(<span class="hljs-keyword">int</span> id)</span></span>;  <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">void</span>)</span>  </span><br><span class="hljs-function"></span>&#123;  <br>  <span class="hljs-comment">//创建三个子进程，并赋予子进程id  </span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; <span class="hljs-number">4</span>; i++)  <br>  &#123;  <br>    <span class="hljs-keyword">if</span> (fork() == <span class="hljs-number">0</span>)  <br>    &#123;  <br>      proc(i);  <br>    &#125;  <br>  &#125;  <br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <br>&#125;  <br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">proc</span><span class="hljs-params">(<span class="hljs-keyword">int</span> id)</span>  </span><br><span class="hljs-function"></span>&#123;  <br>  <span class="hljs-keyword">int</span> loop;  <br>  <span class="hljs-keyword">switch</span> (id)  <br>  &#123;  <br>  <span class="hljs-keyword">case</span> <span class="hljs-number">1</span>: <span class="hljs-comment">//子进程1，设置deadline=20  </span><br>    chrt(<span class="hljs-number">20</span>);  <br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;proc1 set success\n&quot;</span>);  <br>    <span class="hljs-comment">//sleep(1);  </span><br>    <span class="hljs-keyword">break</span>;  <br>  <span class="hljs-keyword">case</span> <span class="hljs-number">2</span>: <span class="hljs-comment">//子进程2，设置deadline=15  </span><br>    chrt(<span class="hljs-number">15</span>);  <br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;proc2 set success\n&quot;</span>);  <br>    <span class="hljs-comment">//sleep(1);  </span><br>    <span class="hljs-keyword">break</span>;  <br>  <span class="hljs-keyword">case</span> <span class="hljs-number">3</span>: <span class="hljs-comment">//子进程3，普通进程  </span><br>    chrt(<span class="hljs-number">0</span>);  <br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;proc3 set success\n&quot;</span>);  <br>    <span class="hljs-keyword">break</span>;  <br>  &#125;  <br>  <span class="hljs-keyword">for</span> (loop = <span class="hljs-number">1</span>; loop &lt; <span class="hljs-number">40</span>; loop++)  <br>  &#123;  <br>    <span class="hljs-comment">//子进程1在5s后设置deadline=5  </span><br>    <span class="hljs-keyword">if</span> (id == <span class="hljs-number">1</span> &amp;&amp; loop == <span class="hljs-number">5</span>)  <br>    &#123;  <br>      <span class="hljs-keyword">long</span> tmp;  <br>      tmp = chrt(<span class="hljs-number">5</span>);  <br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Status of CHRT: %d\n&quot;</span>, tmp);  <br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Change proc1 deadline to 5s\n&quot;</span>);  <br>    &#125;  <br>    <span class="hljs-comment">//子进程3在10s后设置deadline=3  </span><br>    <span class="hljs-keyword">if</span> (id == <span class="hljs-number">3</span> &amp;&amp; loop == <span class="hljs-number">10</span>)  <br>    &#123;  <br>      chrt(<span class="hljs-number">3</span>);  <br>      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Change proc3 deadline to 3s\n&quot;</span>);  <br>    &#125;  <br>    sleep(<span class="hljs-number">1</span>); <span class="hljs-comment">//睡眠，否则会打印很多信息  </span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;prc%d heart beat %d\n&quot;</span>, id, loop);  <br>  &#125;  <br>  <span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);  <br>&#125;<br></code></pre></td></tr></table></figure><p>该程序创建了3个子进程，并对其分别设置了不同的截止时间，其运行结果如下：</p><img src="/2021/04/27/os/os-exp-chrt/run_1.png" class="" title="run_1"><img src="/2021/04/27/os/os-exp-chrt/run_2.png" class="" title="run_2"><p>可以看到，程序中chrt系统调用的返回值为0，表明其成功将消息传入了内核，且程序行为与预期相符，表明了实现的正确性。</p><h2 id="总结">总结</h2><p>在本实验中，我们通过修改Minix3的系统源码，实现了一个完整的系统调用，并在进程调度中实现了EDF算法，极大的加深了我们对一个微内核操作系统的系统调用、消息传递及进程调度机制的理解。</p><p>--&gt;</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目的&quot;&gt;目的&lt;/h2&gt;
&lt;p&gt;修改MINIX3系统内核，增加一个系统调用&lt;strong&gt;chrt&lt;/strong&gt;，并在其中实现&lt;strong&gt;EDF(Earlist-Deadline-First)&lt;/strong&gt;进程调度算法。&lt;/p&gt;
&lt;h2 id=&quot;内容与设</summary>
      
    
    
    
    <category term="操作系统" scheme="http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Operating-System" scheme="http://gonggongjohn.me/tags/Operating-System/"/>
    
  </entry>
  
  <entry>
    <title>离散型随机变量整理</title>
    <link href="http://gonggongjohn.me/2021/04/21/math-prob-stat/prob-drv/"/>
    <id>http://gonggongjohn.me/2021/04/21/math-prob-stat/prob-drv/</id>
    <published>2021-04-21T09:56:35.000Z</published>
    <updated>2022-02-09T10:32:53.238Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二项分布">二项分布</h2><h3 id="定义">定义</h3><blockquote><p><strong>Definition:</strong> 若一个离散型随机变量 <span class="math inline">\(X\)</span> 的分布列满足 <span class="math display">\[P(X=k) = \binom{n}{k} p^k (1-p)^{1-k}\]</span> 其中 <span class="math inline">\(n \in \mathbb{N}^+, k \in \{0,1,2,...,n\}, p \in [0,1]\)</span>，则称随机变量 <span class="math inline">\(X\)</span> 满足二项分布，记为 <span class="math inline">\(X \sim B(n, p)\)</span></p></blockquote><a id="more"></a><p><strong>适用场景：</strong>在 <span class="math inline">\(n\)</span> 次伯努利试验中，若每次成功的概率均为 <span class="math inline">\(p\)</span>，求成功 <span class="math inline">\(k\)</span> 次的概率</p><p>二项分布的<strong>累积分布函数</strong>为 <span class="math display">\[F(k) = P(X \leq k)=\left\{\begin{aligned}\sum_\limits{i=0}^{\lfloor k \rfloor} \binom{n}{k}p^k(1-p)^{1-k}&amp;,&amp;k \geq 0  \\0&amp;,&amp; k &lt; 0\end{aligned}\right.\]</span> 若引入<strong>不完全Beta函数</strong>，则其累积分布函数的非负部分还可表示为 <span class="math display">\[\begin{aligned}F(k) &amp;= I_{1-p} (n-k, k+1) \\&amp;= \frac{\textrm{B} (1-p;n-k,k+1)}{\textrm{B} (n-k,k+1)} \\&amp;=\frac{\int_0^{1-p} t^{n-k-1}(1-t)^k dt}{\int_0^1 t^{n-k-1}(1-t)^k dt} \ , k \geq 0\end{aligned}\]</span></p><h3 id="期望和方差">期望和方差</h3><p>由于每一次伯努利试验均为独立的，因此我们可以将 <span class="math inline">\(n\)</span> 次试验分解为 <span class="math inline">\(n\)</span> 个单次试验，即若定义 <span class="math display">\[Y_i = \left\{\begin{aligned}1,&amp; Succeed \ \ in \ \ i^{th} \ \ exp \\0,&amp; Fail \ \ in \ \ i^{th} \ \ exp\end{aligned}\right.\]</span> 则 <span class="math inline">\(X=\sum\limits_{i = 1}^n Y_i\)</span> （此时 <span class="math inline">\(Y_i\)</span> 服从的分布即 <span class="math inline">\(B(1,p)\)</span> 也被称为<strong>二点分布</strong>或<strong>0-1分布</strong>）</p><p>于是我们可以快速求出二项分布的期望 <span class="math display">\[\begin{aligned}E(X) &amp;= E \left( \sum_{i = 1}^n Y_i \right) \\&amp;= \sum_{i = 1}^n E(Y_i) \\&amp;= \sum_{i = 1}^n p \\&amp;=np\end{aligned}\]</span></p><p>同理，由 <span class="math display">\[Var(Y_i) = (1-p)^2 p + (0-p)^2(1-p)=p(1-p)\]</span> 可知二项分布的方差为 <span class="math display">\[\begin{aligned}Var(X) &amp;= Var(\sum_\limits{i=1}^n Y_i) \\&amp;= \sum_\limits{i=1}^n Var(Y_i) \\&amp;= \sum_\limits{i=1}^n p(1-p) \\&amp;= np(1-p)\end{aligned}\]</span></p><blockquote><p><strong>另解（纯分析法求二项分布期望及方差）：</strong> <span class="math display">\[\begin{aligned}E(X) &amp;= \sum_\limits{k = 0}^n k \binom{n}{k} p^k (1-p)^{n-k} \\&amp;= \sum_\limits{k = 1}^n k \binom{n}{k} p^k (1-p)^{n-k} \\\end{aligned}\]</span> 由于 <span class="math display">\[\begin{aligned}k\binom{n}{k} &amp;= k \cdot \frac{n!}{k!(n-k)!} \\&amp;=\frac{n!}{(k-1)!(n-k)!} \\&amp;=n \cdot \frac{(n-1)!}{(k-1)!(n-k)!} \\&amp;=n \binom{n-1}{k-1}\end{aligned}\]</span> 因此 <span class="math display">\[\begin{aligned}E(X) &amp;= \sum_\limits{k = 1}^n n \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;=np \sum_\limits{k = 1}^n \binom{n-1}{k-1} p^{k-1} (1-p)^{n-k} \\&amp;=np \sum_\limits{m = 0}^{n-1} \binom{n-1}{m} p^m (1-p)^{n-1-m} \\&amp;=np \cdot (p+1-p)^{n-1} \\&amp;=np\end{aligned}\]</span> 又由 <span class="math display">\[\begin{aligned}E(X^2) &amp;= \sum_\limits{k = 0}^n k^2 \binom{n}{k} p^k (1-p)^{n-k} \\&amp;= n \cdot \sum_\limits{k = 1}^n k \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;= n \cdot \sum_\limits{k = 1}^n (k - 1 + 1) \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;= n \cdot \left[ \sum_\limits{k = 1}^n (k - 1) \binom{n-1}{k-1} p^k (1-p)^{n-k} + \sum_\limits{k = 1}^n  \binom{n-1}{k-1} p^k (1-p)^{n-k} \right] \\&amp;=n \cdot \sum_\limits{k = 2}^n (n - 1) \binom{n-2}{k-2} p^k (1-p)^{n-k} + n \cdot \sum_\limits{k = 1}^n  \binom{n-1}{k-1} p^k (1-p)^{n-k} \\&amp;= n(n-1)p^2 + np\end{aligned}\]</span> 可知 <span class="math display">\[\begin{aligned}Var(X) &amp;= E(X^2) - E^2(X) \\&amp;=n(n-1)p^2 + np - n^2p^2 \\&amp;=n^2p^2-np^2+ np - n^2p^2 \\&amp;=np(1-p)\end{aligned}\]</span></p></blockquote><h2 id="泊松分布">泊松分布</h2><h3 id="定义-1">定义</h3><blockquote><p><strong>Definition:</strong> 若一个离散型随机变量 <span class="math display">\[X\]</span> 的分布列满足 <span class="math display">\[P(X=k) = \frac{\lambda^k}{k!} e^{-\lambda}\]</span> 其中 <span class="math display">\[k \in \{0,1,2,3,...\}, \lambda&gt;0\]</span>，则称随机变量 <span class="math display">\[X\]</span> 满足泊松分布，记为 <span class="math display">\[X \sim P(\lambda)\]</span></p></blockquote><p><strong>适用场景：</strong>求一段固定长度的时间中事件发生了 <span class="math display">\[k\]</span> 次的概率</p><p>泊松分布的<strong>累积分布函数</strong>为 <span class="math display">\[F(k) = P(X \leq k) = \left\{\begin{aligned}\sum_{i = 0}^{\lfloor k \rfloor} \frac{\lambda^i}{i!}e^{-\lambda}&amp;,&amp; k \geq 0 \\0&amp;,&amp; k &lt; 0\end{aligned}\right.\]</span> 若引入<strong>不完全伽马函数</strong>，则其累积分布函数的非负部分还可表示为 <span class="math display">\[\begin{aligned}F(k) &amp;= \frac{\Gamma(\lfloor k + 1\rfloor, \lambda)}{\Gamma(\lfloor k +1 \rfloor)} \\&amp;=Q(\lfloor k + 1\rfloor, \lambda)\end{aligned}\]</span></p><h3 id="期望和方差-1">期望和方差</h3><p>利用 <span class="math display">\[e^x = \sum_\limits{k = 0}^\infty \frac{x^k}{k!}\]</span> 可快速求出泊松分布的期望 <span class="math display">\[\begin{aligned}E(X) &amp;= \sum_{k = 0}^\infty k \cdot \frac{\lambda^k}{k!} e^{-\lambda} \\&amp;=e^{-\lambda} \cdot \sum_{k = 1}^\infty k \cdot \frac{\lambda^k}{k!} \\&amp;=\lambda e^{-\lambda} \cdot \sum_{k = 1}^\infty \frac{\lambda^{k-1}}{(k-1)!} \\&amp;=\lambda e^{-\lambda} e^\lambda \\&amp;=\lambda\end{aligned}\]</span> 又由 <span class="math display">\[\begin{aligned}E(X^2) &amp;= \sum_{k = 0}^\infty k^2 \cdot \frac{\lambda^k}{k!} e^{-\lambda} \\&amp;=e^{-\lambda} \sum_{k = 1}^\infty k^2 \cdot \frac{\lambda^k}{k!} \\&amp;=\lambda e^{-\lambda} \sum_{k = 1}^\infty k \cdot \frac{\lambda^{k-1}}{(k-1)!} \\&amp;=\lambda e^{-\lambda} \sum_{k = 1}^\infty (k-1+1) \cdot \frac{\lambda^{k-1}}{(k-1)!} \\&amp;=\lambda e^{-\lambda} \left( \sum_{k = 2}^\infty (k-1) \cdot \frac{\lambda^{k-1}}{(k-1)!} + \sum_{k = 1}^\infty \frac{\lambda^{k-1}}{(k-1)!} \right) \\&amp;=\lambda e^{-\lambda} \left( \lambda \sum_{k = 2}^\infty \frac{\lambda^{k-2}}{(k-2)!} + \sum_{k = 1}^\infty \frac{\lambda^{k-1}}{(k-1)!} \right) \\&amp;=\lambda e^{-\lambda} \left( \lambda e^\lambda + e^\lambda \right) \\&amp;=\lambda^2 + \lambda\end{aligned}\]</span> 可知其方差为 <span class="math display">\[\begin{aligned}Var(X) &amp;= E(X^2) - E^2(X) \\&amp;= \lambda^2 + \lambda - \lambda^2 \\&amp;=\lambda\end{aligned}\]</span></p><h3 id="泊松分布与二项分布">泊松分布与二项分布</h3><p>泊松分布与二项分布有如下定理成立：</p><blockquote><p><strong>Theorem(Poisson):</strong> 设 <span class="math display">\[k \leq n \in N, \lambda &gt; 0\]</span>，<span class="math display">\[\{p_n\}\]</span> 是一个与 <span class="math display">\[n\]</span> 有关的序列且 <span class="math display">\[0 \leq p_n \leq 1\]</span>，<span class="math display">\[np_n \to \lambda (n \to \infty)\]</span>，则 <span class="math display">\[\lim_{n \to \infty} \binom{n}{k} p_n^k(1-p_n)^{n-k} = \frac{\lambda^k}{k!} e^{-\lambda}\]</span> <strong>Proof:</strong> 令 <span class="math display">\[np_n = \lambda_n\]</span></p><p>故由 <span class="math display">\[np_n \to \lambda(n \to \infty)\]</span> 可知 <span class="math display">\[\lambda_n \to \lambda(n \to \infty)\]</span></p><p>故 <span class="math display">\[\begin{aligned}\binom{n}{k} p_n^k(1-p_n)^{n-k} &amp;= \binom{n}{k} (\frac{\lambda_n}{n})^k \left( 1-\frac{\lambda_n}{n} \right)^{n-k} \\&amp;= \frac{n(n-1) \cdots (n-k-1)}{k!} \cdot \frac{\lambda_n^k}{n^k} \cdot \left( 1-\frac{\lambda_n}{n} \right)^{n-k} \\&amp;=\frac{\lambda_n^k}{k!} \cdot \frac{n-1}{n} \cdot \frac{n-2}{n} \cdots \frac{n-k-1}{n} \cdot \left( 1-\frac{\lambda_n}{n} \right)^{n-k}\end{aligned}\]</span> 又 <span class="math display">\[\lim_{n \to \infty} \frac{n-1}{n} \cdot \frac{n-2}{n} \cdots \frac{n-k-1}{n} = 1^k = 1 \\\lim_{n \to \infty} \left( 1-\frac{\lambda_n}{n} \right)^{n-k} = e^{-\lambda}\]</span> 因此 <span class="math display">\[\begin{aligned}\lim_{n \to \infty} \binom{n}{k} p_n^k(1-p_n)^{n-k} &amp;= \lim_{n \to \infty} \frac{\lambda_n^k}{k!} \cdot \frac{n-1}{n} \cdot \frac{n-2}{n} \cdots \frac{n-k-1}{n} \cdot \left( 1-\frac{\lambda_n}{n} \right)^{n-k} \\&amp;=\frac{\lambda^k}{k!} e^{-\lambda}\end{aligned}\]</span></p></blockquote><p>由上面的定理可以看出，泊松分布可以看作是一个二项分布当 <span class="math display">\[n\]</span> 趋于无穷时的极限情况（此时泊松分布中的参数 <span class="math display">\[\lambda\]</span> 即为二项分布的期望 <span class="math display">\[np\]</span>），因此对于一个二项分布 <span class="math display">\[B(n,p)\]</span> 来说，当 <strong><span class="math display">\[n\]</span> 充分大且 <span class="math display">\[p\]</span> 充分小</strong>时，其对应点的值可使用泊松分布的值来近似。即若随机变量 <span class="math display">\[X \sim B(n,p)\]</span>，则 <span class="math display">\[P(X=k) \approx \frac{n^kp^k}{k!} e^{-np}\]</span> 一般来说，当 <span class="math display">\[n \geq 20, p \leq 0.05\]</span> 时，泊松分布就可作为二项分布的一个可用的近似；当 <span class="math display">\[n \geq 100, np \leq 10\]</span> 时，泊松分布就是二项分布的一个较为精准的近似了。</p><h2 id="几何分布">几何分布</h2><h3 id="定义-2">定义</h3><blockquote><p><strong>Definition:</strong> 若一个离散型随机变量 <span class="math display">\[X\]</span> 的分布列满足 <span class="math display">\[P(X=k) = (1-p)^{k-1} p\]</span> 其中 <span class="math display">\[k \in \{1,2,3,...\}, p \in [0,1]\]</span>，则称随机变量 <span class="math display">\[X\]</span> 满足几何分布，记为 <span class="math display">\[X \sim Ge(p)\]</span></p></blockquote><p><strong>适用场景：</strong>在一组伯努利实验中，若每次成功的概率为 <span class="math display">\[p\]</span>，求当进行到第 <span class="math display">\[k\]</span> 次试验时才第一次成功的概率</p><p>几何分布的<strong>累积分布函数</strong>为 <span class="math display">\[\begin{aligned}F(k) &amp;= P(X \leq k) \\&amp;= \sum_{i =1}^{\lfloor k \rfloor} (1-p)^{i-1}p \\&amp;=p \cdot \frac{1-(1-p)^{\lfloor k \rfloor}}{p} \\&amp;=1-(1-p)^{\lfloor k \rfloor}, k \geq 1\end{aligned}\]</span></p><h3 id="无记忆性">无记忆性</h3><p>几何分布有如下的性质成立：</p><blockquote><p><strong>Theorem:</strong> 若 <span class="math display">\[X \sim Ge(p)\]</span>，则对任意 <span class="math display">\[m,n \geq 1\]</span>，有 <span class="math display">\[P(X &gt; m+n | X &gt; m) = P(X &gt; n)\]</span> <strong>Proof:</strong> 由于 <span class="math display">\[\begin{aligned}P(X &gt; m) &amp;= \sum_{k = m+1}^\infty (1-p)^{k-1} p \\&amp;= p \cdot \frac{(1-p)^m}{p} \\&amp;=(1-p)^m\end{aligned}\]</span> 故 <span class="math display">\[\begin{aligned}P(X &gt; m+n | X &gt; m) &amp;= \frac{P(X&gt;m+n,X&gt;m)}{P(X&gt;m)} \\&amp;=\frac{P(X&gt;(m+n))}{P(X&gt;m)} \\&amp;=\frac{(1-p)^{m+n}}{(1-p)^m} \\&amp;=(1-p)^{n} \\&amp;=P(X&gt;n)\end{aligned}\]</span></p></blockquote><p>该定理表明，在一串伯努利试验中若前 <span class="math display">\[m\]</span> 次试验均不成功，则后续试验每一次成功的概率与重新从第一次开始计数试验成功的概率相同，即前 <span class="math display">\[m\]</span> 次试验并不对接下来的结果造成任何影响。</p><p>事实上，几何分布是离散型分布中<strong>唯一</strong>具有无记忆性的分布：</p><blockquote><p><strong>Theorem:</strong> 设 <span class="math display">\[X\]</span> 为一个离散随机变量，其取值范围为 <span class="math display">\[\{1,2,3,...\}\]</span>，若对任意 <span class="math display">\[m,n \geq 1 \in \mathbb{N}\]</span>，有 <span class="math display">\[P(X&gt;m+n | X&gt;m) = P(X&gt;n)\]</span>，则存在 <span class="math display">\[0 \leq p \leq 1\]</span>，使得 <span class="math display">\[X \sim Ge(p)\]</span></p><p><strong>Proof:</strong> 令 <span class="math display">\[F(x) = P(X&gt;x)\]</span></p><p>则原条件可写为对任意 <span class="math display">\[m,n \geq 1 \in \mathbb{N}\]</span>，有 <span class="math display">\[\frac{F(m+n)}{F(m)} = F(n)\]</span> 即 <span class="math display">\[F(m+n) = F(m)F(n)\]</span></p><p>令 <span class="math display">\[m = n = 1\]</span>，则 <span class="math display">\[F(2) = F^2(1)\]</span></p><p>再令 <span class="math display">\[m=2, n =1\]</span>，则 <span class="math display">\[F(3) = F^3(1)\]</span></p><p>如此递推，可得 <span class="math display">\[F(m) = F^m(1)\]</span></p><p>令 <span class="math display">\[P(X=1) = p\]</span></p><p>则 <span class="math display">\[\begin{aligned}F(1) &amp;= P(X&gt;1) \\&amp;=1-P(X=1) \\&amp;=1-p\end{aligned}\]</span> 由此可知对任意 <span class="math display">\[m \geq 1 \in \mathbb{N}\]</span>，有 <span class="math display">\[\begin{aligned}P(X=m) &amp;= P(X&gt;m-1) - P(X&gt;m) \\&amp;=F(m-1) - F(m) \\&amp;=F^{m-1}(1) - F^m(1) \\&amp;=(1-p)^{m-1} - (1-p)^m \\&amp;=(1-p)^{m-1}p\end{aligned}\]</span> 即 <span class="math display">\[X \sim Ge(p)\]</span></p></blockquote><h3 id="期望和方差-2">期望和方差</h3><p>利用几何分布的无记忆性，我们可以快速求出几何分布的期望和方差。</p><p>易见 <span class="math display">\[E(X|X=1) = 1\]</span></p><p>而 <span class="math display">\[\begin{aligned}E(X|X&gt;1) &amp;= \sum_{k = 2}^\infty k \cdot P(X=k|X&gt;1) \\&amp;= \sum_{k = 2}^\infty k \cdot P(X=k-1) \\&amp;= \sum_{k = 2}^\infty (k-1) \cdot P(X=k-1) + \sum_{k = 2}^\infty P(X=k-1) \\&amp;=E(X) + 1\end{aligned}\]</span> 故由<strong>全期望公式</strong>可知 <span class="math display">\[\begin{aligned}E(X) &amp;= P(X=1)E(X|X=1) + P(X&gt;1)E(X|X&gt;1) \\&amp;=p + (1-p) (E(X) + 1) \\&amp;=(1-p) \cdot E(X) + 1\end{aligned}\]</span> 即几何分布的期望 <span class="math display">\[E(X) = \frac{1}{p}\]</span></p><p>同理，<span class="math display">\[E(X^2|X = 1) = 1\]</span> <span class="math display">\[\begin{aligned}E(X^2|X&gt;1) &amp;= \sum_{k = 2}^\infty k^2 \cdot P(X=k|X&gt;1) \\&amp;= \sum_{k = 2}^\infty k^2 \cdot P(X=k-1) \\&amp;= \sum_{k = 2}^\infty (k-1)^2 \cdot P(X=k-1) + 2 \cdot \sum_{k = 2}^\infty (k-1) \cdot P(X=k-1) + \sum_{k = 2}^\infty P(X=k-1) \\&amp;=E(X^2) + 2E(X) + 1\end{aligned}\]</span> 故 <span class="math display">\[\begin{aligned}E(X^2) &amp;= P(X = 1)E(X^2|X=1) + P(X&gt;1)E(X^2|X&gt;1) \\&amp;= p + (1-p)(E(X^2) + 2E(X) + 1) \\&amp;= (1-p)E(X^2) + 2(1-p)E(X) + 1 \\&amp;=(1-p)E(X^2) + \frac{2}{p} - 1\end{aligned}\]</span> 于是 <span class="math display">\[E(X^2) = \frac{2-p}{p^2}\]</span></p><p>因此几何分布的方差 <span class="math display">\[\begin{aligned}Var(X) &amp;= E(X^2) - E^2(X) \\&amp;=\frac{2-p}{p^2} - \frac{1}{p^2} \\&amp;=\frac{1-p}{p^2}\end{aligned}\]</span></p><blockquote><p><strong>另解（纯分析法求几何分布期望和方差）：</strong></p><p>首先我们对其表达式进行化简： <span class="math display">\[\begin{aligned}E(X) &amp;= \sum_{k = 1}^\infty k(1-p)^{k-1} p \\&amp;=p \cdot \sum_{k = 1}^\infty k(1-p)^{k-1} \\&amp;=p \cdot \sum_{k = 1}^\infty \left( -\frac{d}{dp} (1-p)^k \right)\end{aligned}\]</span> 由于几何级数<strong>一致收敛</strong>于其极限值，故 <span class="math display">\[\sum_{k = 1}^\infty \frac{d}{dp} \left( (1-p)^k \right)  = \frac{d}{dp} \sum_{k = 1}^\infty \left( (1-p)^k \right)\]</span> 因此几何分布的期望为 <span class="math display">\[\begin{aligned}E(X) &amp;=-p \cdot \frac{d}{dp} \left( \sum_{k = 1}^\infty (1-p)^k \right) \\&amp;= -p \cdot \left( - \frac{1}{p^2}\right) \\&amp;=\frac{1}{p}\end{aligned}\]</span> 同理可知 <span class="math display">\[\begin{aligned}E(X^2) &amp;= \sum_{k = 1}^\infty k^2 (1-p)^{k-1} p \\&amp;=p \sum_{k = 1}^\infty k(k+1-1) (1-p)^{k-1} \\&amp;=p \left( \sum_{k = 1}^\infty \left(\frac{d^2}{dp^2} \left( (1-p)^{k+1} \right) \right) - \sum_{k = 1}^\infty \left( \frac{d}{dp} \left( (1-p)^k \right) \right) \right) \\&amp;=p \left( \frac{d^2}{dp^2} \left( \sum_{k = 1}^\infty \left( (1-p)^{k+1} \right) \right) - \frac{d}{dp} \left( \sum_{k = 1}^\infty \left( (1-p)^k \right) \right) \right) \\&amp;=p \left(\frac{d^2}{dp^2} \left( \frac{1}{p}-2+p \right) - \frac{d}{dp} \left( \frac{1}{p} - 1 \right) \right) \\&amp;=\frac{2}{p^2} - \frac{1}{p}\end{aligned}\]</span> 因此其方差为 <span class="math display">\[\begin{aligned}Var(X) &amp;= E(X^2) - E^2(X) \\&amp;=\frac{2}{p^2} - \frac{1}{p} - \frac{1}{p^2} \\&amp;=\frac{1-p}{p^2}\end{aligned}\]</span></p></blockquote><h2 id="负二项分布">负二项分布</h2><h3 id="定义-3">定义</h3><blockquote><p><strong>Definition:</strong> 若一个离散型随机变量 <span class="math display">\[X\]</span> 的分布列满足 <span class="math display">\[P(X=k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}\]</span> 其中 <span class="math display">\[r \leq k \in \{1,2,3,...\}, p \in [0,1]\]</span>，则称随机变量 <span class="math display">\[X\]</span> 满足负二项分布，记为 <span class="math display">\[X \sim Nb(r, p)\]</span></p></blockquote><p><strong>适用场景：</strong>在一组伯努利实验中，若每次成功的概率为 <span class="math display">\[p\]</span>，求第 <span class="math display">\[r\]</span> 次成功时总共进行的试验次数 <span class="math display">\[k\]</span></p><p>负二项分布的累积分布函数 <span class="math display">\[F(k) = P(X \leq k) = \left\{\begin{aligned}\sum_{i = 1}^k \binom{i-1}{r-1} p^r (1-p)^{i-r}&amp;,&amp; k \geq r \\0&amp;,&amp; k &lt; r\end{aligned}\right.\]</span> 若引入<strong>不完全Beta函数</strong>，则其累积分布函数的非负部分还可表示为 <span class="math display">\[\begin{aligned}F(k) &amp;= I_{1-p}(r, k-r+1) \\&amp;=\frac{B(1-p;r,k-r+1)}{B(r,k-r+1)}\end{aligned}\]</span></p><h3 id="负二项分布与几何分布">负二项分布与几何分布</h3><p>从直观上来看，几何分布描述的是一组伯努利实验中<strong>第一次</strong>成功的实验次数，而负二项分布描述的是一组伯努利实验中<strong>第 <span class="math display">\[r\]</span> 次</strong>成功的实验次数，自然的，几何分布可以被负二项分布所包含。事实上，对于一个负二项分布，当 <span class="math display">\[r = 1\]</span> 时，其分布列退化为 <span class="math display">\[P(X=k)=(1-p)^{k - 1}p\]</span> 此即为几何分布的分布列。由此可知 <span class="math display">\[Ge(p) = Nb(1,p)\]</span></p><h3 id="期望和方差-3">期望和方差</h3><p>与二项分布类似，我们可将负二项分布拆分成一系列相互独立的事件以简化期望和方差的计算。注意到负二项分布与几何分布的关系，我们可将一个负二项分布中的实验拆分为 <span class="math display">\[r\]</span> 个独立成功的实验，而每次实验服从一个几何分布。</p><p>令 <span class="math display">\[X_i\]</span> 为第 <span class="math display">\[i\]</span> 次实验成功所用次数的随机变量 <span class="math display">\[(1 \leq i \leq r)\]</span>，<span class="math display">\[X\]</span> 为前 <span class="math display">\[r\]</span> 次实验成功所用次数的随机变量</p><p>此时 <span class="math display">\[1 \leq \forall i \neq j \leq r\]</span>，<span class="math display">\[X_i\]</span> 与 <span class="math display">\[X_j\]</span> 独立，且 <span class="math display">\[X_i \sim Ge(p), X \sim Nb(r, p), X = \sum_\limits{i = 1}^r X_i\]</span></p><p>于是由几何分布的期望可知 <span class="math display">\[\begin{aligned}E(X) &amp;= E(\sum_{i = 1}^r X_i) \\&amp;=\sum_{i = 1}^r E(X_i) \\&amp;=\sum_{i = 1}^r \frac{1}{p} \\&amp;=\frac{r}{p}\end{aligned}\]</span></p><p>同理 <span class="math display">\[\begin{aligned}Var(X) &amp;= Var(\sum_{i = 1}^r X_i) \\&amp;=\sum_{i = 1}^r Var(X_i) \\&amp;=\sum_{i = 1}^r \frac{1-p}{p^2} \\&amp;=\frac{r(1-p)}{p^2}\end{aligned}\]</span></p><blockquote><p><strong>另解（纯分析法求负二项分布的期望和方差）：</strong> <span class="math display">\[\begin{aligned}E(X) &amp;= \sum_{k = r}^{\infty} k \binom{k-1}{r-1} p^r (1-p)^{k-r} \\&amp;= \sum_{k = r}^{\infty} \frac{k!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} \\&amp;=\frac{r}{p} \sum_{k = r}^{\infty} \frac{k!}{r!(k-r)!} p^{r+1}(1-p)^{k-r} \\&amp;=\frac{r}{p} \sum_{k = r}^{\infty} \binom{k}{r} p^{r+1}(1-p)^{k-r} \\&amp;=\frac{r}{p}\end{aligned}\]</span> 又 <span class="math display">\[\begin{aligned}E(X^2) &amp;= \sum_{k = r}^{\infty} k^2 \binom{k-1}{r-1} p^r (1-p)^{k-r} \\&amp;= \sum_{k = r}^{\infty} (k+1-1) \cdot \frac{k!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} \\&amp;= \sum_{k = r}^{\infty} \frac{(k+1)!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} - \sum_{k = r}^{\infty} \frac{k!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} \\&amp;= \frac{r(r+1)}{p^2} \sum_{k = r}^{\infty} \frac{(k+1)!}{(r+1)!(k-r)!} p^{r+2} (1-p)^{k-r} - \frac{r}{p} \sum_{k = r}^{\infty} \frac{k!}{r!(k-r)!} p^{r+1}(1-p)^{k-r} \\&amp;= \frac{r(r+1)}{p^2} \sum_{k = r}^{\infty} \binom{k+1}{r+1} p^{r+2} (1-p)^{k-r} - \frac{r}{p} \sum_{k = r}^{\infty} \binom{k}{r} p^{r+1}(1-p)^{k-r} \\&amp;=\frac{r^2+r}{p^2} - \frac{r}{p} \\\end{aligned}\]</span> 故 <span class="math display">\[\begin{aligned}Var(X) &amp;= E(X^2) - E^2(X) \\&amp;= \frac{r^2+r}{p^2} - \frac{r}{p} - \frac{r^2}{p^2} \\&amp;=\frac{r(1-p)}{p^2}\end{aligned}\]</span></p></blockquote><h3 id="广义负二项分布与泊松分布">广义负二项分布与泊松分布</h3><p>在负二项分布中，参数 <span class="math display">\[r\]</span> 的取值范围要求为正整数，而在某些情况下，我们需要将负二项分布中的 <span class="math display">\[r\]</span> 的取值范围拓展到一切正实数。为了做到这一点，我们需要借助<strong>Gamma函数</strong>对其中的组合式进行拓展。</p><p>由于有 <span class="math display">\[\Gamma(n) = (n-1)!\]</span>，故 <span class="math display">\[\binom{k-1}{r-1} = \frac{(k-1)!}{(r-1)!(k-r)!} = \frac{(k-1)!}{\Gamma(r)\Gamma(k-r+1)}\]</span> 因此我们可以将广义负二项分布的分布列定义为： <span class="math display">\[P(X=k)=\frac{(k-1)!}{\Gamma(r)\Gamma(k-r+1)}p^r(1-p)^{k-r}, k \in \{1,2,...\},r \in \mathbb{R}\]</span> 事实上，在实际使用中，一个更常用的负二项分布的分布列定义为 <span class="math display">\[P(X=k) = \binom{k+r-1}{r-1}p^r(1-p)^k, k \in \{0,1,2,...\}\]</span> 这里的 <span class="math display">\[k\]</span> 代表第 <span class="math display">\[r\]</span> 次实验成功前实验失败的次数。</p><p>基于该定义进行拓展，我们就能得到广义负二项分布的标准定义：（该分布也被称为<strong>Polya分布</strong>）</p><blockquote><p><strong>Definition:</strong> 若一个离散型随机变量 <span class="math display">\[X\]</span> 的分布列满足 <span class="math display">\[P(X=k) = \frac{\Gamma(k+r)}{k!\Gamma(r)}p^r (1-p)^k\]</span> 其中 <span class="math display">\[k \in \{0,1,2,...\}, r \in \mathbb{R}, p \in [0,1]\]</span>，则称随机变量 <span class="math display">\[X\]</span> 服从广义负二项分布</p></blockquote><p>广义负二项分布与泊松分布有如下定理成立：</p><blockquote><p><strong>Theorem:</strong> 设 <span class="math display">\[k \in \mathbb{N}, \lambda &gt; 0, r \in \mathbb{R}\]</span>，则有 <span class="math display">\[\lim_{r \to \infty} \frac{\Gamma(k+r)}{k!\Gamma(r)} \left( \frac{\lambda}{r+\lambda} \right)^r \left(\frac{r}{r+\lambda} \right)^{k} = \frac{\lambda^k}{k!} e^{-\lambda}\]</span> <strong>Proof:</strong> //待补全</p></blockquote><p>由上述定理可知，当 <span class="math display">\[r\]</span> 很大时，广义负二项分布可以作为泊松分布的一个很好的近似。</p><h3 id="ab-分布类"><span class="math display">\[(a,b)\]</span> 分布类</h3><p>事实上，<strong>二项分布、负二项分布、泊松分布</strong>的概率密度函数均满足以下的递推关系： <span class="math display">\[p_n = p_{n-1} \left(a + \frac{b}{n} \right), n \geq 1\]</span> 其中，<span class="math display">\[a,b \in \mathbb{R}\]</span> 为常数（该递推式被称为<strong>Panjer递推式</strong>）</p><p>我们称概率密度函数满足上述递推关系的离散分布为 <strong><span class="math display">\[(a,b)\]</span> 分布</strong>，所有<span class="math display">\[(a,b)\]</span> 分布构成的集合被称为 <strong><span class="math display">\[(a,b)\]</span> 分布类</strong> 。</p><p><span class="math display">\[(a,b)\]</span> 分布类在精算领域的损失模型中有着十分重要的应用。</p><p>事实上，二项分布、负二项分布、泊松分布是 <strong><span class="math display">\[(a,b)\]</span> 分布类</strong>中的所有分布，这是因为有如下定理：</p><blockquote><p><strong>Theorem:</strong> 若一个 <span class="math display">\[(a,b)\]</span> 分布为非退化分布，则其必为二项分布、负二项分布、泊松分布中的一种</p><p><strong>Proof:</strong> //待补全</p></blockquote><h2 id="超几何分布">超几何分布</h2><h3 id="定义-4">定义</h3><blockquote><p><strong>Definition:</strong> 若一个离散型随机变量 <span class="math display">\[X\]</span> 的分布列满足 <span class="math display">\[P(X=k) = \frac{\binom{N_1}{k} \binom{N-N_1}{n-k}}{\binom{N}{n}}\]</span> 其中 <span class="math display">\[k \leq n,N_1 \leq N \in \{0,1,2,...\}\]</span>，则称随机变量 <span class="math display">\[X\]</span> 满足超几何分布，记为 <span class="math display">\[X \sim H(N, N_1, n)\]</span></p></blockquote><p><strong>适用场景：</strong>在一个袋子中有两种共 <span class="math display">\[N\]</span> 个物品，其中物品 <span class="math display">\[A\]</span> 有 <span class="math display">\[N_1\]</span> 个，物品 <span class="math display">\[B\]</span> 有 <span class="math display">\[N-N_1\]</span> 个，现从袋子中抽出 <span class="math display">\[n\]</span> 个物品，求抽出的物品中 <span class="math display">\[A\]</span> 的个数 <span class="math display">\[k\]</span></p><p>超几何分布的<strong>累积分布函数</strong>为 <span class="math display">\[F(k) = P(X=k) = \left\{\begin{aligned}\sum_{i = 0}^k \frac{\binom{N_1}{i} \binom{N-N_1}{n-i}}{\binom{N}{n}}&amp;,&amp; k \geq 0 \\0&amp;,&amp; k &lt; 0\end{aligned}\right.\]</span> 若引入<strong>广义超几何函数</strong>，则其非负部分还可表示为 <span class="math display">\[F(k) = 1 - \frac{\binom{n}{k+1}\binom{N-n}{N_1-k-1}}{\binom{N}{N_1}} \cdot _3F_2 \left(\begin{aligned}1, k+1-N_1, k+1-n \\k+2, N+k+2-N_1-n\end{aligned};1\right), k \geq 0\]</span></p><h3 id="期望和方差-4">期望和方差</h3><p>我们可以用与负二项分布类似的分析技巧导出超几何分布的期望和方差 <span class="math display">\[\begin{aligned}E(X) &amp;= \sum_{k = 0}^{N_1} k \cdot \frac{\binom{N_1}{k} \binom{N-N_1}{n-k}}{\binom{N}{n}} \\&amp;= \frac{n}{N} \sum_{k = 1}^{N_1} \frac{k \binom{N_1}{k} \binom{N-N_1}{n-k}}{\binom{N-1}{n-1}} \\&amp;= \frac{n \cdot N_1}{N} \sum_{k = 1}^{N_1} \frac{\binom{N_1 - 1}{k - 1} \binom{N-N_1}{n-k}}{\binom{N-1}{n-1}} \\&amp;=\frac{n \cdot N_1}{N}\end{aligned}\]</span></p><p>又 <span class="math display">\[\begin{aligned}E(X^2) &amp;= \sum_{k = 0}^{N_1} k^2 \cdot \frac{\binom{N_1}{k} \binom{N-N_1}{n-k}}{\binom{N}{n}} \\&amp;= \sum_{k = 1}^{N_1} k(k-1) \cdot \frac{\binom{N_1}{k} \binom{N-N_1}{n-k}}{\binom{N}{n}} + \sum_{k = 1}^{N_1} k \cdot \frac{\binom{N_1}{k} \binom{N-N_1}{n-k}}{\binom{N}{n}} \\&amp;= \frac{n(n-1)N_1(N_1-1)}{N(N-1)} \cdot \sum_{k = 2}^{N_1} \frac{\binom{N_1-2}{k-2} \binom{N-N_1}{n-k}}{\binom{N-2}{n-2}} + \frac{n \cdot N_1}{N} \\&amp;= \frac{n(n-1)N_1(N_1-1)}{N(N-1)} + \frac{n \cdot N_1}{N}\end{aligned}\]</span> 故 <span class="math display">\[\begin{aligned}Var(X) &amp;= E(X^2) - E^2(X) \\&amp;= \frac{n(n-1)N_1(N_1-1)}{N(N-1)} + \frac{n \cdot N_1}{N} - \frac{n^2N_1^2}{N^2} \\&amp;= \frac{n(N-n)(N-N_1)}{N^2(N-1)}\end{aligned}\]</span></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;二项分布&quot;&gt;二项分布&lt;/h2&gt;
&lt;h3 id=&quot;定义&quot;&gt;定义&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; 若一个离散型随机变量 &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt; 的分布列满足 &lt;span class=&quot;math display&quot;&gt;\[
P(X=k) = \binom{n}{k} p^k (1-p)^{1-k}
\]&lt;/span&gt; 其中 &lt;span class=&quot;math inline&quot;&gt;\(n \in \mathbb{N}^+, k \in \{0,1,2,...,n\}, p \in [0,1]\)&lt;/span&gt;，则称随机变量 &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt; 满足二项分布，记为 &lt;span class=&quot;math inline&quot;&gt;\(X \sim B(n, p)\)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="概率论" scheme="http://gonggongjohn.me/categories/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
    
    <category term="Mathematics" scheme="http://gonggongjohn.me/tags/Mathematics/"/>
    
    <category term="Probability" scheme="http://gonggongjohn.me/tags/Probability/"/>
    
  </entry>
  
  <entry>
    <title>新闻搜索网站构建记录</title>
    <link href="http://gonggongjohn.me/2021/04/18/web/search-site/"/>
    <id>http://gonggongjohn.me/2021/04/18/web/search-site/</id>
    <published>2021-04-18T10:26:25.000Z</published>
    <updated>2021-04-30T06:30:39.187Z</updated>
    
    <content type="html"><![CDATA[<h2 id="服务部署">服务部署</h2><p>请按照如下流程部署本项目：</p><ol type="1"><li>在<strong>news_search</strong>目录下安装所需的依赖插件：<strong>（国内请使用淘宝源安装nodejieba）</strong></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> npm install request iconv-lite cheerio mysql jschardet moment</span><br><span class="hljs-meta">&gt;</span><span class="bash"> npm install nodejieba --registry=https://registry.npm.taobao.org --nodejieba_binary_host_mirror=https://npm.taobao.org/mirrors/nodejieba</span><br></code></pre></td></tr></table></figure><a id="more"></a><ol start="2" type="1"><li>启动本地MySQL服务，修改<strong>news_search/mysql.js</strong>中的相关信息为数据库登录信息：</li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> pool = mysql.createPool(&#123;<br>    host: <span class="hljs-string">&#x27;#数据库地址&#x27;</span>,<br>    user: <span class="hljs-string">&#x27;#本地数据库连接用户名&#x27;</span>, <br>    password: <span class="hljs-string">&#x27;#本地数据库连接密码&#x27;</span>,<br>    database: <span class="hljs-string">&#x27;#目标数据库名&#x27;</span><br>&#125;);<br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>登陆数据库管理系统，在控制台中设置相关变量以防止后续连接池堵塞：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql">&gt; set global wait_timeout&#x3D;10;<br>&gt; set global max_connections&#x3D;5000;<br>&gt; set session wait_timeout&#x3D;10;<br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>在数据库管理系统中创建所需的表结构：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs mysql">&gt; CREATE TABLE &#96;news&#96; (<br>    &#96;id&#96; INT NOT NULL AUTO_INCREMENT,<br>    &#96;origin&#96; TEXT NOT NULL,<br>    &#96;category&#96; TEXT NOT NULL,<br>    &#96;title&#96; TEXT NOT NULL,<br>    &#96;time&#96; TEXT,<br>    &#96;source&#96; TEXT,<br>    &#96;abstract&#96; TEXT,<br>    &#96;content&#96; TEXT,<br>    PRIMARY KEY (&#96;id&#96;)<br>);<br>&gt; CREATE TABLE &#96;indices&#96; (<br>    &#96;id&#96; INT NOT NULL AUTO_INCREMENT,<br>    &#96;word&#96; TEXT,<br>    &#96;docs&#96; TEXT,<br>    PRIMARY KEY (&#96;id&#96;)<br>);<br></code></pre></td></tr></table></figure><ol start="5" type="1"><li>执行爬虫脚本爬取新闻内容：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> node crawler.js</span><br><span class="hljs-meta">&gt;</span><span class="bash"> node create_indices.js</span><br></code></pre></td></tr></table></figure><p><strong>P.S:</strong> 在测试环境下，若希望快速得到效果，可打开news_research/crawler.js文件，并将如下行</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> total_pages = <span class="hljs-number">8</span>; <span class="hljs-comment">//Modify to a smaller number to speed up in demo environment</span><br></code></pre></td></tr></table></figure><p>改为</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> total_pages = <span class="hljs-number">1</span>; <span class="hljs-comment">//Modify to a smaller number to speed up in demo environment</span><br></code></pre></td></tr></table></figure><p>保存后再执行上述代码。</p><ol start="6" type="1"><li>在<strong>news_site</strong>目录下安装所需的依赖：<strong>（国内请使用淘宝源安装nodejieba）</strong></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> npm install express moment</span><br><span class="hljs-meta">&gt;</span><span class="bash"> npm install nodejieba --registry=https://registry.npm.taobao.org --nodejieba_binary_host_mirror=https://npm.taobao.org/mirrors/nodejieba</span><br></code></pre></td></tr></table></figure><ol start="7" type="1"><li>启动网站后端服务：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> node bin/www</span><br></code></pre></td></tr></table></figure><ol start="8" type="1"><li>使用浏览器访问网站前端：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs web-idl">http:&#x2F;&#x2F;localhost:3000<br></code></pre></td></tr></table></figure><h2 id="源内容抓取">源内容抓取</h2><h3 id="新闻网站解析">新闻网站解析</h3><h4 id="网易新闻">网易新闻</h4><p>网易新闻的主体分为国内和国际两个模块，其网站结构大体相同，因此我们集中针对这两个板块进行内容爬取。</p><p>分析新闻索引页面的HTML结构我们可以发现，新闻条目被放在了类名为<strong>newsdata_wrap</strong>的<strong>div</strong>标签下。然而由于网易新闻使用了动态加载新闻条目的方式，若我们使用GET请求直接获取页面的HTML时，该标签下的内容为空，因此我们无法直接通过解析网站的HTML数据获得具体的新闻信息。</p><p>继续分析访问网站时的文件传输流我们会发现网站的新闻条目是由一个叫<strong>cm_guonei.js</strong>（<strong>cm_guoji.js</strong>）的文件动态装载的，其原始路径为<code>https://temp.163.com/special/00804KVA/cm_guonei.js</code>。跟踪页面我们发现同级目录下还有<strong>cm_guonei_02.js<sub>cm_guonei_08.js<strong>（</strong>cm_guoji_02.js</sub>cm_guoji_08.js</strong>）共8个文件用于流式加载所有需要加载的新闻条目。打开文件发现其为一个类JSON结构，其中按条目存储了新闻页面的标题、网址、关键字、时间等基本信息。由此我们可以通过直接解析这些文件来获得所有需要爬取的新闻页面。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs json">[<br>    &#123;<br>        <span class="hljs-attr">&quot;title&quot;</span>:<span class="hljs-string">&quot;“港独”周竖峰出逃加拿大，曾辱骂内地生为“支那人”&quot;</span>,<br>        <span class="hljs-attr">&quot;digest&quot;</span>:<span class="hljs-string">&quot;&quot;</span>,<br>        <span class="hljs-attr">&quot;docurl&quot;</span>:<span class="hljs-string">&quot;https://www.163.com/news/article/G8GJUT8700019B3E.html&quot;</span>,<br>        <span class="hljs-attr">&quot;commenturl&quot;</span>:<span class="hljs-string">&quot;https://comment.tie.163.com/G8GJUT8700019B3E.html&quot;</span>,<br>        <span class="hljs-attr">&quot;tienum&quot;</span>:<span class="hljs-number">5276</span>,<br>        <span class="hljs-attr">&quot;tlastid&quot;</span>:<span class="hljs-string">&quot;&lt;a href=&#x27;http://news.163.com/&#x27;&gt;新闻&lt;/a&gt;&quot;</span>,<br>        <span class="hljs-attr">&quot;tlink&quot;</span>:<span class="hljs-string">&quot;https://www.163.com/news/article/G8GJUT8700019B3E.html&quot;</span>,<br>        <span class="hljs-attr">&quot;label&quot;</span>:<span class="hljs-string">&quot;其它&quot;</span>,<br>        <span class="hljs-attr">&quot;keywords&quot;</span>:[<br>            &#123;<span class="hljs-attr">&quot;akey_link&quot;</span>:<span class="hljs-string">&quot;https://news.163.com/keywords/5/6/54687ad65cf0/1.html&quot;</span>,<span class="hljs-attr">&quot;keyname&quot;</span>:<span class="hljs-string">&quot;周竖峰&quot;</span>&#125;,<br>            &#123;<span class="hljs-attr">&quot;akey_link&quot;</span>:<span class="hljs-string">&quot;https://news.163.com/keywords/6/2/6e2f72ec/1.html&quot;</span>,<span class="hljs-attr">&quot;keyname&quot;</span>:<span class="hljs-string">&quot;港独&quot;</span>&#125;,<br>            &#123;<span class="hljs-attr">&quot;akey_link&quot;</span>:<span class="hljs-string">&quot;https://news.163.com/keywords/5/a/52a062ff5927/1.html&quot;</span>,<span class="hljs-attr">&quot;keyname&quot;</span>:<span class="hljs-string">&quot;加拿大&quot;</span>&#125;],<br>        <span class="hljs-attr">&quot;time&quot;</span>:<span class="hljs-string">&quot;04/26/2021 10:19:15&quot;</span>,<br>        <span class="hljs-attr">&quot;newstype&quot;</span>:<span class="hljs-string">&quot;article&quot;</span>,<br>        <span class="hljs-attr">&quot;pics3&quot;</span>:[],<br>        <span class="hljs-attr">&quot;channelname&quot;</span>:<span class="hljs-string">&quot;guonei&quot;</span>,<br>        <span class="hljs-attr">&quot;source&quot;</span>:<span class="hljs-string">&quot;观察者网&quot;</span>,<br>        <span class="hljs-attr">&quot;point&quot;</span>:<span class="hljs-string">&quot;60&quot;</span>,<br>        <span class="hljs-attr">&quot;imgurl&quot;</span>:<span class="hljs-string">&quot;http://cms-bucket.ws.126.net/2021/0426/bc6435dep00qs5fri00kkc000s600e3c.png&quot;</span>,<br>        <span class="hljs-attr">&quot;add1&quot;</span>:<span class="hljs-string">&quot;&quot;</span>,<br>        <span class="hljs-attr">&quot;add2&quot;</span>:<span class="hljs-string">&quot;&quot;</span>,<br>        <span class="hljs-attr">&quot;add3&quot;</span>:<span class="hljs-string">&quot;&quot;</span><br>    &#125;<br>]<br></code></pre></td></tr></table></figure><p>接下来我们分析新闻内容页面。该页面的具体内容是静态加载的，因此我们可以直接对其HTML内容进行抽取。然而随着进一步的分析我们会发现新闻页面的编码并不统一，分为UTF-8和GBK两种。为了得到网站的编码方式，我们使用了一个名为<strong>jschardet</strong>的插件。该插件可以通过分析文本的二进制编码给出其最可能的编码方法。由于目标网站只有两种编码方式，因此我们可以保证使用该插件检测得到的结果是可靠的。</p><img src="/2021/04/18/web/search-site/coding.png" class="" title="coding"><p>分析页面的HTML结构我们可以发现新闻内容被封装在了类名为<strong>post_main</strong>的<strong>div</strong>标签下，其中新闻标题类名为<strong>post_title</strong>，时间、来源的类名为<strong>post_info</strong>，正文的类名为<strong>post_body</strong>。我们首先使用<strong>iconv-lite</strong>插件对页面进行解码，随后利用<strong>Cheerio</strong>模块即可快速从网站的DOM结构中抽取出所需的内容。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> coding = chardet.detect(body)[<span class="hljs-string">&#x27;encoding&#x27;</span>]<br><span class="hljs-keyword">var</span> $ = cheerio.load(iconv.decode(body, coding).toString());<br><span class="hljs-keyword">var</span> title = $(<span class="hljs-string">&#x27;.post_title&#x27;</span>).text();<br><span class="hljs-keyword">if</span>(title != <span class="hljs-string">&#x27;&#x27;</span>)&#123;<br>    <span class="hljs-keyword">var</span> body_text = <span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">if</span>($(<span class="hljs-string">&quot;.content.all-txt&quot;</span>).length &gt; <span class="hljs-number">0</span>)&#123;<br>        body_text = $(<span class="hljs-string">&#x27;.content.all-txt &gt; p&#x27;</span>);<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>($(<span class="hljs-string">&#x27;.newscontents&#x27;</span>).length &gt; <span class="hljs-number">0</span>)&#123;<br>        body_text = $(<span class="hljs-string">&#x27;.newscontents &gt; p&#x27;</span>);<br>    &#125;<br>    <span class="hljs-keyword">else</span>&#123;<br>        body_text = $(<span class="hljs-string">&#x27;.post_body &gt; p&#x27;</span>);<br>    &#125;<br>    <span class="hljs-keyword">var</span> content = <span class="hljs-string">&quot;&quot;</span>;<br>    body_text.each(<span class="hljs-function">(<span class="hljs-params">index, item</span>) =&gt;</span> &#123;<br>        <span class="hljs-keyword">if</span>($(item).text() != <span class="hljs-string">&quot;&quot;</span>)&#123;<br>            content = content + $(item).text() + <span class="hljs-string">&#x27;\n&#x27;</span>;<br>        &#125;<br>&#125;);<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="环球网">环球网</h4><p>与网易新闻类似，环球网同样分为国内和国际两个模块，且采用了动态装载新闻条目的方式。通过追踪其文件传输流，我们发现其新闻源数据地址分别为<code>https://china.huanqiu.com/api/list?offset=0&amp;limit=20</code>和<code>https://world.huanqiu.com/api/list?offset=0&amp;limit=20</code>，其基本结构为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs json">&#123;<br>    <span class="hljs-attr">&quot;list&quot;</span>:[<br>        &#123;<br>            <span class="hljs-attr">&quot;aid&quot;</span>:<span class="hljs-string">&quot;42vOMMYVUm3&quot;</span>,<br>            <span class="hljs-attr">&quot;title&quot;</span>:<span class="hljs-string">&quot;前国脚张恩华去世，享年48周岁&quot;</span>,<br>            <span class="hljs-attr">&quot;summary&quot;</span>:<span class="hljs-string">&quot;张恩华的职业生涯大部分时间是在大连实德以及前身大连万达队度过的，是大连实德队主力后卫，也是大连夺得联赛“七冠王”和多次杯赛冠军的主要功臣之一&quot;</span>,<br>            <span class="hljs-attr">&quot;addltype&quot;</span>:<span class="hljs-string">&quot;normal&quot;</span>,<br>            <span class="hljs-attr">&quot;typedata&quot;</span>:&#123;<br>                <span class="hljs-attr">&quot;audio&quot;</span>:&#123;<br>                    <span class="hljs-attr">&quot;members&quot;</span>:[]<br>                &#125;,<br>                <span class="hljs-attr">&quot;video&quot;</span>:&#123;<br>                    <span class="hljs-attr">&quot;members&quot;</span>:[]<br>                &#125;,<br>                <span class="hljs-attr">&quot;gallery&quot;</span>:&#123;<br>                    <span class="hljs-attr">&quot;members&quot;</span>:[]<br>                &#125;<br>            &#125;,<br>            <span class="hljs-attr">&quot;source&quot;</span>:&#123;<br>                <span class="hljs-attr">&quot;url&quot;</span>:<span class="hljs-literal">null</span>,<br>                <span class="hljs-attr">&quot;name&quot;</span>:<span class="hljs-string">&quot;环球时报&quot;</span><br>            &#125;,<br>            <span class="hljs-attr">&quot;ext_displaytime&quot;</span>:<span class="hljs-string">&quot;&quot;</span>,<br>            <span class="hljs-attr">&quot;ext_defertime&quot;</span>:<span class="hljs-string">&quot;&quot;</span>,<br>            <span class="hljs-attr">&quot;ctime&quot;</span>:<span class="hljs-string">&quot;1619721799662&quot;</span>,<br>            <span class="hljs-attr">&quot;xtime&quot;</span>:<span class="hljs-string">&quot;1619721799662&quot;</span>,<br>            <span class="hljs-attr">&quot;cover&quot;</span>:<span class="hljs-string">&quot;&quot;</span>,<br>            <span class="hljs-attr">&quot;host&quot;</span>:<span class="hljs-string">&quot;china.huanqiu.com&quot;</span>,<br>            <span class="hljs-attr">&quot;ext-serious&quot;</span>:<span class="hljs-string">&quot;1&quot;</span><br>        &#125;<br>    ]<br>&#125;<br></code></pre></td></tr></table></figure><p>环球网的新闻内容页根路径分别为<code>https://china.huanqiu.com/article/</code>和<code>https://world.huanqiu.com/article/</code>，因此我们只需使用该路径加上索引数据中的<strong>aid</strong>号，即可得到新闻页的完整网址。</p><p>分析其新闻内容页的HTML结构我们可以发现其正文的外层包裹分别有一个类名为<strong>l-con clear</strong>的<strong>div</strong>标签，一个<strong>article</strong>标签以及一个<strong>section</strong>标签，于是我们同样可以使用Cheerio插件快速将其内容从结构中抽取出来：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> coding = chardet.detect(body)[<span class="hljs-string">&#x27;encoding&#x27;</span>]<br><span class="hljs-keyword">var</span> $ = cheerio.load(iconv.decode(body, coding).toString());<br><span class="hljs-keyword">var</span> title = $(<span class="hljs-string">&#x27;.t-container-title&#x27;</span>).text();<br><span class="hljs-keyword">if</span>(title != <span class="hljs-string">&#x27;&#x27;</span>)&#123;<br>    <span class="hljs-keyword">var</span> body_text = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">if</span>($(<span class="hljs-string">&quot;.l-con.clear&quot;</span>).length &gt; <span class="hljs-number">0</span>)&#123;<br>        body_text = $(<span class="hljs-string">&#x27;.l-con.clear &gt; article &gt; section &gt; p&#x27;</span>);<br>        <span class="hljs-keyword">var</span> content = <span class="hljs-string">&quot;&quot;</span>;<br>        body_text.each(<span class="hljs-function">(<span class="hljs-params">index, item</span>) =&gt;</span> &#123;<br>            <span class="hljs-keyword">if</span>($(item).text() != <span class="hljs-string">&quot;&quot;</span>)&#123;<br>                <span class="hljs-keyword">var</span> para = $(item).text();<br>                content = content + para + <span class="hljs-string">&#x27;\n&#x27;</span>;<br>            &#125;<br>        &#125;);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="数据库构建">数据库构建</h3><p>提取出网站的内容后，我们需要将其以一定结构存放在一个可外部访问的空间内。为此，我们首先创建一个名为<strong>netease_news</strong>的数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE DATABASE netease_news;<br></code></pre></td></tr></table></figure><p>并在其中构建一张名为<strong>news</strong>的表用于结构化存储新闻的各种信息。对于本项目，我们设计了8个表项，分别为：<strong>id（新闻的唯一标识符）、origin（新闻源网址）、category（分类：国内/国外）、title（标题）、time（创建时间）、source（来源）、abstract（内容摘要）、content（新闻内容）</strong>。我们将<strong>id</strong>设为主键，并设置其在每次插入时自增，这样在实际插入时我们只需插入其他7项即可，并能自动分配到一个唯一的id。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE &#96;news&#96; (<br>    &#96;id&#96; INT NOT NULL AUTO_INCREMENT,<br>    &#96;origin&#96; TEXT NOT NULL,<br>    &#96;category&#96; TEXT NOT NULL,<br>    &#96;title&#96; TEXT NOT NULL,<br>    &#96;time&#96; TEXT,<br>    &#96;source&#96; TEXT,<br>    &#96;keyword&#96; TEXT,<br>    &#96;heat&#96; INT,<br>    &#96;content&#96; TEXT,<br>    PRIMARY KEY (&#96;id&#96;)<br>);<br></code></pre></td></tr></table></figure><h3 id="基本爬虫逻辑">基本爬虫逻辑</h3><p>根据上面的分析，我们可以快速设计出爬虫的基本逻辑，其基本流程如下：</p><img src="/2021/04/18/web/search-site/crawl.png" class="" title="crawl"><p>在实际实现中，我们首先封装了一套mysql的读写工具：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> mysql = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;mysql&quot;</span>);<br><span class="hljs-keyword">var</span> pool = mysql.createPool(&#123;<br>    host: <span class="hljs-string">&#x27;127.0.0.1&#x27;</span>,<br>    user: <span class="hljs-string">&#x27;root&#x27;</span>,<br>    password: <span class="hljs-string">&#x27;root&#x27;</span>,<br>    database: <span class="hljs-string">&#x27;netease_news&#x27;</span><br>&#125;);<br><span class="hljs-keyword">var</span> query = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">sql, sqlparam, callback</span>) </span>&#123;<br>    pool.getConnection(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, conn</span>) </span>&#123;<br>        <span class="hljs-keyword">if</span> (err) &#123;<br>            callback(err, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            conn.query(sql, sqlparam, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">qerr, vals, fields</span>) </span>&#123;<br>                conn.release();<br>                callback(qerr, vals, fields); <br>            &#125;);<br>        &#125;<br>    &#125;);<br>&#125;;<br><span class="hljs-keyword">var</span> query_noparam = <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">sql, callback</span>) </span>&#123;<br>    pool.getConnection(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">err, conn</span>) </span>&#123;<br>        <span class="hljs-keyword">if</span> (err) &#123;<br>            callback(err, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            conn.query(sql, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">qerr, vals, fields</span>) </span>&#123;<br>                conn.release();<br>                callback(qerr, vals, fields); <br>            &#125;);<br>        &#125;<br>    &#125;);<br>&#125;;<br><span class="hljs-built_in">exports</span>.query = query;<br><span class="hljs-built_in">exports</span>.query_noparam = query_noparam;<br></code></pre></td></tr></table></figure><p>对于爬虫任务，我们将其封装为了六个函数，其中<strong>traverseNeteaseIndices</strong>用于遍历网易新闻的索引文件，<strong>phaseNeteaseLinkList</strong>用于解析网易新闻列表，<strong>phaseNeteaseNews</strong>用于解析网易新闻页的具体内容，另外三个函数<strong>traverseHQWIndices</strong>、<strong>phaseHQWLinkList</strong>和<strong>phaseHQWNews</strong>用于获取环球网新闻数据时的对应行为<strong>（具体实现见crawler.js）</strong>。</p><p>这里需要注意的是，由于<strong>request请求</strong>和<strong>mysql操作</strong>均为<strong>异步操作</strong>，程序执行的顺序无法确定，在同一时刻内，mysql服务器中可能同时有上千个连接，且当连接释放后，<strong>连接池不会立即关闭相应连接</strong>，这样就会造成<strong>连接池堵塞</strong>。为解决这一问题，我们首先在数据库控制台中缩小闲置连接回收间隔，并增大连接限制数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql">&gt; set global wait_timeout&#x3D;10;<br>&gt; set global max_connections&#x3D;5000;<br>&gt; set session wait_timeout&#x3D;10;<br></code></pre></td></tr></table></figure><p>随后我们通过在爬虫逻辑中使用<strong>setTimeout</strong>函数延迟发送数据库请求，将数据库操作任务平摊到多个时间戳上，这样就有效避免了连接池堵死的情况发生</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">1</span>; i &lt;= pages; i++)&#123;<br>        <span class="hljs-comment">//Irrelevant code omitted</span><br>        <span class="hljs-built_in">setTimeout</span>(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)</span>&#123;<br>            phaseNeteaseLinkList(url, category, i, pages);<br>        &#125;, <span class="hljs-number">3000</span> * (i - <span class="hljs-number">1</span>));<br>&#125;<br><br><span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt;= pages; i++)&#123;<br>        <span class="hljs-comment">//Irrelevant code omitted</span><br>        <span class="hljs-built_in">setTimeout</span>(<span class="hljs-function">() =&gt;</span> &#123;<br>            phaseHQWLinkList(url, pred, category, i, pages, last_flag);<br>        &#125;, <span class="hljs-number">5000</span> * i);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="布隆过滤器与去重">布隆过滤器与去重</h3><p>当我们需要多次执行爬虫任务时，就可能会遇到重复爬取同一网站的情况。为此，我们需要一套快速判断是否已经爬取过一个网址的方法。通常情况下，我们可以使用以下两种办法做到这一点：</p><ul><li>每次爬取一个页面前，在数据库中使用<strong>SELECT</strong>命令查询该网址是否已经存在</li><li>对新闻网址建立<strong>哈希表</strong>，每次爬取前查询该表以判断网址是否已经存在</li></ul><p>若使用第一种方法，根据不同数据库的存储及查询方法，其单次查询的时间复杂度在 <span class="math display">\[\mathcal{O}(\lg n)\]</span> 和 <span class="math display">\[\mathcal{O(n)}\]</span> 之间，<span class="math display">\[k\]</span> 次查询的时间复杂度最坏可能退化到 <span class="math display">\[O(kn)\]</span>；若使用第二种方法，尽管其单次查询的时间复杂度可以保证为 <span class="math display">\[\mathcal{O}(1)\]</span>，但对于一个含有 <span class="math display">\[n\]</span> 个网址的数据库，其空间复杂度为 <span class="math display">\[O(n)\]</span>。由此可见，随着爬虫规模的扩大，两种去重方法均有着一定的弊端，不利于任务的扩展。</p><p>为解决此问题，我们引入一种名为<strong>布隆过滤器（Bloom Filter）</strong>的数据结构<strong>（见filter.js）</strong>。布隆过滤器的核心思想为通过一串哈希函数将关键字映射到一个比特位串。查询时，先将目标关键字通过同样的哈希函数找到对应的索引位，若索引位存在映射，则表明目标关键字<strong>可能存在</strong>；若所有索引位均不存在映射，则表明目标关键字<strong>一定不存在</strong>。</p><img src="/2021/04/18/web/search-site/filter.png" class="" title="filter"><p>布隆过滤器是一种概率型数据结构，其误判率约为 <span class="math display">\[\left(1 - e^{-\frac{kn}{m}}\right)^k\]</span>。在实际使用场景下，只要当我们选择合适的 <span class="math display">\[k\]</span> 和 <span class="math display">\[m\]</span> 值，就可以让误判率几乎不影响业务逻辑。这可以由如下公式给出： <span class="math display">\[k = \frac{m}{n} \ln 2 , m = - \frac{n \ln p}{\ln^2 2}\]</span> 其中 <span class="math display">\[k\]</span> 为哈希函数的个数，<span class="math display">\[m\]</span> 为位串长度，<span class="math display">\[p\]</span> 为预期的误报率。</p><p>布隆过滤器增加和查询时间复杂度均为 <span class="math display">\[\mathcal{O}(k)\]</span>（ <span class="math display">\[k\]</span> 为哈希函数的个数），空间复杂度为 <span class="math display">\[\mathcal{O}(m)\]</span>（<span class="math display">\[m\]</span> 为比特位长度），相比前两种方法可以很好的平衡存储空间和查询效率。</p><h3 id="分词与倒排索引">分词与倒排索引</h3><p>当用户发起搜索请求时，我们需要从数据库中<strong>快速找出所有内容含有用户所请求关键字的新闻条目</strong>。若使用全文搜索的方法，随着数据规模增大，会造成极大的延迟。为解决此问题，我们在爬取文章的时候，对文章内容进行<strong>分词</strong>，并使用词关键字对文章建立<strong>倒排索引</strong>，在搜索时，只需要将关键字使用同样的方法进行分词，并在倒排索引表中查询对应的文档编号即可。</p><img src="/2021/04/18/web/search-site/inverted_index.jpg" class="" title="inverted_index"><p>为此，我们首先在数据库中再建立一张索引表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE &#96;indices&#96; (<br>    &#96;id&#96; INT NOT NULL AUTO_INCREMENT,<br>    &#96;word&#96; TEXT,<br>    &#96;docs&#96; TEXT,<br>    PRIMARY KEY (&#96;id&#96;)<br>);<br></code></pre></td></tr></table></figure><p>随后我们读取news表中的新闻内容，并使用<strong>nodejieba</strong>插件对其进行分词。由于文章中还有部分特殊符号及无意义词，我们通过一个<strong>停用词表</strong>来将其去除。为保证词关键字的唯一性，我们维护一个<strong>集合</strong>，将每个文档分词后的结果依次插入该集合，并将结果插入数据库中：<strong>（见create_indices.js）</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> word_set = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Set</span>();<br><span class="hljs-keyword">var</span> para = item.content;<br><span class="hljs-comment">//Cut word</span><br><span class="hljs-keyword">var</span> para_filtered = para.replace(<span class="hljs-string">&quot;　&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;\n&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot; &quot;</span>, <span class="hljs-string">&quot;&quot;</span>);<br>para_filtered = para_filtered.replace(<span class="hljs-string">&quot;，&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;。&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;,&quot;</span>, <span class="hljs-string">&quot;&quot;</span>);<br><span class="hljs-keyword">var</span> word_list = jieba.cut(para_filtered);<br><span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; word_list.length; i++)&#123;<br>    word_set.add(word_list[i]);<br>&#125;<br>word_set.forEach(<span class="hljs-function">(<span class="hljs-params">word</span>) =&gt;</span> &#123;<br>    <span class="hljs-keyword">if</span>(!stop_list.includes(word))&#123;<br>        <span class="hljs-comment">//Insert the result to the database</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="网站构建">网站构建</h2><h3 id="基本构架">基本构架</h3><p>接下来我们来构建新闻搜索网站。新闻搜索网站的主要行为是提供一个可供用户输入的界面，当用户输入关键字后，系统从数据库中检索出带有用户所指定关键字的新闻条目，并将结果以一定的顺序生成相应的内容页面返回给用户。我们使用<strong>Express脚手架</strong>来构建网站的后端。对于网站路由，我们共设计了4个入口，其中根目录为浏览器访问入口，用于呈现相应的HTML页面，其他三个入口<strong>/query</strong>、<strong>/qcontent</strong>和<strong>/qheat</strong>分别用于前端请求<strong>关键字结果</strong>、<strong>完整正文内容</strong>及<strong>关键字热度分析结果</strong>。</p><p>对于网站前端，我们使用了<strong>Bootstrap框架</strong>来生成所需的样式。搜索引擎页面设计的一个核心宗旨即为简洁，因此在搜索界面，我们参考了百度和Google的设计样式，通过卡片的方式将目标条目呈现给用户。在一张卡片中，我们呈现了新闻条目的<strong>标题、事件、来源、摘要及类别</strong>，以方便用户初步预览新闻的大致内容。</p><img src="/2021/04/18/web/search-site/search_page.png" class="" title="search_page"><p>由于卡片的内容是由后端返回的结果动态决定的，因此我们不能直接将其写死在HTML中，而需要通过Javascript脚本动态生成并将其添加至HTML的DOM结构中：<strong>（见public/index.html）</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">appendCard</span>(<span class="hljs-params">father, title, id, time, source, abstract, cat</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> card = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;div&#x27;</span>);<br>    card.class = <span class="hljs-string">&#x27;card&#x27;</span>;<br>    <span class="hljs-keyword">var</span> card_body = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;div&#x27;</span>);<br>    card_body.class = <span class="hljs-string">&#x27;card-body&#x27;</span>;<br>    <span class="hljs-keyword">var</span> card_link = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;a&#x27;</span>);<br>    card_link.class = <span class="hljs-string">&#x27;card-link&#x27;</span>;<br>    <span class="hljs-comment">//Irrelevant code omitted</span><br>    card_link.innerText = title;<br>    card_link.style.fontSize = <span class="hljs-string">&quot;large&quot;</span>;<br>    card_body.appendChild(card_link);<br>    <span class="hljs-keyword">var</span> card_info = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&quot;p&quot;</span>);<br>    <span class="hljs-keyword">if</span>(source != <span class="hljs-literal">null</span>)&#123;<br>        card_info.innerText = time + <span class="hljs-string">&quot; &quot;</span> + source;<br>    &#125;<br>    <span class="hljs-keyword">else</span>&#123;<br>        card_info.innerText = time;<br>    &#125;<br>    card_body.appendChild(card_info);<br>    <span class="hljs-keyword">var</span> card_abstract = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&quot;p&quot;</span>);<br>    card_abstract.innerText = abstract;<br>    card_abstract.style.fontSize = <span class="hljs-string">&quot;small&quot;</span>;<br>    card_body.appendChild(card_abstract);<br>    <span class="hljs-keyword">var</span> card_cat = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&quot;p&quot;</span>);<br>    <span class="hljs-keyword">if</span>(cat == <span class="hljs-string">&quot;domestic&quot;</span>)&#123;<br>        card_cat.innerText = <span class="hljs-string">&quot;类别：国内&quot;</span>;<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(cat == <span class="hljs-string">&quot;world&quot;</span>)&#123;<br>        card_cat.innerText = <span class="hljs-string">&quot;类别：国外&quot;</span>;<br>    &#125;<br>    card_body.appendChild(card_cat);<br>    card.appendChild(card_body);<br>    <span class="hljs-keyword">var</span> page_elem = <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">&#x27;page-list&#x27;</span>);<br>    page_elem.appendChild(card);<br>&#125;<br></code></pre></td></tr></table></figure><p>当用户点击一个条目后，将跳转到一个新的页面，页面将向后端请求该新闻条目的完整内容。我们可以通过URL含参跳转的方法来实现这一跳转请求操作：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">//index.html</span><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">appendCard</span>(<span class="hljs-params">father, title, id, time, source, abstract, cat</span>)</span>&#123;<br>    <span class="hljs-comment">//Irrelevant code omitted</span><br>    card_link.href = <span class="hljs-string">&#x27;/content.html?id=&#x27;</span> + id;<br>    <span class="hljs-comment">//Irrelevant code omitted</span><br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">//content.html</span><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">GetUrlParam</span>(<span class="hljs-params">name</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> reg = <span class="hljs-keyword">new</span> <span class="hljs-built_in">RegExp</span>(<span class="hljs-string">&quot;(^|&amp;)&quot;</span>+ name +<span class="hljs-string">&quot;=([^&amp;]*)(&amp;|$)&quot;</span>);<br>    <span class="hljs-keyword">var</span> r = <span class="hljs-built_in">window</span>.location.search.substr(<span class="hljs-number">1</span>).match(reg);<br>    <span class="hljs-keyword">if</span>(r!=<span class="hljs-literal">null</span>)<span class="hljs-keyword">return</span> r[<span class="hljs-number">2</span>]; <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>&#125;<br><br><span class="hljs-keyword">var</span> id = GetUrlParam(<span class="hljs-string">&quot;id&quot;</span>);<br>$.get(<span class="hljs-string">&quot;/qcontent?id=&quot;</span> + id, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">data</span>)</span>&#123;<br>    <span class="hljs-comment">//Irrelevant code omitted</span><br>&#125;);<br></code></pre></td></tr></table></figure><p>对于内容的呈现，我们同样使用了动态方法将正文添加至页面上：<strong>（见public/content.html）</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">var</span> title = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;h1&#x27;</span>);<br>title.align = <span class="hljs-string">&quot;center&quot;</span>;<br>title.innerText = data.title;<br><span class="hljs-keyword">var</span> info = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;h5&#x27;</span>);<br>info.style.color = <span class="hljs-string">&quot;#808080&quot;</span>;<br>info.innerText = data.time + <span class="hljs-string">&quot; 来源：&quot;</span> + data.source;<br><span class="hljs-keyword">var</span> para = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;p&#x27;</span>); <br>para.innerText = data.content;<br><span class="hljs-keyword">var</span> page_elem = <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">&#x27;news-content&#x27;</span>);<br>page_elem.appendChild(title);<br>page_elem.appendChild(info);<br>page_elem.appendChild(para);<br></code></pre></td></tr></table></figure><h3 id="搜索提示">搜索提示</h3><p>在现代搜索引擎中，我们希望系统能够即时根据当前的输入智能推测用户想要搜索的完整内容。为实现这一功能，我们需要监听输入框的内容变化事件，并在每次这一事件发生时向后端发送搜索请求：<strong>（见public/index.html）</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">search</span>(<span class="hljs-params">callback, mode</span>)</span>&#123;<br>    <span class="hljs-keyword">let</span> keywords = $(<span class="hljs-string">&quot;:input[name=&#x27;keywords&#x27;]&quot;</span>).val();<br>    $.get(<span class="hljs-string">&quot;/query?keywords=&quot;</span> + keywords + <span class="hljs-string">&quot;&amp;mode=&quot;</span> + mode, callback);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">middleSearch</span>(<span class="hljs-params"></span>)</span>&#123;<br>    <span class="hljs-comment">//Irrelevant code omitted</span><br>    search(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">data</span>)</span>&#123;<br>        <span class="hljs-keyword">var</span> recList = [];<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">Math</span>.min(<span class="hljs-number">10</span>, data.length); i++)&#123;<br>            recList.push(data[i].title);<br>        &#125;<br>        <span class="hljs-comment">//Irrelevant code omitted</span><br>    &#125;, <span class="hljs-string">&quot;middle&quot;</span>);<br>&#125;<br><br>$(<span class="hljs-string">&quot;:input[name=&#x27;keywords&#x27;]&quot;</span>).on(<span class="hljs-string">&#x27;input&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)</span>&#123;<br>    middleSearch();<br>&#125;);<br></code></pre></td></tr></table></figure><p>由于搜索提示要求即时响应，因此我们通过向后端传入一个<strong>mode</strong>参数来决定搜索的响应精度和速度。对于<strong>提示用搜索请求（mode=middle）</strong>，后端将只扫描数据库<strong>新闻标题（title）</strong>列中含有目标关键字的条目，并只返回前10条结果。<strong>（事实上，若使用预训练的关键词关联库，我们可以引入更为智能的搜索提示，不过由于本项目为新闻搜索网站，这一功能并不实用）</strong></p><img src="/2021/04/18/web/search-site/auto_complete.png" class="" title="auto-complete"><p>对于前端，我们使用了<strong>JQuery-UI框架</strong>实现了补全列表的界面。通过JQuery语句在搜索框后附加<strong>autocomplete</strong>属性，即可使得列表中的内容随着用户的输入自动改变：<strong>（见public/index.html）</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs javascript">$(<span class="hljs-string">&quot;:input[name=&#x27;keywords&#x27;]&quot;</span>).autocomplete(&#123;<br>    source: <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">query, response</span>)</span>&#123;<br>        search(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">data</span>)</span>&#123;<br>            <span class="hljs-keyword">var</span> recList = [];<br>            <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">Math</span>.min(<span class="hljs-number">10</span>, data.length); i++)&#123;<br>                recList.push(data[i].title);<br>            &#125;<br>            <span class="hljs-keyword">return</span> response(recList);<br>        &#125;, <span class="hljs-string">&quot;middle&quot;</span>);<br>    &#125;<br>&#125;);<br></code></pre></td></tr></table></figure><h3 id="关键词热度分析">关键词热度分析</h3><p>最后，我们来实现对用户的搜索关键词进行时间热度分析的逻辑。由于在爬虫过程中我们抓取了文章的创建时间，并对正文内容进行了倒排索引，我们可以快速实现这一功能。</p><p>与显示新闻正文时的逻辑类似，当用户选择热度分析后，页面将含参跳转到一个新的页面，并向后端的<strong>/qheat</strong>入口请求热度分析结果。后端首先从<strong>news</strong>和<strong>indices</strong>表中分别找出包含目标关键词的新闻条目，并抽取出它们的时间信息。随后，我们按月份对其进行统计，并将其按时间排序，最终将结果封装为JSON字符串传回给前端：<strong>（见routes/index.js）</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">//Irrelevant code omitted</span><br><span class="hljs-keyword">var</span> seq = &#123;&#125;;<br>result.forEach(<span class="hljs-function">(<span class="hljs-params">item</span>) =&gt;</span> &#123;<br>    <span class="hljs-keyword">if</span>(seq.hasOwnProperty(item.time.slice(<span class="hljs-number">0</span>, <span class="hljs-number">7</span>)))&#123;<br>        seq[item.time.slice(<span class="hljs-number">0</span>, <span class="hljs-number">7</span>)] += <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">else</span>&#123;<br>        seq[item.time.slice(<span class="hljs-number">0</span>, <span class="hljs-number">7</span>)] = <span class="hljs-number">1</span>;<br>    &#125;<br>&#125;);<br><span class="hljs-keyword">var</span> sortedKeys = <span class="hljs-built_in">Object</span>.keys(seq).sort();<br><span class="hljs-keyword">var</span> seq_sort = &#123;&#125;;<br>sortedKeys.forEach(<span class="hljs-function">(<span class="hljs-params">item</span>) =&gt;</span> &#123;<br>    seq_sort[item] = seq[item];<br>&#125;);<br><span class="hljs-comment">//Irrelevant code omitted</span><br></code></pre></td></tr></table></figure><p>对于分析类功能，图表是一个较为直观的呈现形式。在这里我们使用了<strong>HighCharts</strong>图表框架来根据后端返回的数据快速生成这一样式：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs javascript">Highcharts.chart(<span class="hljs-string">&#x27;chart&#x27;</span>, &#123;<br>    title: &#123;<br>        text: <span class="hljs-string">&quot;关键词时间热度分布&quot;</span><br>    &#125;,<br>    xAxis: &#123;<br>        categories: <span class="hljs-built_in">Object</span>.keys(data)<br>    &#125;,<br>    series: [&#123;<br>        data: value_list,<br>        type: <span class="hljs-string">&quot;line&quot;</span>,<br>        name: <span class="hljs-string">&quot;关键词：&quot;</span> + sdecodeURI(keyword)<br>    &#125;]<br>&#125;);<br></code></pre></td></tr></table></figure><p>最终的显示效果如下：</p><img src="/2021/04/18/web/search-site/heat_analysis.png" class="" title="heat_analysis">]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;服务部署&quot;&gt;服务部署&lt;/h2&gt;
&lt;p&gt;请按照如下流程部署本项目：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;在&lt;strong&gt;news_search&lt;/strong&gt;目录下安装所需的依赖插件：&lt;strong&gt;（国内请使用淘宝源安装nodejieba）&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;code class=&quot;hljs shell&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; npm install request iconv-lite cheerio mysql jschardet moment&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; npm install nodejieba --registry=https://registry.npm.taobao.org --nodejieba_binary_host_mirror=https://npm.taobao.org/mirrors/nodejieba&lt;/span&gt;&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
    <category term="Computer-Science" scheme="http://gonggongjohn.me/tags/Computer-Science/"/>
    
    <category term="Web" scheme="http://gonggongjohn.me/tags/Web/"/>
    
    <category term="Frontend" scheme="http://gonggongjohn.me/tags/Frontend/"/>
    
  </entry>
  
  <entry>
    <title>数据科学与工程数学基础 作业3</title>
    <link href="http://gonggongjohn.me/2021/04/12/dase-math/dase-math-assignment-3/"/>
    <id>http://gonggongjohn.me/2021/04/12/dase-math/dase-math-assignment-3/</id>
    <published>2021-04-12T02:00:00.000Z</published>
    <updated>2022-02-10T08:37:20.703Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一">一</h2><blockquote><p>分别求下面向量的1-范数、2-范数和无穷范数 <span class="math display">\[a_1 = \begin{pmatrix}1 \\2 \\1\end{pmatrix},a_2 = \begin{pmatrix}-1 \\0 \\1\end{pmatrix},a_3 = \begin{pmatrix}-2 \\1 \\1\end{pmatrix}\]</span></p></blockquote><p><span class="math display">\[\begin{aligned}||a_1||_1 &amp;= |1| + |2| + |1| = 4 \\||a_1||_2 &amp;= \sqrt{1^2+2^2+1^2} = \sqrt{6} \\||a_1||_\infty &amp;= \max\{|1|,|2|,|1|\} = 2 \\\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}||a_2||_1 &amp;= |-1| + |0| + |1| = 2 \\||a_2||_2 &amp;= \sqrt{(-1)^2+0^2+1^2} = \sqrt{2} \\||a_2||_\infty &amp;= \max\{|-1|,|0|,|1|\} = 1 \\\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}||a_2||_1 &amp;= |-2| + |1| + |1| = 4 \\||a_2||_2 &amp;= \sqrt{(-2)^2+1^2+1^2} = \sqrt{6} \\||a_2||_\infty &amp;= \max\{|-2|,|1|,|1|\} = 2 \\\end{aligned}\]</span></p><h2 id="二">二</h2><blockquote><p>证明函数 <span class="math inline">\(F: \mathbb{R}^n \to \mathbb{R}, F(x) = \sqrt{\langle x, x \rangle }\)</span> 是向量范数</p></blockquote><p><strong>非负性：</strong>易见任取 <span class="math inline">\(\textbf{x} \in \mathbb{R}^n\)</span> <span class="math display">\[F(\mathbf{x}) = \sqrt{\langle \mathbf{x}, \mathbf{x}\rangle} = \sqrt{\sum_\limits{i = 1}^n x_i^2} \geq 0\]</span> 且 <span class="math inline">\(F(\mathbf{x}) = 0 \leftrightarrow \forall i \in \{1,2,...,n\}, x_i = 0\)</span>，即 <span class="math inline">\(F(\textbf{x}) = 0\)</span> 当且仅当 <span class="math inline">\(\textbf{x} = \textbf{0}\)</span></p><p><strong>齐次性：</strong>任取 <span class="math inline">\(\textbf{x} \in \mathbb{R}^n, \lambda \in \mathbb{R}\)</span> <span class="math display">\[\begin{aligned}F(\lambda \textbf{x}) &amp;= \sqrt{\langle \lambda \textbf{x}, \lambda \textbf{x}\rangle} \\&amp;=\sqrt{(\lambda \textbf{x})^T\lambda \textbf{x}} \\&amp;=\sqrt{\lambda^2 \textbf{x}^T \textbf{x}} \\&amp;=|\lambda| \sqrt{\textbf{x}^T \textbf{x}} \\&amp;=|\lambda| F(\textbf{x})\end{aligned}\]</span> <strong>三角不等式：</strong>任取 <span class="math inline">\(\textbf{x}, \textbf{y} \in \mathbb{R}^n\)</span> <span class="math display">\[\begin{aligned}F^2(\textbf{x} + \textbf{y}) &amp;= (\textbf{x} + \textbf{y})^T(\textbf{x} + \textbf{y}) \\&amp;=(\textbf{x}^T + \textbf{y}^T)(\textbf{x} + \textbf{y}) \\&amp;= \textbf{x}^T \textbf{x} + \textbf{y}^T \textbf{x} + \textbf{x}^T \textbf{y} + \textbf{y}^T \textbf{y} \\ \end{aligned}\]</span> 由<strong>Cauchy-Schwarz不等式</strong>可知 <span class="math inline">\(\forall \textbf{x}, \textbf{y} \in \mathbb{R}^n, | \langle \textbf{x}, \textbf{y} \rangle | \leq ||\textbf{x}||_2 \cdot \||\textbf{y}||_2\)</span></p><p>故 <span class="math display">\[\begin{aligned}F^2(\textbf{x} + \textbf{y}) &amp;\leq \textbf{x}^T \textbf{x} + |\textbf{y}^T \textbf{x}| + |\textbf{x}^T \textbf{y}| + \textbf{y}^T \textbf{y} \\&amp;\leq \textbf{x}^T \textbf{x} + 2 \sqrt{\textbf{x}^T \textbf{x} \textbf{y}^T \textbf{y}} + \textbf{y}^T \textbf{y} \\&amp;=\left( \sqrt{\textbf{x}^T \textbf{x}} + \sqrt{\textbf{y}^T \textbf{y}} \right)^2 \\&amp;=\left(F(\textbf{x}) + F(\textbf{y})\right)^2\end{aligned}\]</span> 于是由非负性可知 <span class="math display">\[F(\textbf{x} + \textbf{y}) \leq F(\textbf{x}) + F(\textbf{y})\]</span></p><p>因此 <span class="math inline">\(F(\mathbf{x}) = \sqrt{\langle \mathbf{x}, \mathbf{x}\rangle}\)</span> 是向量范数</p><h2 id="三">三</h2><blockquote><p>对任给的 <span class="math inline">\(x = (x_1, x_2, x_3)^T \in \mathbb{C}^3\)</span>，试问如下实值函数是否构成向量范数？ <span class="math display">\[f_1(x) = |x_1|^4 + |x_2|^4 + |x_3|^4 \\f_2(x) = |x_1| + 3 |x_2| + 2 |x_3|\]</span></p></blockquote><p><strong>(1)</strong> 任取 <span class="math inline">\(\textbf{x} = (x_1, x_2, x_3)^T \in \mathbb{C}^3, \lambda \in \mathbb{R}\)</span> <span class="math display">\[\begin{aligned}f_1(\lambda \textbf{x}) &amp;=|\lambda x_1|^4 + |\lambda x_2|^4 + |\lambda x_3|^4 \\&amp;= |\lambda|^4 |x_1|^4 + |\lambda|^4 |x_2|^4 + |\lambda|^4 |x_3|^4 \\\end{aligned}\]</span> 故 <span class="math inline">\(f_1\)</span> 不满足齐次性，因此 <strong><span class="math inline">\(f_1\)</span> 不构成向量范数</strong></p><p><strong>(2)</strong> 任取 <span class="math inline">\(\textbf{x}, \textbf{y} \in \mathbb{C}^3, \lambda \in \mathbb{R}\)</span></p><p>易见 <span class="math display">\[f_2(\textbf{x}) = |x_1| + 3 |x_2| + 2|x_3| \geq 0\]</span> 且 <span class="math inline">\(f_2(\textbf{x}) = 0 \leftrightarrow x_1=x_2=x_3 = 0\)</span> <span class="math display">\[\begin{aligned}f_2(\lambda \textbf{x}) &amp;= |\lambda x_1| + 3 |\lambda x_2| + 2 |\lambda x_3| \\&amp;=|\lambda| (|x_1| + 3 |x_2| + 2 |x_3|) \\&amp;=|\lambda| f_2 (\textbf{x})\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}f_2(\textbf{x} + \textbf{y}) &amp;= |x_1+y_1| + 3 |x_2+y_2| + 2|x_3 + y_3| \\&amp;\leq |x_1| + |y_1| + 3|x_2| + 3|y_2| + 2|x_3| + 2|y_3| \\&amp;=f_2(\textbf{x}) + f_2(\textbf{y})\end{aligned}\]</span></p><p>因此 <strong><span class="math inline">\(f_2\)</span> 构成向量范数</strong></p><h2 id="四">四</h2><blockquote><p>证明如下定义的函数 <span class="math inline">\(\langle \cdot, \cdot \rangle: \mathbb{R}^2 \times \mathbb{R}^2 \to \mathbb{R}\)</span> 是内积： <span class="math display">\[\langle x, y \rangle := x_1 y_1 - (x_1 y_2 + x_2 y_1) + 2 x_2 y_2\]</span></p></blockquote><p><span class="math inline">\(\forall \textbf{x}, \textbf{y}, \textbf{z} \in \mathbb{R}^2, \lambda \in \mathbb{R}\)</span></p><p><strong>非负性：</strong> <span class="math display">\[\begin{aligned}\langle \textbf{x}, \textbf{x} \rangle &amp;= x_1^2+2x_2^2-2x_1x_2 \\&amp;=(x_1-x_2)^2+x_2^2 \geq 0\end{aligned}\]</span> <span class="math inline">\(\langle \textbf{x}, \textbf{x} \rangle = 0 \leftrightarrow x_1=x_2 = 0 \leftrightarrow \textbf{x} = 0\)</span></p><p><strong>对称性：</strong><span class="math inline">\(\langle \textbf{x}, \textbf{y} \rangle = x_1y_1 - x_2y_1 - x_1y_2 + 2x_2y_2 = y_1x_1-y_2x_1-y_1x_2+2y_2x_2= \langle \textbf{y}, \textbf{x}\rangle\)</span></p><p><strong>齐次性：</strong> <span class="math display">\[\begin{aligned}\langle \lambda\textbf{x}, \textbf{y} \rangle &amp;=\lambda x_1y_1 - (\lambda x_1y_2 + \lambda x_2y_1) + 2 \lambda x_2y_2 \\&amp;=\lambda (x_1y_1 - x_1y_2 - x_2y_1 + 2x_2y_2) \\&amp;=\lambda \langle \textbf{x}, \textbf{y} \rangle\end{aligned}\]</span> <strong>线性性：</strong> <span class="math display">\[\begin{aligned}\langle \textbf{x} + \textbf{y}, \textbf{z} \rangle &amp;= (x_1 + y_1) z_1 - [(x_1 + y_1)z_2 + (x_2 + y_2) z_1] + 2 (x_2 + y_2) z_2 \\&amp;=x_1z_1 + y_1z_1 - x_1z_2 - y_1z_2 + x_2z_1 + y_2z_1 + 2x_2z_2 + 2y_2z_2 \\&amp;= \langle \textbf{x}, \textbf{z} \rangle + \langle \textbf{y}, \textbf{z} \rangle\end{aligned}\]</span> 因此 <span class="math inline">\(\langle \textbf{x}, \textbf{y} \rangle = x_1y_1 - (x_1y_2 + x_2y_1) + 2x_2y_2\)</span> 是一个内积</p><h2 id="五">五</h2><blockquote><p>分别求下面矩阵1-范数、2-范数和无穷范数 <span class="math display">\[A_1 = \begin{pmatrix}1 &amp; 2 \\1 &amp; 0\end{pmatrix},A_2 = \begin{pmatrix}-1 &amp; 0 \\1 &amp; 2\end{pmatrix}\]</span></p></blockquote><p><span class="math display">\[\begin{aligned}||A_1||_1 &amp;= \max \{|1| + |1|, |2| + |0|\} = 2 \\||A_1||_2 &amp;= \sqrt{\max\{3 + \sqrt{5}, 3 - \sqrt{5}\}} = \frac{1+\sqrt{5}}{\sqrt{2}} \\||A_1||_\infty &amp;= \max\{|1| + |2|, |1| + |0| \} = 3 \\\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}||A_2||_1 &amp;= \max \{|-1| + |1|, |0| + |2|\} = 2 \\||A_2||_2 &amp;= \sqrt{\max\{3 + \sqrt{5}, 3 - \sqrt{5}\}} = \frac{1+\sqrt{5}}{\sqrt{2}} \\||A_2||_\infty &amp;= \max\{|-1| + |0|, |1| + |2| \} = 3\end{aligned}\]</span></p><h2 id="六">六</h2><blockquote><p>求矩阵 <span class="math inline">\(\begin{pmatrix} 1 &amp; -1 &amp; 0 \\ 2 &amp; 4 &amp; 1 \\ 4 &amp; 2 &amp; 1 \end{pmatrix}\)</span> 的行空间、列空间、零空间和左零空间。</p></blockquote><p>设 <span class="math inline">\(A = \begin{pmatrix} 1 &amp; -1 &amp; 0 \\ 2 &amp; 4 &amp; 1 \\ 4 &amp; 2 &amp; 1\end{pmatrix}\)</span></p><p>设 <span class="math inline">\(\alpha_1 = (1, 2, 4)^T, \alpha_2 = (-1, 4, 2)^T, \alpha_3 = (0, 1, 1)^T\)</span></p><p>故 <span class="math display">\[\textbf{Col}(A) = \textbf{span} \{\alpha_1, \alpha_2, \alpha_3\} = \{ k_1 \alpha_1 + k_2 \alpha_2 + k_3 \alpha_3 : k_1, k_2, k_3 \in \mathbb{R} \}\]</span> 设 <span class="math inline">\(r_1 = (1, -1, 0)^T, r_2 = (2, 4, 1)^T, r_3 = (4, 2, 1)^T\)</span></p><p>故 <span class="math display">\[\textbf{Row}(A) = \textbf{span} \{r_1, r_2, r_3 \} = \{k_1 r_1 + k_2 r_2 + k_3 r_3: k_1, k_2, k_3 \in \mathbb{R} \}\]</span> 对 <span class="math inline">\(A\)</span> 作行初等变换 <span class="math display">\[A \xrightarrow[r_3-4_1]{r_2-2r_1}\begin{pmatrix}1 &amp; -1 &amp; 0 \\0 &amp; 6 &amp; 1 \\0 &amp; 6 &amp; 1\end{pmatrix}\xrightarrow{r_3-r_2}\begin{pmatrix}1 &amp; -1 &amp; 0 \\0 &amp; 6 &amp; 1 \\0 &amp; 0 &amp; 0\end{pmatrix}\xrightarrow{\frac{1}{6}r_2}\begin{pmatrix}1 &amp; -1 &amp; 0 \\0 &amp; 1 &amp; \frac{1}{6} \\0 &amp; 0 &amp; 0\end{pmatrix}\xrightarrow{r_1+r_2}\begin{pmatrix}1 &amp; 0 &amp; \frac{1}{6} \\0 &amp; 1 &amp; \frac{1}{6} \\0 &amp; 0 &amp; 0\end{pmatrix}\]</span> 故令 <span class="math inline">\(\alpha = (-1, -1, 6)^T\)</span>，则 <span class="math display">\[\textbf{Null}(A) = \textbf{span}(\alpha) = \{k\alpha: k \in \mathbb{R} \}\]</span> 对 <span class="math inline">\(A^T\)</span> 作行初等变换</p><p><span class="math display">\[\begin{aligned}A^T \xrightarrow{r_2+r_1}\begin{pmatrix}1 &amp; 2 &amp; 4 \\0 &amp; 6 &amp; 6 \\0 &amp; 1 &amp; 1\end{pmatrix}\xrightarrow{\frac{1}{6}r_2}\begin{pmatrix}1 &amp; 2 &amp; 4 \\0 &amp; 1 &amp; 1 \\0 &amp; 1 &amp; 1\end{pmatrix}\xrightarrow{r_3-r_2}\begin{pmatrix}1 &amp; 2 &amp; 4 \\0 &amp; 1 &amp; 1 \\0 &amp; 0 &amp; 0\end{pmatrix}\xrightarrow{r_1-2r_2}\begin{pmatrix}1 &amp; 0 &amp; 2 \\0 &amp; 1 &amp; 1 \\0 &amp; 0 &amp; 0\end{pmatrix}\end{aligned}\]</span> 故令 <span class="math inline">\(\beta = (-2, -1, 1)^T\)</span>，则 <span class="math display">\[\textbf{Null}(A^T) = \textbf{span}(\beta) = \{k \beta: k \in \mathbb{R} \}\]</span></p><h2 id="七">七</h2><blockquote><p>求由向量 <span class="math inline">\(\begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}, \begin{pmatrix} 0 \\ 1 \\ 2 \end{pmatrix}\)</span> 张成的子空间的正交补空间。</p></blockquote><p>由 <span class="math display">\[\begin{pmatrix}1 &amp; 2 &amp; 0 \\0 &amp; 1 &amp; 2\end{pmatrix}\xrightarrow{r_1-2r_2}\begin{pmatrix}1 &amp; 0 &amp; -4 \\0 &amp; 1 &amp; 2\end{pmatrix}\]</span> 可知 <span class="math display">\[\textbf{span}^{\bot} \left\{\begin{pmatrix}1 \\ 2 \\ 0\end{pmatrix},\begin{pmatrix}0 \\ 1 \\ 2\end{pmatrix}\right\}=\textbf{span} \left\{\begin{pmatrix}4 \\ -2 \\ 1\end{pmatrix}\right\}\]</span></p><h2 id="八">八</h2><blockquote><p>写出一个与子空间 <span class="math inline">\(\textrm{span} \left\{(1,2,1)^T \right\}\)</span> 正交的子空间。</p></blockquote><p>由于 <span class="math display">\[(-1,0,1) \cdot (1,2,1)^T = 0\]</span> 故 <span class="math display">\[\textbf{span} \left\{ (-1,0,1)^T \right\} \bot \ \textbf{span} \left\{ (1,2,1)^T \right\}\]</span></p><h2 id="九">九</h2><blockquote><p>求向量 <span class="math inline">\((1,1,1)^T\)</span> 投影到一维子空间 <span class="math inline">\(\textrm{span} \left\{(1,-1,1)^T \right\}\)</span> 的正交投影。</p></blockquote><p>设 <span class="math inline">\(\alpha = (1,-1,1)^T, x = (1,1,1)^T\)</span></p><p>则 <span class="math inline">\(\textbf{span}\left\{(1,-1,1)^T\right\}\)</span> 的投影矩阵为 <span class="math display">\[P_\pi = \frac{\alpha \alpha^T}{\alpha^T \alpha} = \frac{1}{3}\begin{pmatrix}1 &amp; -1 &amp; 1 \\-1 &amp; 1 &amp; -1 \\1 &amp; -1 &amp; 1\end{pmatrix}\]</span> 于是 <span class="math inline">\(x\)</span> 在 <span class="math inline">\(\textbf{span}\left\{(1,-1,1)^T\right\}\)</span> 中的正交投影为 <span class="math display">\[\pi(x) = P_\pi \cdot x = \left( \frac{1}{3},-\frac{1}{3},\frac{1}{3} \right)^T\]</span></p><h2 id="十">十</h2><blockquote><p>求向量 <span class="math inline">\((1,1,1)^T\)</span> 投影到仿射空间 <span class="math inline">\(\textrm{span} \left\{(1,-1,1)^T , (1,1,0)^T \right\} + (1,2,1)^T\)</span> 的正交投影。</p></blockquote><p>设 <span class="math inline">\(\alpha_1 = (1, -1, 1)^T, \alpha_2 = (1,1,0)^T, \beta = (1,2,1)^T, x = (1,1,1)^T, x_0 = x - \beta = (0,-1,0)^T\)</span></p><p>于是令 <span class="math inline">\(B = (\alpha_1, \alpha_2) = \begin{pmatrix} 1 &amp; 1 \\ -1 &amp; 1 \\ 1 &amp; 0 \end{pmatrix}\)</span></p><p>因此 <span class="math display">\[B^TB = \begin{pmatrix}3 &amp; 0 \\0 &amp; 2\end{pmatrix},B^Tx_0 = (1,-1)^T\]</span> 故由 <span class="math inline">\(B^TB\lambda = B^Tx_0\)</span> 可知，<span class="math inline">\(\lambda = (\frac{1}{3}, -\frac{1}{2})^T\)</span></p><p>故 <span class="math display">\[\pi(x_0) = B \lambda = (-\frac{1}{6}, -\frac{5}{6}, \frac{1}{3})^T\]</span> 于是 <span class="math display">\[\pi(x) = \pi(x_0) + \beta = (\frac{5}{6}, \frac{7}{6}, \frac{4}{3})^T\]</span></p><h2 id="十一">十一</h2><blockquote><p>设 <span class="math display">\[a_1 = \begin{pmatrix} 1 \\2 \\-1\end{pmatrix},a_2 = \begin{pmatrix} -1 \\3 \\1\end{pmatrix},a_3 = \begin{pmatrix} 4 \\-1 \\0\end{pmatrix}\]</span> ，试将向量组 <span class="math inline">\((a_1, a_2, a_3)\)</span> 标准正交化。</p></blockquote><p>令 <span class="math display">\[\begin{aligned}b_1 &amp;= a_1 = (1,2,-1)^T \\b_2 &amp;= a_2 - \frac{\langle b_1, a_2 \rangle}{\langle b_1,b_1 \rangle} b_1 = \frac{5}{3}(-1,1,1)^T \\b_3 &amp;= a_3 - \frac{\langle b_1, a_3 \rangle}{\langle b_1,b_1 \rangle} b_1 - \frac{\langle b_2, a_3 \rangle}{\langle b_2,b_2 \rangle} b_2 = 2(1, 0, 1)^T\end{aligned}\]</span> 故 <span class="math display">\[\begin{aligned}e_1 &amp;= \textbf{e}_{b_1} = \frac{1}{\sqrt{6}} (1,2,-1)^T \\e_2 &amp;= \textbf{e}_{b_2} = \frac{1}{\sqrt{3}}(-1,1,1)^T \\e_3 &amp;= \textbf{e}_{b_3} = \frac{1}{\sqrt{2}}(1,0,1)^T\end{aligned}\]</span> 因此 <span class="math inline">\((a_1, a_2, a_3)\)</span> 标准正交化后的向量组为 <span class="math inline">\((e_1, e_2, e_3)\)</span></p><h2 id="十二">十二</h2><blockquote><p>复现Lec6例13的结果。其中负例为 <span class="math inline">\((1.5,2), (1.7, 1.5), (2,2), (1.5,2.5)\)</span>，正例为 <span class="math inline">\((1,2),(0.3,0.3), (2,1), (1,1)\)</span>，分别采用了欧式距离和曼哈顿距离两种距离度量方式。</p></blockquote><p><strong>实现代码：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 数据集</span><br>p=[[<span class="hljs-number">1</span>,<span class="hljs-number">0.3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>,<span class="hljs-number">0.3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]]<br>n=[[<span class="hljs-number">1.5</span>,<span class="hljs-number">1.7</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1.5</span>], [<span class="hljs-number">2</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2.5</span>]]<br>p=np.array(p)<br>n=np.array(n)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">divide</span>(<span class="hljs-params">dist,k,X,Y</span>):</span>  <span class="hljs-comment"># dist为一距离函数，k为KNN的参数，(X,Y)为数据的坐标</span><br>    ans_p=[np.sort(dist(p[<span class="hljs-number">0</span>]-X[i],p[<span class="hljs-number">1</span>]-Y[i]))<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(X))]<br>    ans_n=[np.sort(dist(n[<span class="hljs-number">0</span>]-X[i],n[<span class="hljs-number">1</span>]-Y[i]))<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(X))]<br>    t=[ans_p[i][int((k<span class="hljs-number">-1</span>)/<span class="hljs-number">2</span>)]&gt;ans_n[i][int((k<span class="hljs-number">-1</span>)/<span class="hljs-number">2</span>)]<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(ans_p))]<br>    <span class="hljs-keyword">return</span> np.array(t) <span class="hljs-comment"># 返回分类结果</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dist1</span>(<span class="hljs-params">x,y</span>):</span>  <span class="hljs-comment"># Euclid distance</span><br>    result = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(x)):<br>        result.append(math.sqrt(x[i] * x[i] + y[i] * y[i]))<br>    <span class="hljs-keyword">return</span> np.array(result)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dist2</span>(<span class="hljs-params">x,y</span>):</span>  <span class="hljs-comment"># Manhattan distance</span><br>    <span class="hljs-keyword">return</span> np.abs(x) + np.abs(y)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">example_dist</span>(<span class="hljs-params">x,y</span>):</span>  <span class="hljs-comment"># Minkovski distance</span><br>    <span class="hljs-keyword">return</span> np.max([np.abs(x),np.abs(y)],axis=<span class="hljs-number">0</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot</span>(<span class="hljs-params">dist,k,ax</span>):</span>  <span class="hljs-comment"># 画图</span><br>    N=<span class="hljs-number">200</span>  <span class="hljs-comment"># 在平面上生成 N x N个点</span><br>    X=np.linspace(<span class="hljs-number">-0</span>,<span class="hljs-number">3</span>,N)  <span class="hljs-comment"># 生成横坐标</span><br>    Y=X <span class="hljs-comment"># 生成纵坐标</span><br>    X,Y=np.meshgrid(X,Y)  <span class="hljs-comment"># 生成 N x N个点</span><br>    X=X.reshape(<span class="hljs-number">1</span>,N*N)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 将横坐标化为向量形式</span><br>    Y=Y.reshape(<span class="hljs-number">1</span>,N*N)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 将纵坐标化为向量形式</span><br>    predict=divide(dist, k, X, Y)<br>    ax.contourf(X.reshape(N,N), Y.reshape(N,N), predict.reshape(N,N),<br>                cmap=plt.cm.Spectral,alpha=<span class="hljs-number">0.3</span>)  <span class="hljs-comment"># 此函数将根据预测值和对应坐标生成图像</span><br>    ax.plot(p[<span class="hljs-number">0</span>],p[<span class="hljs-number">1</span>],<span class="hljs-string">&#x27;rx&#x27;</span>)<br>    ax.plot(n[<span class="hljs-number">0</span>],n[<span class="hljs-number">1</span>],<span class="hljs-string">&#x27;bo&#x27;</span>)<br>    plt.text(<span class="hljs-number">0.5</span>,<span class="hljs-number">2.5</span>,<span class="hljs-string">&quot;k=&quot;</span>+str(k))<br>    plt.show()<br><br><br>fig, ax = plt.subplots()<br>plot(dist2, <span class="hljs-number">3</span>, ax)<br></code></pre></td></tr></table></figure><p><strong>输出结果：（欧几里得距离）</strong></p><img src="/2021/04/12/dase-math/dase-math-assignment-3/euclid.png" class="" title="euclid"><p><strong>输出结果：（曼哈顿距离）</strong></p><img src="/2021/04/12/dase-math/dase-math-assignment-3/manhattan.png" class="" title="manhattan">]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一&quot;&gt;一&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;分别求下面向量的1-范数、2-范数和无穷范数 &lt;span class=&quot;math display&quot;&gt;\[
a_1 = \begin{pmatrix}
1 \\
2 \\
1
\end{pmatrix},
a_2 </summary>
      
    
    
    
    <category term="数据科学数学基础" scheme="http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Mathematics" scheme="http://gonggongjohn.me/tags/Mathematics/"/>
    
    <category term="DataScience" scheme="http://gonggongjohn.me/tags/DataScience/"/>
    
  </entry>
  
</feed>
