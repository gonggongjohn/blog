{"meta":{"title":"GONGGONGJOHN's Blog","subtitle":"","description":"A sophomore student major in Data Science.","author":"GONGGONGJOHN","url":"http://gonggongjohn.me","root":"/"},"pages":[{"title":"About Me","date":"2021-01-21T06:39:15.000Z","updated":"2022-07-18T07:59:56.873Z","comments":false,"path":"about/index.html","permalink":"http://gonggongjohn.me/about/index.html","excerpt":"","text":"I'm currently a senior undergraduate student major in Data Science &amp; Engineering. This blog is an academic record of stuffs I have learned or explored in Computer Science and Mathematics. Major courses I took in the past two and a half years: Mathematical Analysis I (Fall 2019) Mathematical Analysis II (Spring 2020) Advanced Algebra &amp; Analytic Geometry I (Fall 2019) Advanced Algebra &amp; Analytic Geometry II (Spring 2020) Computer Systems &amp; Cloud Computing (Fall 2020) Algorithm Design &amp; Analysis (Fall 2020) Professional English (Fall 2020) Introduction to Data Science and Engineering (Fall 2020) Cloud Computing Applications and Development (Fall 2020) Probability and Mathematical Statistics (Spring 2021) Discrete Mathematics (Spring 2021) Mathematical Foundation of Data Science (Spring 2021) Data Structure (Spring 2021) Operation System (Spring 2021) Web Programming (Spring 2021) Data Ethics (Spring 2021) Design Thinking (Summer 2021) Statistical Method &amp; Machine Learning (Fall 2021) Algorithm Foundation of Data Science (Fall 2021) Contemporary Database System (Fall 2021) Information Retrieval &amp; Natural Language Processing (Fall 2021) Contemporary Artificial Intelligence (Spring 2022) Distributed Computing Model &amp; System (Spring 2022) Deep Learning (Spring 2022) Several courses I'm working on currently: Computer Vision (Fall 2022) Software Optimization (Fall 2022) Human Computer Interaction Convex Optimization"},{"title":"categories","date":"2021-01-21T07:04:43.000Z","updated":"2021-01-21T07:06:55.172Z","comments":false,"path":"categories/index.html","permalink":"http://gonggongjohn.me/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"当代人工智能 课程项目二 A*算法","slug":"contemporary-ai/contemporary-ai-exp-2","date":"2022-04-05T02:00:00.000Z","updated":"2022-12-05T11:47:42.608Z","comments":true,"path":"2022/04/05/contemporary-ai/contemporary-ai-exp-2/","link":"","permalink":"http://gonggongjohn.me/2022/04/05/contemporary-ai/contemporary-ai-exp-2/","excerpt":"","text":"摘要 \\(A^*\\) 算法是一种经典的启发式搜索算法，其在路径规划、语意搜索和在线学习等任务中都有着极为广泛的应用。相比传统的遍历搜索，\\(A^*\\) 通过启发式代价优先选择代价估计值最小的状态进行展开，从而更有可能较为高效地到达目标状态。在本文中，我们整理了 \\(A^*\\) 算法的思想和相关性质，设计并实现了八数码问题和 K 短路问题的求解算法，并对测试数据进行了求解。 **关键字：启发式搜索，A*算法，八数码问题，K 短路问题** A*算法 \\(A^*\\) 算法是一种启发式单源最小代价搜索算法，由Peter Hart、Nils Nilsson和Bertram Raphael三人于1968年作为一项机器人研究课题的一部分提出。与传统的遍历式搜索算法不同，\\(A^*\\) 算法通过考虑更多的信息来估计每种状态到目标间的代价，并以此为依据智能地选择后续的搜索方向。具体来说，若设 \\(\\mathcal{H}\\) 为一个搜索问题的状态集合，定义每种状态 \\(n \\in \\mathcal{H}\\) 的代价估计值 \\(f(n) = g(n) + h(n)\\)，其中 \\(g(n)\\) 为从初始状态到当前状态的实际代价，\\(h(n)\\) 为从当前状态到目标状态的启发代价。在每一次迭代中，\\(A^*\\)算法会计算每种候选状态的代价估计值，并选择代价估计值最小的状态进一步搜索。\\(A^*\\)算法的算法流程如下： algorithm_a_star 从上面的描述可以发现，设计\\(A^*\\)算法的关键便是定义每种状态到目标状态的启发代价。对于一棵搜索树而言，并不是任意的启发函数都能保证\\(A^*\\)算法找到最优解，其必须为一个可接受启发（Admissible Heuristic），定义如下： Definition 1（可接受启发）：设状态集合 \\(\\mathcal{H}\\)，函数\\(h: \\mathcal{H} \\to \\mathbb{R}\\) 为给定状态到目标状态的一个代价估计函数，\\(h^*: \\mathcal{H} \\to \\mathbb{R}\\) 为从给定状态到目标状态的真实代价函数。若对任意 \\(n \\in \\mathcal{H}\\)，有 \\(0 \\leq h(n) \\leq h^*(n)\\)，则称函数 \\(h\\) 为一个可接受启发。 对于一棵状态搜索树，若启发函数为可接受启发，则使用\\(A^*\\)算法必定能够找出最优解。这是由于有如下定理保证： Theorem 1：若状态搜索树满足如下条件： 分支因子（Branching Factor）是有限的 状态转移代价为正 启发函数为可接受启发 则 \\(A^*\\) 算法是完全（若存在解则能够找到解）且最优（能够找到最优解）的。 Proof： 完全性 设解的深度为 \\(d\\)，状态搜索树的最大分支因子为 \\(b\\)，则算法最多遍历 \\(b^d\\) 个结点即可找到该解，也即算法完全。 最优性 设最优状态结点为 \\(A\\)，\\(N\\) 为从根节点到最优状态结点的路径上的任意一点，任一个次优状态结点为 \\(B\\)。 由代价估计函数的定义可知 \\[ \\begin{aligned} f(N) &amp;= g(N) + h(N) \\\\ f(A) &amp;= g(A) \\end{aligned} \\] 由于 \\(h\\) 为可接受启发，因此有 \\(h(N) \\leq g(A) - g(N)\\)，于是有 \\(f(N) \\leq f(A)\\)。又由于 \\(f(A) \\leq f(B)\\)，因此 \\(f(N) \\leq f(B)\\)。由此可知最优路径上的每个结点 \\(N\\) 都会优先于 \\(B\\) 被展开。故 \\(A\\) 会优先于 \\(B\\) 被展开，也即最优性成立。 \\(A^*\\)算法的效率主要取决于启发函数对目标状态的引导效率。在最坏情况下（启发函数不提供任何信息），\\(A^*\\)算法退化为广度优先搜索算法，其时间复杂度为 \\(\\mathcal{O}(b^d)\\)，其中 \\(b\\) 为分支因子，\\(d\\) 为状态搜索树深度。由于要同时记录已搜索的结点和待搜索的结点，因此其最坏情况下的空间复杂度也为 \\(\\mathcal{O}(b^d)\\)。 问题一：小明玩球 问题描述 小明在一个九宫格中随机摆了八个球，每个球上标有1-8中的某一数字（球上数字不重复）。九宫格中留有一个空格，该空格用0表示。空格周围的球可以移动到空格中。现在，给出一种初始布局（即初始状态）和目标布局（本题的目标布局设为123804765），现在小明想找到一种最少步骤的移动方法，实现从初识布局到目标布局的转变，你能帮帮他吗？ 要求只能用\\(A^*\\)算法。 输入格式 输入初始状态，一行九个数字，空格用0表示，除0之外，分别表示从左到右从上到下的对应球上的数字。例：初始状态为283104765，即对应了下图所示的九宫格布局： q1_example_input 输出格式 只有一行，该行只有一个数字，表示从初始状态到目标状态需要的最少移动次数（测试数据中无特殊无法到达的目标状态数据）。 输入样例 283104765 输出样例 4 问题求解 可解性判断 尽管测试数据中保证了不存在无法到达的目标状态数据，但出于算法的完整性，我们首先对状态的可解性进行判断。对于一个八数码问题，其可解性可以通过比较当前状态和目标状态下九宫格数码排列的奇偶性来快速判断。这是由于有如下定理保证： Theorem 2：一个八数码问题可解当且仅当当前状态的数码排列（除去空白格）与目标状态的数码排列（除去空白格）的奇偶性相同。 Proof：由于横向移动操作不改变除去空白格后的数码排列，因此我们仅需考虑纵向移动。 当空白格向上移动时，涉及格点周围的数码排列由 \\(\\cdots xyz \\cdots\\) 变为 \\(\\cdots yzx \\cdots\\)；当空白格向下移动时，涉及格点周围的数码排列由 \\(\\cdots xyz \\cdots\\) 变为 \\(\\cdots zxy \\cdots\\)。易见两种操作均可分解为对换 \\((x,y)\\) 和对换 \\((x,z)\\)。由于对换改变排列的奇偶性，因此两种操作对数码排列的奇偶性均不改变，也即仅当当前状态和目标状态的数码排列同奇偶时该问题才可解。 又由于任一 \\(n\\) 元排列均可由其同奇偶的其他 \\(n\\) 元排列经过偶数次对换得到，因此在满足上述可解性的前提下，目标状态必定可达。 对于当前问题，易知目标状态的除空数码排列12384765的逆序数位为7，也即该排列为一个奇排列。因此，对于初始状态的除空数码排列为偶排列的输入，我们可直接返回。 启发函数 从上面的介绍中可以知道，为了能够高效地利用\\(A^*\\)算法对问题进行求解，我们需要设计一个较为合理的启发函数。对于当前问题，我们使用总曼哈顿距离（Total Manhattan Distance）作为一个状态的启发代价。具体来说，若一个数码 \\(i\\) 在当前状态 \\(c\\) 的坐标为 \\((x_i^c, y_i^c)\\)，其在目标状态 \\(t\\) 对应的坐标为 \\((x_i^t, y_i^t)\\)，则其曼哈顿距离定义为 \\[ d(i_c, i_t) = |x_i^c - x_i^t| + |y_i^c - y_i^t| \\] 于是整个状态的总曼哈顿距离即为 \\[ h(c, t) = \\sum_{i = 0}^8 d(i_c) = \\sum_{i = 0}^8 \\left( |x_i^c - x_i^t| + |y_i^c - y_i^t| \\right) \\] 以样例输入为例，其启发距离如下图所示。可以看到，该状态下共有3个数码与目标状态下位置不一致，其曼哈顿距离分别为1，2，1，因此该状态的总曼哈顿距离为4。 q1_manhattan 由于允许了数码的直接移动，因此这一代价必定小于实际代价，也即 \\(h(n)\\) 为一个可接受启发。 搜索过程 接下来我们使用\\(A^*\\)算法求解该问题。对于当前问题，每一种九宫格布局对应了一个状态，也即为状态搜索树上的一个结点。若以空白格为中心，则对于一个状态，空白格可以有上、下、左、右四种移动方式，对应了4种新的状态。由此，以初始状态为根结点，我们便可以生成出整棵状态搜索树，如下图所示。根据\\(A^*\\)算法的运行逻辑和上面定义的启发函数，对于每一步搜索，我们只需要从待搜索状态中选择代价估计值最小的状态作为当前选择的结点，枚举其下一步移动后的各个状态并计算相应的代价估计值，并将它们放入待搜索状态集合即可。 q1_status_tree 算法实现 根据上面的算法分析，我们来实现具体的算法逻辑。对于一个输入的初始状态，我们首先判断其可解性。通过上面的分析可知，我们只需求解出输入数码（除去空白格）的逆序数即可。求解排列逆序数的一个经典方法便是对排列数组进行归并排序，并在归并过程中记录逆序对。我们可以快速实现这一过程： 12345678910111213141516171819202122int get_inverse_number(int _seq[], int _aux_seq[], int left, int right)&#123; int ans = 0; if(left &lt; right)&#123; int mid = (left + right) &gt;&gt; 1; ans += get_inverse_number(_seq, _aux_seq, left, mid); ans += get_inverse_number(_seq, _aux_seq, mid + 1, right); int i, j, k; j = mid + 1, k = left; for(i = left; i &lt;= mid &amp;&amp; j &lt;= right; )&#123; if(_seq[i] &gt; _seq[j])&#123; _aux_seq[k++] = _seq[j++]; ans += mid-i+1; &#125;else&#123; _aux_seq[k++] = _seq[i++]; &#125; &#125; while(i &lt;= mid) _aux_seq[k++] = _seq[i++]; while(j &lt;= right) _aux_seq[k++] = _seq[j++]; for(i = left; i &lt;= right; i++) _seq[i] = _aux_seq[i]; &#125; return ans;&#125; 随后我们来实现搜索逻辑。为了方便起见，我们首先定义一个结构作为状态搜索树上的结点以支持后续的搜索操作。在一个结点中，我们需要保存当前状态的九宫格数字布局、从初始状态到当前状态的实际代价以及启发代价。此外，为了提高算法效率，我们还可以标记该状态下空白格的坐标。具体实现如下： 123456789101112131415161718192021struct status&#123; int layout[3][3]; int g, h; int blank_x, blank_y; status(int _layout[][3], int _g, pair&lt;int, int&gt; _target_map[])&#123; h = 0; for(int i = 0; i &lt; 3; i++) for(int j = 0; j &lt; 3; j++)&#123; int content = _layout[i][j]; pair&lt;int, int&gt; pos = _target_map[content]; h += abs(i - pos.first) + abs(j - pos.second); layout[i][j] = content; if(content == 0)&#123; blank_x = i; blank_y = j; &#125; &#125; g = _g; &#125;&#125;; 根据上面的算法流程，我们需要分别维护一个用于保存待搜索结点的开集以及一个用于保存已搜索结点的闭集。由于开集需要支持\"取最小代价结点\"的操作，因此我们使用一个优先队列来作为维护开集元素的数据结构。对于闭集，由于其元素唯一，且我们只需要其支持“查询给定元素是否存在于集合中”这一操作，因此我们直接使用集合结构来进行维护。由于元素均为为自定义结构，因此我们还需要覆写比较运算符来确定结构序的计算方法。代码如下： 1234567891011121314151617181920struct compare_open&#123; bool operator() (status a, status b)&#123; return (a.g + a.h) &gt; (b.g + b.h); &#125;&#125;;struct compare_close&#123; bool operator() (status a, status b)&#123; for(int i = 0; i &lt; 3; i++) for(int j = 0; j &lt; 3; j++)&#123; if(a.layout[i][j] &lt; b.layout[i][j]) return true; else if(a.layout[i][j] &gt; b.layout[i][j]) return false; &#125; return false; &#125;&#125;;int main()&#123; priority_queue&lt;status, vector&lt;status&gt;, compare_open&gt; open_set; set&lt;status, compare_close&gt; close_set; //Irrelevant codes&#125; 之后我们只需要根据算法分析中的搜索过程实现整个搜索逻辑即可，算法终止条件为目标状态结点已存在于闭集中。实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839int main()&#123; /* Get the inverse number of the initial sequence */ if(inverse_cnt % 2 == 1) &#123; status init_status(init_status_layout, 0, target_status_map); status target_status(target_status_layout, 0, target_status_map); open_set.push(init_status); while (close_set.find(target_status) == close_set.end()) &#123; status current_status = open_set.top(); open_set.pop(); for (int i = 0; i &lt; 4; i++) &#123; int delta_x = move_direction[i][0]; int delta_y = move_direction[i][1]; int candidate_x = current_status.blank_x + delta_x; int candidate_y = current_status.blank_y + delta_y; if (candidate_x &lt; 0 || candidate_x &gt; 2 || candidate_y &lt; 0 || candidate_y &gt; 2) continue; int candidate_layout[3][3]; for (int j = 0; j &lt; 3; j++) for (int k = 0; k &lt; 3; k++) &#123; if (j == candidate_x &amp;&amp; k == candidate_y) &#123; candidate_layout[j][k] = 0; &#125; else if (j == current_status.blank_x &amp;&amp; k == current_status.blank_y) &#123; candidate_layout[j][k] = current_status.layout[candidate_x][candidate_y]; &#125; else &#123; candidate_layout[j][k] = current_status.layout[j][k]; &#125; &#125; status candidate_status(candidate_layout, current_status.g + 1, target_status_map); if (close_set.find(candidate_status) == close_set.end()) &#123; open_set.push(candidate_status); &#125; &#125; close_set.insert(current_status); &#125; set&lt;status, compare_close&gt;::iterator goal_iter = close_set.find(target_status); status goal_status = *goal_iter; printf(&quot;%d\\n&quot;, goal_status.g); &#125; //Irrelevant codes&#125; 测试数据结果 测试数据1 输入 024657318 输出 22 测试数据2 输入 587346120 输出 26 测试数据3 输入 375148206 输出 21 测试数据4 输入 512768340 输出 26 测试数据5 输入 123804765 输出 0 问题二：小明爱跑步 问题描述 众所周知，小明身材很好。但自从他博士毕业当老师后，他就自我感觉身体变差了，于是他就想锻炼了。为了不使自己太累，他提出一种从山顶跑步到山脚的锻炼方法。 千寻万觅，终于在郊区找到这样一座山，这座山有 \\(N\\) 个地标，有先行者在这些地标之间开辟了 \\(M\\) 条道路。并且这些地标按照海拔从低到高进行了编号，例如山脚是 \\(1\\)，山顶是 \\(N\\)。 小明这个人对跑步的方式很挑： 只跑最短路径。但一条最短路径跑久了会烦，需要帮他设计 \\(K\\) 条最短路径。 不想太累，每次选道路的时候只从（海拔的）高处到低处。 现在问题来了，给你一份这座山地标间道路的列表，每条道路用 \\((X_i, Y_i, D_i)\\) 表示，表示地标 \\(X_i\\) 和地标 \\(Y_i\\) 之间有一条长度为 \\(D_i\\) 的下坡道路。你来计算下小明这 \\(K\\) 条路径的对应长度，看看小明的锻炼强度大不大？ 要求只能用\\(A^*\\)算法。 输入格式 第一行三个用空格分开的整数 \\(N, M, K\\)。 第二行到第 \\(M+1\\) 行，每行有三个空格分开的整数 \\(X_i, Y_i, D_i\\)，描述了一条下坡的路。 输出格式 共 \\(K\\) 行。 在第 \\(i\\) 行输出第 \\(i\\) 短的路线长度，如果不存在就输出 \\(-1\\)。 如果出现多条相同长度的路线，务必全部依次输出。 输入样例 1234567895 8 75 4 15 3 15 2 15 1 14 3 43 1 13 2 12 1 1 输出样例 1234567122367-1 结果解释 这些路线分别为(5-1)、(5-3-1)、(5-2-1)、(5-3-2-1)、(5-4-3-1)和(5-4-3-2-1)。只有6条路线，所以最后一行（第7行）为-1。 问题求解 启发函数 和上一题类似，我们首先定义各个状态所对应的启发代价。由于整张图的结点关系、边权和目标结点是确定的，因此我们可以求出各个结点到目标结点的实际最小代价并以此作为各个结点的启发代价，也即对于状态 \\(i\\)，其启发代价为 \\[ h(i) = dist(v_i, v_t) \\] 其中 \\(v_i\\) 为状态 \\(i\\) 对应的结点，\\(v_t\\) 为目标状态对应的结点。 以样例图为例，其各个结点的启发代价如下图所示： q2_dijkstra 由于该代价为当前结点到目标结点的实际最小代价，因此必然为一个可接受启发。 搜索过程 通过题目描述可以发现，该问题是一个经典的K短路（K-Shortest Path）问题。对于一个一般的K短路问题，我们有如下定理成立： Theorem 3：一张有向图的K短路问题是NP-Hard的。 Proof：这里仅证明K条路径均为简单路径时的情况。由于一般路径包含简单路径，因此其求解难度必不小于简单路径时的情况。 对于一张包含 \\(n\\) 个节点的有向图，其最多包含 \\(n!\\) 条简单路径。 若存在一个算法 \\(A\\) 可以在多项式时间内求解K短路问题，则对于一个初始结点和目标结点，我们可以使用二分搜索法通过调用 \\(\\mathcal{O}(n \\log n)\\) 次 \\(A\\) 来找到一条长度为 \\(n\\) 的路径。由于整张图共有 \\(n\\) 个结点，因此我们只需要通过调用 \\(\\mathcal{O}(n^3 \\log n)\\) 次 \\(A\\) 即可找到所有结点对的长度为 \\(n\\) 的路径，也即在多项式时间内求解了哈密顿路径问题（Hamiltonian Path Problem）。 由于哈密顿路径问题是NP-Hard的，因此若该算法存在，则 \\(P=NP\\)。也即K短路问题是NP-Hard的。 根据上面的定理我们可以发现，我们很难找到一个高效的算法来求解K短路问题。因此，若使用\\(A^*\\)算法求解该问题，我们仍然需要枚举结点的指数级跳路径才能找到前K短路径。 在\\(A^*\\)算法中，由于开集中的元素按照代价估计值从小到大排序，因此我们可以通过选中目标状态的次数来依次找到第 \\(2,3,\\cdots,K\\) 短的路径。由于前K短的路径可能包含重叠部分，因此我们不再记录已经搜索过的状态。在一般的图中，这样做可能导致算法重复探索一条路径且无法终止。不过由于本题为一张有向无环图，且其边的数量有限，因此我们可以枚举所有可能的状态，也即算法最终能够终止。 算法实现 由于本题的搜索空间为一张有向图，因此我们使用邻接表的方式来对输入的图进行存储。由于要计算终点到其他各个结点的距离，因此我们在对图进行存储时还需同时存储一张反向图。输入和结构化过程实现如下： 123456789101112131415161718int main()&#123; int n, m, k; vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt; graph, reverse_graph; scanf(&quot;%d %d %d&quot;, &amp;n, &amp;m, &amp;k); graph.resize(n); reverse_graph.resize(n); for(int i = 0; i &lt; m; i++)&#123; int from, to, weight; scanf(&quot;%d %d %d&quot;, &amp;from, &amp;to, &amp;weight); from -= 1; to -= 1; pair&lt;int, int&gt; edge&#123;to, weight&#125;; pair&lt;int, int&gt; reverse_edge&#123;from, weight&#125;; graph[from].push_back(edge); reverse_graph[to].push_back(reverse_edge); &#125; //Irrelevant codes&#125; 根据上面的算法分析，我们使用终点到其他各个结点的实际最短路作为该结点的启发代价。对于单源最短路问题，一个经典的算法便是Dijkstra算法。由于本题无环状路径，因此可以保证这一算法结果的正确性。具体实现如下： 12345678910111213141516171819202122232425262728void get_heuristic(vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt;&amp; _graph, vector&lt;int&gt;&amp; _cost, int _n)&#123; vector&lt;int&gt; vis(_n, 0); int vis_cnt; for(int i = 0; i &lt; _n; i++)&#123; _cost[i] = 10000007; &#125; _cost[0] = 0; vis_cnt = 0; while (vis_cnt &lt; _n) &#123; int candidate_index = 0, candidate_cost = 10000007; for (int i = 0; i &lt; _n; i++) &#123; if (_cost[i] &lt; candidate_cost &amp;&amp; vis[i] == 0) &#123; candidate_index = i; candidate_cost = _cost[i]; &#125; &#125; vis[candidate_index] = 1; vis_cnt += 1; for (int i = 0; i &lt; _graph[candidate_index].size(); i++) &#123; int edge_to, edge_cost; edge_to = _graph[candidate_index][i].first; edge_cost = _graph[candidate_index][i].second; if (_cost[candidate_index] + edge_cost &lt; _cost[edge_to]) &#123; _cost[edge_to] = _cost[candidate_index] + edge_cost; &#125; &#125; &#125;&#125; 随后我们来实现搜索过程中的开集。与上题类似，我们同样使用优先队列在存储开集中的各个状态。为了方便起见，我们同样为状态搜索树中的结点定义一个新的结构，其中存储了该状态对应的图结点号、从初始状态到当前状态的实际代价以及启发代价。随后由于队列中为自定义结构，我们需要覆写序关系的判定函数： 1234567891011121314struct node&#123; int index; int g; int h;&#125;;struct compare_open&#123; bool operator() (node a, node b)&#123; return (a.g + a.h) &gt; (b.g + b.h); &#125;&#125;;int main()&#123; //Irrelevant codes priority_queue&lt;node, vector&lt;node&gt;, compare_open&gt; open_set;&#125; 之后我们使用\\(A^*\\)算法的一般搜索流程实现求解过程即可。当每次目标结点作为最小估计代价结点被弹出开集时，也就意味着找到了一条新的路径，而\\(A^*\\)的路径选择过程保证了这些路径必定是从小到大依次返回的。算法的终止条件为已经找到K条路径或图中所有满足条件的路径均已被探索完毕（也即开集为空）。具体实现如下： 123456789101112131415161718192021int main()&#123; //Irrelevant codes while(path_cnt &lt; k &amp;&amp; !open_set.empty())&#123; node current_node = open_set.top(); open_set.pop(); int current_index = current_node.index; int current_cost = current_node.g; if(current_index == 0)&#123; printf(&quot;%d\\n&quot;, current_cost); path_cnt += 1; &#125; for(int i = 0; i &lt; graph[current_index].size(); i++)&#123; int candidate_index = graph[current_index][i].first; int candidate_cost = current_cost + graph[current_index][i].second; int candidate_heuristic = heuristic_cost[candidate_index]; node candidate_node&#123;candidate_index, candidate_cost, candidate_heuristic&#125;; open_set.push(candidate_node); &#125; &#125; //Irrelevant codes&#125; 测试数据结果 测试数据1 输入 1234567895 8 35 4 15 3 15 2 15 1 14 3 43 1 13 2 12 1 1 输出 123122 测试数据2 输入 12345678910116 10 46 3 26 5 15 4 15 3 15 2 15 1 14 3 43 1 13 2 12 1 1 输出 12342333 测试数据3 输入 12345678910116 10 126 3 26 5 15 4 15 3 15 2 15 1 14 3 43 1 13 2 12 1 1 输出 12345678910111223334478-1-1-1-1 测试数据4 输入 12345678910111213141516178 16 88 7 28 5 28 4 38 2 17 6 27 4 36 3 26 5 15 4 15 3 15 2 15 1 14 3 43 1 13 2 12 1 1 输出 1234567823445677 测试数据5 输入 12345678910111213141516178 16 168 7 28 5 28 4 38 2 17 6 27 4 36 3 26 5 15 4 15 3 15 2 15 1 14 3 43 1 13 2 12 1 1 输出 1234567891011121314151623445677788889910 总结 在本实验中，我们探索了\\(A^*\\)算法的一般性质，并使用\\(A^*\\)算法及其变种解决了小明玩球（八数码问题）和小明爱跑步（K短路问题）两个问题。通过本实验，我们对启发式搜索算法及其相关应用有了更为深入的了解。 References Alexei.I.Kostrikin(张英伯译). 代数学引论(第一卷). 高等教育出版社, 2011. amit. How can i use the a star algorithm to find the first 100 shortest paths? https://stackoverflow.com/questions/14088898/ how-can-i-use-the-a-star-algorithm-to-find-the-first-100-shortest-paths, 2012. Mike Chiang. A* optimality proof, cycle checking. https://www.cs.ubc.ca/~hutter/ teaching/cpsc322/2-Search5.pdf, 2011. Peter E. Hart, Nils J. Nilsson, and Bertram Raphael. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, 4(2):100–107, 1968.","categories":[{"name":"当代人工智能","slug":"当代人工智能","permalink":"http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Artificial-Intelligence","slug":"Artificial-Intelligence","permalink":"http://gonggongjohn.me/tags/Artificial-Intelligence/"}]},{"title":"当代人工智能 课程项目一 文本分类","slug":"contemporary-ai/contemporary-ai-exp-1","date":"2022-03-16T02:00:00.000Z","updated":"2022-12-05T11:56:31.321Z","comments":true,"path":"2022/03/16/contemporary-ai/contemporary-ai-exp-1/","link":"","permalink":"http://gonggongjohn.me/2022/03/16/contemporary-ai/contemporary-ai-exp-1/","excerpt":"","text":"摘要 文本分类是自然语言处理领域中一项十分基本的任务，其在多个领域都有着广泛的应用。在本文中，我们实现了基于 XLNet 预训练语言模型的文本分类模型，并使用微调(Fine-Tuning)的方法对给定数据集进行了文 本分类。通过对验证集的分类效果评估比较，我们得到了适用于当前数据集上最佳的模型超参数组合。随后，我们将模型与其他几种经典文本分类模型(支持向量机、MLP、TextCNN、Bert)的分类效果进行了比较，进一步验证了预训练语言模型和网络构架对文本分类效果的巨大影响。 关键字：文本分类，支持向量机，多层感知机，TextCNN，Bert，XLNet 项目介绍 任务介绍 在本项目中，我们需要实现一种机器学习模型，实现对文本的多分类任务。具体来说，给定一组文本集 \\(\\mathcal{D} = \\{\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\cdots, \\boldsymbol{x}_n \\}\\) 和类别集 \\(\\mathcal{C} = \\{c_1, c_2, \\cdots, c_k \\}\\)，我们需要让机器学习出一种映射 \\(f: \\mathcal{D} \\to \\mathcal{C}\\)，使得对于任意 \\(\\boldsymbol{x} \\in \\mathcal{C}\\)，存在一个 \\(c \\in \\mathcal{C}\\)，使得 \\(f(\\boldsymbol{x}) = c\\)。 数据集介绍 本实验的数据集共分为训练集和测试集两个部分。其中训练集包含了8000条各类别的带标签文本，测试集包含了2000条待预测的不含标签文本。训练集中各类别文本的词云如下图所示。通过词云我们可以大致推断出每个类别的主题，例如Class 0的主题可能为电视剧/电影，Class 1的主题可能为手机应用，Class 2的主题可能为汽车相关产品。这为我们后续的分类结果提供了一个人工的验证标准。 dataset_wordcloud 基准模型 为了评估目标模型的文本分类效果，我们首先需要一组基准模型（Baseline Model）。在本实验中，我们使用了支持向量机、多层感知机、TextCNN以及Bert四种模型作为基准模型。 支持向量机 支持向量机（Support Vector Machine）是一个经典的机器学习分类器，其通过计算最优分隔超平面来对向量空间中线性可分的点进行分类。通过使用核技巧（Kernel Trick），其还可以进一步分隔线性不可分的数据集并取得不错的效果。 由于支持向量机仅作用于向量空间，要使得其能够对文本进行分类，我们就需要先对文本进行嵌入（Embedding）操作，使其能够在向量空间中表示。一个最朴素的方法便是使用计数方法，将词典中每个词在每句话中出现的次数作为句子的表示向量。然而，这样做并不能利用词和词之间的分布特征信息，因此分类效果并不好。一个更为合适的方法是使用所谓的TF-IDF嵌入法。 对于一个文本数据集，词项 \\(t\\) 在文档 \\(d\\) 中的TF-IDF值被定义为 \\[ TF-IDF(t, d) = TF(t, d) \\times IDF(t) \\] 其中 \\(TF(t, d)\\) 为词项 \\(t\\) 在文档 \\(d\\) 中的词频（Term Frequency），\\(IDF(t)\\) 为词项 \\(t\\) 在整个数据集中的逆文档频率（Inverse Document Frequency）。由于测试集中可能出现训练集中不存在的词项，我们对 \\(IDF\\) 引入拉普拉斯平滑（Laplace Smoothing）来给这些不存在的词项一个默认的TF-IDF值，此时的 \\(IDF\\) 计算公式可以写为 \\[ IDF(t) = \\log \\frac{1 + n}{1 + DF(t)} + 1 \\] 其中 \\(n\\) 为文档个数，\\(DF(t)\\) 为词项 \\(t\\) 在数据集中出现的文档数。我们只要对句子中所有的词计算其在数据集中的TF-IDF值，即可得到该句子的TF-IDF向量表示。 在本实验中，我们使用了机器学习包Scikit-Learn提供的SVC（SVM Classifier）类实现了文本分类模型。对于核技巧，我们使用了高斯核（Gaussian Kernel）作为核函数，也即 \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) = = \\exp \\left( - \\gamma || \\boldsymbol{x} - \\boldsymbol{y} ||^2 \\right) \\] 该核函数被广泛地用于向量空间的特征分离任务中并通过能取得不错的效果。通常情况下，我们需要使用网格搜索（Grid Search）的方法来确定核函数中的超参数 \\(\\gamma\\)，然而当我们无法确定合理的参数范围时，搜索空间可能会变得十分庞大。由于从直观上看，高斯核中的参数 \\(\\gamma\\) 表征了数据集在向量空间中的分散程度，因此一个更为合理的方法便是使用数据集本身的方差来决定该超参数，也即 \\[ \\gamma = \\frac{1}{n_{feature} \\cdot Var(\\boldsymbol{X})} \\] 其中 \\(n_{feature}\\) 为数据集的特征维度，\\(Var(\\boldsymbol{X})\\) 为数据集的方差。这也是我们的实现中所使用的超参数决定方法。 多层感知机 多层感知机（Multilayer Perceptron）又称为前向全连接神经网络（Feedforward Fully-Connected Neural Network），是一种经典的深度学习网络构架。通过多个隐藏层对输入数据中不同粒度特征的提取，其就可以实现对数据的分类。感知机由一个个神经元构成，其单个神经元结构如下图所示。 fcnn_neuron 将多个神经元一层层地连接起来，便构成了多层感知机。对于当前数据集和任务，我们设计的神经网络结构如下图所示。对于输入层，我们同样使用上述SVM模型中提到的TF-IDF嵌入法得到句子的向量表示。经过统计，训练集中不同的词项个数共有 \\(29999\\)个，因此我们将输入层的神经元个数设置为 \\(29999\\)。随后，我们使用两层隐藏层结构来增加网络的非线性拟合能力，其神经元个数分别为 \\(64\\) 和 \\(32\\) 。最后，由于我们有 \\(10\\) 个文本类别，因此输出神经元个数设置为 \\(10\\)。 fcnn_structure 我们选择了ReLU（Rectified Linear Unit）作为当前网络的隐藏层激活函数。对于最后的分类结果，我们使用Softmax函数将其放缩为 \\((0,1)\\) 之间的概率值，其定义如下： \\[ \\textrm{Softmax}(\\boldsymbol{x}_i, \\{\\boldsymbol{x}_1, \\cdots, \\boldsymbol{x}_n \\}) = \\frac{e^{\\boldsymbol{x}_i}}{\\sum_{j = 1}^n e^{\\boldsymbol{x}_j}} \\] 相应的，我们选择了交叉熵损失（CrossEntropyLoss）作为当前任务的损失函数，其定义为 \\[ \\mathcal{H}(\\boldsymbol{y}^{pred}, \\boldsymbol{y}^{true}) = - \\sum_{i = 1}^n y^{true}_i \\log y^{pred}_i \\] 。 神经网络通常使用反向传播（Backward Propagation）算法来对网络进行训练，其具体细节在此不再赘述。我们选择了AdamW优化器作为当前网络的优化器。AdamW作为Adam优化器的改进版本，相比随机梯度下降（Stochastic Gradient Descent）算法能够自适应地调整梯度下降的速率，并能够从一定程度上对抗网络落入局部最低点（Local Minima）的情况发生。而相比Adam，AdamW通过一种改进的实现方法解决了其正则化难以收敛的问题，使得网络参数能够更快地收敛到预期的位置。在超参数的设置上，我们通过网格搜索的方式对学习率（Learning Rate）进行了搜索，并最终确定学习率 \\(lr = 0.01\\)。对于迭代次数，我们发现当网络迭代10次后 网络的损失不再出现明显的下降，因此我们设置迭代次数 \\(epoch=10\\)。 TextCNN 受到Word2Vec等词嵌入方法和图像处理任务中卷积方法的启发，Yoon Kim等人于2014年提出了用于文本分类的TextCNN方法。TextCNN方法本质上是一个N-Gram语言模型，这一方法将句子的词向量嵌入矩阵视为一个一维的特征图，通过使用多个不同大小的一维卷积核在词向量矩阵上做滑动，就可以获得句子中不同粒度上的语言特征。 textcnn_illustrate 通常来说，TextCNN由嵌入层（Embedding Layer）、卷积层（Convolutional Layer）、池化层（Max-Pooling Layer）和全连接层（Fully-Connected Layer）组成，其中所有的权重参数都会从数据集中学习得到。然而，由于当前任务中数据集规模并不大，网络可能会出现难以收敛或过拟合的问题。受到图像处理任务中迁移学习（Transfer Learning）方法的启发，我们使用一个经过预训练的词嵌入词典来直接作为嵌入层的输出，这样网络在初始化时，每个词的语义关系就能够被明确，网络也能够快速找出合适的分类特征。在当前项目中，我们使用了经过无监督预训练的GloVe通用词向量词典来对文本进行词嵌入。该词典使用Common Crawl数据集进行无监督训练，共包含了190万个词项，嵌入维度为300维，具有足够的通用性和较为合适的特征大小。 对于网络构架，我们参考了Ye Zhang等人的结果，使用了大小分别为2、3、4的卷积核，每种卷积核各有16个。随后，我们使用和多层感知机相同的ReLU作为激活函数，并通过池化核大小为 \\(l_{sentence} - l_{kernel} + 1\\) 的池化层将其每个特征特征压缩至1个神经元内（其中 \\(l_{sentence}\\) 为句子长度，\\(l_{kernel}\\) 为卷积核大小）。最后，通过将这些特征神经元进行拼接并通过一层全连接层，网络即可输出文本的分类概率结果。 为了保证基准模型的公平性，我们将损失函数及优化器设置与上文中的多层感知机保持一致。对于迭代次数，我们发现当网络迭代20次后损失不再出现明显的下降，因此我们设置迭代次数 \\(epoch=20\\)。 Bert 随着语言模型（Language Model）和Transformer架构的提出，预训练（Pretrain）+微调（Finetune）方法逐渐成为了自然语言处理任务中的主流。其中最为经典的就是Google于2018年提出的Bert（Bidirectional Encoder Representation from Transformers）模型。 Bert模型是一个自编码语言模型（Autoencoder Language Model），其网络构架如下图所示。Bert的主体由多个Transformer结构组成，网络首先接受一串由词项和特殊标识符（CLS、SEP）经过嵌入得到的句子向量，并使用Transformer构架计算句子的语言特征，得到一串同等长度的语言特征向量。通过将网络的输出与下游的网络结构相连接，我们就可以使用Bert模型进行各种自然语言处理任务。对于当前文本分类任务，我们只需要使用网络输出中的第一项（即CLS标识符的特征表示），并将其连接至一个全连接层即可得到文本的概率分类结果。 bert_classify 我们使用了Google提供的bert-base-uncased预训练模型作为网络构架及初始化参数，这一构架包含12个Transformer模块，每个Transformer模块中包含12个自注意力头以及一个维度为768的全连接层（共110万网络参数），并同样使用了AdamW作为网络的优化器。由于微调训练通常具有较小的网络梯度，我们将学习率设置为了 \\(lr=5e-5\\)。 XLNet文本分类器 XLNet是Google于2019年提出的一种对Bert的改进模型。通过融合GPT中使用的自回归语言模型（Autoregressive Language Model）和Bert中使用的自编码语言模型并引入更多的构架改进，XLNet在许多下游任务中都获得了十分出色的表现，也是我们在当前实验中最终使用的文本分类模型。 模型构架 XLNet的整体模型构架与Bert模型类似，其都由多组Transformer模块组成。然而，XLNet在进行预训练时的逻辑和Bert有很大的不同，其使用的自回归语言模型相比Bert可以解决其预训练/微调时的数据分布不一致的问题。而通过引入轮换语言模型（Permutation Language Modeling），XLNet就能够在自回归语言模型中保留Bert中的双向语义视野的能力。为了在网络结构中实现这一点，XLNet在实现自注意力层时也使用了不同的方法，其基本构架如下图所示。可以看到，在实际实现过程中，XLNet并没有真正的对文本进行轮换，而是使用了掩盖（Masking）的方法来使得网络在预训练时无法得到目标词项的词义信息。 xlnet_architecture 模型实现 由于该模型的实现细节较多且不是本文的重点，我们直接使用了HuggingFace提供的transformers工具包中所实现的XLNet模型。对于网络构架和参数，我们使用了HuggingFace提供的xlnet-large-cased进行初始化。相比xlnet-base-cased以及Bert的同级别模型，XLNet Large网络使用了更多的数据进行预训练，使得网络的语言特征捕捉能力得到了进一步的提升，其更大的网络结构（340万网络参数）也保证了网络足够的泛化能力，使得其不会出现过拟合的情况。 与使用Pytorch训练其他模型时一致，我们需要定义一个数据集对象（Dataset）来作为训练及测试时的数据源。在数据集初始化中，我们首先使用封装好的XLNetTokenizer对象对文本进行词条化及文本嵌入。通过对数据集的检查，我们发现当前数据集中文本的最大长度约为257个词项，因此我们将文本截断/补全长度设置为了256，这也作为了网络的输入尺寸。随后，通过覆写相应的数据集方法，我们就能得到一个可用的文本数据集对象。具体代码片段如下：（utils.py） 123456789101112131415161718192021222324252627282930from transformers import BertTokenizer, XLNetTokenizerfrom torch.utils.data import Datasetclass TextDatasetForTrainer(Dataset): def __init__(self, source_df, model_type): self.model_type = model_type if model_type == &#x27;bert&#x27;: self.tokenizer = BertTokenizer.from_pretrained(&#x27;bert-base-uncased&#x27;) elif model_type == &#x27;xlnet&#x27;: self.tokenizer = XLNetTokenizer.from_pretrained(&#x27;xlnet-large-cased&#x27;) if &#x27;label&#x27; in source_df: self.mode = &#x27;paired&#x27; self.labels = [label for label in source_df[&#x27;label&#x27;]] else: self.mode = &#x27;unpaired&#x27; self.texts = [self.tokenizer(text, padding=&#x27;max_length&#x27;, max_length=256, truncation=True, return_tensors=&#x27;pt&#x27;) for text in source_df[&#x27;text&#x27;]] def __len__(self): return len(self.texts) def __getitem__(self, index): item_dict = self.texts[index] if self.model_type == &#x27;xlnet&#x27; or self.model_type == &#x27;bert&#x27;: item_dict[&#x27;attention_mask&#x27;] = item_dict[&#x27;attention_mask&#x27;].squeeze(0) item_dict[&#x27;input_ids&#x27;] = item_dict[&#x27;input_ids&#x27;].squeeze(0) item_dict[&#x27;token_type_ids&#x27;] = item_dict[&#x27;token_type_ids&#x27;].squeeze(0) if self.mode == &#x27;paired&#x27;: item_dict[&#x27;labels&#x27;] = torch.tensor(self.labels[index]) return item_dict transformers包中提供了一组统一的模型训练调度器，我们可以直接通过创建训练器对象并传入相关参数来对模型进行训练。在TrainingArguments对象中，我们可以定义网络训练时的各种属性及网络、优化器的各种超参数。我们只需要将配置好的TrainingArguments对象传递给Trainer对象，即可开始对网络进行训练、评估和预测操作。相关代码片段如下：（xlnet_train.py） 123456789101112131415161718192021222324from transformers import Trainer, TrainingArgumentstrain_args = TrainingArguments( output_dir=&#x27;output&#x27;, evaluation_strategy=&#x27;epoch&#x27;, save_strategy=&#x27;no&#x27;, eval_steps=50, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, gradient_accumulation_steps=1, num_train_epochs=epoch, seed=0, logging_strategy=&#x27;step&#x27;, logging_steps=64, # Other parameters to set)trainer = Trainer( model=model, args=train_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics=compute_metrics)trainer.train() 超参调优 Batch Size 首先我们来确定训练时的Batch Size。在使用随机梯度下降类算法对网络进行优化时，Batch Size往往决定了网络的收敛速度及泛化能力，过小的Batch Size可能导致网络难以收敛（Loss波动剧烈），而过大的Batch Size可能导致网络落入Sharp Minima，使其泛化能力降低（Loss无法降低）。在当前数据集上，不同Batch Size在训练时的Loss变化及在验证集上的正确率表现如下图所示。我们发现，当 \\(Batch Size &gt; 16\\) 时，Training Loss就可以表现的较为稳定；而在相同的迭代次数下，\\(Batch Size = 64\\) 时网络获得了最好的Training Loss表现。 batchsize_loss_acc 可以发现，由于XLNet模型本身的语言特征捕捉能力及预训练的存在，Batch Size本身对网络的表现影响并不明显。然而在实际应用场景下中，我们还需要考虑训练模型时的资源消耗情况。在使用了梯度累计（Gradient Accumulation）技巧时，显存占用随Batch Size的增长情况如下图所示。随着Batch Size的增长，训练XLNet时的显存占用急剧增长，在Batch Size=128时显存占用甚至达到了近50GB，这一资源消耗代价在平日的应用场景下显然是难以接受的。 gpu_mem 综合上面两种因素考虑，我们将训练时的Batch Size确定为64（或Batch Size=32 + Gradient Accumulation=2）。 学习率 由于我们使用了AdamW作为网络的优化器，因此每个参数的学习率（Learning Rate）会随着梯度的变化而不断发生变化。尽管如此，我们仍然需要决定一个整体学习率以确定各个参数学习率的变化尺度（由于后文所要介绍的学习率调度器的存在，这一学习率实际上为一个初始化学习率）。在当前数据集上，训练时的Loss随学习率的变化情况如下图所示（使用相同的学习率调度器）。可以看到，当学习率过大时，Loss的变化幅度巨大且难以收敛，而当学习率过小时，尽管Loss能够很快达到一个较低的水平，但由于每次优化幅度过小，使得其最终也难以收敛到一个较为合适的水平。 loss_lr 根据实验结果，最终我们将学习率设定为了5e-5。 学习率调度器 在训练较为庞大的神经网络模型时，我们通常会在训练的不同阶段赋予优化器不同的基准学习率，这就需要一个较为合适的学习率调度器（Learning Rate Scheduler）。常用的学习率调度器包含恒定调度器、线性调度器、指数调度器、阶梯形调度器等，其对于学习率的影响如下图所示。可以看到，优化器的学习率在不同学习率调度器的控制下所表现出的变化情况呈现出不同的特征。 scheduler_lr 在实际的实验过程中，由于AdamW优化器本身的特性，学习率调度器对训练时Loss的变化影响及模型在验证集上的预测正确率并没有显著的影响。最终我们使用线形（Linear）调度器作为训练过程中的学习率调度器。 迭代次数 最后我们来确定训练时的迭代次数（Iterations）。通常来说，对于预训练语言模型的微调任务，我们会使用一个较小的迭代次数以防止其过拟合。在当前数据集上，训练时的Loss及模型在验证集上的分类正确率表现如下图所示。可以发现，当 \\(epoch&lt;4\\) 时，网络在验证集上的正确率表现快速提升，而当 \\(epoch &gt; 4\\)时，其正确率表现不再出现明显的提升，甚至开始出现下降。 epoch_loss_acc 因此，我们将训练时的迭代次数设定为4。 交叉验证 在验证机器学习模型时，模型的表现有很大一部分来自于数据集本身。若使用常规的方法固定的划分训练集和验证集，则可能会造成模型的表现带有偏向性（Bias）。因此，我们通常会使用交叉验证（Cross Validation）的方式来验证模型的性能。 交叉验证通常有两种方法。一种被称为留一法（Leave-one-out Cross Validation），这种方法的问题在于每次验证集只有一个数据，若数据集规模很大，则需要循环迭代大量的次数。一个更常用的方法被称为K-折交叉验证（K-Fold Cross Validation），其流程如下图所示（Figure ）。具体来说，我们将所有数据集分成K份，每次取其中一份作为验证集，其他的作为训练数据，依次对模型进行训练和测试，得到 \\(K\\) 个验证集上的评价指标。 cross_val 随后，我们使用取平均值的方式得到最终的模型评价指标 \\[ Score = \\frac{1}{K} \\sum_{i = 1}^K Score_i \\] Scikit-Learn提供了一个K-折交叉验证的数据集索引生成器，我们可以直接利用其来完成这一工作。这里我们选择 \\(K = 5\\)。具体实现如下： 1234567891011121314151617181920from sklearn.model_selection import KFoldimport numpy as npkf = KFold(n_splits=5, shuffle=True)accuracy_list, precision_list, recall_list, f1_list = [], [], [], []fold_cnt = 0for train_index, test_index in kf.split(data_df): fold_cnt += 1 train_df = data_df.iloc[train_index] val_df = data_df.iloc[test_index] # Irrelevant codes accuracy_list.append(eval_metrics[&#x27;eval_accuracy&#x27;]) precision_list.append(eval_metrics[&#x27;eval_precision&#x27;]) recall_list.append(eval_metrics[&#x27;eval_recall&#x27;]) f1_list.append(eval_metrics[&#x27;eval_f1&#x27;])accuracy_cross = np.array(accuracy_list).mean()precision_cross = np.array(precision_list).mean()recall_cross = np.array(recall_list).mean()f1_cross = np.array(f1_list).mean()print(&#x27;Average: Validation Accuracy: &#123;0&#125;, Precision: &#123;1&#125;, Recall: &#123;2&#125;, F1: &#123;3&#125;&#x27;.format(accuracy_cross, precision_cross, recall_cross, f1_cross)) 效果对比 我们使用Scikit-Learn及Pytorch工具包实现了本文中提到的各个模型，并使用上述的5折交叉验证方法对模型的分类效果进行了评估（具体代码请参考随附的README.md说明文档）。各个模型在训练集上的5折交叉验证结果如下表所示。可以看出，经过超参调优的XLNet模型在各个指标上均取得了所有模型中最好的分类表现，Bert和多层感知机模型的表现紧随其后，而传统的SVM分类器和TextCNN模型的表现则较为落后。 evaluation_score 进一步的，各个模型在各折验证结果中的正确率变化如下图所示。可以看出，基于传统机器学习和通用深度学习方法的分类模型在验证集上的正确率波动较大，而基于预训练+微调的语言模型分类方法则有着较好的稳定性。 models_acc_fold 最后，我们使用所有模型中效果最好的经过调优的XLNet模型对目标测试集进行了文本类别预测，其结果可见随附的test_output.txt文件。 总结 在本实验中，我们实现了基于XLNet语言模型的文本分类器，并对其各个超参数进行了调优使其在验证集上得到较好的效果。随后，我们将其与其他几种经典文本分类模型的分类效果进行了对比，探索了几种不同的文本分类模型的特征及其在目标数据集上的表现。最后，我们使用训练完成的文本分类模型对目标测试集进行了标签预测，达到了预期的实验要求。 References Bernhard E. Boser, Isabelle M. Guyon, and Vladimir N. Vapnik. A training algorithm for optimal margin classifiers. In Proceedings of the Fifth Annual Workshop on Com- putational Learning Theory, COLT ’92, page 144–152, New York, NY, USA, 1992. Association for Computing Machinery. Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning, 20(3):273–297, 1995. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre- training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Com- putational Linguistics. Ben Dickson. What are artificial neural networks (ann)? https://bdtechtalks. com/2019/08/05/what-is-artificial-neural-network-ann/, 2019. Yoon Kim. Convolutional neural networks for sentence classification. In Proceed- ings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751, Doha, Qatar, October 2014. Association for Computa- tional Linguistics. Scikit learn Developers. Cross-validation: evaluating estimator performance. https://scikit-learn.org/stable/modules/cross_validation.html, 2021. Scikit learn Developers. Feature extraction. https://scikit-learn.org/stable/ modules/feature_extraction.html, 2021. Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. ArXiv, abs/1711.05101, 2017. Katherine (Yi) Li. How to choose a learning rate scheduler for neural networks. https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler, 2021. Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, 2014. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45, Online, October 2020. Association for Computational Linguistics. Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. Xlnet: Generalized autoregressive pretraining for language understanding. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Gar- nett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. Ye Zhang and Byron C. Wallace. A sensitivity analysis of (and practitioners’guide to) convolutional neural networks for sentence classification. In IJCNLP, 2017.","categories":[{"name":"当代人工智能","slug":"当代人工智能","permalink":"http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Artificial-Intelligence","slug":"Artificial-Intelligence","permalink":"http://gonggongjohn.me/tags/Artificial-Intelligence/"}]},{"title":"数据科学与工程算法基础 文本摘要实验","slug":"machine-learning/dase-alg-exp-summary","date":"2021-12-24T03:00:00.000Z","updated":"2022-03-06T15:03:20.128Z","comments":true,"path":"2021/12/24/machine-learning/dase-alg-exp-summary/","link":"","permalink":"http://gonggongjohn.me/2021/12/24/machine-learning/dase-alg-exp-summary/","excerpt":"","text":"摘要 文本摘要是自然语言处理中一个十分重要的任务，一个好的摘要可以通过少量的文字很好地概括一段长文的核心内容，帮助读者快速理解文章的意思。当前，对于文本摘要任务，其方法大致可分为抽取式（Extractive）和生成式（Generative）两种，而其中前者由于拥有语句级的语法完整性，已经被广泛的应用于各种应用场景下。在抽取式文本摘要中，一种经典的方法是将其转化为最大集合覆盖问题，并采用子模函数（Submodular Function）的方法进行求解。本文详细推导并实现了基于爬山算法的文本抽取方法，讨论了一系列优化及其变体算法，并用其对同一主题下的20段论文语料进行了抽取式文本摘要。随后，我们还将其与另一种经典的抽取式文本摘要方法TextRank进行了对比，比较了两者的适用场景和异同。 关键字：文本摘要，集合覆盖，子模函数，爬山算法，TextRank Text summarization is an important task in natural language processing. A good summary can summarize the crucial content of a long article with a small amount of text and help readers quickly understand the meaning of the article. Currently, the methods for text summarization task can be roughly divided into two types: Extractive and Generative. The former has been widely used in various application scenarios due to its sentence-level grammatical integrity. A classic method in extractive text summarization is to convert it into a maximum coverage problem and use the submodular function method to solve it. In this paper, we derived and implemented the extractive text summarization method based on hill climbing algorithm in detail, discussed a series of optimization and its variant algorithms, and used it to extract text summaries from a corpus of 20 papers under the same topic. Moreover, we compared it with another classic extractive text summarization method —— TextRank, and compared the application scenarios and similarities and differences of the two. Keywords: Text summarization, Set coverage, Submodular function, Hill-climbing algorithm, TextRank 项目概述 自动文本摘要是自然语言中一个十分重要的任务。这项任务要求我们从一个给定的文本语料（通常拥有较大的文本长度）中生成一段短文本，并使得其能够最大程度上表达原文本的含义。现阶段的文本摘要方法主要分为抽取式和生成式两类。其中，固定长度的抽取式文本摘要可以看作是一个最大K-子覆盖（Maximum K-Coverage Problem），因此我们可以使用组合优化的方法来对其进行求解。本项目要求我们实现一种基于最大K-子覆盖问题的抽取式文本摘要算法，通过其一个从互联网上爬取的语料库中抽取100句话作为其文本摘要，并对摘要的性能进行分析。 问题描述 使用最大集合子覆盖问题的语言对抽取式文本摘要问题的描述如下： 给定一个语料库 \\(D = \\{s_1, s_2, \\cdots, s_n \\}\\)，其中 \\(s_i(i \\in \\{1,2,\\cdots, n\\})\\) 为单个句子，我们设其概念单元为 \\(C = \\{c_1, c_2, \\cdots, c_m\\}\\)，其中 \\(c_i (i \\in \\{1,2,\\cdots, m\\}\\) 为关键词。抽取式文本摘要的目标是寻找一个子集 \\(S \\subset D\\)（其中 \\(|S| \\leq K\\)），使其能够覆盖的概念单元 \\(|C&#39;|(C&#39; \\subset C)\\) 尽可能的多。若使用优化的语言，则该问题可以写为 \\[ \\begin{aligned} &amp;\\textbf{maximize} &amp;|C&#39;| \\\\ &amp;\\textbf{s.t} &amp;|S| \\leq K \\end{aligned} \\] 事实上，我们可以通过指示器变量（Indicator Variable）更具体的刻画这一问题。若设 \\(x_i(i \\in \\{1, \\cdots, n\\})\\) 为语句选择的指示器变量，\\(a_{ij}(j \\in \\{1, \\cdots, m\\})\\) 为关键词选择的指示器变量，也即 \\[ \\begin{aligned} &amp;x_i = \\left\\{ \\begin{aligned} 1, s_i \\in S \\\\ 0, s_i \\notin S \\end{aligned} \\right. , \\quad &amp;a_{ij} = \\left\\{ \\begin{aligned} 1, c_j \\in s_i \\\\ 0, c_j \\notin s_i \\end{aligned} \\right. \\end{aligned} \\] 则原问题还可以写为 \\[ \\begin{aligned} &amp;\\textbf{maximize} &amp;\\left|\\left\\{j \\Big| \\sum_{i = 1}^n a_{ij} x_i \\geq 1\\right\\}\\right| \\\\ &amp;\\textbf{s.t} &amp; \\sum_{i = 1}^n x_i \\leq K, x_i \\in \\{0, 1\\} \\end{aligned} \\] 可以看出，这是一个带有背包限制的最大集合子覆盖问题（MCKP，Maximum Coverage Problem with Knapsack Constraint）。 数据集描述 为了比较文本摘要算法的性能和效果，我们需要一个相应的语料库。在本文中，我们使用了同一主题下的论文文本作为语料库，论文摘要作为单文档文本摘要的关键词集合，并将一篇同主题下的综述性论文作为多文档文本摘要的关键词集合。具体的，我们爬取了预印本网站Arxiv中计算机视觉和模式识别（Computer Vision and Pattern Recognition, cs.CV）主题下的20篇有关目标检测（Object Detection）的论文，并将其作为目标语料库。此外，我们使用了发表于期刊Computer Science Review上的一篇关于目标检测的综述性论文作为多文档文本摘要的目标关键词集。 数据集获取 我们首先来对论文数据进行爬取。论文爬取的过程分为两步，第一步我们搜索所有满足条件的候选论文的相关信息（标题、类别、论文编号等），第二步我们下载论文的实际数据（PDF源码等资源）。 Arxiv提供了一个可以按主题查看最近一周论文的网页界面（https://arxiv.org/list/cs.CV/pastweek），因此我们首先对该网页进行分析。论文列表网页的HTML元素布局如下图所示： 可以看到，对于一个论文信息显示块，其论文编号、论文标题、作者、主题分类被分别放置在标记为Abstract、list-title mathjax、list-authors和list-subjects的HTML元素块里。 我们使用Python自带的requests模块对网站发起请求，拉取其页面的HTML字符串，并使用社区开发者提供的BeautifulSoup模块对HTML的DOM结构进行解析，取出上述的元素。随后，我们将标题中带有“Object”和“Detection”两个关键词（不区分大小写）的论文取出，作为我们候选语料库文档。筛选的部分结果如下图所示： 得到了论文编号后，我们就可以对论文的各种元数据（MetaData）进行获取。我们可以通过解析https://arxiv.org/abs/{arXiv_ID}获得论文的摘要，通过{https://arxiv.org/pdf/{arXiv_ID}下载其PDF文档，通过https://arxiv.org/e-print/{arXiv_ID}下载其原始资源，在此不再赘述。 事实上，Arxiv本身提供了一个可供程序访问的论文资源获取的API（实现完才发现QAQ）。我们只需要使用布尔查询表达式（Boolean Query Expression）即可获得相应的论文结果。社区开发者对其接口请求和数据格式进行了封装，因此在Python我们只需直接引入arxiv包即可发起查询并获得论文的标题、摘要、PDF文档及原始文档（Latex文本及图片等源文件）等资源。 同样的，我们使用该API实现了自动爬取论文源数据的相关代码，并获得了最终的语料库。 文本预处理 文本提取 得到了原始的论文文档后，我们需要对文档集进行整理和清洗，抽取出语料库，并对文本进行预处理。 我们首先尝试使用Pdfminer模块直接对论文的PDF文档进行分析，通过关键字的方式对文本进行抽取，结果如下图所示： 。可以看到，由于PDF是以矢量图的方式对元素进行排布，其排布并不完全按照视觉上的排布顺序，因此该方法并不能准确的抽取出文档中的相应文本。 事实上，我们可以通过对PDF文档进行版面分析（Layout Analysis）的方式提取论文的原始文本，但这一做法就导致不确定因素更多，使问题变得更为复杂，因此我们不做考虑。 幸运的是，Arxiv提供了论文源文件的下载地址，这也就意味着我们可以直接获取到论文的Latex源代码。因此，我们只需要直接从Latex文档中对纯文本进行抽取即可。Latex是一种标准化的排版工具，我们可以通过声明式的代码语言在一个Latex文档中插入各种元素。由于我们只需要对其中的纯文本进行分析，因此这些元素在当前的任务下是多余的。这时，我们就需要使用正则表达式对其进行替换。例如，对于\\cite{}，我们就可以使用正则表达式 \\\\cite\\{(.*?)\\}将其匹配出来。 方法 朴素枚举法 贪心算法（爬山算法） 带权的贪心算法 Stack Encoding TextRank 实验结果 最后，我们从摘要质量和摘要推理时间两个方面来对上面的方法进行分析。 对于摘要质量，我们自然的可以想到使用关键词覆盖率作为其评价指标。沿用上面的记号，若我们将抽取出的概括文本 \\(S\\) 看作词项的集合，则覆盖率被定义为 \\[ Coverage = S \\cap C \\] 。对于文本摘要任务，一个常用的评价指标被称为ROUGE-N（Recall-Oriented Understudy for Gisting Evaluation-N），其定义为 \\[ ROUGE-N = \\frac{|N-Gram_{Extracted} \\cap N-Gram_{Reference}|}{|N-Gram_{Reference}|} \\] ，也即抽取的摘要中匹配的N-Gram数除以标准摘要中的N-Gram总数。从定义中我们可以发现，ROUGE-N通常需要一个参考的摘要文本才能计算，而这里我们并没有这样的文本。不过，由于我们有目标关键字，而这可以视作一种1-Gram，因此我们仍然可以计算ROUGE-1的值。 结论 在本实验中，我们首先从集合覆盖的角度分析了抽取式文本摘要问题，并将其转化了为了一个MCKP问题。由于该问题是一个NP-Hard问题，我们无法在可接受的时间内用朴素搜索算法求解出精确解。随后，我们实现了基于贪心算法的最大子覆盖算法，并用其实现了抽取式文本摘要。进一步的，我们对贪心算法实现了一系列的改进，包括考虑文本的权重，以及使用队列的方式进行聚合搜索。最后，我们实现了经典的TextRank算法，并将其与前面的算法进行了比较。 我们可以很容易的发现，基于最大子覆盖的文本摘要算法能够更好的贴合目标关键字，但其语义连贯性明显不如TextRank算法。这就意味着当我们有一个好的关键词集合或面对多文档摘要场景时，我们可以使用基于最大子覆盖问题的文本摘要算法。而在实际应用场景或单文本的摘要场景下，我们更倾向于使用TextRank等基于语义的文本摘要算法。 通过本实验，我们对抽取式文本摘要任务和子模函数、最大K-子覆盖问题有了更深入的了解。","categories":[{"name":"数据科学算法基础","slug":"数据科学算法基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"http://gonggongjohn.me/tags/Machine-Learning/"}]},{"title":"数据科学与工程算法基础 PCA实验","slug":"machine-learning/dase-alg-exp-pca","date":"2021-11-29T02:00:00.000Z","updated":"2022-02-12T10:16:50.056Z","comments":true,"path":"2021/11/29/machine-learning/dase-alg-exp-pca/","link":"","permalink":"http://gonggongjohn.me/2021/11/29/machine-learning/dase-alg-exp-pca/","excerpt":"","text":"摘要 图像压缩一直是图像处理中一个重要的任务，一个好的图像压缩算法可以大大降低存储和传输代价。主成分分析（Principal Component Analysis）作为一个经典的降维方法，已经在图像压缩领域得到了极为广泛的运用。在本文中，我们从主成分分析的原理出发，导出并实现了基于特征分解的朴素PCA算法，并使用奇异值分解方法对其计算进行了优化。随后，我们实现了更适合图像处理的2DPCA、其改进方法2D-2DPCA。此外，我们还实现了基于核方法的Kernel PCA来进一步提升主成分的表达能力，并对比了多种不同的核函数下图像的压缩效果。进一步的，我们尝试使用了较为现代的基于神经网络的GHA（Generalized Hebbian Algorithm）算法来迭代得到主成分。最后，我们将实现的结果与时下较为常用的基于离散余弦变换的JPEG图像压缩算法进行了对比。 关键字：图像压缩，主成分分析，核方法，感知机，余弦变换 Image compression has long be a fundamental task in image processing, a good image compression algorithm can massively reduce the cost of storage and transmission. As a classic dimension reduction algorithm, Principle Component Analysis has been widely used in the field of image compression. In this article, we derive and implement the naive PCA algorithm based on eigenvalue decomposition, and use the singular value decomposition method to optimize its calculation. Subsequently, we implemented 2DPCA and its improvement version 2D-2DPCA, which is more suitable for image processing. In addition, we implemented Kernel PCA based on the kernel method to further improve the expression ability of principal components, and compared the compression effects of images under a variety of different kernel functions. Further, we tried to use a more modern neural network-based GHA (Generalized Hebbian Algorithm) algorithm to iteratively obtain the principal components. Finally, we compared the achieved results with the contemporary mainstream JPEG image compression algorithm which is based on discrete cosine transform. Keywords: Image compression, Principle component analysis, Perceptron, Cosine transformation 项目概述 主成分分析（Principal Component Analysis）可以用来减少矩阵（图像）的维度，并将这些新的维度投射到图像上，使其保留质量。本项目要求我们使用PCA方法及其变体，对3组图像（每组包含100张图像）进行压缩，并对图像压缩的性能进行分析。 问题描述 一张\\(8\\)位三通道（RGB）正方形彩色图片可视为三个 \\(N\\) 维矩阵 \\(\\boldsymbol{X}\\)，其中 \\(x_{ij} \\in \\{0,1, \\cdots, 255\\}\\)，其存储代价为 \\(b\\)。图像压缩的目标即为寻找一个映射 \\(\\mathcal{Q}\\)，使得 \\(\\mathcal{Q}(\\boldsymbol{X}) \\in \\mathbb{R}^{k \\times n}(k \\ll n), \\mathcal{Q}^{-1} (\\mathcal{Q}(\\boldsymbol{X})) \\approx X\\)，且存储 \\(\\mathcal{Q} (\\boldsymbol{X})\\) 和 \\(\\mathcal{Q}^{-1}\\) 所需的空间 \\(\\tilde{b} \\ll b\\)。 方法 朴素PCA PCA的主要思想是通过将一个高维样本 \\(\\boldsymbol{x} \\in \\mathbb{R}^n\\) 左乘一个正交矩阵 \\(\\boldsymbol{Q} \\in \\mathbb{R}^{k \\times n}(k \\ll n)\\)，使得其映射到一个较低维的超平面 \\(\\boldsymbol{Q x} \\in \\mathbb{R}^k\\) 上，同时又保证多个数据点映射后的统计性质保持不变。具体来说，这样的超平面要具有如下的性质： 最近重构性：样本点到这个超平面的距离足够近 最大可分性：样本点在这个超平面上的投影尽可能分开 由此，我们就有两种角度来求解这一正交矩阵。事实上，在中心化条件下，这两者是等价的。这是由于有如下定理保证： Theorem: 对于中心化数据集 \\(\\{\\boldsymbol{x}^{(i)}\\}_{i = 1}^N\\)，最小化重构距离等价于最大化投影方差 Proof: 这里仅证明投影到一维时的情形，高维时的情况可自然推广 设投影直线的方向向量为 \\(\\boldsymbol{v}\\)，其中 \\(||\\boldsymbol{v}||^2 = 1\\) 则由勾股定理可知，\\(||\\boldsymbol{x}^{(i)} - \\boldsymbol{v^T} \\boldsymbol{x}^{(i)}\\boldsymbol{v}||^2 = ||\\boldsymbol{x}^{(i)}||^2 - \\left(\\boldsymbol{v}^T \\boldsymbol{x}^{(i)}\\right)^2\\) 于是 \\(\\boldsymbol{v}\\) 的最优解 \\[ \\begin{aligned} \\boldsymbol{v}^* &amp;= \\mathop{\\arg\\min}_{\\boldsymbol{v}: ||\\boldsymbol{v}||^2 = 1} \\frac{1}{N} \\sum_{i = 1}^N ||\\boldsymbol{x}^{(i)} - \\boldsymbol{v^T} \\boldsymbol{x}^{(i)}\\boldsymbol{v}||^2 \\\\ &amp;= \\mathop{\\arg\\min}_{\\boldsymbol{v}: ||\\boldsymbol{v}||^2 = 1} \\frac{1}{N} \\sum_{i = 1}^N \\left( ||\\boldsymbol{x}^{(i)}||^2 - \\left(\\boldsymbol{v}^T \\boldsymbol{x}^{(i)}\\right)^2 \\right) \\\\ &amp;= \\mathop{\\arg\\max}_{\\boldsymbol{v}: ||\\boldsymbol{v}||^2 = 1} \\frac{1}{N} \\sum_{i = 1}^N \\left(\\boldsymbol{v}^T \\boldsymbol{x}^{(i)}\\right)^2 \\end{aligned} \\] 也即最小化重构距离与最大化投影方差等价 这里我们通过最大化投影方差的方法来求解。 我们知道，对于一个中心化矩阵 \\(\\boldsymbol{X}\\)（即 \\(E(\\boldsymbol{X}) = \\boldsymbol{0}\\)），其协方差矩阵 \\[ \\begin{aligned} \\Sigma (\\boldsymbol{X}) &amp;= E \\left[ (\\boldsymbol{X} - E(\\boldsymbol{X})) (\\boldsymbol{X} - E(\\boldsymbol{X}))^T \\right] \\\\ &amp;= \\begin{pmatrix} \\textrm{Cov}(\\boldsymbol{X}_1, \\boldsymbol{X}_1) &amp; \\textrm{Cov}(\\boldsymbol{X}_1, \\boldsymbol{X}_2) &amp; \\cdots &amp; \\textrm{Cov}(\\boldsymbol{X}_1, \\boldsymbol{X}_n) \\\\ \\textrm{Cov}(\\boldsymbol{X}_2, \\boldsymbol{X}_1) &amp; \\textrm{Cov}(\\boldsymbol{X}_2, \\boldsymbol{X}_2) &amp; \\cdots &amp; \\textrm{Cov}(\\boldsymbol{X}_2, \\boldsymbol{X}_n) \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\textrm{Cov}(\\boldsymbol{X}_n, \\boldsymbol{X}_1) &amp; \\textrm{Cov}(\\boldsymbol{X}_n, \\boldsymbol{X}_2) &amp; \\cdots &amp; \\textrm{Cov}(\\boldsymbol{X}_n, \\boldsymbol{X}_n) \\end{pmatrix} \\\\ &amp;= \\frac{1}{N} \\boldsymbol{X} \\boldsymbol{X}^T \\end{aligned} \\] 若将投影矩阵 \\(\\boldsymbol{Q}\\) 按行划分为向量组，也即设 \\[ \\boldsymbol{Q} = \\begin{pmatrix} \\boldsymbol{q}_1 \\\\ \\boldsymbol{q}_2 \\\\ \\vdots \\\\ \\boldsymbol{q}_k \\end{pmatrix} \\] ，则要使得投影方差和最大，也即求解 \\[ \\begin{aligned} \\mathop{\\arg\\max}_{\\boldsymbol{Q}: \\boldsymbol{Q}\\boldsymbol{Q}^T = \\boldsymbol{I}} \\sum_{i = 1}^k || \\boldsymbol{q}_i \\boldsymbol{X} ||_2^2 &amp;= \\mathop{\\arg\\max}_{\\boldsymbol{Q}: \\boldsymbol{Q}\\boldsymbol{Q}^T = \\boldsymbol{I}} ||\\boldsymbol{QX}||_F^2 \\\\ &amp;=\\mathop{\\arg\\max}_{\\boldsymbol{Q}: \\boldsymbol{Q}\\boldsymbol{Q}^T = \\boldsymbol{I}} \\textrm{tr} \\left( \\boldsymbol{X}^T \\boldsymbol{Q}^T \\boldsymbol{Q} \\boldsymbol {X} \\right) \\end{aligned} \\] 由此可得优化问题 \\[ \\begin{aligned} \\min \\quad &amp; - \\textrm{tr} \\left( \\boldsymbol{X}^T \\boldsymbol{Q}^T \\boldsymbol{Q} \\boldsymbol {X} \\right) \\\\ \\textbf{s.t} \\quad &amp; \\boldsymbol{Q} \\boldsymbol{Q}^T = \\boldsymbol{I}_{k \\times k} \\end{aligned} \\] 利用拉格朗日乘子法，我们可得当目标函数取到最小值时，有 \\[ \\boldsymbol{Q} \\boldsymbol{X} \\boldsymbol{X}^T = \\boldsymbol{Q} \\boldsymbol{\\lambda} \\] 也即 \\(\\boldsymbol{Q}\\) 中的第 \\(i\\) 行为 \\(\\boldsymbol{X} \\boldsymbol{X}^T\\) 的第 \\(i\\) 个特征值 \\(\\lambda_i\\) 对应的特征向量。进一步的，将结果代回原式我们可以发现，由于 \\(\\boldsymbol{Q}\\) 为一个 \\(k \\times n\\) 的矩阵，因此若要使得目标函数取到最小值，\\(\\boldsymbol{Q}\\) 中的行向量应取前 \\(k\\) 大的特征值所对应的特征向量。 在图像压缩任务中，当将数据集映射到低维空间后，我们还需要将其重构回原来的图像空间以保证图像的可用性。对于使用正交变换的PCA方法，这一重构任务是容易的。由于 \\(\\boldsymbol{Q}\\) 为一正交矩阵，其逆矩阵 \\(\\boldsymbol{Q}^{-1} = \\boldsymbol{Q}^T\\)。因此要重构压缩后的图像，进行我们只需要对降维数据进行逆变换，即左乘 \\(\\boldsymbol{Q}^T\\) 即可。 由此，我们导出了使用朴素PCA方法进行图像压缩的一般过程。需要注意的是，要使用基于特征分解的PCA方法对图像进行分析和处理，我们需要将图像矩阵划分为向量组并进行中心化操作，这里我们采用按列划分的方法。算法的具体流程如下： 在选择了不同主成分个数时，使用朴素PCA算法进行图像压缩的效果结果如下图所示： 可以看到，仅使用前10个主成分已经能还原出整体的图像轮廓，当 \\(k=50\\) 时，图像的细节已基本得到恢复。 基于奇异值分解的PCA 可以看到，基于特征值分解的PCA算法中计算开销最大的部分为计算协方差矩阵 \\(\\boldsymbol{X} \\boldsymbol{X}^T\\) 的特征值与特征向量。事实上，我们可以使用奇异值分解来避免这一高开销计算，一个 \\(m \\times n\\) 的矩阵 \\(\\boldsymbol{A}\\) 的奇异值分解是指将其分解为三个特殊矩阵乘积的形式 \\(\\boldsymbol{A} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^T\\)，其中 \\(\\boldsymbol{U}\\) 为 \\(m\\) 阶正交矩阵，\\(\\boldsymbol{V}\\) 为 \\(n\\) 阶正交矩阵，\\(\\Sigma\\) 是由降序排列的非负的对角线元素组成的 \\(m \\times n\\) 对角矩阵。 对于任意实矩阵，我们都能找到它的奇异值分解。这是由于有如下定理保证： Theorem: 若 \\(\\boldsymbol{A}\\) 为一 \\(m \\times n\\) 实矩阵，\\(\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}\\)，则 \\(\\boldsymbol{A}\\) 的奇异值分解存在 \\(\\boldsymbol{A} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^T\\)其中 \\(\\boldsymbol{U}\\) 是 \\(m\\) 阶正交矩阵，\\(\\boldsymbol{V}\\) 是 \\(n\\) 阶正交矩阵，\\(\\boldsymbol{\\Sigma}\\) 是 \\(m \\times n\\) 对角矩阵，其前 \\(r\\) 个对角元素 \\((\\sigma_1, \\cdots, \\sigma_r)\\) 为正，且按降序排列，其余均为 \\(0\\)。 Proof: 由于 \\(\\boldsymbol{A}^T \\boldsymbol{A}\\) 为对称半正定矩阵，因此可以对其进行特征分解 \\(\\boldsymbol{A}^T \\boldsymbol{A} = \\boldsymbol{V} \\boldsymbol{\\Lambda}_n \\boldsymbol{V}^T\\)，其中 \\(V \\in \\mathbb{R}^{n \\times n}\\) 是正交矩阵，\\(\\boldsymbol{\\Lambda}_n\\) 是对称矩阵，并且对角线元素是 \\(\\boldsymbol{A}^T \\boldsymbol{A}\\) 的特征值 \\(\\lambda_i \\geq 0, i = 1, \\cdots, n\\)，并且是按降序排列的。因为 \\(\\textrm{rank} (\\boldsymbol{A}) = \\textrm{rank}(\\boldsymbol{A}^T \\boldsymbol{A}) = r\\)，所以前 \\(r\\) 个特征值是正的。 注意到 \\(\\boldsymbol{A} \\boldsymbol{A}^T\\) 和 \\(\\boldsymbol{A}^T \\boldsymbol{A}\\) 有相同的非零特征值，因此他们的秩是相等的。我们定义 \\[ \\sigma_i = \\sqrt{\\lambda_i} &gt; 0, i = 1, \\cdots, r \\] ，记 \\(\\boldsymbol{v}_1, \\cdots,\\boldsymbol{v}_r\\) 是 \\(\\boldsymbol{V}\\) 的前 \\(r\\) 列，它们同时也是 \\(\\boldsymbol{A}^T \\boldsymbol{A}\\) 前 \\(r\\) 个特征值对应的特征向量。即有 \\[ \\boldsymbol{A}^T \\boldsymbol{A} \\boldsymbol{v}_i = \\lambda_i \\boldsymbol{v}_i, i = 1, \\cdots, r \\] 。因此同时在两边左乘上 \\(\\boldsymbol{A}\\) 就有 \\[ (\\boldsymbol{A} \\boldsymbol{A}^T) \\boldsymbol{A} \\boldsymbol{v}_i = \\lambda_i \\boldsymbol{A} \\boldsymbol{v}_i,i = 1, \\cdots, r \\] 。这就意味着 \\(\\boldsymbol{A} \\boldsymbol{v}_i\\) 是 \\(\\boldsymbol{A} \\boldsymbol{A}^T\\) 的特征向量，因为 \\(\\boldsymbol{v}_i^T \\boldsymbol{A}^T \\boldsymbol{A} \\boldsymbol{v}_j = \\lambda_j \\boldsymbol{v}_i^T \\boldsymbol{v}_j\\) 所以这些特征向量也是正交的。所以将他们标准化则有 \\[ \\boldsymbol{u}_i = \\frac{\\boldsymbol{A} \\boldsymbol{v}_i}{\\sqrt{\\lambda_i}} = \\frac{\\boldsymbol{A} \\boldsymbol{v}_i}{\\sigma_i}, i = 1, \\cdots, r \\] 这些 \\(\\boldsymbol{u}_1, \\cdots, \\boldsymbol{u}_r\\) 是 \\(r\\) 个 \\(\\boldsymbol{A} \\boldsymbol{A}^T\\) 关于非零特征值 \\(\\lambda_1, \\cdots, \\lambda_r\\) 的特征向量。因此 \\[ \\boldsymbol{u}_i^T \\boldsymbol{A} \\boldsymbol{v}_j = \\frac{1}{\\sigma_i} \\boldsymbol{v}_i^T \\boldsymbol{A}^T \\boldsymbol{A} \\boldsymbol{v}_j = \\frac{\\lambda_j}{\\sigma_i} \\boldsymbol{v}_i^T \\boldsymbol{v}_j = \\left\\{ \\begin{aligned} \\sigma_i, &amp; i = j \\\\ 0, 其他 \\end{aligned} \\right. \\] 以矩阵的方式重写即有 \\[ \\begin{pmatrix} \\boldsymbol{u}_1^T \\\\ \\vdots \\\\ \\boldsymbol{u}_r^T \\end{pmatrix} \\boldsymbol{A} (\\boldsymbol{v}_1, \\cdots, \\boldsymbol{v}_r) = \\textrm{diag} (\\sigma_1, \\cdots, \\sigma_r) = \\boldsymbol{\\Sigma}_r \\] 注意到根据定义 \\[ \\boldsymbol{A}^T \\boldsymbol{A} \\boldsymbol{v}_i = 0, i = r + 1, \\cdots, n \\] 即有 \\[ \\boldsymbol{A} \\boldsymbol{v}_i = 0, i = r + 1, \\cdots, n \\] 取相互正交的单位向量 \\(\\boldsymbol{u}_{r+1}, \\cdots, \\boldsymbol{u}_m\\) 均与 \\(\\boldsymbol{u}_1, \\cdots, \\boldsymbol{u}_r\\) 正交，即有 \\[ \\boldsymbol{u}_i^T \\boldsymbol{A} \\boldsymbol{v}_j = 0. i = 1, \\cdots, m; j = r + 1, \\cdots, n \\] 它们共同构成了 \\(\\mathbb{R}^m\\) 的一组标准正交基。因此，扩展前述奇异值分解式即有 \\[ \\begin{pmatrix} \\boldsymbol{u}_1^T \\\\ \\vdots \\\\ \\boldsymbol{u}_m^T \\end{pmatrix} \\boldsymbol{A} (\\boldsymbol{v}_1, \\cdots, \\boldsymbol{v}_n) = \\begin{pmatrix} \\boldsymbol{\\Sigma}_r &amp; \\boldsymbol{0}^T \\\\ \\boldsymbol{0} &amp; \\boldsymbol{O} \\end{pmatrix} = \\boldsymbol{\\Sigma} \\] 令 \\(\\boldsymbol{U} = (\\boldsymbol{u}_1, \\cdots, \\boldsymbol{u}_m)\\)，\\(\\boldsymbol{V} = (\\boldsymbol{v}_1, \\cdots, \\boldsymbol{v}_n)\\)，即有 \\(\\boldsymbol{A} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^T\\)。 由此可知，矩阵 \\(\\boldsymbol{A}\\) 必存在奇异值分解。 根据矩阵的奇异值分解定理，对于中心化图像矩阵 \\(\\boldsymbol{X}\\)，我们有 \\[ \\begin{aligned} \\boldsymbol{X}^T \\boldsymbol{X} &amp;= \\left( \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^T \\right)^T \\left( \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^T \\right) \\\\ &amp;= \\boldsymbol{V} \\boldsymbol{\\Sigma} \\boldsymbol{V}^T \\end{aligned} \\] 也即 \\(\\boldsymbol{X}^T \\boldsymbol{X} \\boldsymbol{V} = \\boldsymbol{V} \\boldsymbol{\\Sigma}\\)。由此我们得知协方差矩阵的第 \\(i\\) 个特征向量也即右奇异值矩阵 \\(\\boldsymbol{V}\\) 的第 \\(i\\) 列。 基于奇异值分解的PCA图像压缩算法具体流程如下： 同样的，我们使用Python实现了上述算法。对于奇异值分解操作，我们使用Numpy模块中提供的svd()函数来完成。Numpy模块使用了LAPACK科学计算包来完成矩阵分解的相关操作。其中，SVD分解采用了Householder变换的方式来完成，这一操作的时间开销远低于一般的采用Gram-Schimdt正交化的求解方式，也远低于对协方差矩阵作特征值分解的时间开销。 2DPCA 由于常规的PCA方法是对向量组进行操作，因此当我们使用该方法对图像进行压缩时，需要先将其划分为列向量组再进行处理。由此得到的协方差矩阵规模十分巨大，需要极大的时间开销来完成计算。此外，由于图像压缩通常被作为其他图像处理任务的上游任务，如此操作会导致图像的特征信息出现大量的丢失。因此，之后的研究者提出了另一种简单的图像投影技术，称为二维主成分分析(2DPCA)，专门用于图像特征提取。与传统的PCA方法不同，2DPCA基于2D矩阵直接构建图像的协方差矩阵。与PCA的协方差矩阵相比，使用2DPCA的图像协方差矩阵的大小要小得多，这就意味着确定相应的特征向量所需的时间更少。此外，由于其更多的利用了图像的空间信息，对图像的特征也能够更好的保留。 2DPCA的主要思想是直接利用一个 \\(n \\times k\\) 维矩阵对整张图像进行投影。这里我们先考虑投影矩阵为一维时的情况，再将其推广到 \\(k\\) 维上去。 若设图像矩阵为 \\(\\boldsymbol{A}\\)，\\(\\boldsymbol{X}\\) 为投影向量，\\(\\boldsymbol{Y} = \\boldsymbol{AX}\\) 为投影后的特征。则 \\(\\boldsymbol{Y}\\) 的协方差矩阵 \\(\\boldsymbol{S}_x\\) 可以写为 \\[ \\begin{aligned} \\boldsymbol{S}_x &amp;= E \\left[(\\boldsymbol{Y} - E[\\boldsymbol{Y}])(\\boldsymbol{Y} - E[\\boldsymbol{Y}])^T \\right] \\\\ &amp;=E \\left[(\\boldsymbol{AX} - E[\\boldsymbol{AX}])(\\boldsymbol{AX} - E[\\boldsymbol{AX}])^T \\right] \\\\ &amp;= E \\left[((\\boldsymbol{A} - E[\\boldsymbol{A}]) \\boldsymbol{X})((\\boldsymbol{A} - E[\\boldsymbol{A}]) \\boldsymbol{X})^T \\right] \\end{aligned} \\] 与一般的PCA方法类似，我们定义判断投影好坏的评价指标为 \\(J(\\boldsymbol{X}) = \\textrm{tr} (\\boldsymbol{S}_x)\\)，则代入上面的式子就可以写为 \\[ \\begin{aligned} J(\\boldsymbol{X}) &amp;= \\textrm{tr} (\\boldsymbol{S}_x) \\\\ &amp;= \\boldsymbol{X}^T E \\left[ (\\boldsymbol{A} - E[\\boldsymbol{A}])^T (\\boldsymbol{A} - E[\\boldsymbol{A}]) \\right] \\boldsymbol{X} \\end{aligned} \\] 。从上面的式子我们可以看出，2DPCA通常是同时作用于多张图像矩阵上的，这也是其协方差矩阵维度相对较小的原因。若设图像集合为 \\(\\boldsymbol{A}_1, \\cdots, \\boldsymbol{A}_M\\)，则 \\[ \\begin{aligned} \\boldsymbol{G} &amp;\\overset{def}{=} E \\left[ (\\boldsymbol{A} - E[\\boldsymbol{A}])^T (\\boldsymbol{A} - E[\\boldsymbol{A}]) \\right] \\\\ &amp;= \\frac{1}{M} \\sum_{i = 1}^M \\left( \\boldsymbol{A}_i - \\bar{\\boldsymbol{A}} \\right)^T \\left( \\boldsymbol{A}_i - \\bar{\\boldsymbol{A}} \\right) \\end{aligned} \\] 现在我们将投影矩阵推广为 \\(k\\) 维，也即设投影矩阵为 \\(\\boldsymbol{X} = \\{\\boldsymbol{X}_1, \\cdots, \\boldsymbol{X}_d \\}\\)，则优化问题为 \\[ \\begin{aligned} \\min \\quad &amp; - J(\\boldsymbol{X}) \\\\ \\textbf{s.t} \\quad &amp; \\boldsymbol{X}_i^T \\boldsymbol{X}_j = 0, i \\neq j \\end{aligned} \\] 由拉格朗日乘子法我们可以得知，要提取前 \\(k\\) 个特征，投影矩阵的最优解即为 \\(\\boldsymbol{G}\\) 前 \\(k\\) 大个特征值对应的特征向量所组成的矩阵。 由此我们就得到了使用2DPCA进行图像压缩的一般算法： 在选择了不同主成分个数时，使用2DPCA算法进行图像压缩的效果结果如下图所示： 2D-2DPCA 在上述介绍的2DPCA中，若我们用 \\(\\boldsymbol{A}^{(t)}\\) 来表示矩阵 \\(\\boldsymbol{A}\\) 的第 \\(t\\) 行，则 \\[ \\begin{aligned} \\boldsymbol{A}_i &amp;= \\left( \\left( \\boldsymbol{A}_i^{(1)} \\right)^T, \\cdots, \\left( \\boldsymbol{A}_i^{(n)} \\right)^T \\right)^T \\\\ \\bar{\\boldsymbol{A}} &amp;= \\left( \\left( \\bar{\\boldsymbol{A}}^{(1)} \\right)^T, \\cdots, \\left( \\bar{\\boldsymbol{A}}^{(n)} \\right)^T \\right)^T \\end{aligned} \\] ，于是协方差矩阵 \\(\\boldsymbol{G}\\) 就可以被写为 \\[ \\boldsymbol{G} = \\frac{1}{M} \\sum_{i = 1}^M \\sum_{k = 1}^n \\left( \\boldsymbol{A}_i^{(k)} - \\bar{\\boldsymbol{A}}^{(k)}\\right)^T \\left( \\boldsymbol{A}_i^{(k)} - \\bar{\\boldsymbol{A}}^{(k)}\\right) \\] 。通过该式我们可以发现，\\(\\boldsymbol{G}\\) 可以通过图像集合中行向量的外积得到，这也就意味着2DPCA实际上仅按行提取了图像之间的联系。自然的，我们可以想到是否可以用类似的方法提取图像列之间的联系并将它们结合在一起，从而挖掘出图像更多的特征联系。这一想法也就形成了所谓的双方向二维主成分分析（2D-2DPCA）。 我们设 \\(\\boldsymbol{Z} \\in \\mathbb{R}^{n \\times k}\\) 为另一投影矩阵，其作用即为对图像矩阵 \\(\\boldsymbol{A}\\) 的列进行投影。于是与2DPCA的做法类似，我们设矩阵 \\(\\boldsymbol{A}\\) 投影得到的特征为 \\[ \\boldsymbol{B} = \\boldsymbol{Z}^T \\boldsymbol{A} \\] 。于是投影得到的协方差矩阵即为 \\[ J(\\boldsymbol{Z}) = \\boldsymbol{Z}^T E \\left[ (\\boldsymbol{A} - E[\\boldsymbol{A}]) (\\boldsymbol{A} - E[\\boldsymbol{A}])^T \\right] \\boldsymbol{Z} \\] 我们定义 \\[ \\begin{aligned} \\boldsymbol{G}&#39; &amp;\\overset{def}{=} E \\left[ (\\boldsymbol{A} - E[\\boldsymbol{A}]) (\\boldsymbol{A} - E[\\boldsymbol{A}])^T \\right] \\\\ &amp;= \\frac{1}{M} \\sum_{i = 1}^M \\left( \\boldsymbol{A}_i - \\bar{\\boldsymbol{A}} \\right) \\left( \\boldsymbol{A}_i - \\bar{\\boldsymbol{A}} \\right)^T \\\\ &amp;= \\frac{1}{M} \\sum_{i = 1}^M \\sum_{k = 1}^n \\left( \\boldsymbol{A}_i^{(k)} - \\bar{\\boldsymbol{A}}^{(k)}\\right) \\left( \\boldsymbol{A}_i^{(k)} - \\bar{\\boldsymbol{A}}^{(k)}\\right)^T \\end{aligned} \\] 其中 \\(\\boldsymbol{A}^{(t)}\\) 为矩阵 \\(\\boldsymbol{A}\\) 的第 \\(t\\) 列。 与上面类似，我们最大化 \\(J(\\boldsymbol{Z})\\)，同样可以得到 \\(\\boldsymbol{Z}\\) 的最优解即为 \\(\\boldsymbol{G}\\) 的前 \\(k\\) 大个特征值对应的特征向量所组成的矩阵。 将行投影和列投影结合，我们就能得到图像集合中的任一图像 \\(\\boldsymbol{A}\\) 经过投影后的特征为 \\[ \\boldsymbol{C} = \\boldsymbol{Z}^T \\boldsymbol{A} \\boldsymbol{Z} \\] ，其重构图像为 \\[ \\tilde{\\boldsymbol{A}} = \\boldsymbol{Z} \\boldsymbol{C} \\boldsymbol{X}^T \\] 。由此我们就得到了使用2D-2DPCA进行图像压缩的一般算法： 在选择了不同主成分个数时，使用2D-2DPCA算法进行图像压缩的效果结果如下图所示： Generalized Hebbian Algorithm 可以看到，上面几种PCA方法均为基于矩阵分解的求解方法。近年来随着机器学习和神经网络模型的提出，研究者也提出了基于学习的方法来快速提取数据集的主成分。其中较为典型的即为基于Gram-Schmidt正交化方法的扩展Hebbian算法（Generalized Hebbian Algorithm）。GHA算法是一种无监督的学习算法，我们可以将其看作Oja方法的一种推广。 首先我们构建一个单层全连接神经网络（Single-layer Feed Forward Neural Network），如下图所示： 可以证明，通过GHA算法对该神经网络进行权重调整，则训练完成后，连接每个输出神经元的权重向量即为一个主成分向量。 首先我们考虑输出层只有 \\(1\\) 个神经元的情况。若设第 \\(t\\) 次迭代的输入向量为 \\(\\boldsymbol{x}_t \\in \\mathbb{R}\\)，网络的权重向量为 \\(\\boldsymbol{w}_t \\in \\mathbb{R}^n\\)，输出 \\(y_t = \\boldsymbol{w}_t^T \\boldsymbol{x}_t\\)，\\(\\eta\\) 为学习率。则根据Oja方法，权重更新公式为 \\[ \\boldsymbol{w}_{t + 1} = \\boldsymbol{w}_{t} + \\eta \\boldsymbol{y}_{t} (\\boldsymbol{x}_{t} - \\boldsymbol{y}_{t} \\boldsymbol{w}_{t}) \\] 。现在我们将其推广到 \\(k\\) 个输出时的情况，即求解前 \\(k\\) 个主成分。设 \\(\\boldsymbol{W}_t \\in \\mathbb{R}^{k \\times n}\\)，输出 \\(\\boldsymbol{y}_t = \\boldsymbol{W}_t \\boldsymbol{x}_t\\)，则 \\[ \\boldsymbol{W}_{t + 1} = \\eta \\left( \\boldsymbol{y}_t \\boldsymbol{x}_t^T - \\textrm{LOWER}(\\boldsymbol{y}_t \\boldsymbol{y}_t^T) \\boldsymbol{W}_t \\right) \\] ，其中 \\(\\textrm{LOWER}(\\boldsymbol{A})\\) 为取矩阵 \\(\\boldsymbol{A}\\) 的下三角操作（上三角部分置为 \\(0\\)）。 于是，使用GHA进行图像压缩的算法流程如下： 对于训练结果的评价指标，我们定义损失函数 \\[ \\mathcal{L}(\\boldsymbol{W}, \\boldsymbol{Q}) = \\sum_{i = 1}^k ||\\boldsymbol{w}_i - \\boldsymbol{q}_i||^2 = ||\\boldsymbol{W} - \\boldsymbol{Q}||_F^2 \\] 及向量夹角 \\[ \\mathcal{A}(\\boldsymbol{w}_i, \\boldsymbol{q}_i) = \\arccos \\left( \\frac{\\boldsymbol{w}_i \\cdot \\boldsymbol{q}_i}{|| \\boldsymbol{w}_i ||_2 \\cdot ||\\boldsymbol{q}_i||_2} \\right) \\] 由于该算法的收敛速度较为不可控，因此这里我们仅使用网络提取前两个主成分。我们使用正态分布 \\(\\mathcal{N}(0, 0.5)\\) 随机初始化了权重矩阵，并设置学习率 \\(\\eta = 10^{-4}\\) 进行了两次模拟，每次对网络进行了 \\(20000\\) 次训练迭代。两次迭代过程中Loss和向量夹角的变化情况如下图所示： 可以发现，随着权重矩阵初始值的不同，网络的收敛特征也会随之发生变化。 使用神经网络算法进行模型训练时一个经典的问题即为学习率过大。事实上，在训练该模型的过程中，我们同样遇到了这一问题，并且固定的学习率很难保证适合整个损失超平面。为此，研究者提出了适用于GHA的自适应学习率优化方法。由于该方法实现过于复杂，在此仅作为了解。 Kernel PCA 由PCA的推导过程我们可以看出，要对一个数据集使用PCA方法进行降维的一大前提即为数据集必须在当前维度下线性可分，而类似图像这样高度紧凑的数据集通常会出现线性不可分的问题。在这种情况下，我们通常会尝试使用一个映射 \\(\\phi: \\mathbb{R}^n \\to \\mathbb{R}^d, d &gt; n\\) 将数据集映射到更高维度的特征空间，使得其在该空间下线性可分，该方法被称为核方法（Kernel Method）。利用核方法，我们可以对朴素的PCA方法进行改进，使其能够表达更多的原始特征，这就形成了所谓的核主成分分析（Kernel PCA）。 若设图像矩阵为 \\(\\boldsymbol{X}\\)，非线性映射 \\(\\phi(\\boldsymbol{X})\\) 对应的核函数 \\(\\boldsymbol{K} = \\phi(\\boldsymbol{X})^T \\phi(\\boldsymbol{X})\\)，特征空间为 \\(\\mathcal{F}\\)，则特征空间中的协方差矩阵就可以写为 \\[ \\boldsymbol{C}_{\\mathcal{F}} = \\frac{1}{N} \\phi(\\boldsymbol{X}) (\\phi(\\boldsymbol{X}))^T \\] 其特征值问题的方程 \\(\\boldsymbol{C}_{\\mathcal{F}} \\boldsymbol{v} = \\lambda \\boldsymbol{v}\\) 就可以写为 \\[ \\sum_{i = 1}^N \\phi(\\boldsymbol{x}_i) \\phi(\\boldsymbol{x}_i)^T \\boldsymbol{v} = \\lambda \\boldsymbol{v} \\] 由此我们发现其每一个特征向量 \\(\\boldsymbol{v}_j\\) 都可以表示为 \\(\\phi(\\boldsymbol{x}_i)\\) 的线性组合 \\[ \\boldsymbol{v} = \\sum_{i = 1}^N a_i \\phi(\\boldsymbol{x}_i) = \\phi (\\boldsymbol{X}) \\boldsymbol{a} \\] ，其中 \\(\\boldsymbol{a} = (a_1, \\cdots, a_N)^T\\)。 引入核函数，化简即可得到 \\[ \\boldsymbol{K}(\\boldsymbol{X}) \\boldsymbol{a} = \\lambda \\boldsymbol{a} \\] ，也即经过特征空间所得的降维变换向量即为矩阵 \\(\\boldsymbol{K}\\) 的特征向量。 使用Kernel PCA进行图像压缩时所涉及的变换如下图所示： 通常来说，核函数要求矩阵为正定矩阵。在本文中，我们实现了以下几种核函数： 线性核（Linear Kernel） \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) = \\boldsymbol{x}^T \\boldsymbol{y} \\] 多项式核（Polynomial Kernel） \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) = \\left( \\boldsymbol{x}^T \\boldsymbol{y} + c \\right)^d \\] 高斯核（Gaussian Kernel/Radial Basis Function Kernel） \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) = \\exp \\left( - \\frac{|| \\boldsymbol{x} - \\boldsymbol{y} ||^2}{2 \\sigma^2} \\right) = \\exp \\left( - \\gamma || \\boldsymbol{x} - \\boldsymbol{y} ||^2 \\right) \\] 指数核（Exponential Kernel） \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) = \\exp \\left( - \\frac{|| \\boldsymbol{x} - \\boldsymbol{y} ||}{2 \\sigma^2} \\right) = \\exp \\left( - \\gamma || \\boldsymbol{x} - \\boldsymbol{y} || \\right) \\] ANOVA核 \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) = \\exp \\left( -\\sigma \\left( \\boldsymbol{x}^k - \\boldsymbol{y}^k \\right)^2 \\right)^d \\] Sigmoid核 \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) = \\tanh \\left( a \\boldsymbol{x}^T \\boldsymbol{y} + r \\right) \\] 对于部分核函数，我们还需要给定合适的超参数以达到最好的特征提前效果。以高斯核为例，我们采用网格搜索的方式来选取合适的超参数 \\(\\gamma\\)。图像的重构误差随 \\(\\gamma\\) 的变化如下图所示：（左一） 可以看到，随着 \\(\\gamma\\) 值的增大，图像的重构误差逐渐减少。然而这并不意味着 \\(\\gamma\\) 值越大越好，这是由于当 \\(\\gamma\\) 值过大时，模型会出现过拟合（overfitting）的问题。具体来说，当 \\(\\gamma\\) 值过大时，核函数 \\[ \\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y}) \\approx \\left\\{ \\begin{aligned} &amp;e^0 = 1 &amp;,\\boldsymbol{x} = \\boldsymbol{y} \\\\ &amp;e^{-\\infty} = 0 &amp;,\\boldsymbol{x} \\neq \\boldsymbol{y} \\end{aligned} \\right. \\] ，此时核矩阵退化为 \\(\\boldsymbol{I}_n\\)，也即单位变换。这就导致了降维空间成为原空间的一个子空间，自然就失去了特征提取的功能。 若设核矩阵 \\(\\boldsymbol{K}\\) 的前 \\(k\\) 个特征值为 \\(\\lambda_1, \\cdots, \\lambda_k\\)，我们定义其方差（该指标衡量了特征值的分散程度）为 \\[ Var(\\lambda_1, \\cdots, \\lambda_k) = \\frac{1}{k} \\sum_{i = 1}^k \\left(\\lambda_i - \\bar{\\lambda} \\right)^2 \\] ，则核矩阵方差及核矩阵行列式的值如图所示（上图左二、左三）。易见当 \\(\\gamma \\gg 10^{-3}\\) 时，核矩阵的方差趋近于 \\(0\\)，其行列式趋近于 \\(1\\)，这也印证了上述的理论论述，表明模型确实出现了过拟合。 可以看到，由于核函数基本都为非线性函数，其逆变换通常难以求得。因此使用核方法对数据集进行降维的一个很大的问题在于对数据集进行重构，这对于图像压缩问题来说是十分不友好的。 若设 \\(\\mathcal{H}_K\\) 为核 \\(\\boldsymbol{K}(\\boldsymbol{x}, \\boldsymbol{y})\\) 所生成的再生希尔伯特核空间，其对应的特征变换 \\(\\phi(\\boldsymbol{x}): \\mathbb{R}^n \\to \\mathcal{H}_k\\)，则图像重构问题即为给定 \\(\\mathcal{H}_K\\) 中的一点 \\(\\boldsymbol{\\Psi}\\)，求输入空间中的一点 \\(\\boldsymbol{z} \\in \\mathbb{R}^n\\)，使得 \\[ \\boldsymbol{z} = \\mathop{\\arg\\min}_{\\boldsymbol{z}} || \\boldsymbol{\\Psi} - \\phi (\\boldsymbol{z}) ||^2 \\] 事实上自Kernel PCA被提出以来，已经有大量的研究提出了一系列对KPCA降维后数据进行重构的方法，这些方法大多都是基于近似拟合的方法。其中，基于梯度下降（Gradient Descent）的方法和基于回归（Regression）的方法是两大较为有代表性的求解方法。由于这一过程实现过于复杂，我们直接使用了Scikit-Learn工具包中提供的inverse_transform()函数来完成。 使用Kernel PCA进行图像压缩的算法流程如下： 以高斯核为例，在选择了不同主成分个数时，使用Kernel PCA算法进行图像压缩的效果结果如下图所示： 可以发现，与朴素PCA方法不同，当选择的主成分个数为10时图像的主要特征仍然没有得到恢复，而当 \\(k=50\\) 时，图像的质量得到了极大的改善。这也表明经过变换后的数据集在核空间下的特征分离方式与原空间下是不同的。 JPEG 上面使用的几种图像压缩算法均为即为基于PCA的方法。事实上，在日常场景下，人们更常使用基于信号处理和特殊编码的方法来对图像进行压缩。其中较为典型的代表即为基于离散余弦变换的JPEG（JFIF）算法。 JPEG图像压缩算法的具体流程如下图所示： 压缩算法主要分为如下几个步骤： \\(RGB \\to YC_bC_r\\) 空间转换 下采样 图像分割 离散余弦变换 数据量化 Huffman编码 使用JPEG算法进行图像压缩的效果结果如下图所示： 可以看到，尽管JPEG为有损压缩算法，重构后的图片与原图几乎看不到可见的差异，这也从一定程度上解释了该算法流行的原因。 事实上，近年来的许多压缩方法还会将JPEG算法及其变体JPEG2000与PCA方法相结合，从而进一步提高压缩率及重构的准确率。例如在高光谱成像领域，由于原始图像通常还会附带许多频谱信息，将这两种方法相结合可以极大的压缩存储图像所需的空间，从而减少数据传输的开销。 实验结果 前文中我们提及了一系列图像压缩的方法，现在我们从压缩率、重构质量和压缩耗时三个维度来对上述提及的所有方法进行分析和比较。 图像的压缩率被定义为 \\[ \\eta = 1 - \\frac{\\textrm{Size}(\\tilde{\\boldsymbol{X}}) + \\textrm{Size}(\\boldsymbol{Q})}{\\textrm{Size}(\\boldsymbol{X})} \\] ，其中 \\(\\textrm{Size}(\\boldsymbol{A})\\) 为 \\(\\boldsymbol{A}\\) 的空间度量，\\(\\boldsymbol{X}\\) 为原始图像，\\(\\tilde{\\boldsymbol{X}}\\) 为重构图像，\\(\\boldsymbol{Q}\\) 为重构变换矩阵。 以 \\(k = 50\\) 为例，本文中实现的不同算法的压缩率如下表所示： 压缩算法 单张图片压缩率 100张图片压缩率 300张图片压缩率 PCA \\(60.94\\%\\) \\(60.94\\%\\) \\(60.94\\%\\) 2DPCA \\(60.94\\%\\) \\(80.27\\%\\) \\(80.40\\%\\) 2D-2DPCA \\(41.41\\%\\) \\(80.08\\%\\) \\(80.34\\%\\) Kernel PCA \\(60.94\\%\\) \\(60.94\\%\\) \\(60.94\\%\\) JPEG \\(84.54\\%\\) \\(86.09\\%\\) \\(87.22\\%\\) 可以发现，朴素PCA和Kernel PCA对单张图片计算主成分，因此其在单张图片和多张图片上的压缩率相同；而2DPCA和2D-2DPCA由于对整个数据集计算特征，因此随着数据集的增长，总体的图像压缩率逐渐增长。JPEG在所有算法中拥有最高的压缩率。 对于重构质量，我们使用均方误差（Mean Square Error）和峰值信噪比（Peak Signal-to-Noise Ratio）来进行评估。其中，原始图像 \\(\\boldsymbol{X}\\) 和重构图像 \\(\\tilde{\\boldsymbol{X}}\\) 间的均方误差被定义为 \\[ \\textrm{MSE}(\\boldsymbol{X}, \\tilde{\\boldsymbol{X}}) = \\frac{1}{N^2} \\sum_{i = 1}^N \\sum_{j = 1}^N (x_{ij} - \\tilde{x}_{ij})^2 \\] 其之间的峰值信噪比被定义为 \\[ \\textrm{PSNR}(\\boldsymbol{X}, \\tilde{\\boldsymbol{X}}) = 10 \\cdot \\log_{10} \\left( \\frac{\\textrm{MAX}_{\\boldsymbol{X}}^2}{\\textrm{MSE}(\\boldsymbol{X}, \\tilde{\\boldsymbol{X}})}\\right) \\] ，其中 \\(\\textrm{MAX}_{\\boldsymbol{X}}\\) 为矩阵 \\(\\boldsymbol{X}\\) 每个元素可能的最大值（对于一张 \\(8\\) 位图像即为 \\(255\\)）。 当 \\(k\\) 为 \\(50\\) 时，使用不同算法进行压缩重构后得到的MSE和PSNR值由下表给出： 压缩算法 MSE PSNR PCA \\(47.8774\\) \\(31.3295\\) 2DPCA \\(76.1444\\) \\(29.3144\\) 2D-2DPCA \\(90.1605\\) \\(28.5806\\) Kernel PCA \\(11.1868\\) \\(37.6437\\) JPEG \\(53.2189\\) \\(30.8701\\) 更进一步的，当主成分选择数 \\(k\\) 从 \\(1\\) 上升到 \\(200\\) 的过程中，不同算法的重构质量如下图所示： 可以看到，在所有实现的方法中，Kernel PCA在两项指标中均获得了最好的结果。然而，由于其重构变换使用了近似的方法，这一过程并不稳定，因此其误差曲线出现了一定程度的波动。相比较而言，一般的PCA方法两项评价指标随主成分选择数增加的变化十分稳定。 最后我们来考察不同压缩算法的压缩耗时。压缩耗时的计算公式被定义为 \\[ \\mathcal{T} = \\mathcal{T}_{Compress} + \\mathcal{T}_{Reconstruct} \\] 其中 \\(\\mathcal{T}_{Compress}\\) 为编码耗时，\\(\\mathcal{T}_{Reconstruct}\\) 重构耗时。 不同算法随着待压缩的图片总量从单张到 \\(100\\) 张所用的时间如下图所示： 可以发现，基于特征分解的朴素PCA算法随着数据集的增长进行压缩所用的时间迅速的增大，这是由于其计算协方差矩阵的特征值和特征向量的巨额时间开销。基于奇异值分解的PCA算法由于使用了更为高效的Householder变换算法，其耗时相比特征值分解得到了显著的下降。在我们的实现中，Kernel PCA同样使用了SVD方法进行优化，但其时间开销仍然十分巨大，表明其主要耗时在图像重构上。2DPCA和2D-2DPCA由于对整个数据集进行统一变换，因此在多张图像数据集上拥有极高的压缩效率。 结论 在本实验中，我们完整推导并实现了基于特征值分解的 PCA 算法、基于奇异值分解的 PCA 算法、基于 GHA 的 PCA 算法、2DPCA 算法、2D-2DPCA 算法、Kernel PCA 算法及 JPEG 算法，并将它们应用于图像压缩任务中。经过比较我们可以发现，在不同的度量标准下， 不同的算法均有着相应的优势和劣势。一般的 PCA 算法具有较好的稳定性和可解释性，2DPCA 和 2D-2DPCA 算法拥有较高的压缩效率，Kernel PCA 算法拥有较高的重构精度。这也表明这些 方法没有严格的好坏之分，在不同任务下需要根据实际情况选择合适的方法。 参考文献 Daniel Báscones, Carlos González, and Daniel Mozos. Hyperspectral image compression using vector quantization, pca and jpeg2000. Remote sensing, 10(6):907, 2018. Liang-Hwa Chen and Shyang Chang. An adaptive learning algorithm for principal component analysis. IEEE Transactions on Neural Networks, 6(5):1255–1263, 1995. COMP-652 and ECSE-608. Dimensionality reduction. pca. kernel pca. https://www.cs.mcgill.ca/~dprecup/courses/ML/Lectures/ml-lecture13.pdf, 2016. Alberto García-González, Antonio Huerta, Sergio Zlotnik, and Pedro Díez. A kernel principal component analysis (kpca) digest with a new backward mapping (pre-image reconstruction) strategy, 2021. Matt Gormley. Deriving principal component analysis (pca). https://www.cs.cmu. edu/~mgormley/courses/606-607-f18/slides606/lecture11-pca.pdf, October 2018. R.B. Lehoucq. The computation of elementary unitary matrices. Technical report, University of Tennessee, 1994. Graphics Mill. Working with jpeg. https://www.graphicsmill.com/docs/gm/ working-with-jpeg.htm. Sebastian Mika, Bernhard Schölkopf, Alex Smola, Klaus-Robert Müller, Matthias Scholz, and Gunnar Rätsch. Kernel pca and de-noising in feature spaces. In M. Kearns, S. Solla, and D. Cohn, editors, Advances in Neural Information Processing Systems, volume 11. MIT Press, 1999. Erkki Oja. Simplified neuron model as a principal component analyzer. Journal of mathematical biology, 15(3):267–273, 1982. Terence D. Sanger. Optimal unsupervised learning in a single-layer linear feedforward neural network, 1989. Bernhard Schölkopf, Alexander Smola, and Klaus-Robert Müller. Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation, 10(5):1299–1319, 1998. Wikipedia contributors. Jpeg — Wikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=JPEG&amp;oldid=1056557277, 2021. [Online; accessed 23-November-2021]. Wikipedia contributors. Singular value decomposition — Wikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=Singular_value_decomposition&amp;oldid=1055826758, 2021. [Online; accessed 24-November-2021]. Chih-Wen Wang and Jyh-Horng Jeng. Image compression using pca with clustering. In 2012 International Symposium on Intelligent Signal Processing and Communications Systems, pages 458–462, 2012. Frank Wood. http://www.stat.columbia.edu/~fwood/Teaching/w4315/Fall2009/pca.pdf, December 2009. Jason Weston, Bernhard Schölkopf, and Gökhan Bakir. Learning to find pre-images. In S. Thrun, L. Saul, and B. Schölkopf, editors, Advances in Neural Information Processing Systems, volume 16. MIT Press, 2004. Jian Yang, D. Zhang, A.F. Frangi, and Jing yu Yang. Two-dimensional pca: a new approach to appearance-based face representation and recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(1):131–137, 2004. Daoqiang Zhang and Zhi-Hua Zhou. (2d)2pca: Two-directional two-dimensional pca for eﬀicient face representation and recognition. Neurocomputing, 69(1):224–231, 2005. Neural Networks in Signal Processing. 周志华. 机器学习. 清华大学出版社, 2016.","categories":[{"name":"数据科学算法基础","slug":"数据科学算法基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"http://gonggongjohn.me/tags/Machine-Learning/"}]},{"title":"寻宝游戏(MongoDB)","slug":"database/db-assignment-1","date":"2021-10-08T02:00:00.000Z","updated":"2021-12-10T05:51:04.111Z","comments":true,"path":"2021/10/08/database/db-assignment-1/","link":"","permalink":"http://gonggongjohn.me/2021/10/08/database/db-assignment-1/","excerpt":"","text":"实验要求 考虑以下游戏场景： 每个游戏玩家都有一定数量的金币、宝物。有一个市场供玩家们买卖宝物。玩家可以将宝物放到市场上挂牌，自己确定价格。其他玩家支付足够的金币，可购买宝物。 宝物分为两类:一类为工具，它决定持有玩家的工作能力;一类为配饰，它决定持有玩家的运气。 每位玩家每天可以通过寻宝获得一件宝物，宝物的价值由玩家的运气决定。每位玩家每天可以通过劳动赚取金币，赚得多少由玩家的工作能力决定。（游戏中的一天可以是现实中的 1 分钟、5 分钟、10 分钟，自主设定。） 每个宝物都有一个自己的名字（尽量不重复）。每位玩家能够佩戴的宝物是有限的（比如一个玩家只能佩戴一个工具和两个配饰）。多余的宝物被放在存储箱中，不起作用，但可以拿到市场出售。 在市场上挂牌的宝物必须在存储箱中并仍然在存储箱中，直到宝物被卖出。挂牌的宝物可以被收回，并以新的价格重新挂牌。当存储箱装不下时，运气或工作能力值最低的宝物将被系统自动回收。 假设游戏永不停止而玩家的最终目的是获得最好的宝物。 请根据以上场景构建一个假想的 Web 游戏，可供多人在线上玩耍。后台的数据库使用 MongoDB。对游戏玩家提供以下几种操作：寻宝（可以自动每天一次）、赚钱（可以自动每天一 次）、佩戴宝物、浏览市场、买宝物、挂牌宝物、收回宝物。 实验过程 网站构架 本次寻宝游戏网站的整体构架如下图所示。 system_structure 由于游戏平台通常会由多个不同的模块构成，且需要不断的迭代和集成，因此我们采用了前后端分离的架构来设计网站。整个网站分为 四个部分，分别为前端维生服务器、前端页面、后端请求服务器及服务器数据库。 对于前端维生服务器，我们使用了基于 NodeJS 的经典 Web 服务器维持框架 Express。这一 框架提供了一个快速的 Web 应用搭建流程，我们只需要直接将前端页面框架生成的相关资源统 一放在相应的位置，Express 就会帮我们自动托管之后的服务器维持事务。 对于前端页面，我们使用了经典的 Vue 3 框架来进行搭建。这一框架提供了一整套完善的 UI 及前后端交互流程，可以十分清晰的梳理出各个模块之间的继承及通信关系，方便后续维护。对于 UI 样式，我们使用了基于 Vue 3 的 Quasar Framework 2 框架，这一框架支持流式数据加载 及响应式的交互访问，可以吸引用户访问并使用该平台。 由于需要应对各种不同的情况，后端服务器由多个模块联合构成。首先，我们使用了 Flask 作为容器实现框架，并通过蓝图（Blueprint）功能将接口分摊至五个子接口集合上以实现业务隔离。随后，由于我们使用了前后端分离架构，自然会涉及到跨域问题。因此我们在请求处理接口 上加上了一层 CORS 包装器。最后，为了应对高并发请求，我们使用了 Gunicorn 网关容器对全 应用进行了封装，并对 Flask 开启了多线程支持。这样在面对高并发请求时系统可以较为均衡的分摊整个负载。 本次实验使用了 MongoDB 作为服务器存储数据库。作为一个文档型数据库，其类 Json 格 式的数据管理模型更贴近 Web 交互时的数据格式，这使得我们在后续在设计接口数据协议时更为方便。 数据库设计 内嵌存储 v.s 归一化存储 对于当前应用，我们主要需要存储以下几种数据:系统中可用的宝物及其价值、用户的各种 基本信息、用户正在佩戴的物品、用户当前拥有的物品、市场上正在出售的宝物。 对于文档型数据库，一个最直接的想法便是将所有的用户数据全部存储在同一个集合中。因此，对于当前应用，一个可能的数据库设计如下图所示。 embed_db 其中，用户已佩戴的物品及储物箱中的物品被以数组的形式嵌入用户集合中。这样做的好处是在每次用户访问其拥有物品 时，我们始终能够以 \\(O(1)\\) 的代价（获取到用户文档之后）完成对用户物品查询。然而，当用户想要变更物品的状态时，系统就需要遍历整个数组以找到对应的物品，此时其时间开销便会变得极为糟糕，在最坏情况下甚至能达到 \\(O(n)\\)（获取到用户文档之后），且索引功能很难帮助优化这 一查询代价。此外，这一存储方式会带来大量的数据冗余，且由于宝物的全部信息均被存储在了用户表中，当系统要对宝物信息进行更新时，就需要对所有集合中的所有玩家的每一条宝物数据进行遍历，当用户规模较大时，这一代价将变得十分巨大，且此时可能出现数据不一致的问题， 破坏了数据库的 ACID 原则。 在数据库设计中，我们通常还会尽可能的让同一数据在所有集合中尽可能只保留一份以减少数据冗余，即所谓的存储归一化（Storage Normalization）。在这种模式下，数据库可以以下图所示的方式设计。 normalize_db 这样做的好处是极大的减少了数据冗余，且从灾备的角度来看， 即使发生了数据丢失，由于宝物和用户的信息是单独存储的，其数据损失的概率也相对较小。此外，当宝物状态需要发生改变时，我们只需要移动其唯一标识即可进行更改，数据移动的开销较小。然而，由于宝物与用户的信息发生了分离，对于用户的每一件物品，我们都需要至少访问两个集合才能获取到所有需要的数据，而访问不同的集合对于 MongoDB 而言开销是巨大的，因此对于本应用来说仍然不是一个合适的选择。 缓存型存储 为了解决上面两种方式的问题，对于本应用，我们采用了一种称为缓存型存储（或存储反归一化， Storage Denormalization）的思想来设计本应用的数据库结构。与直接存储不同的是，缓存 型存储是先将数据进行归一化，随后再将数据以最适合访问的方式进行冗余缓存，这样既保证了数据修改时的数据一致性，又使得数据能以较高的效率被访问。 本应用的数据库集合设计如下图所示。 denormalize_db 其中，用户集合包含了用户的全部基本信息，而宝物集合则维护了当前系统中能够被提供的全部宝物信息。持有物品集合中存储了所有玩家所拥有的物品及其相关状态，其在本应用中既用作玩家存储箱信息的维护，也用作市场上物品信息的维护。此外，根据实际的查询需求，我们对宝物集合的 gain 键建立了索引，对持有物品集合的 owner 和 status 两个键分别建立了索引。 更具体的，每个集合中各个键的数据类型定义如下表所示。 table_db_structure 这里需要注意的是，对于用户的头像，我们使用了一个对象标识符类型将其指向一个外部的位置。由于 MongoDB 采用了 BSON 作为其文档存储实现，其最大单个文档的大小限制为 4MB。而若要将用户头像这样的二进制数据直接存储在单个文档中，则很容易超过这一限制导致无法存储。为了解决这一问题，MongoDB 提供了一个名为 GridFS 的存储方案。通过将二进制文件拆分为多 个小块（Chunk，通常为 256KB/个），我们便可以将图片等媒体数据存储在数据库中。因此事实上该应用一共有 5 个集合，额外的两个集合（分别名为 fs.chunks 和 fs.files）分别用于存储 大文件的二进制数据及其块索引。 作为归一化集合，当数据进行更新时，用户集合和宝物集合拥有最高的更新优先级。持有物品集合作为本应用的缓存集合，包含了玩家可能频繁访问的全部物品数据。因此无论玩家是在访问自己的装备物品、存储箱还是市场上正在出售的物品时，我们都只需要访问持有物品这一个集合，极大地提高了数据查询的效率。 此外，为了保证数据一致性，在每一次应用启动时，系统都会对缓存集合中的数据进行检查。 由于缓存集合中记录了其他集合相关条目的唯一标识符，因此这一同步是可行的。当管理员需要进行某些更新(例如对某件宝物的属性进行调整时)，系统也会先更新宝物和用户集合，再将数据同步至持有物品集合中。 可以注意到，这里我们没有单独为市场设计一个缓存集合，这是由于用户查询市场上的物品就等价于查询所有玩家中 status=3 的物品，而我们已经对持有物品集合中的 status 键建立了索引，这一查询的效率是极高的，因此无需再另设一个集合专门对市场上的物品进行缓存。此外， 若再设一个缓存集合，则需要花费更高的代价去解决数据不一致的问题，得不偿失，可见这样做是并不合适的。 ODM 与数据库交互实现 MongoDB 提供了对 Python 的原生访问接口模块 pymongo。通过这一模块，我们可以使用和 命令行中类似的类 JSON 方式对数据库中的对象进行 CRUD（Create-Retrieve-Update-Delete）操作。然而，由于其没有与 Python 中对象的直接映射关系，我们无法快速获知当前操作对数据库及 Python 对象进行了怎样的数据变化，这样很容易使得操作逻辑变得不可控（尤其是考虑到文档型数据库中可以动态加入键值的特性）。 受到 MySQL 等关系型数据库中 ORM 概念的启发，对于对象型编程语言与数据库间的交互，一个极好的办法便是实用所谓的对象-文档映射（ODM，Object Document Mapping）模型。 通过将数据库中的对象映射为 Python 中的类，我们便可以直接使用 Python 中的类操作方法对数据库中的对象进行操作。由于每一个数据库文档中的键都与对象中的一个变量有一一对应关系，我们便可以随时掌握当前操作的内容及其可能的行为，这样就使得整个系统更易于维护。 幸运的是，对于 MongoDB，Python 中已经存在了一款十分完善的 ODM 实现模块 Mongo-Engine。对于本应用，我们直接使用专门针对 Flask 框架封装的 Flask-MongoEngine 来实现对应的 ODM 模型。对于上述提出的集合结构，其 ODM 模型申明代码如下: 12345678910111213141516171819202122232425262728293031class User(db.Document): username = db.StringField(required=True) password = db.StringField(required=True) nickname = db.StringField() permission = db.IntField(default=1) # 1 - Player; 2 - Admin avatar = db.FileField() coin = db.IntField(default=10) power = db.IntField(default=1) luck = db.IntField(default=1) regtime = db.DateTimeField(default=datetime.now()) tool_equipped = db.IntField(default=0) accessory_equipped = db.IntField(default=0) container_usage = db.IntField(default=0)class Treasure(db.Document): name = db.StringField(required=True) type = db.IntField(required=True) # 1 - Tools; 2 - Accessories gain = db.IntField() meta = &#123; &#x27;indexes&#x27;: [ &#x27;gain&#x27; ] &#125;class Container(db.Document): treasure_id = db.ObjectIdField(required=True) treasure_name = db.StringField() treasure_type = db.IntField() treasure_gain = db.IntField() owner = db.ObjectIdField(required=True) owner_name = db.StringField() status = db.IntField() # 1 - Equipped; 2 - In inventory; 3 - On sale price = db.IntField() # Only exists when status = 3 meta = &#123; &#x27;indexes&#x27;: [ &#x27;owner&#x27;, &#x27;status&#x27; ] &#125; 在该种映射模型下，数据库的 CRUD 操作变得异常简单。下面以用户表的一次 CRUD 操作 代码为例： 12345user_create = User(username=username, password=password) # Createuser_item = User.objects(username=username).first() # Retrieveuser_item.nickname = abc # Updateuser_item.delete() # Deleteuser_create.save() # Save 业务实现 账户管理 对于玩家来说，一款游戏的账户管理系统主要涉及用户注册及用户登录两个功能，因此我们分别设计两个接口/register 及/login 来完成这一交互逻辑。 首先我们来设计注册接口。当用户发起注册请求时，我们首先从请求中拿到用户所要注册的用户名和密码，随后使用 MongoEngine 提供的查询语句查询数据库中用户名是否已经存在。若用户名不存在，则向数据库的 User 文档集合中插入一条新的用户文档，否则则报错。为了方便后续维护，我们约定/register 接口的返回状态码如下： register_status 对于登录接口，我们首先从 request 请求体中获得用户名及密码，随后使用 MongoEngine 查询数据库中用户名符合的第一条记录（由于在注册时对数据库中是否存在重名用户进行了检查， 因此这里可以保证获得的第一条记录是整个数据库中唯一符合条件的记录）。得到记录后，我们只需要对其密码进行比对，并将判断结果返回给用户（前端）即可。 同样的，这里我们约定/login 接口的返回状态码如下： login_status 对于账户管理页面的前端设计，我们使用了 Layout+Page 的模式对其进行了样式统一，并使 界面尽可能的保持简洁。其效果如下图所示。 login_page register_page Session 与用户组 由于后续的请求中大量涉及到用户验证，若每次都需要在请求体中加入用户名和密码，则后续操作将会变得十分复杂，且由于用户信息始终在端与端之间传输，会造成极大的安全隐患。因此这里我们使用会话（Session）技术来保持用户的登录状态。同时，为了保证请求安全性，我们还需要对 Session 进行加密。 Flask原生提供了对Session的支持，我们可以直接使用键值对的方式对一个应用中的Session 进行操作。对于本应用，我们对除登录注册外的所有接口都设置了 Session 验证，当检测到用户发来的请求头中没有 Session 信息的话，则会直接返回 100 状态码告诉用户无权访问。 在实际场景下，有时我们需要对游戏中的内容进行更新操作（如添加新的可用宝物），为了方便这一操作，我们将其引入前端的交互界面中。然而一旦将修改全局数据库的操作暴露在公开接口中，我们就需要开始考虑操作的权限验证问题，否则就有可能产生安全问题。得益于 Session 用户验证机制，我们可以通过设置用户组来对用户的访问权限进行限制。 对于当前应用，我们进行如下的权限组约定： permission_table 可以看到，在前面的数据库结构设计中，我们在用户集合中设置了一个 permission 键用于标识用户所在的组。当用户注册完成后，该键默认被设置为 1，且不可通过接口请求的方式进行更改。为了方便统一管理，我们将所有的管理员操作专门放到一个/admin 蓝图中。该蓝图中的所有接口均进行了用户组认证。当用户发起请求时，系统会首先检查请求头 Session 中包含的用户信息，若用户的权限组高于 2，则继续处理用户所请求的操作，否则直接返回用户码 2 告诉用户无权修改服务器。 对于不同的用户组，前端界面的呈现也进行了一定的区分。其中当用户为管理员时，菜单中会多出一栏管理员界面可供用户进行操作，这与常规游戏中的设计也基本吻合。 normal_player_navigate command_player_navigate","categories":[],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Database","slug":"Database","permalink":"http://gonggongjohn.me/tags/Database/"}]},{"title":"数据科学与工程数学基础 作业7","slug":"dase-math/dase-math-assignment-7","date":"2021-06-30T02:00:00.000Z","updated":"2022-02-10T14:38:31.914Z","comments":true,"path":"2021/06/30/dase-math/dase-math-assignment-7/","link":"","permalink":"http://gonggongjohn.me/2021/06/30/dase-math/dase-math-assignment-7/","excerpt":"","text":"一 下面的集合哪些是凸集？ 平板， 即形如 \\(\\left\\{ x \\in \\mathbb{R}^n | \\alpha \\leq a^T x \\leq \\beta \\right\\}\\) 的集合。 矩形， 即形如 \\(\\left\\{ x \\in \\mathbb{R}^n | \\alpha_i \\leq x_i \\leq \\beta_i, i = 1, \\cdots, n \\right\\}\\) 的集合。当 \\(n &gt; 2\\) 使，矩形有时也称为超矩形。 楔形，即 \\(\\left\\{ x \\in \\mathbb{R}^n | a_1^T x \\leq b_1, a_2^T x \\leq b_2 \\right\\}\\)。 距离给定点比距离给定集合近的点构成的集合，即 \\[ \\left\\{ x | || x - x_0 ||_2 \\leq || x - y ||_2, \\forall y \\in S \\right\\} \\] ，其中 \\(S \\subseteq \\mathbb{R}^n\\) (a) 该集合可写为 \\(\\{x \\in \\mathbb{R}^n | a^Tx \\leq \\beta \\} \\cap \\{x \\in \\mathbb{R}^n | a^Tx &gt; \\alpha \\}\\)，故为一个凸集 (b) 该集合可写为一组半空间的交集，故为一个凸集 (c) 该集合可写为 \\(\\{x \\in \\mathbb{R}^n | a_1^T x \\leq b_1\\} \\cap \\{x \\in \\mathbb{R}^n | a_2^T x \\leq b_2\\}\\)，故为一个凸集 (d) 该集合可写为 \\[ \\bigcap_{y \\in S} \\{x | ||x - x_0||_2 \\leq ||x-y||_2 \\} \\] 故为一个凸集 二 下面的函数哪些是凸函数? 请说明理由： \\(f(x)=e^{x}+1, x \\in \\mathbb{R}\\) \\(f(x)=\\max \\left(\\|A x+b\\|_{2},\\left\\|x^{T} A x\\right\\|_{1}\\right), A \\in \\mathbb{R}^{m \\times n} x \\in \\mathbb{R}^{n} b \\in \\mathbb{R}^{m}\\) \\(f(x)=-\\cos x, x \\in[-\\pi / 2, \\pi / 2]\\) (a) \\[ f&#39;(x) = e^x, f&#39;&#39;(x) = e^x &gt; 0, x \\in \\mathbb{R} \\] 故 \\(f(x)\\) 为凸函数 (b) 由于仿射映射、仿射函数取范数、取最大值为保凸运算，故 \\(f(x)\\) 为凸函数 (c) \\[ f&#39;(x) = \\sin x, f&#39;&#39;(x) = \\cos x \\geq 0, x \\in [-\\frac{\\pi}{2}, \\frac{\\pi}{2}] \\] 故 \\(f(x)\\) 为凸函数 三 证明 \\(x^* = (1, 0.5, -1)\\) 是如下优化问题的最优解： \\[ \\begin{aligned} &amp;\\min &amp;\\frac{1}{2} x^T P x + q^T x + r \\\\ &amp;\\textrm{s.t} &amp; -1 \\leq x_i \\leq 1, i = 1,2,3 \\end{aligned} \\] 其中 \\[ P = \\begin{pmatrix} 13 &amp; 12 &amp; -2 \\\\ 12 &amp; 17 &amp; 6 \\\\ -2 &amp; 6 &amp; 12 \\end{pmatrix}, q = \\begin{pmatrix} -22 \\\\ -14.5 \\\\ 13 \\end{pmatrix}, r = 1 \\] 由于 \\(\\nabla f_0 = \\frac{1}{2} (P+P^T) x +q = px+q\\) 故 \\(\\nabla f_0(x^*) = (-1,0,2)^T\\) 因此 \\(\\forall y \\in [-1,1]^n\\)，\\(\\nabla f_0(x^*)^T(y-x) \\geq 0\\) 即 \\(x^*\\) 满足最优性条件，也即目标函数的最优点 四 计算函数 \\(f(x)\\) 的共轭函数，以及共轭函数的定义域： \\(f(x) = - \\log x\\) \\(f(x) = e^x\\) (a) 由 \\(f(x)=- \\log x\\) 可知 \\(domf = \\{x|x&gt;0\\}\\) 令 \\(g(x,y) = xy + \\log x\\) 当 \\(y \\geq 0\\) 时，\\(\\sup g(x,y) = +\\infty\\) 当 \\(y &lt; 0\\) 时，\\(\\sup g(x,y) = -1- \\log(-y)\\) 当且仅当 \\(x = -\\frac{1}{y}\\) 故 \\(f^*(y) = -1-\\log(-y),y &lt; 0\\) (b) \\(domf = \\mathbb{R}\\) 令 \\(g(x,y) = xy- e^x\\) 当 \\(y&gt;0\\) 时，\\(\\sup g(x,y) = y \\log y - y\\) 当且仅当 \\(x = \\log y\\) 当 \\(y = 0\\) 时，\\(\\sup g(x,y) = \\sup (-e^x) = 0\\) 当 \\(y &lt;0\\) 时，\\(\\sup g(x,y) = +\\infty\\) 故 \\[ f^*(y) = \\left\\{ \\begin{aligned} y \\log y - y, y &gt; 0 \\\\ 0, y = 0 \\end{aligned} \\right. \\] 五 求解线性规划 \\[ \\begin{aligned} &amp;\\min &amp;e^T x \\\\ &amp;\\textrm{s.t} &amp;G x \\leq h \\\\ &amp; &amp;Ax = b \\end{aligned} \\] 的对偶函数，给出对偶问题。 拉格朗日函数 \\[ \\begin{aligned} L(x, \\lambda, \\mu) &amp;= e^T x + \\lambda^T (Gx-h) + \\mu^T(Ax-b) \\\\ &amp;= (e^T + \\lambda G+\\mu^T A)x - \\lambda^T h - \\mu^T b \\end{aligned} \\] 故 \\[ g(\\lambda, \\mu) = \\left\\{ \\begin{aligned} -\\lambda^T h - \\mu^T b &amp;,&amp; e + G^T \\lambda + A^T \\mu = 0 \\\\ -\\infty&amp;,&amp; otherwise \\end{aligned} \\right. \\] 因此其对偶问题为 \\[ \\max_{\\lambda, \\mu} \\left( -\\lambda^Th-\\mu^Tb \\right) \\\\ s.t. \\ \\ e + G^T \\lambda + A^T \\mu = 0, \\lambda \\geq 0 \\] 六 证明：Gauss概率密度函数的累积分布函数 \\[ \\Phi(x) = \\frac{1}{\\sqrt{2 \\pi}} \\int_{- \\infty}^x e^{-\\frac{u^2}{2}} du \\] 是对数-凹函数。即 \\(\\log(\\Phi(x))\\) 是凹函数。 由于 \\[ \\Phi&#39;(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} \\\\ \\Phi&#39;&#39;(x) = -\\frac{x}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} \\] 故 \\[ (\\Phi&#39;(x))^2 = \\frac{1}{2 \\pi} e^{-\\frac{x^2}{2}} \\\\ \\Phi(x) \\Phi&#39;&#39;(x) = -\\frac{x}{2 \\pi} e^{-\\frac{x^2}{2}} \\int_{-\\infty}^x e^{-\\frac{u^2}{2}} du \\] 当 \\(x \\geq 0\\) 时，易见 \\(\\Phi(x) \\Phi&#39;&#39;(x) \\leq (\\Phi&#39;(x))^2\\) 当 \\(x &lt; 0\\) 时，由 \\(\\frac{u^2}{2}\\) 的凸性可知 \\[ \\begin{aligned} \\Phi(x) \\Phi&#39;&#39;(x) &amp;= -\\frac{x}{2 \\pi} e^{-\\frac{x^2}{2}} \\int_{-\\infty}^x e^{-\\frac{u^2}{2}} du \\\\ &amp;\\leq -\\frac{x}{2 \\pi} e^{-\\frac{x^2}{2}} \\int_{-\\infty}^x e^{-\\frac{x^2}{2}-(u-x)x} du \\\\ &amp;=\\frac{1}{2\\pi} e^{-\\frac{x^2}{2}} \\\\ &amp;= \\left(\\Phi&#39;(x)\\right)^2 \\end{aligned} \\] 由此可知 \\(\\Phi(x)\\) 时对数凸函数 七 求优化问题 \\(\\arg\\min_{x_1, x_2, x_3} x_1x_2x_3\\) 当 \\(x_1,x_2,x_3\\) 满足 \\(x_1^2 + x_2^2 + x_3^2 = 1\\) 的解 拉格朗日函数 \\(L = x_1x_2x_3 + \\lambda (x_1^2 + x_2^2+x_3^2 - 1)\\) 令 \\(\\nabla L = 0\\)，即 \\[ \\left\\{ \\begin{aligned} &amp;\\frac{\\partial L}{\\partial x_1} = x_2 x_3 + 2\\lambda x_1 = 0 \\\\ &amp;\\frac{\\partial L}{\\partial x_2} = x_1 x_3 + 2\\lambda x_2 = 0 \\\\ &amp;\\frac{\\partial L}{\\partial x_3} = x_1 x_2 + 2\\lambda x_3 = 0 \\\\ &amp;\\frac{\\partial L}{\\partial \\lambda} = x_1^2 + x_2^2 + x_3^2 - 1 = 0 \\\\ \\end{aligned} \\right. \\] 解得 \\(|x_1| = |x_2| = |x_3| = \\frac{1}{\\sqrt{3}}\\) 故 \\(|x_1x_2x_3| = \\frac{\\sqrt{3}}{9}\\) 代入原方程可知 \\(x_1x_2x_3 = -\\frac{\\sqrt{3}}{9}\\) 八 已知矩阵 \\(A \\in \\mathbb{R}^{p \\times q}, B \\in \\mathbb{R}^{p \\times r}, \\textrm{rank}(A) = \\min (p,q)\\)，未知矩阵 \\(X \\in \\mathbb{R}^{q \\times r}\\)，求以下优化问题： 若 \\(p &lt; q\\)，求Frobenius范数最小的矩阵 \\(X\\)，使得 \\(AX = B\\)，也即优化问题为 \\[ \\begin{aligned} &amp;\\min &amp;f(X) = \\frac{1}{2} ||X||_F^2 \\\\ &amp;\\textrm{s.t} &amp;AX = B \\end{aligned} \\] 拉格朗日函数 \\(L = Tr(\\frac{1}{2} X^T X) - Tr(\\Lambda^T(AX-B))\\) 令 \\(\\nabla L = 0\\)，即 \\[ \\left\\{ \\begin{aligned} &amp;\\frac{\\partial L}{\\partial X} = X-A^T \\Lambda = 0 \\\\ &amp;\\frac{\\partial L}{\\partial \\Lambda} = AX-B = 0 \\end{aligned} \\right. \\] 由于 \\(A\\) 行满秩，故 \\(AA^T\\) 可逆 故 \\(AX = B = AA^T(AA^T)^{-1}B\\) 即 \\(X = A^T(AA^T)^{-1} B\\) 九 给出优化问题 \\(\\min_x (x^3 - ax)\\) 使用牛顿法时的迭代格式。 \\[ f&#39;(x) = 3x^2-a, f&#39;&#39;(x) = 6x \\] 故 \\[ x_n = x_{n-1} - \\frac{f&#39;(x_n)}{f&#39;&#39;(x_n)} = x_{n-1} - \\frac{3x_n^2-a}{6x_n} \\] 十 梯度下降法是最常用的优化方法之一。考虑优化问题 \\[ \\min f(x) = x_1^2 + x_2^2 + 2x_3^2 \\] 证明:在点 \\(x_0 = (x_1, x_2, x_3)\\) 处沿负梯度方向迭代的最佳步⻓为 \\[ \\lambda = \\frac{x_1^2 + x_2^2 + 4x_3^2}{2x_1^2 + 2x_2^2 + 16 x_3^2} \\] 令 \\(x&#39; = x - \\lambda \\nabla f(x)\\) 故 \\[ \\begin{aligned} g(\\lambda) &amp;= f(x&#39;) \\\\ &amp;= f(x - \\lambda \\nabla f(x)) \\\\ &amp;= (1-2\\lambda)^2 x_1^2 + (1-2\\lambda)^2 x_2^2 + 2 (1-4\\lambda)^2 x_3^2 \\end{aligned} \\] 于是 \\[ g&#39;(\\lambda) = -4(1-2\\lambda)^2 x_1^2 - 4 (1-2\\lambda)^2x_2^2 - 16(1-4\\lambda)x_3^2 \\] 令 \\(g&#39;(\\lambda) = 0\\) 解得 \\[ \\lambda = \\frac{x_1^2+x_2^2+4x_3^2}{2x_1^2+2x_2^2+16x_3^2} \\]","categories":[{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"}]},{"title":"数据科学与工程数学基础 作业6","slug":"dase-math/dase-math-assignment-6","date":"2021-06-30T01:00:00.000Z","updated":"2022-02-10T14:36:32.120Z","comments":true,"path":"2021/06/30/dase-math/dase-math-assignment-6/","link":"","permalink":"http://gonggongjohn.me/2021/06/30/dase-math/dase-math-assignment-6/","excerpt":"","text":"一 证明：若 \\(H(Y|X) = 0\\) 则 \\(Y\\) 是 \\(X\\) 的函数（即对于满足 \\(p(x) &gt; 0\\) 的任意 \\(x\\)，仅存在一个可能的取值 \\(y\\)，使得 \\(p(x,y) &gt; 0\\)） 由 \\(H(Y|X) = 0\\) 可知，对任意 \\(x_i\\)，存在唯一的 \\(y_j\\) 使得 \\(P(Y=y_j|X=x_i) = 1\\) 故 \\[ \\begin{aligned} p(x_i, y_j) &amp;= p(y_j|x_i) \\cdot p(x_i) \\\\ &amp;=p(x_i), X=x_i \\land Y=y_j \\end{aligned} \\] 也即 \\(Y\\) 是 \\(X\\) 的函数 二 一个容器里面装有 \\(a\\) 个红球和 \\(b\\) 个白球，若从容器中取出 \\(k(k \\geq 2)\\) 个球。对于有放回和无放回两种情况，哪种情况的熵更大?请回答并给予说明。 有放回时，第 \\(i\\) 次摸出红球和白球的概率是相同的 无放回时， 第 \\(i\\) 次摸出红球和白球的概率与前 \\(i-1\\) 次的结果有关 于是由熵的极值性可知，有放回的熵更大。 三 投掷一枚均匀的硬币。硬币出现正面和反面的互信息是多少？ \\[ I(H,T) = \\log \\frac{P(H|T)}{P(H)} = -\\infty \\] 四 投掷一颗 \\(6\\) 面均匀的骰子，出现顶面和前面的互信息是多少？ \\[ I(Top, Front) = \\log \\frac{P(Top|Front)}{P(Top)} = -\\infty \\] 五 求均匀分布 \\(X \\sim U(a,b)\\) 的微分熵 \\[ \\begin{aligned} h(X) &amp;= -\\int_a^b \\frac{1}{b-a} \\log \\frac{1}{b-a} dx \\\\ &amp;=\\log(b-a) \\end{aligned} \\]","categories":[{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"}]},{"title":"树莓派在线教学系统","slug":"web/remote-teaching","date":"2021-06-29T03:28:35.000Z","updated":"2021-07-02T16:20:12.083Z","comments":true,"path":"2021/06/29/web/remote-teaching/","link":"","permalink":"http://gonggongjohn.me/2021/06/29/web/remote-teaching/","excerpt":"树莓派部署 ​ 树莓派（Raspberry Pi）是由英国慈善组织“Raspberry Pi基金会”开发的一款ARM微型单片机，其具备了一台标准计算机的绝大部分功能，常被用于提供各类小型服务类应用及嵌入式产品驱动。本项目基于Raspberry Pi 4B型号进行开发。 ​ 树莓派官方提供了一个基于Linux内核的专为树莓派硬件设计的Raspberry Pi OS操作系统，可以直接在其官网进行镜像的下载。这里我们使用当前最新版（Kernel Version: 5.10）进行开发。","text":"树莓派部署 ​ 树莓派（Raspberry Pi）是由英国慈善组织“Raspberry Pi基金会”开发的一款ARM微型单片机，其具备了一台标准计算机的绝大部分功能，常被用于提供各类小型服务类应用及嵌入式产品驱动。本项目基于Raspberry Pi 4B型号进行开发。 ​ 树莓派官方提供了一个基于Linux内核的专为树莓派硬件设计的Raspberry Pi OS操作系统，可以直接在其官网进行镜像的下载。这里我们使用当前最新版（Kernel Version: 5.10）进行开发。 ​ 将系统烧录至SD卡并引导进入系统后，我们首先打开系统的SSH及VNC服务，使得其可以通过远程访问： 1&gt; sudo raspi-config 在弹出的GUI界面中选择Interfacing Options，依次打开SSH及VNC配置项即可。 ​ 接下来我们来为树莓派创建一个热点，使得其他设备可以连接到树莓派的WIFI网络中以通过局域网访问后续的教学网站页面。首先我们安装在系统中安装hostapd（一个类Unix系统下可以提供热点访问的服务端工具）和dnsmasq（一个用于配置DNS和DHCP的工具）： 12&gt; sudo apt-get install hostapd&gt; sudo apt install dnsmasq 在/etc/hostapd/目录下创建一个hostapd.conf配置文件，并在其中指定要创建热点的相关信息： 1234567891011121314interface=wlan0driver=nl80211ssid=graspberryhw_mode=gchannel=7wmm_enabled=0macaddr_acl=0auth_algs=1ignore_broadcast_ssid=0wpa=2wpa_passphrase=1029384756wpa_key_mgmt=WPA-PSKwpa_pairwise=TKIPrsn_pairwise=CCMP 随后我们将这一配置文件添加到/etc/default/hostapd中： 1DAEMON_CONF=&quot;/etc/hostapd/hostapd.conf&quot; 重启系统后，我们打开hostapd服务： 123&gt; sudo systemctl unmask hostapd&gt; sudo systemctl enable hostapd&gt; sudo systemctl start hostapd 现在，我们便可以在其他设备上搜索到树莓派的热点信号了： 连接热点后，我们只需要使用SSH工具，便可以远程访问树莓派： ​ 由于Raspberry Pi OS是Linux系统的一种，我们可以使用与开发环境类似的方式部署网站。首先我们从官网下载并安装Node运行环境包（https://nodejs.org/zh-cn/download/），并配置相应的环境变量：（.bash_profile） 123export NODE_HOME=/home/pi/ node-v14.17.2-linux-armv7lexport PATH=$PATH:$NODE_HOME/bin export NODE_PATH=$NODE_HOME/lib/node_modules 随后我们使用apt-get安装MariaDB-Server作为服务端数据库环境： 1&gt; sudo apt-get install mariadb-server-10.0 以安全模式进入数据库并修改数据库默认密码： 123456&gt; sudo service mysql stop&gt; sudo mysqld_safe --skip-grant-tables &amp;&gt; mysql -u rootMariaDB&gt; update mysql.user set authentication_string=PASSWORD(&#x27;1029384756&#x27;), plugin=&#x27;mysql_native_password&#x27; where user=&#x27;root&#x27;;&gt; sudo service mysql stop&gt; sudo service mysql start 现在我们的树莓派系统已经可以支持网页应用的部署了。 系统构架 ​ 整个树莓派在线教学系统分为用户端（前端）及服务端（后端），其中用户端又分为学生端和教师端，其基本系统构架如下图所示： structure ​ 可以看到，整个系统的构架是十分清晰的。用户首先通过用户管理系统登录在线教学系统，系统会根据教师或学生身份分别跳转到教师端的课程路由界面或学生端课程路由界面。随后，系统通过请求后端的课程数据库来返回用户当前参与或教授的所有课程，用户可根据界面提示进入到相应的课程界面中。对于一个课程界面，系统提供了签到、实时聊天、文件下载、在线答题及视频推流5个基本模块，每个模块经过后端路由再传递给服务器文件系统或另一学生/教师客户端。对于学生签到机制，后端会通过深度学习模型对前端传入的照片进行人脸识别，并将相应的签到结果传给教师客户端；而对于在线答题机制，则由教师端先上传一定格式的题目描述及答题限制，再由后端的试题结构解析器进行解析分发给学生客户端，当学生完成答题后，再通过路由送到后端进行结果统计，并将统计结果发送回教师端展示。 ​ 以用户视角来看，教学系统的主体界面效果如下： Quasar Framework与前端整合 ​ 由于该网站的前端元素较为繁杂，我们需要一个合适易用的前端框架来避免大量不必要的重复编码。Quasar Framework是一款基于Vue.js的前端UI框架，其开箱即用和跨平台的属性使得我们可以快速的对各类UI元素进行整合。要构架Quasar Framework开发环境是容易的，Quasar官方提供了一个基于Vuex的脚手架，我们以此为起点来进行网站前端的构建。 ​ 首先我们使用npm工具全局安装Quasar-CLI最新版： 1&gt; npm install -g @quasar/cli 系统会自动安装相关的必要的组建，包括Vue-CLI脚手架（如果没有自动安装的话，可以手动安装Vue-CLI最新版本）。 随后，我们在目标位置使用Quasar-CLI生成一个前端开发环境： 1&gt; quasar create frontend 系统会自动解析并生成所需的相应配置文件，并会在其中询问我们若干次相关参数的设置值，这里我们直接使用默认选项即可。 生成完成后，我们进入目录安装相应的Node依赖包： 1&gt; npm install 现在，我们的前端开发环境就配置完成了。我们可以使用如下命令即时查看开发效果，也可以对整个应用进行打包送至后端进行整合： 12&gt; quasar dev # 开发环境测试&gt; quasar build # 打包至生产环境 ​ Vue将布局（Layout）和页面（Page）进行了分离，使得在同种布局下网站中的内容可以进行缺省替换，这正是本项目所需要的。对于本项目，我们设计了两种不同的界面布局，分别用于用户管理和授课窗口。网站的前端路由结构如下图所示： Express与后端路由 ​ 为了与前端达到最佳的适配，我们使用NodeJS+Express框架作为服务端的实现基础。与Quasar类似，Express同样提供了一个官方脚手架用于搭建后端的开发环境。我们只需使用npm工具全局安装即可： 12&gt; npm install -g express&gt; npm install -g express-generator 安装完成后，我们在目标位置生成一个新的后端项目： 1&gt; express backend Express脚手架会在目标位置自动生成相关的依赖文件： 生成完后端环境后，我们进入目录，使用npm安装相应的依赖包，即可使用如下命令进行后端的测试： 1&gt; node bin/www ​ 本项目后端路由的整体结构如图所示： 可以发现，除了根目录为网页推送接口，其他接口均为前端请求响应接口，故这些接口可以向用户隐去。此外，本项目还需要额外创建一个WebSocket服务器来响应实时的前后端数据交互请求。 用户管理 ​ 我们在数据库中创建一张表user来管理用户的基本信息。对于一个用户而言，我们需要记录其用户名（username）、密码（password）、邮箱（email）和身份（identity）。此外，我们还需要记录其参加/开设的课程编号（lessons）： 123456789CREATE TABLE user( &#96;id&#96; INT NOT NULL AUTO_INCREMENT, &#96;username&#96; TEXT NOT NULL, &#96;password&#96; TEXT NOT NULL, &#96;email&#96; TEXT, &#96;identity&#96; INT NOT NULL, &#96;lessons&#96; TEXT, PRIMARY KEY (&#96;id&#96;)); ​ 用户的基本管理逻辑分为注册和登录。我们将两个逻辑分别封装在两个独立的函数中，并采用回调函数的方式让路由调用。对于用户登录，我们只需要查询表中是否存在对应username键和password键的行即可。由于Node.JS中的Mysql插件为异步访问的，这里我们需要使用Promise函数来确保其执行顺序。为了向回调函数提供统一的接口，我们使用status状态字来指示查询的结果和状态： 123456789101112131415161718192021222324252627var login = function(username, password, callback)&#123; var sql_str = &quot;SELECT username,password FROM user WHERE username=?&quot;; var sql_param = [username]; var promise = new Promise(function(resolve, reject)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject(err); &#125; else&#123; resolve(result); &#125; &#125;); &#125;); promise.then((result) =&gt; &#123; var status = 0; /* 0 - 未确定; 1 - 成功; 2 - 用户名不存在; 3 - 密码错误 */ if(result == undefined || result.length == 0)&#123; status = 2; &#125; else if(result[0].password == password)&#123; status = 1; &#125; else&#123; status = 3; &#125; callback(status); &#125;);&#125; ​ 注册的逻辑同登录类似，只需将Mysql查询语句改为插入语句即可。这里需要注意的是，为了确保用户名的唯一性，我们在插入数据之前需首先查询表中是否已经存在对应的username键值，如果存在相同用户名，我们需要返回用户一个“用户名已存在”的错误： 123456789101112131415161718192021222324252627282930313233343536373839var register = function(username, password, email, identity, callback)&#123; var sql_str = &quot;SELECT username FROM user WHERE username=?&quot;; var sql_param = [username]; var promise_query = new Promise(function(resolve, reject)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject(err); &#125; else&#123; resolve(result); &#125; &#125;); &#125;); promise_query.then((result) =&gt; &#123; var status = 0; /* 0 - 未确定; 1 - 成功; 2 - 用户名已存在 */ if(result.length &gt; 0)&#123; status = 2; callback(status); &#125; else&#123; sql_str = &quot;INSERT INTO user(username, password, email, identity) VALUES (?,?,?,?)&quot;; sql_param = [username, password, email, identity]; var promise_insert = new Promise(function(resolve, reject)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject(err); &#125; else&#123; resolve(result); &#125; &#125;); &#125;); promise_insert.then((result) =&gt; &#123; status = 1; callback(status); &#125;) &#125; &#125;);&#125; 课程管理 ​ 为了提高整个系统的可扩展性，我们希望能够并行的同时进行多个课程的在线教学。要做到这一点，我们需要将每个课程的工作环境隔离开来。幸运的是，在Mysql数据库中，我们可以创建一个唯一的ID使得其在每次插入数据的时候进行自增，因此我们可以直接使用这一ID作为课程的唯一标识。 ​ 我们首先创建一张lesson表用于维护整个系统中的全局课程信息，这张表中应当维护课程名（name）、授课教师ID（teacher）及学生列表（students）三个关键字： 1234567CREATE TABLE lesson( &#96;id&#96; INT NOT NULL AUTO_INCREMENT, &#96;name&#96; TEXT NOT NULL, &#96;teacher&#96; TEXT, &#96;students&#96; TEXT, PRIMARY KEY (&#96;id&#96;)); ​ 随后，我们需要封装一系列函数来对这一表格内容进行维护。当教师新创建一门课程时，前端会向教师询问课程名，并请求后端的/lesson_create口进行课程创建： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;template&gt; &lt;q-page class=&quot;flex flex-top-left&quot;&gt; &lt;div style=&quot;width: 100%; margin-top: 2%&quot;&gt; &lt;q-btn color=&quot;secondary&quot; hidden=&quot;false&quot; padding=&quot;sm xl&quot; ref=&quot;create_btn&quot; style=&quot;margin-left: 3%&quot; label=&quot;创建课程&quot; @click=&quot;createLesson = true&quot; /&gt; &lt;/div&gt; &lt;q-dialog v-model=&quot;createLesson&quot;&gt; &lt;q-card&gt; &lt;q-card-section align=&quot;center&quot;&gt; &lt;q-input outlined v-model=&quot;lesson_name&quot; class=&quot;q-pa-sm&quot; :rules=&quot;[val =&gt; !!val || &#x27;课程名称不能为空！&#x27;]&quot; label=&quot;课程名称&quot; /&gt; &lt;q-btn color=&quot;secondary&quot; padding=&quot;sm xl&quot; label=&quot;创建课程&quot; @click=&quot;onCreateLesson&quot; v-close-popup /&gt; &lt;/q-card-section&gt; &lt;/q-card&gt; &lt;/q-dialog&gt; &lt;/q-page&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: &#x27;lessonList&#x27;, data()&#123; return&#123; username: &quot;&quot;, createLesson: false, lesson_name: &quot;&quot;, &#125; &#125;, methods: &#123; onCreateLesson()&#123; var full_url = &#x27;lesson_create?name=&#x27; + this.lesson_name + &#x27;&amp;teacher=&#x27; + this.username; this.axios.get(full_url).then((response) =&gt; &#123; var status = response.data.status; if(status == 1)&#123; alert(&quot;创建成功！&quot;); &#125; else &#123; console.log(&quot;Error occurred!&quot;); &#125; &#125;).catch((response) =&gt; &#123; console.log(response); &#125;); &#125; &#125; &#125;&lt;/script&gt; 创建课程的基本逻辑为无重名确认-&gt;创建课程-&gt;查询课程ID-&gt;将课程信息添加到教师授课列表中，我们可以快速写出相应的实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113var createLesson = function(name, teacher, callback)&#123; var sql_str = &quot;SELECT name FROM lesson WHERE name=? AND teacher=?&quot;; var sql_param = [name, teacher]; var promise_check = new Promise(function(resolve_check, reject_check)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_check(err); &#125; else&#123; resolve_check(result); &#125; &#125;); &#125;); promise_check.then((result_check) =&gt; &#123; var status = 0; /* 1 - 成功; 2 - 课程重名; 3 - 内部错误 */ if(result_check.length &gt; 0)&#123; status = 2; callback(status); &#125; else&#123; sql_str = &quot;INSERT INTO lesson(name, teacher) VALUES (?,?)&quot;; sql_param = [name, teacher]; var promise_create = new Promise(function(resolve_create, reject_create)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_create(err); &#125; else&#123; resolve_create(result); &#125; &#125;); &#125;); promise_create.then((result_create) =&gt; &#123; sql_str = &quot;SELECT id FROM lesson WHERE name=? AND teacher=?&quot;; sql_param = [name, teacher]; var promise_getid = new Promise(function(resolve_getid, reject_getid)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_getid(err); &#125; else&#123; resolve_getid(result); &#125; &#125;); &#125;); promise_getid.then((result_getid) =&gt; &#123; if(result_getid == undefined || result_getid.length == 0)&#123; status = 3; callback(status); &#125; else&#123; appendLesson(teacher, result_getid[0].id, function(status_append)&#123; if(status_append != 1)&#123; status = 3; &#125; else&#123; status = 1; callback(status); &#125; &#125;); &#125; &#125;); &#125;); &#125; &#125;);&#125;var appendLesson = function(username, lesson_id, callback)&#123; var sql_str = &quot;SELECT lessons FROM user WHERE username=?&quot;; var sql_param = [username]; var status = 0; /* 1 - 成功; 2 - 用户名不存在 */ var promise_showlist = new Promise(function(resolve_showlist, reject_showlist)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_showlist(err); &#125; else&#123; resolve_showlist(result); &#125; &#125;); &#125;); promise_showlist.then((result_showlist) =&gt; &#123; if(result_showlist == undefined || result_showlist.length == 0)&#123; status = 2; callback(status); &#125; else&#123; var lesson_str = result_showlist[0].lessons; if(lesson_str == undefined || lesson_str == null)&#123; lesson_str = String(lesson_id); &#125; else&#123; lesson_str = lesson_str + &quot;,&quot; + lesson_id; &#125; sql_str = &quot;UPDATE user SET lessons=? WHERE username=?&quot;; sql_param = [lesson_str, username]; var promise_update = new Promise(function(resolve_update, reject_update)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_update(err); &#125; else&#123; resolve_update(result); &#125; &#125;); &#125;); promise_update.then((resule_update) =&gt; &#123; status = 1; callback(status); &#125;); &#125; &#125;);&#125; 这里需要注意的是，由于MySQL中没有“数组”这一基本数据类型，因此我们使用字符串拼接的方式将课程ID以字符串的形式存储到用户的lessons字段中，当需要查询用户的课程列表时，再通过字符串拆分的方式将其还原为ID列表。 参与已有的课程与查询用户参与的课程列表的逻辑也基本类似，基本都是对通过课程ID作为唯一的键桥梁分别在user和lesson中进行查询操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112var getLessons = function(username, callback)&#123; var sql_str = &quot;SELECT lessons FROM user WHERE username=?&quot;; var sql_param = [username]; var promise_showlist = new Promise(function(resolve_showlist, reject_showlist)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_showlist(err); &#125; else&#123; resolve_showlist(result); &#125; &#125;); &#125;); promise_showlist.then((result_showlist) =&gt; &#123; var errno = 0; /* 0 - 无错误; 1 - 用户名不存在; 2 - 课程不存在 */ if(result_showlist == undefined || result_showlist.length == 0)&#123; errno = 1; callback(errno, undefined); &#125; else&#123; var lesson_str = result_showlist[0].lessons; if(lesson_str == null)&#123; callback(errno, []); &#125; else&#123; var lesson_list = lesson_str.split(&quot;,&quot;); var fetch_total = lesson_list.length; var fetched_num = 0; var promise_loop = new Promise(function(resolve_loop, reject_loop)&#123; var detail_list = []; lesson_list.forEach((lesson) =&gt; &#123; sql_str = &quot;SELECT name,teacher FROM lesson where id=?&quot;; sql_param = [lesson]; var promise_detail = new Promise(function(resolve_detail, reject_detail)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_detail(err); &#125; else&#123; resolve_detail(result); &#125; &#125;); &#125;); promise_detail.then((result_detail) =&gt; &#123; if(result_detail == undefined || result_detail.length == 0)&#123; errno = 2; reject_loop(&quot;Lesson doesn&#x27;t exist!&quot;); &#125; else&#123; detail_list.push(&#123;id: lesson, name: result_detail[0].name, teacher: result_detail[0].teacher&#125;); fetched_num += 1; if(fetched_num == fetch_total)&#123; resolve_loop(detail_list); &#125; &#125; &#125;); &#125;); &#125;); promise_loop.then((result_loop) =&gt; &#123; callback(errno, result_loop); &#125;); &#125; &#125; &#125;);&#125;var appendLesson = function(username, lesson_id, callback)&#123; var sql_str = &quot;SELECT lessons FROM user WHERE username=?&quot;; var sql_param = [username]; var status = 0; /* 1 - 成功; 2 - 用户名不存在 */ var promise_showlist = new Promise(function(resolve_showlist, reject_showlist)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_showlist(err); &#125; else&#123; resolve_showlist(result); &#125; &#125;); &#125;); promise_showlist.then((result_showlist) =&gt; &#123; if(result_showlist == undefined || result_showlist.length == 0)&#123; status = 2; callback(status); &#125; else&#123; var lesson_str = result_showlist[0].lessons; if(lesson_str == undefined || lesson_str == null)&#123; lesson_str = String(lesson_id); &#125; else&#123; lesson_str = lesson_str + &quot;,&quot; + lesson_id; &#125; sql_str = &quot;UPDATE user SET lessons=? WHERE username=?&quot;; sql_param = [lesson_str, username]; var promise_update = new Promise(function(resolve_update, reject_update)&#123; mysql.query(sql_str, sql_param, function(err, result)&#123; if(err)&#123; reject_update(err); &#125; else&#123; resolve_update(result); &#125; &#125;); &#125;); promise_update.then((resule_update) =&gt; &#123; status = 1; callback(status); &#125;); &#125; &#125;);&#125; 现在，我们可以在界面中自由创建/加入并随时查看当前参与的课程了： 文件管理 ​ 接下来我们来实现文件共享的功能。Quasar Framework提供了一个用于文件上传的UI组件，我们可以直接通过调用它来提示用户选择文件并发送至后端： 123456789&lt;template&gt; &lt;q-page class=&quot;flex flex-center&quot;&gt; &lt;q-uploader url=&quot;file_upload&quot; :headers=&quot;[&#123;name: &#x27;lesson_id&#x27;, value: this.lesson_id &#125;]&quot; field-name=&quot;file&quot; /&gt; &lt;/q-page&gt;&lt;/template&gt; 这里为了方便后续的资源隔离，我们在其发送的请求头中加入了课程ID号。 ​ Quasar文件上传器使用了HTTP协议进行文件上传，因此我们需要在后端实现符合这一协议的文件接受通道。这里我们使用了一个名为multer的NodeJS插件，它可以以极高的效率处理前端发来的文件数据。我们先在服务端文件系统上新建一个file_upload目录，用于专门管理课堂中的共享资源。随后，我们在后端路由中附上这一组件，并将接收到的文件统一保存至file_upload目录： 123456789101112var multer = require(&#x27;multer&#x27;);var file_upload = multer(&#123;dest: &#x27;file_upload/&#x27;&#125;);router.post(&#x27;/file_upload&#x27;, file_upload.single(&#x27;file&#x27;), function(request, response)&#123; file.file_redirect(request.file.destination, request.file.path, request.headers.lesson_id, request.file.originalname, function()&#123; response.writeHead(200, &#123; &#x27;Content-Type&#x27;: &#x27;application/json&#x27; &#125;); response.write(JSON.stringify(&#123;&#x27;status&#x27;: 1&#125;)); response.end(); &#125;);&#125;); 由于需要支持多个课堂同时进行，我们需要将每个课程的资源隔离。为此，我们在创建课程时，为每个课程创建一个相应的子目录，以课程ID作为目录名。随后，我们封装一个文件重定位函数，当multer将前端发来的文件保存到目标位置后，随即将其移动至相应的子文件夹下： 1234567891011121314151617181920212223242526272829303132var file_redirect = function(origin_path, origin_fullname, lesson_id, target_name, callback)&#123; console.log(origin_path, origin_fullname, lesson_id, target_name); fs.exists(origin_path + lesson_id + &#x27;/&#x27;, function(exists)&#123; if(!exists)&#123; fs.mkdir(origin_path + lesson_id + &#x27;/&#x27;, function(err)&#123; if(err)&#123; console.log(err); &#125; else&#123; fs.rename(origin_fullname, origin_path + lesson_id + &quot;/&quot; + target_name, function(err)&#123; if(err)&#123; console.log(&quot;Rename error!&quot;); &#125; else&#123; callback(); &#125; &#125;); &#125; &#125;); &#125; else&#123; fs.rename(origin_fullname, origin_path + lesson_id + &quot;/&quot; + target_name, function(err)&#123; if(err)&#123; console.log(&quot;Rename error!&quot;); &#125; else&#123; callback(); &#125; &#125;); &#125; &#125;);&#125; ​ 现在，我们可以正常将文件上传至服务端并共享给其他用户了： ​ 对于学生端而言，每当学生用户进入课程时，我们只需要列出对应文件夹下的文件名，并将其发回给前端，就可以让用户随时看到课堂中的所有共享文件： 1234567891011121314151617var list_files = function(base_path, lesson_id, callback)&#123; fs.exists(base_path + lesson_id + &#x27;/&#x27;, function(exists)&#123; if(!exists)&#123; callback([]); &#125; else&#123; fs.readdir(base_path + lesson_id + &#x27;/&#x27;, function(err, data)&#123; if(err)&#123; console.log(err); &#125; else&#123; callback(data); &#125; &#125;); &#125; &#125;);&#125; ​ 当一个客户端请求下载某个课堂中的文件时，我们可以使用NodeJS自带的fs插件中的流式传输功能，将其输出管道重定向到请求回应流中即可： 1234567891011121314router.get(&#x27;/file_download&#x27;, function(request, response)&#123; var lesson_id = request.query.id; var filename = request.query.filename; if(lesson_id == undefined || filename == undefined)&#123; response.end(); &#125; else&#123; response.writeHead(200, &#123; &#x27;Content-Type&#x27;: &#x27;application/octet-stream&#x27;, &#x27;Content-Disposition&#x27;: &#x27;attachment; filename=&#x27; + encodeURI(filename) &#125;); fs.createReadStream(&#x27;file_upload/&#x27; + lesson_id + &#x27;/&#x27; + filename).pipe(response); &#125;&#125;); 至此，我们已经实现了一个基本的文件共享功能，效果如下： 实时做题 ​ 在在线课堂系统中，有时教师希望能够即时给学生分发一道课堂练习，并实时看到学生的答题状况，这就需要我们实现一套在线做题系统。 ​ 在线做题首先需要教师端上传一道指定的题目。以选择题为例，为了方便结构化解析，我们要求教师上传一个固定格式的json文件作为题目（当然也可使用深度学习技术自动解析非结构化的题目信息，不过这一工程量将大幅度增长，在此我们不做讨论）： ​ 题目共享功能实现的主体思路与文件共享类似，我们只需要让教师端将题目以文件的形式发送给服务端，再通过服务端将题目分发给学生端即可。不过，为了让用户即时看到可阅读的题目信息，我们还需要在后端将题目文件解析为格式化信息，并通过json字符串的方式将结构化的题目发送给前端： 1234567891011121314151617181920var get_problem = function(problem_base, lesson_id, callback)&#123; fs.exists(problem_base + lesson_id + &#x27;/question.json&#x27;, function(exists)&#123; var status = 0; /* 1 - 读取成功; 2 - 文件不存在; 3 - 读取错误 ;*/ if(!exists)&#123; status = 2; callback(status, undefined); &#125; else&#123; var data = fs.readFileSync(problem_base + lesson_id + &#x27;/question.json&#x27;, &#x27;utf8&#x27;); if(typeof data == &#x27;string&#x27;)&#123; status = 1; callback(status, data); &#125; else&#123; status = 3; callback(status, undefined); &#125; &#125; &#125;);&#125; 前端展示实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;template&gt; &lt;q-page class=&quot;flex flex-top-left&quot;&gt; &lt;div style=&quot;margin-top: 3%; margin-left: 3%&quot;&gt; &lt;q-btn color=&quot;secondary&quot; padding=&quot;sm xl&quot; style=&quot;margin-bottom: 5%&quot; label=&quot;上传题目&quot; @click=&quot;onProblemUpload&quot; /&gt; &lt;q-form @submit=&quot;onSubmitAnswer&quot; class=&quot;q-gutter-md&quot;&gt; &lt;h5&gt; 实时题目 &lt;/h5&gt; &lt;p&gt; &#123;&#123;problem_description&#125;&#125; &lt;/p&gt; &lt;q-option-group v-model=&quot;chosen_answer&quot; :options=&quot;answer_options&quot; color=&quot;primary&quot; /&gt; &lt;q-btn label=&quot;提交答案&quot; type=&quot;submit&quot; color=&quot;primary&quot;/&gt; &lt;/q-form&gt; &lt;/div&gt; &lt;/q-page&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: &#x27;lesson&#x27;, data()&#123; return&#123; username: &quot;&quot;, lesson_id: 0, problem_description: &quot;3466645r15&quot;, chosen_answer: &quot;&quot;, answer_options: [ &#123; label: &quot;Answer1&quot;, value: &quot;A&quot; &#125; ] &#125; &#125;, mounted: function() &#123; this.onInitLesson(); &#125;, methods: &#123; onInitLesson()&#123; this.username = this.$route.query.username; this.lesson_id = this.$route.query.lesson_id; this.getProblem(); &#125;, getProblem()&#123; var full_url = &#x27;problem_get?id=&#x27; + this.lesson_id; this.axios.get(full_url).then((response) =&gt; &#123; var problem_json = response.data; if(problem_json != undefined)&#123; this.problem_description = problem_json.description; for(var key in problem_json.options)&#123; this.answer_options.push(&#123; label: problem_json.options[key], value: key &#125;); &#125; console.log(this.answer_options); &#125; &#125;).catch((response) =&gt; &#123; console.log(response); &#125;); &#125; &#125; &#125;&lt;/script&gt; ​ 现在，学生用户已经可以随时接受教师下发的课堂练习并做答了。接下来，我们需要让教师端能够实时得到学生的做题反馈。为了实现这一功能，我们需要让前端实时监听后端的数据变化，并在后端产生数据变化时发送消息给前端。在NodeJS中，我们可以使用WebSocket插件来实现。 ​ 首先，我们在服务端创建一个WebSocket服务器，并监听8000端口： 12345var ws = require(&#x27;nodejs-websocket&#x27;);var ws_server = ws.createServer(function(socket)&#123; //Irrelevant codes&#125;).listen(8000); 当学生前端点击提交答案按钮时，我们通过这一端口将回答信息通知给后端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;template&gt; &lt;q-page class=&quot;flex flex-top-left&quot;&gt; &lt;div style=&quot;margin-top: 3%; margin-left: 3%&quot;&gt; &lt;q-form @submit=&quot;onSubmitAnswer&quot; class=&quot;q-gutter-md&quot;&gt; &lt;h5&gt; 实时题目 &lt;/h5&gt; &lt;p&gt; &#123;&#123;problem_description&#125;&#125; &lt;/p&gt; &lt;q-option-group v-model=&quot;chosen_answer&quot; :options=&quot;answer_options&quot; color=&quot;primary&quot; /&gt; &lt;q-btn label=&quot;提交答案&quot; type=&quot;submit&quot; color=&quot;primary&quot;/&gt; &lt;/q-form&gt; &lt;/div&gt; &lt;/q-page&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: &#x27;lesson&#x27;, data()&#123; return&#123; username: &quot;&quot;, lesson_id: 0, chosen_answer: &quot;&quot; &#125; &#125;, mounted: function() &#123; this.onInitLesson(); var full_path = window.document.location.href; var route_path = this.$route.path; var base_path = full_path.substring(7, full_path.indexOf(route_path)); var base_path_stripped = base_path.substring(0, base_path.indexOf(&#x27;:&#x27;)); this.web_socket = new WebSocket(&quot;ws://&quot; + base_path_stripped + &quot;:8000&quot;); this.web_socket.onopen = () =&gt; &#123; console.log(&quot;Websocket连接成功！&quot;) &#125; this.web_socket.onmessage = (event) =&gt; &#123; console.log(event.data); &#125; &#125;, destroyed: function()&#123; this.web_socket.close(); &#125;, methods: &#123; onSubmitAnswer()&#123; this.web_socket.send(JSON.stringify(&#123;type: &quot;problem_answer&quot;, username: this.username, lesson_id: this.lesson_id, answer: this.chosen_answer&#125;)); &#125; &#125; &#125;&lt;/script&gt; 对于每一个课程实例，服务端维护着一个当前题目的回答列表，每当后端收到前端发来的回答通知时，便将对应的计数器加一。随后，服务端会通知教师客户端更新实时统计信息： 12345678910111213141516171819202122232425262728293031var ws_server = ws.createServer(function(socket)&#123; var answer_status = &#123; &quot;6&quot;: &#123; &quot;A&quot;: 0, &quot;B&quot;: 0, &quot;C&quot;: 0, &quot;D&quot;: 0 &#125; &#125; socket.on(&#x27;text&#x27;, function(str)&#123; try &#123; var obj=JSON.parse(str); if(typeof obj == &#x27;object&#x27; &amp;&amp; obj )&#123; if(obj.type == &quot;problem_answer&quot;)&#123; var lesson_id = obj.lesson_id; var answer = obj.answer; if(lesson_id != undefined &amp;&amp; answer != undefined)&#123; answer_status[lesson_id][answer] += 1; ws_server.connections.forEach((connection) =&gt; &#123; connection.sendText(JSON.stringify(answer_status)); &#125;); &#125; &#125; &#125;else&#123; console.log(&quot;Error phasing json!&quot;); &#125; &#125; catch(e) &#123; console.log(e); &#125; &#125;);&#125;).listen(8000); 对于前端统计信息，这里我们使用Echarts图表的形式将答题的即时情况展现给教师： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;template&gt; &lt;q-page class=&quot;flex flex-center&quot;&gt; &lt;div id=&quot;answer_chart&quot; :style=&quot;&#123;width: &#x27;300px&#x27;, height: &#x27;300px&#x27;&#125;&quot;&gt;&lt;/div&gt; &lt;/q-page&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: &#x27;problemStatistics&#x27;, data()&#123; return&#123; username: &quot;&quot;, lesson_id: 0, web_socket: null, chart: null &#125; &#125;, mounted: function() &#123; this.onInitLesson(); var echarts = require(&#x27;echarts&#x27;); this.chart = echarts.init(document.getElementById(&#x27;answer_chart&#x27;)); this.chart.setOption(&#123; title: &#123; text: &#x27;学生实时答题情况统计&#x27; &#125;, tooltip: &#123;&#125;, xAxis: &#123; data: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;] &#125;, yAxis: &#123;&#125;, series: [&#123; name: &#x27;选择人数&#x27;, type: &#x27;bar&#x27;, data: [0, 0, 0, 0] &#125;] &#125;); var full_path = window.document.location.href; var route_path = this.$route.path; var base_path = full_path.substring(7, full_path.indexOf(route_path)); var base_path_stripped = base_path.substring(0, base_path.indexOf(&#x27;:&#x27;)); this.web_socket = new WebSocket(&quot;ws://&quot; + base_path_stripped + &quot;:8000&quot;); this.web_socket.onopen = () =&gt; &#123; console.log(&quot;Websocket连接成功！&quot;) &#125; this.web_socket.onmessage = (event) =&gt; &#123; var latest_data = JSON.parse(event.data); if(latest_data != undefined)&#123; var stat_dict = latest_data[this.lesson_id]; var x_tags = []; var y_values = []; for(var key in stat_dict)&#123; x_tags.push(key); y_values.push(stat_dict[key]); &#125; this.refreshChart(x_tags, y_values); &#125; &#125; &#125;, methods: &#123; onInitLesson()&#123; this.username = this.$route.query.username; this.lesson_id = this.$route.query.lesson_id; &#125;, refreshChart(x, y)&#123; this.chart.setOption(&#123; title: &#123; text: &#x27;学生实时答题情况统计&#x27; &#125;, tooltip: &#123;&#125;, xAxis: &#123; data: x &#125;, yAxis: &#123;&#125;, series: [&#123; name: &#x27;选择数&#x27;, type: &#x27;bar&#x27;, data: y &#125;] &#125;); &#125; &#125; &#125;&lt;/script&gt; 页面效果如下： 快速签到 视频推流 远程访问 ​ 至此，我们已经实现了树莓派在线教学系统的绝大部分基本功能。我们将其通过SFTP上传至树莓派中的目标目录下，并启动服务。通过树莓派提供的热点，我们在另一台设备上远程访问树莓派的网站接口，发现其已经可以正常工作： 同样的，我们也可以使用移动端访问树莓派上的教学服务：","categories":[],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Web","slug":"Web","permalink":"http://gonggongjohn.me/tags/Web/"},{"name":"Frontend","slug":"Frontend","permalink":"http://gonggongjohn.me/tags/Frontend/"}]},{"title":"数据科学与工程数学基础 作业5","slug":"dase-math/dase-math-assignment-5","date":"2021-06-12T02:00:00.000Z","updated":"2022-02-10T14:31:28.203Z","comments":true,"path":"2021/06/12/dase-math/dase-math-assignment-5/","link":"","permalink":"http://gonggongjohn.me/2021/06/12/dase-math/dase-math-assignment-5/","excerpt":"","text":"一 求随机变量 \\(X \\sim b(n,p)\\) 的期望与方差。 由 \\(X \\sim b(n, p)\\) 可知 \\[ P(X=k) = \\binom{n}{k} p^k (1-p)^{1-k}, k \\in \\{0,1,2,\\cdots,n\\} \\] 故其期望为 \\[ \\begin{aligned} E(X) &amp;= \\sum_\\limits{k = 0}^n k \\binom{n}{k} p^k (1-p)^{n-k} \\\\ &amp;= \\sum_\\limits{k = 1}^n k \\binom{n}{k} p^k (1-p)^{n-k} \\\\ &amp;= \\sum_\\limits{k = 1}^n n \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;=np \\sum_\\limits{k = 1}^n \\binom{n-1}{k-1} p^{k-1} (1-p)^{n-k} \\\\ &amp;=np \\sum_\\limits{m = 0}^{n-1} \\binom{n-1}{m} p^m (1-p)^{n-1-m} \\\\ &amp;=np \\cdot (p+1-p)^{n-1} \\\\ &amp;=np \\end{aligned} \\] 又由 \\[ \\begin{aligned} E(X^2) &amp;= \\sum_\\limits{k = 0}^n k^2 \\binom{n}{k} p^k (1-p)^{n-k} \\\\ &amp;= n \\cdot \\sum_\\limits{k = 1}^n k \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;= n \\cdot \\sum_\\limits{k = 1}^n (k - 1 + 1) \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;= n \\cdot \\left[ \\sum_\\limits{k = 1}^n (k - 1) \\binom{n-1}{k-1} p^k (1-p)^{n-k} + \\sum_\\limits{k = 1}^n \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\right] \\\\ &amp;=n \\cdot \\sum_\\limits{k = 2}^n (n - 1) \\binom{n-2}{k-2} p^k (1-p)^{n-k} + n \\cdot \\sum_\\limits{k = 1}^n \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;= n(n-1)p^2 + np \\end{aligned} \\] 可知其方差为 \\[ \\begin{aligned} Var(X) &amp;= E(X^2) - E^2(X) \\\\ &amp;=n(n-1)p^2 + np - n^2p^2 \\\\ &amp;=n^2p^2-np^2+ np - n^2p^2 \\\\ &amp;=np(1-p) \\end{aligned} \\] 二 设连续性随机变量 \\(X\\) 的分布函数为 \\[ F_X(x) = \\left\\{ \\begin{aligned} &amp;0 ,&amp; x &lt; 1 \\\\ &amp;\\ln x ,&amp; 1 \\leq x &lt; e \\\\ &amp;1 ,&amp; x \\geq e \\end{aligned} \\right. \\] 求 \\(P(X &lt; 2), P(0 &lt; X &lt;3)\\) 求概率密度函数 \\(f_X(x)\\) \\[ P(X&lt;2) = F_X(2)= \\ln 2 \\\\ P(0&lt;X&lt;3) = F_X(3)-F_X(0)=1-0=1 \\] 由 \\[ f_X(x) = \\frac{d}{dx}F_X(x) \\] 可知 当 \\(x&lt;1\\) 时，\\(f_X(x) = 0\\) 当 \\(1&lt;x&lt;e\\) 时，\\(f_X(x)=\\frac{1}{x}\\) 当 \\(x&gt;e\\) 时，\\(f_X(x) = 0\\) 又 \\[ F&#39;_-(1) = \\lim_{x \\to 1^-} \\frac{f(1)-f(x)}{1-x}= 0 \\neq 1 = F&#39;_+(1) \\\\ F&#39;_-(e) = \\lim_{x \\to e^-} \\frac{f(e)-f(x)}{e-x}= \\frac{1}{e} \\neq 0 = F&#39;_+(e) \\] 故 \\(f_X(x)\\) 在 \\(x=1\\) 和 \\(x=e\\) 处不存在 因此 \\[ f_X(x) = \\left\\{ \\begin{aligned} 0 &amp;,&amp; x &lt; 1 \\\\ \\frac{1}{x} &amp;,&amp; 1 &lt; x &lt; e \\\\ 0 &amp;,&amp; x&gt;e \\end{aligned} \\right. \\] 三 下表为二维离散随机变量 \\((X,Y)\\) 的联合分布列，其中最后一列为随机变量 \\(Y\\) 的边缘分布列，最后一行为随机变量 \\(X\\) 的边缘分布列，且 \\(X,Y\\) 独立。试将下表补充完整，并给出 \\(X,Y\\) 的协方差 \\(\\textrm{Cov}(X,Y)\\) \\(X=1\\) \\(X=2\\) \\(X=3\\) \\(P_Y(Y)\\) \\(Y=1\\) \\(0.03\\) \\(0.15\\) \\(0.12\\) \\(0.3\\) \\(Y=2\\) \\(0.03\\) \\(0.15\\) \\(0.12\\) \\(0.3\\) \\(Y=3\\) \\(0.02\\) \\(0.1\\) \\(0.08\\) \\(0.2\\) \\(Y=4\\) \\(0.02\\) \\(0.1\\) \\(0.08\\) \\(0.2\\) \\(P_X(X)\\) \\(0.1\\) \\(0.5\\) \\(0.4\\) \\(/\\) 由于 \\(X,Y\\) 独立，故 \\(Cov(X,Y) = 0\\) 四 已知所有的胰腺癌患者都有某症状，若一个人有该症状的概率为万分之一，并且胰腺癌的发病概率也为万分之一。问若一个人有该症状，则他也是胰腺癌患者的概率为多少。 设 \\(A=\\{有该症状\\},B=\\{有胰腺癌\\}\\) 由于 \\(B \\subset A\\) 故 \\[ P(B|A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{P(B)}{P(A)} = 1 \\] 五 一个不透明的箱子中有一些红球和白球，有放回地在箱子中随机摸出5个球，分别为红、白、白、白、红，试估计箱子中红球与白球的比例。 设箱子中摸出红球的概率为 \\(p\\)， \\[ X_i = \\left\\{ \\begin{aligned} 1, 第i次摸出红球 \\\\ 0, 第i次摸出白球 \\end{aligned} \\right. \\] 故 \\(X_i \\stackrel{i.i.d}{\\sim} b(1,p) \\ , i \\in \\{1,2,3,4,5\\}\\) 于是 \\[ L(p) = p^{\\sum_\\limits{i = 1}^n x_i} (1-p)^{n-\\sum_\\limits{i = 1}^n x_i} \\] 故 \\[ \\frac{\\partial \\ln L(p)}{\\partial p} = \\frac{\\sum_\\limits{i = 1}^n x_i}{p} - \\frac{n - \\sum_\\limits{i = 1}^n x_i}{1-p} \\] 于是 \\(p\\) 的极大似然估计 \\[ \\hat{p} = \\bar{x} = \\frac{1+0+0+0+1}{5} = \\frac{2}{5} \\] 故 \\[ \\frac{红球}{白球} = \\frac{2}{3} \\] 六 随机地取8只活塞环，测得他们的直径为(以mm计) 1274.001 74.005 74.003 74.00174.000 73.998 74.006 74.002 试求总体均值 \\(\\mu\\) 以及方差 \\(\\sigma^2\\) 的矩估计值。 \\[ \\begin{aligned} \\hat{\\mu} &amp;= \\bar{x} \\\\ &amp;= \\frac{74.001+74.005+74.003+74.001+74.000+73.998+74.006+74.002}{8} \\\\ &amp;=74.002 \\end{aligned} \\] \\[ \\begin{aligned} \\hat{\\sigma^2} &amp;= s^2 \\\\ &amp;=\\frac{1}{7} \\left[ (74.001 - 74.002)^2 + (74.005 - 74.002)^2 + (74.003 - 74.002)^2 + (74.001 - 74.002)^2 + (74.000 - 74.002)^2 + (73.998 - 74.002)^2 + (74.006 - 74.002)^2 + (74.002 - 74.002)^2 \\right] \\\\ &amp; \\approx 6.8571 \\times 10^{-6} \\end{aligned} \\] 七 给定 \\(N\\) 个独立同分布样本 \\(x_t\\)，服从多元正态分布 \\[ G(x_t) = \\frac{1}{(2 \\pi)^{\\frac{d}{2}} |\\Sigma|^{\\frac{1}{2}}} \\exp \\left\\{ -\\frac{1}{2} (x_t - \\mu)^T \\Sigma^{-1} (x_t - \\mu) \\right\\} \\] ，其中 \\(\\Sigma\\) 是可逆对称矩阵，\\(x_t, \\mu \\in \\mathbb{R}^d\\)。 利用极大似然估计(MLE)估计参数 \\(\\mu, \\Sigma\\)。 似然函数 \\[ \\begin{aligned} L(\\mu, \\Sigma) &amp;= \\prod_{i = 1}^n \\frac{1}{(2 \\pi)^{\\frac{d}{2}} |\\Sigma|^{\\frac{1}{2}}} e^{-\\frac{1}{2} (x_i - \\mu)^T \\Sigma^{-1} (x_i - \\mu)} \\\\ &amp;=\\frac{1}{(2\\pi)^{\\frac{nd}{2}} |\\Sigma|^{\\frac{n}{2}}} e^{-\\frac{1}{2} \\sum_\\limits{i = 1}^n (x_i-\\mu)^T \\Sigma^{-1} (x_i - \\mu)} \\end{aligned} \\] 故其对数似然函数 \\[ l(\\mu, \\Sigma) = -\\frac{nd}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln |\\Sigma| - \\frac{1}{2}\\sum_{i = 1}^n (x_i - \\mu)^T \\Sigma^{-1} (x_i - \\mu) \\] 由于 \\[ \\begin{aligned} dl &amp;= Tr\\left[ d \\left( -\\frac{nd}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln |\\Sigma| - \\frac{1}{2}\\sum_{i = 1}^n (x_i - \\mu)^T \\Sigma^{-1} (x_i - \\mu) \\right) \\right] \\\\ &amp;=Tr \\left[ -\\frac{1}{2} \\sum_{i = 1}^n \\left( d (x_i- \\mu)^T \\cdot \\Sigma^{-1} \\cdot (x_i - \\mu) + (x_i - \\mu)^T \\cdot \\Sigma^{-1} \\cdot d(x_i - \\mu) \\right)\\right] \\\\ &amp;=Tr \\left[ \\frac{1}{2} \\sum_{i = 1}^n \\left( d \\mu^T \\cdot \\Sigma^{-1} \\cdot (x_i - \\mu) + (x_i - \\mu)^T \\cdot \\Sigma^{-1} \\cdot d \\mu \\right) \\right] \\\\ &amp;=Tr \\left[ \\frac{1}{2} \\sum_{i = 1}^n \\left( (x_i - \\mu)^T \\cdot \\left( \\Sigma^{-1} \\right)^T \\cdot d \\mu + (x_i - \\mu)^T \\cdot \\Sigma^{-1} \\cdot d \\mu \\right) \\right] \\\\ &amp;=Tr \\left[ \\sum_{i = 1}^n \\left( (x_i - \\mu)^T \\cdot \\Sigma^{-1}\\right) d\\mu \\right] \\end{aligned} \\] 故 \\[ \\frac{\\partial l}{\\partial \\mu} = \\Sigma^{-1} \\sum_{i = 1}^n (x_i - \\mu) \\] 因此 \\[ \\hat{\\mu} = \\frac{1}{n}\\sum_{i = 1}^n x_i = \\bar{x} \\] 又由于 \\[ \\begin{aligned} dl &amp;= Tr \\left[ -\\frac{n}{2} d \\ln |\\Sigma| -\\frac{1}{2} \\sum_{i = 1}^n (x_i - \\mu)^T \\cdot d \\Sigma^{-1} \\cdot (x_i - \\mu) \\right] \\\\ &amp;=Tr \\left[ -\\frac{n}{2 |\\Sigma|} |\\Sigma|\\Sigma^{-1} d \\Sigma + \\frac{1}{2}\\sum_{i = 1}^n \\left( (x_i - \\mu)^T \\cdot \\Sigma^{-1} d\\Sigma \\cdot \\Sigma^{-1} \\cdot (x_i - \\mu) \\right)\\right] \\\\ &amp;=Tr \\left[-\\frac{n}{2}\\Sigma^{-1} d \\Sigma \\right] + \\frac{1}{2} \\sum_{i = 1}^n Tr \\left[ \\Sigma^{-1} \\cdot (x_i - \\mu)(x_i - \\mu)^T \\cdot \\Sigma^{-1} d \\Sigma \\right] \\\\ &amp;=Tr \\left[\\left( -\\frac{n}{2}\\Sigma^{-1} + \\frac{1}{2}\\sum_{i = 1}^n \\left( \\Sigma^{-1} (x_i - \\mu)(x_i - \\mu)^T \\Sigma^{-1} \\right) \\right) d \\Sigma \\right] \\end{aligned} \\] 故 \\[ \\frac{\\partial l}{\\partial \\Sigma} = \\frac{1}{2} \\sum_{i = 1}^n \\left(\\Sigma^{-1} (x_i - \\mu)(x_i - \\mu)^T \\Sigma^{-1} \\right) - \\frac{n}{2}\\Sigma^{-1} \\] 因此 \\[ \\begin{aligned} \\hat{\\Sigma} &amp;= \\frac{1}{n}\\sum_{i = 1}^n (x_i - \\mu)(x_i - \\mu)^T \\\\ &amp;=\\frac{1}{n}\\sum_{i = 1}^n (x_i - \\bar{x})(x_i - \\bar{x})^T \\end{aligned} \\] 八 证明：在多分类问题中，利用交叉熵函数作为损失函数和用KL散度作为损失函数是等价的。 对于多分类问题，若设 \\(p_i\\) 为第 \\(i\\) 个数据的目标输出，\\(q_i\\) 为第 \\(i\\) 个数据的实际输出，则 \\[ L_{CrossEntropy} = -\\sum_{i = 1}^n p_i \\ln q_i \\\\ L_{KL} = \\sum_{i = 1}^n p_i \\ln p_i - \\sum_{i = 1}^n p_i \\ln q_i \\] 二者仅相差一个与 \\(q_i\\) 无关的常数，即 \\[ \\frac{\\partial L_{CrossEntropy}}{\\partial q_i} = \\frac{\\partial L_{KL}}{\\partial q_i} = -\\frac{p_i}{q_i} \\] 故二者作为损失函数等价 九 同时抛2颗骰子，事件 \\(A,B,C\\) 分别表示为 \\[ A: 仅有一个骰子是3 \\\\ B: 至少一个骰子是4 \\\\ C: 骰子上点数总和为偶数 \\] 试计算事件 \\(A,B,C\\) 发生后所提供的信息量 \\[ \\begin{aligned} I_1 &amp;= - \\lg \\frac{5}{18} \\approx 1.8480 \\\\ I_2 &amp;= -\\lg \\frac{11}{36} \\approx 1.7105 \\\\ I_3 &amp;= -\\lg \\frac{1}{2} = 1 \\end{aligned} \\]","categories":[{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"}]},{"title":"操作系统实验 内存管理","slug":"os/os-exp-memory","date":"2021-06-08T03:54:46.000Z","updated":"2022-02-09T14:20:33.022Z","comments":true,"path":"2021/06/08/os/os-exp-memory/","link":"","permalink":"http://gonggongjohn.me/2021/06/08/os/os-exp-memory/","excerpt":"","text":"目的 修改Minix3.1.2a的内存分配机制，使得当调用brk系统调用时，系统重新给进程分配一块更大的空间并将数据复制至新空间中。 内容与设计思想 将Minix系统中的内存分配机制由First-Fit修改为Best-Fit。 修改brk系统调用行为，使得当被调用时系统重新开辟空间并分配给进程。 实验过程 Minix3.1.2a的内存管理策略 在较早的Minix3版本中，内存管理机制是十分固定和清晰的（Minix3.1.4引入了页式存储管理，使得分配给进程的内存空间可能实际分布在内存地址的各个地方）。系统的进程管理器（Process Manager）维护一个空闲空间列表，根据内存地址从低到高排列： 当一个进程请求内存时，进程管理器会采用最先匹配法在空闲列表中找到第一个符合要求的空闲区，并将其分配给该进程。一旦进程被装入内存后，该片内存空间就被固定了下来，不会再被扩展。 Minix3的程序大多被编译为进程的各个部分共用一个内存块的形式以方便作为一个整体进行加载，其中，栈和数据/代码段分别位于内存空间的顶部和底部，整体结构大体如下： 内存分配原则修改 Minix系统中的空闲块由一个链接来维护其元信息，其单元结构如下：（include/minix/type.h） 123456/* Memory allocation by PM. */ struct hole &#123; struct hole *h_next; /* pointer to next entry on the list */ phys_clicks h_base; /* where does the hole begin? */ phys_clicks h_len; /* how big is the hole? */ &#125;; 在Minix3.1.2a中，内存分配遵循首次适配原则（First-Fit），即在遍历到第一个能够容纳该进程的空闲块时，便将这一空闲块分配给进程。 现在我们来将这一分配机制修改为最优适配原则（Best-Fit）。Best-Fit原则需要遍历整个空闲块链表，找出与进程所需空间最接近的空闲块。由于要保证空闲块大小大于进程所需内存大小，因此我们采用外部逼近的更新思路来实现。若在现有的空闲块中能够找到满足要求的空闲块，我们还需要更新空闲块的信息并将已被完全分配的空闲块从空闲链表中移出：（servers/pm/alloc.c） 123456789101112131415161718192021222324252627282930313233343536373839404142434445PUBLIC phys_clicks alloc_mem(clicks) phys_clicks clicks; /* amount of memory requested */ &#123; register struct hole *hp, *prev_ptr,*best,*prev_best; phys_clicks old_base,best_clicks; int flag= 0; do &#123; prev_ptr = NIL_HOLE; hp = hole_head; //Procedure of finding the best-fit block while (hp != NIL_HOLE &amp;&amp; hp-&gt;h_base &lt; swap_base) &#123; if (hp-&gt;h_len &gt;= clicks) &#123; if(!flag)&#123; best = hp; prev_best=prev_ptr; flag=1; best_clicks=best-&gt;h_len; &#125; else if(flag &amp;&amp; hp-&gt;h_len&lt;best_clicks)&#123; best=hp; prev_best=prev_ptr; best_clicks=best-&gt;h_len; &#125; &#125; prev_ptr = hp; hp = hp-&gt;h_next; &#125; &#125; while (swap_out()); /* try to swap some other process out */ //Update the status of the hole if (flag)&#123; old_base = best-&gt;h_base; best-&gt;h_base += clicks; best-&gt;h_len -= clicks; if (best-&gt;h_base &gt; high_watermark) high_watermark = best-&gt;h_base; if (best-&gt;h_len == 0) del_slot(prev_best,best); return(old_base); &#125; return(NO_MEM); &#125; 内存申请行为修改 在Minix3.1.2中，系统为进程分配的内存空间是不可变的。一旦进程使用完了分配的空间，程序便将报错退出，这可以在系统代码中直观的体现出来：（servers/pm/break.c） 123456789PUBLIC int adjust(rmp, data_clicks, sp) register struct mproc *rmp; /* whose memory is being adjusted? */ vir_clicks data_clicks; /* how big is data segment to become? */ vir_bytes sp; /* new value of sp */ &#123; //Irrelevant code if (lower &lt; gap_base) return(ENOMEM); /* data and stack collided */ //Irrelevant code &#125; 现在我们来修改这一行为。首先我们定义一个新的局部函数用于分配新的内存：（servers/pm/break.c） 123PUBLIC int allocate_new_mem(rmp,old_clicks) register struct mproc *rmp; //Pointer of target process phys_clicks old_clicks; //Original space size 并在检测到程序空间不足时调用这一函数：（servers/pm/break.c） 1234567891011121314#define ERROR 0PUBLIC int adjust(rmp, data_clicks, sp) register struct mproc *rmp; /* whose memory is being adjusted? */ vir_clicks data_clicks; /* how big is data segment to become? */ vir_bytes sp; /* new value of sp */ &#123; //Irrelevant code if (lower &lt; gap_base) &#123;/* data and stack collided */ if (allocate_new_mem(rmp, (phys_clicks)(mem_sp-&gt;mem_vir+mem_sp-&gt;mem_len-mem_dp-&gt;mem_vir)) == ERROR) return(ENOMEM); &#125; //Irrelevant code &#125; 现在我们来实现内存空间的更新。allocate_new_mem中需要完成以下几个任务： 1) 分配一块比原先更大的内存空间 2) 将远数据段和栈段分别复制至新空间的对应位置 3) 释放原内存空间 4) 通知系统映射新内存段 受动态表（Dynamic Table）的启发，我们在每次需要扩展空间时将空间大小扩展至原来的两倍。在Minix中，进程的栈段和数据段基地址均被存放在其进程管理表（Process Management Table）中：（servers/pm/mproc.h） 1234EXTERN struct mproc &#123; struct mem_map mp_seg[NR_LOCAL_SEGS]; /* points to text, data, stack */ //Irrelevant codes &#125; 其中mp_seg[1]为数据段基地址，mp_seg[2]为栈段基地址，因此我们可以直接读取这一地址并根据新分配的空间大小计算出新的基地址。对于内存内容拷贝，Minix提供了一个现成的sys_abscopy函数可供我们使用：（include/minix/syslib.h） 1234#define sys_abscopy(src_phys, dst_phys, bytes) \\ sys_physcopy(NONE, PHYS_SEG, src_phys, NONE, PHYS_SEG, dst_phys, bytes) _PROTOTYPE(int sys_physcopy, (int src_proc, int src_seg, vir_bytes src_vir, int dst_proc, int dst_seg, vir_bytes dst_vir, phys_bytes bytes)); 同样，对于内存释放，系统也封装了相应的函数：（servers/pm/proto.h） 1_PROTOTYPE( void free_mem, (phys_clicks base, phys_clicks clicks) ); 于是我们便可以快速实现这一完整逻辑： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556PUBLIC int allocate_new_mem(rmp,old_clicks) register struct mproc *rmp; phys_clicks old_clicks; &#123; register struct mem_map *mem_sp, *mem_dp; phys_clicks new_clicks, old_base,new_base; phys_clicks old_stack_base,new_stack_base; phys_bytes data_bytes,stak_bytes; phys_bytes old_base_bytes,new_base_bytes; phys_bytes old_stack_base_bytes,new_stack_base_bytes; int x; mem_dp = &amp;rmp-&gt;mp_seg[D]; /* Pointer to data segment */ mem_sp = &amp;rmp-&gt;mp_seg[S]; /* Pointer to stack segment */ old_base=mem_dp-&gt;mem_phys; old_stack_base=mem_sp-&gt;mem_phys; data_bytes=(phys_bytes) mem_dp-&gt;mem_len &lt;&lt; CLICK_SHIFT; stak_bytes=(phys_bytes) mem_sp-&gt;mem_len &lt;&lt; CLICK_SHIFT; old_base_bytes=old_base &lt;&lt; CLICK_SHIFT; old_stack_base_bytes=old_stack_base &lt;&lt; CLICK_SHIFT; new_clicks=2*old_clicks; new_base=alloc_mem(new_clicks); if(new_base==NO_MEM)&#123; return(ERROR); &#125; new_base_bytes = (phys_bytes) new_base &lt;&lt; CLICK_SHIFT; if ((x=sys_memset(0,new_base_bytes,(new_clicks&lt;&lt;CLICK_SHIFT)))!=OK)&#123; panic(__FILE__,&quot;new mem can&#x27;t be zero&quot;,x); &#125; new_stack_base=new_base+new_clicks-mem_sp-&gt;mem_len; new_stack_base_bytes=new_stack_base &lt;&lt; CLICK_SHIFT; x = sys_abscopy(old_base_bytes,new_base_bytes,data_bytes); if (x &lt; 0 ) panic(__FILE__,&quot;allocate_new_mem can&#x27;t copy&quot;,x); x = sys_abscopy( old_stack_base_bytes,new_stack_base_bytes,stak_bytes); if ( x &lt; 0 ) panic(__FILE__,&quot;allocate_new_mem can&#x27;t copy&quot;,x); rmp-&gt;mp_seg[D].mem_phys = new_base; rmp-&gt;mp_seg[S].mem_phys = new_stack_base; rmp-&gt;mp_seg[S].mem_vir = mem_dp-&gt;mem_vir+new_clicks-mem_sp-&gt;mem_len; free_mem(old_base,old_clicks); return (1); &#125; 功能测试 现在我们可以来重编译系统并测试新实现的内存扩展功能了。由于Minix3.1.2a开发时间较早，需要手动安装新内核并将其加入开机菜单中： 1234/usr/src/servers&gt; make image /usr/src/tools&gt; make hdboot /usr/src/tools&gt; make install d0p0s0&gt; newminix(5,start new kernel) &#123;image=/boot/image/3.1.2ar1;boot;&#125; 需要注意的是，Minix3.1.2a不支持VirtualBox的网卡配置，因此若使用VirtualBox进行调试，将无法通过主机使用SSH服务与Minix联通，需手动在虚拟机环境内修改代码。 首先我们对使用sbrk调用对内存分配进行基本的测试，测试代码如下：（test1.c） 1234567891011121314151617#include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int inc = 1; int total = 0; int i; char *sbrk(int incr); char *result; int main(int argc, int **argv) &#123; while (((int)(result = sbrk(inc))) &gt; 0) &#123; total += inc; printf(&quot;incremented by %d, total %d\\n&quot;, inc, total); inc += inc; &#125; return 0; &#125; 随后，我们实际访问新分配的内存，验证其分配空间是否能够正常使用：（test2.c） 12345678910111213141516171819#include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int inc = 1; int total = 0; char *sbrk(int incr); char *result; int i; int main(int argc, int **argv) &#123; while (((int)(result = sbrk(inc))) &gt; 0) &#123; for (i = 0; i &lt; inc; i++) result[i] = 0x12; total += inc; printf(&quot;incremented by: %d, total: %d , result: %d\\n&quot;, inc, total, (int)result); inc += inc; &#125; exit (0); &#125; 经过测试可以发现，程序输出与预期相符，且两次分配内存大小相同，表明新实现的内存分配机制是有效的。程序输出结果如下： 总结 在本实验中，我们在Minix3.1.2a系统下对内存分配机制进行了修改。将first-fit内存分配策略修改为best-fit策略，可以有效的提高内存的综合利用率，减少内存碎片的产生。通过对brk系统调用实现的修改，得以让程序能够得到的内存空间随着需求动态扩展，极大的增强了系统的通用性和可扩展性。这一实验也使得我们对进程内存管理和内存空间调度的相关知识有了更深刻的了解。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Operating-System","slug":"Operating-System","permalink":"http://gonggongjohn.me/tags/Operating-System/"}]},{"title":"数据科学与工程数学基础 作业4","slug":"dase-math/dase-math-assignment-4","date":"2021-06-02T02:00:00.000Z","updated":"2022-02-10T09:00:53.615Z","comments":true,"path":"2021/06/02/dase-math/dase-math-assignment-4/","link":"","permalink":"http://gonggongjohn.me/2021/06/02/dase-math/dase-math-assignment-4/","excerpt":"","text":"一 构建模型使得预测值与真实值的误差最小常用向量2-范数度量，求解模型过程中需要计算梯度，求梯度： \\(f(A) = \\frac{1}{2} ||Ax + b - y ||_2^2\\)，求 \\(\\frac{\\partial f}{\\partial A}\\) \\(f(x) = \\frac{1}{2} ||Ax + b - y ||_2^2\\)，求 \\(\\frac{\\partial f}{\\partial x}\\) ，其中 \\(A \\in \\mathbb{R}^{m \\times n}, x \\in \\mathbb{R}^n, b, y \\in \\mathbb{R}^m\\) 由 \\[ \\begin{aligned} f(\\textbf{A}, x) &amp;= \\frac{1}{2} || \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} ||_2^2 \\\\ &amp;=\\frac{1}{2} \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\end{aligned} \\] 可知 \\[ \\begin{aligned} df &amp;= d \\left[\\ Tr \\left(\\frac{1}{2} \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)\\right) \\right] \\\\ &amp;= \\frac{1}{2} Tr \\left[ d \\left( \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\right)\\right] \\\\ &amp;=\\frac{1}{2} Tr \\left[ d\\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) + \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\right] \\\\ &amp;=\\frac{1}{2} Tr \\left[ \\textbf{x}^T \\cdot d \\textbf{A}^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) + \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\textbf{A} \\cdot \\textbf{x} \\right] \\\\ &amp;=\\frac{1}{2} \\left\\{ Tr \\left[ \\textbf{x}^T \\cdot d \\textbf{A}^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\right] + Tr \\left[ \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\textbf{A} \\cdot \\textbf{x} \\right] \\right\\} \\\\ &amp;= \\frac{1}{2} \\left\\{ Tr \\left[ d \\textbf{A}^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\cdot \\textbf{x}^T \\right] + Tr \\left[ \\textbf{x} \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\textbf{A} \\right] \\right\\} \\\\ &amp;= \\frac{1}{2} \\left\\{ Tr \\left[ \\textbf{x} \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\textbf{A} \\right] + Tr \\left[ \\textbf{x} \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\textbf{A} \\right] \\right\\} \\\\ &amp;= \\frac{1}{2} Tr \\left[ 2 \\cdot \\textbf{x} \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\textbf{A} \\right] \\\\ &amp;= Tr \\left[ \\textbf{x} \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\textbf{A} \\right] \\end{aligned} \\] 故 \\[ \\frac{\\partial f}{\\partial \\textbf{A}} = \\left(\\textbf{x} \\cdot (\\textbf{A} \\textbf{x}+\\textbf{b}-\\textbf{y})^T\\right)^T = (\\textbf{A} \\textbf{x}+\\textbf{b}-\\textbf{y}) \\cdot \\textbf{x}^T \\] 又 \\[ \\begin{aligned} df &amp;=\\frac{1}{2} Tr \\left[ d\\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) + \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot d \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\right] \\\\ &amp;=\\frac{1}{2} Tr \\left[ d\\textbf{x}^T \\cdot \\textbf{A}^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) + \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\textbf{A} \\cdot d\\textbf{x} \\right] \\\\ &amp;=\\frac{1}{2} \\left\\{ Tr \\left[ d\\textbf{x}^T \\cdot \\textbf{A}^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\right] + Tr \\left[ \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\textbf{A} \\cdot d\\textbf{x} \\right] \\right\\} \\\\ &amp;= \\frac{1}{2} \\left\\{ Tr \\left[ \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\textbf{A} \\cdot d\\textbf{x} \\right] + Tr \\left[ \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\textbf{A} \\cdot d\\textbf{x} \\right] \\right\\} \\\\ &amp;= \\frac{1}{2} Tr \\left[ 2 \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\textbf{A} \\cdot d\\textbf{x} \\right] \\\\ &amp;= Tr \\left[ \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\textbf{A} \\cdot d\\textbf{x} \\right] \\end{aligned} \\] 故 \\[ \\frac{\\partial f}{\\partial \\textbf{x}} = \\left( \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right)^T \\cdot \\textbf{A} \\right)^T = \\textbf{A}^T \\cdot \\left( \\textbf{A} \\textbf{x} + \\textbf{b} - \\textbf{y} \\right) \\] 二 利用迹微分法求解 \\[ \\frac{\\partial \\tr (W^{-1})}{\\partial W} \\] ，其中 \\(W \\in \\mathbb{R}^{m \\times m}\\) 由 \\[ \\begin{aligned} d \\ Tr(\\textbf{W}^{-1}) &amp;= Tr \\left[ d \\left( \\textbf{W}^{-1} \\right) \\right] \\\\ &amp;=Tr \\left[ - \\textbf{W}^{-1} \\cdot d\\textbf{W} \\cdot \\textbf{W}^{-1} \\right] \\\\ &amp;=Tr \\left[ -\\left(\\textbf{W}^{-1}\\right)^2 \\cdot d \\textbf{W} \\right] \\end{aligned} \\] 可知 \\[ \\frac{\\partial Tr(\\textbf{W}^{-1})}{\\partial \\textbf{W}} = -\\left( \\textbf{W}^{-2} \\right)^T \\] 三 二次型是数据分析中常用函数，求 \\[ \\frac{\\partial x^T A x}{\\partial x}, \\frac{\\partial x^T A x}{\\partial A} \\] ，其中 \\(A \\in \\mathbb{R}^{m \\times m}, x \\in \\mathbb{R}^m\\) 由 \\[ \\begin{aligned} d \\left(\\textbf{x}^T \\textbf{A} \\textbf{x} \\right) &amp;= d \\ Tr \\left(\\textbf{x}^T \\textbf{A} \\textbf{x} \\right) \\\\ &amp;=Tr \\left[ d \\left(\\textbf{x}^T \\textbf{A} \\textbf{x} \\right) \\right] \\\\ &amp;=Tr \\left[ d \\textbf{x}^T \\cdot \\textbf{A} \\textbf{x} + \\textbf{x}^T \\textbf{A} \\cdot d\\textbf{x} \\right] \\\\ &amp;=Tr \\left[\\textbf{x}^T \\textbf{A}^T d\\textbf{x} \\right] + Tr \\left[ \\textbf{x}^T \\textbf{A} d\\textbf{x}\\right] \\\\ &amp;=Tr \\left[ \\textbf{x}^T (\\textbf{A}^T + \\textbf{A}) d\\textbf{x}\\right] \\end{aligned} \\] 故 \\[ \\frac{\\partial \\textbf{x}^T \\textbf{A} \\textbf{x}}{\\partial \\textbf{x}} = \\left(\\textbf{x}^T (\\textbf{A}^T + \\textbf{A})\\right)^T = (\\textbf{A}+\\textbf{A}^T)\\textbf{x} \\] 又 \\[ \\begin{aligned} d \\left(\\textbf{x}^T \\textbf{A} \\textbf{x} \\right) &amp;=Tr \\left[ d \\left(\\textbf{x}^T \\textbf{A} \\textbf{x} \\right) \\right] \\\\ &amp;=Tr \\left[ \\textbf{x}^T \\cdot d \\textbf{A} \\cdot \\textbf{x} \\right] \\\\ &amp;=Tr \\left[\\textbf{x} \\textbf{x}^T d \\textbf{A} \\right] \\\\ \\end{aligned} \\] 故 \\[ \\frac{\\partial \\textbf{x}^T \\textbf{A} \\textbf{x}}{\\partial \\textbf{A}} = \\left(\\textbf{x}\\textbf{x}^T \\right)^T = \\textbf{x}\\textbf{x}^T \\] 四 定义 \\((\\exp(z))_i = \\exp(z_i), (\\ln (z))_i = \\ln (z_i)\\)，则 \\[ f(z) = \\frac{\\exp(z)}{\\boldsymbol{1}^T \\exp(z)} \\] 成为Softmax函数，如果 \\(q = f(z), J = -p^T \\ln (q)\\)，其中 \\(p,q,z \\in \\mathbb{R}^n\\)，并且 \\(\\boldsymbol{1}^T p = 1\\)，则 证明：\\(\\frac{\\partial J}{\\partial z} = q - p\\) 若 \\(z = Wx\\)，其中 \\(W \\in \\mathbb{R}^{n \\times m}, x \\in \\mathbb{R}^m, \\frac{\\partial J}{\\partial W} = (q - p)x^T\\) 是否成立。 \\(\\forall \\textbf{x}, \\textbf{y}, \\textbf{z} \\in \\mathbb{R}^2, \\lambda \\in \\mathbb{R}\\) (1) 任取 \\(i, j \\in \\{1,2,...,n\\}\\) 易得 \\[ \\frac{\\partial J}{\\partial q_j} = - \\frac{p_j}{q_j} \\] 当 \\(i \\neq j\\) 时， \\[ \\frac{\\partial q_j}{\\partial z_i} = - \\frac{e^{z_i + z_j}}{\\left( \\sum_\\limits{k = 1}^n e^{z_k} \\right)^2} = -q_i \\cdot q_j \\] 当 \\(i = j\\) 时， \\[ \\frac{\\partial q_j}{\\partial z_i} = \\frac{e^{z_i} \\cdot \\left( \\sum_\\limits{k = 1}^n e^{z_k} \\right) - e^{2z_i}}{\\left( \\sum_\\limits{k = 1}^n e^{z_k} \\right)^2} = q_i - q_i^2 \\] 故 \\[ \\begin{aligned} \\frac{\\partial J}{\\partial z_i} &amp;= \\sum_{j = 1}^n \\frac{\\partial J}{\\partial q_j} \\cdot \\frac{\\partial q_j}{\\partial z_i} \\\\ &amp;=\\sum_{j \\neq i} \\left( - \\frac{p_j}{q_j} \\right) (-q_i q_j) + \\left(- \\frac{p_i}{q_i} \\right) (q_i - q_i^2) \\\\ &amp;=q_i \\cdot \\sum_{j \\neq i} p_j - p_i(1-q_i) \\\\ \\end{aligned} \\] 于是由 \\(1^T p = \\sum_\\limits{i = 1}^n p_i = 1\\) 可知 \\[ \\frac{\\partial J}{\\partial z_i} = q_i (1 - p_i) - p_i(1-q_i) = q_i - p_i \\] 即 \\[ \\frac{\\partial J}{\\partial \\textbf{z}} = \\textbf{q} - \\textbf{p} \\] (2) 由 \\(d \\ Tr (\\textbf{W} \\textbf{x}) = Tr \\left( d \\textbf{W} \\cdot \\textbf{x} \\right) = Tr(\\textbf{x} \\cdot d \\textbf{W})\\) 可知 \\[ \\frac{\\partial J}{\\partial \\textbf{W}} = \\textbf{x}^T \\] 故 \\[ \\frac{\\partial J}{\\partial \\textbf{W}} = \\frac{\\partial J}{\\partial \\textbf{z}} \\cdot \\frac{\\partial \\textbf{z}}{\\partial \\textbf{W}} = (\\textbf{q} - \\textbf{p}) \\textbf{x}^T \\] 成立 五 以下内容是利用极大似然估计求解多元正态分布模型的关键步骤： \\[ L = -\\frac{Nd}{2} \\ln (2 \\pi) - \\frac{N}{2} \\ln |\\Sigma| - \\frac{1}{2} \\sum_t (x_t - \\mu)^T \\Sigma^{-1} (x_t - \\mu) \\] ，\\(L\\) 是对数似然，\\(N\\) 为样本数，\\(d\\) 为样本维数，\\(\\Sigma \\in \\mathbb{R}^{d \\times d}\\) 为协方差矩阵（对称矩阵），\\(\\mu \\in \\mathbb{R}^d\\) 为期望向量。 求 \\(\\frac{\\partial L}{\\partial \\mu}\\) 当 \\(\\mu = \\frac{1}{N} \\sum_t x_t\\) 使，求 \\(\\frac{\\partial L}{\\partial \\Sigma}\\)，并求使 \\(\\frac{\\partial L}{\\partial \\Sigma} = 0\\) 成立的 \\(\\Sigma\\)。 (1) \\[ \\begin{aligned} \\frac{\\partial L}{\\partial \\boldsymbol{\\mu}} &amp;= -\\frac{1}{2} \\sum_{t = 1}^N \\frac{\\partial}{\\partial \\boldsymbol{\\mu}} \\left[ (\\textbf{x}_t - \\boldsymbol{\\mu})^T \\Sigma^{-1} (\\textbf{x}_t - \\boldsymbol{\\mu})\\right] \\\\ &amp;= -\\frac{1}{2} \\sum_{t = 1}^N \\frac{\\partial \\left[(\\textbf{x}_t - \\boldsymbol{\\mu})^T \\right]}{\\partial \\boldsymbol{\\mu}} \\cdot \\frac{\\partial \\left[ (\\textbf{x}_t - \\boldsymbol{\\mu})^T \\Sigma^{-1} (\\textbf{x}_t - \\boldsymbol{\\mu}) \\right]}{\\partial[\\textbf{x}_t - \\boldsymbol{\\mu}]} \\\\ &amp;=-\\frac{1}{2} \\sum_{t = 1}^N \\left[ -2\\Sigma^{-1}(\\textbf{x}_t - \\boldsymbol{\\mu}) \\right] \\\\ &amp;=\\Sigma^{-1} \\cdot \\sum_{t = 1}^N (\\textbf{x}_t - \\boldsymbol{\\mu}) \\end{aligned} \\] (2) 由 \\[ \\begin{aligned} dL &amp;= Tr \\left[ d \\left( - \\frac{Nd}{2} \\ln (2 \\pi) - \\frac{N}{2} \\ln |\\Sigma| - \\frac{1}{2} \\sum_{t = 1}^N (\\textbf{x}_t - \\boldsymbol{\\mu})^T \\Sigma^{-1} (\\textbf{x}_t - \\boldsymbol{\\mu}) \\right) \\right] \\\\ &amp;= Tr \\left[ - \\frac{N}{2} d \\left( \\ln |\\Sigma| \\right) - \\frac{1}{2} \\sum_{t = 1}^N (\\textbf{x}_t - \\boldsymbol{\\mu})^T \\cdot d \\left(\\Sigma^{-1}\\right) \\cdot (\\textbf{x}_t - \\boldsymbol{\\mu}) \\right] \\\\ &amp;= Tr \\left[ - \\frac{N}{2|\\Sigma|}\\cdot |\\Sigma| \\Sigma^{-1} d \\Sigma + \\frac{1}{2} \\sum_{t = 1}^N (\\textbf{x}_t - \\boldsymbol{\\mu}) (\\textbf{x}_t - \\boldsymbol{\\mu})^T \\cdot \\Sigma^{-1} d \\Sigma \\cdot \\Sigma^{-1} \\right] \\\\ &amp;= Tr \\left[ \\left(- \\frac{N}{2}\\cdot \\Sigma^{-1} + \\frac{1}{2} \\sum_{t = 1}^N \\Sigma^{-1} (\\textbf{x}_t - \\boldsymbol{\\mu}) (\\textbf{x}_t - \\boldsymbol{\\mu})^T \\cdot \\Sigma^{-1}\\right) d \\Sigma \\right] \\end{aligned} \\] 及 \\(\\Sigma\\) 为对称矩阵可知 \\[ \\frac{\\partial L}{\\partial \\Sigma} = \\frac{1}{2} \\sum_{t = 1}^N \\Sigma^{-1}(\\textbf{x} - \\boldsymbol{\\mu})(\\textbf{x} - \\boldsymbol{\\mu})^T \\Sigma^{-1} - \\frac{N}{2} \\Sigma^{-1} \\] 故当 \\(\\Sigma = \\frac{1}{N}(\\textbf{x} - \\boldsymbol{\\mu})(\\textbf{x} - \\boldsymbol{\\mu})^T\\) 时，\\(\\frac{\\partial L}{\\partial \\Sigma} = 0\\) 六 求 \\[ \\frac{\\partial |X_k|}{\\partial X} \\] ，其中 \\(X \\in \\mathbb{R}^{m \\times m}\\) 为可逆矩阵。 由 \\(\\textbf{X} \\in \\mathbb{R}^{m \\times m}\\) 可逆可知 \\[ \\begin{aligned} \\frac{\\partial \\left|\\textbf{X}^k\\right|}{\\partial \\textbf{X}} &amp;= \\frac{\\partial \\left|\\textbf{X}^k\\right|}{\\partial \\textbf{|X|}} \\cdot \\frac{\\partial \\left|\\textbf{X}\\right|}{\\partial \\textbf{X}} \\\\ &amp;=k |\\textbf{X}|^{k - 1} \\cdot |\\textbf{X}| \\cdot (\\textbf{X}^{-1})^T \\\\ &amp;= k |\\textbf{X}|^k \\left( \\textbf{X}^{-1} \\right)^T \\end{aligned} \\] 七 求 \\[ \\frac{\\partial \\tr (AXBX^T C)}{\\partial X} \\] ，其中 \\(A \\in \\mathbb{R}^{m \\times n}, X \\in \\mathbb{R}^{n \\times k}, B \\in \\mathbb{R}^{k \\times k}, C \\in \\mathbb{R}^{n \\times m}\\) 由 \\[ \\begin{aligned} d \\left( \\textbf{A} \\textbf{x} \\textbf{B} \\textbf{x}^T \\textbf{C} \\right) &amp;=Tr \\left[d \\left(\\textbf{A} \\textbf{x} \\textbf{B} \\textbf{x}^T \\textbf{C} \\right) \\right] \\\\ &amp;=Tr \\left[\\textbf{A} \\cdot d \\textbf{x} \\cdot \\textbf{B} \\textbf{x}^T \\textbf{C} + \\textbf{A} \\textbf{x} \\textbf{B} \\cdot d \\textbf{x}^T \\cdot \\textbf{C} \\right] \\\\ &amp;=Tr \\left[ \\textbf{B}\\textbf{x}^T \\textbf{C}\\textbf{A} d \\textbf{x} \\right] + Tr \\left[ d \\textbf{x}^T \\cdot \\textbf{C}\\textbf{A}\\textbf{x}\\textbf{B} \\right] \\\\ &amp;=Tr \\left[ \\textbf{B}\\textbf{x}^T \\textbf{C}\\textbf{A} d \\textbf{x} \\right] + Tr \\left[ \\textbf{B}^T\\textbf{x}^T \\textbf{A}^T \\textbf{C}^T d \\textbf{x} \\right] \\\\ &amp;=Tr \\left[ \\left( \\textbf{B}\\textbf{x}^T \\textbf{C}\\textbf{A} + \\textbf{B}^T\\textbf{x}^T \\textbf{A}^T \\textbf{C}^T \\right) d \\textbf{x}\\right] \\end{aligned} \\] 可知 \\[ \\frac{\\partial Tr \\left(\\textbf{A} \\textbf{x} \\textbf{B} \\textbf{x}^T \\textbf{C} \\right)}{\\partial \\textbf{X}} = \\left( \\textbf{B}\\textbf{x}^T \\textbf{C}\\textbf{A} + \\textbf{B}^T\\textbf{x}^T \\textbf{A}^T \\textbf{C}^T \\right)^T = \\textbf{A}^T \\textbf{C}^T \\textbf{x} \\textbf{B}^T + \\textbf{C} \\textbf{A} \\textbf{x} \\textbf{B} \\] 八 求激活函数 \\[ \\sigma(x) = \\frac{1}{1 + e^{-x}} \\] 的导数 \\[ \\frac{d \\sigma}{d \\textbf{x}} = \\frac{d}{d \\textbf{x}} \\left( \\frac{1}{1+e^{- \\textbf{x}}} \\right) = \\frac{e^{- \\textbf{x}}}{\\left(1+e^{-\\textbf{x}}\\right)^2} = \\sigma(\\textbf{x}) \\left(1-\\sigma(\\textbf{x}) \\right) \\] 九 求 \\[ \\frac{\\partial}{\\partial x} \\exp \\left\\{ - \\frac{1}{2 ||\\sigma||_2^2} ||x - \\mu||_2^2 \\right\\} \\] ，其中 \\(x, \\mu, \\sigma \\in \\mathbb{R}^n\\) 由 \\[ \\begin{aligned} d\\left( e^{-\\frac{1}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2} \\right) &amp;=Tr \\left[ d \\left( e^{-\\frac{2}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2} \\right)\\right] \\\\ &amp;=Tr \\left[ -\\frac{1}{2||\\boldsymbol{\\sigma}||^2} e^{-\\frac{1}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2} \\cdot d \\left( ||\\textbf{x} - \\boldsymbol{\\mu}||_2^2\\right) \\right] \\\\ &amp;=Tr \\left[ -\\frac{1}{2||\\boldsymbol{\\sigma}||^2} e^{-\\frac{1}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2} \\cdot d \\left( (\\textbf{x} - \\boldsymbol{\\mu})^T (\\textbf{x} - \\boldsymbol{\\mu}) \\right) \\right] \\\\ &amp;=Tr \\left[ -\\frac{(\\textbf{x} - \\boldsymbol{\\mu})^T}{||\\boldsymbol{\\sigma}||^2} e^{-\\frac{1}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2} \\cdot d\\textbf{x} \\right] \\end{aligned} \\] 可知 \\[ \\frac{\\partial}{\\partial \\textbf{x}} e^{-\\frac{1}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2} = \\left(-\\frac{(\\textbf{x} - \\boldsymbol{\\mu})^T}{||\\boldsymbol{\\sigma}||^2} e^{-\\frac{1}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2}\\right)^T = -\\frac{(\\textbf{x} - \\boldsymbol{\\mu})}{||\\boldsymbol{\\sigma}||^2} e^{-\\frac{1}{2||\\boldsymbol{\\sigma}||^2}||\\textbf{x} - \\boldsymbol{\\mu}||_2^2} \\] 十 阅读以下代码，填写更新梯度部分的代码。（提交时，需要提交补全的代码，以及最后10次输出的截图） 实现代码： 123456789101112131415161718192021222324252627import numpy as npN, D_in, H, D_out = 64, 1000, 100, 10# 随机创建一些训练数据x = np.random.randn(N, D_in)y = np.random.randn(N, D_out)w1 = np.random.randn(D_in, H)w2 = np.random.randn(H, D_out)learning_rate = 1e-6for it in range(500): # Forward pass h = x.dot(w1) # N * H h_relu = np.maximum(h, 0) # N * H y_pred = h_relu.dot(w2) # N * D_out # compute loss loss = np.square(y_pred - y).sum() print(it, loss) # Backward pass # compute the gradient grad_y_pred = y_pred - y grad_w2 = h_relu.T.dot(grad_y_pred) grad_h_relu = grad_y_pred.dot(w2.T) grad_h = grad_h_relu.copy() grad_h[h &lt; 0] = 0 grad_w1 = x.T.dot(grad_h) w1 -= learning_rate * grad_w1 w2 -= learning_rate * grad_w2 输出结果（最后10次循环）：","categories":[{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"}]},{"title":"操作系统实验 I/O子系统","slug":"os/os-exp-io","date":"2021-06-01T03:54:46.000Z","updated":"2022-02-09T14:20:18.671Z","comments":true,"path":"2021/06/01/os/os-exp-io/","link":"","permalink":"http://gonggongjohn.me/2021/06/01/os/os-exp-io/","excerpt":"","text":"目的 在Minix3中创建一块可用的RAM盘，并比较其与DISK盘在各类存取方式下的速度。 内容与设计思想 在Minix3中安装一块 X MB大小的RAM盘（Minix中已有6块用户可用RAM盘，7块系统保留RAM盘），可以挂载并且存取文件操作。 测试RAM盘和DISK盘的文件读写速度，分析其读写速度差异原因。 实验过程 Minix3的存储管理策略 与其整体系统构架类似，Minix3的I/O构架分为5层：用户进程层、资源调度层、设备驱动层、内核中断层及硬件层。 对于磁盘来说，其通常以块为单位进行存储。当一个用户程序要从一个文件读一个块时，操作系统首先在高速缓存中查找有关的块。如果需要的块不在其中，则调用设备驱动程序，向硬件发出一个请求，从磁盘读取该块，然后将进程阻塞。当磁盘操作完成时，硬件产生一个中断，中断处理器随即从设备读取状态并唤醒休眠的的用户进程使其能够继续运行。 RAM盘申请 RAM盘是将主存中的部分空间当作普通磁盘来使用的一种存储模型。在许多场景下，这种使用方式是高效且重要的（尤其是在由外部设备引导的系统下）。Minix3系统中共有6块固有的RAM盘，其设备控制程序分别被挂载在/dev/ram，/dev/kmem，/dev/boot，/dev/mem，/dev/null和/dev/zero下。 为了增加一块RAM盘，我们首先修改这一RAM盘常量：（minix/drivers/storage/memory） 12/* ramdisks (/dev/ram*) */ #define RAMDISKS 7 Minix本身提供了一个用于创建RAM盘的ramdisk指令，但其单位为KB。为了方便起见，我们实现一个单位为MB的buildmyram指令用于创建较大容量的RAM盘：（minix/commands/ramdisk） 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;minix/paths.h&gt; #include &lt;sys/ioc_memory.h&gt; #include &lt;stdio.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdlib.h&gt; int main(int argc, char *argv[]) &#123; int fd; signed long size; char *d; if(argc &lt; 2 || argc &gt; 3) &#123; fprintf(stderr, &quot;usage: %s &lt;size in MB&gt; [device]\\n&quot;, argv[0]); return 1; &#125; d = argc == 2 ? _PATH_RAMDISK : argv[2]; if((fd=open(d, O_RDONLY)) &lt; 0) &#123; perror(d); return 1; &#125; #define KFACTOR 1024 size = atol(argv[1])*KFACTOR*1024; if(size &lt; 0) &#123; fprintf(stderr, &quot;size should be non-negative.\\n&quot;); return 1; &#125; if(ioctl(fd, MIOCRAMSIZE, &amp;size) &lt; 0) &#123; perror(&quot;MIOCRAMSIZE&quot;); return 1; &#125; fprintf(stderr, &quot;size on %s set to %ldMB\\n&quot;, d, size/KFACTOR/1024); return 0; &#125; 修改完必要的内核代码后，我们重新编译系统并重启进入。现在，我们就可以来实际在系统中申请RAM盘了。 与系统固有盘类似，我们首先使用mknod指令创建一个新申请RAM盘的设备控制节点： 随后，我们使用新实现的buildmyram指令申请一块大小为500MB的RAM盘： 最后，我们在新申请的RAM盘上创建相应的文件系统，并将其挂载到/root/myram目录下即可： 通过df指令可以看到，RAM盘已被成功创建。 读写性能测试 接下来，我们需要编写一组用于测试和比较DISK盘和RAM盘读写性能的程序。由于DISK盘和RAM盘使用了同样的抽象模型，我们可以使用相同的逻辑来对其进行测试。 一块磁盘在使用过程中主要会遇到以下四种读写模式：顺序读取、随机读取、顺序写入、随机写入。对于读取操作，我们首先使用open系统调用打开相应的文件，随后使用read系统调用将文件中固定大小的内容读入缓存中。若为随机读取，则在读取完成后我还需要使用lseek和rand函数将文件指针重新指到一个随机的位置。此外，为了产生较为显著的运行时间以方便比较，我们在一次操作中重复读取1000轮： 1234567891011121314151617181920#define ROUND 1000 void read_file(int blocksize, bool isrand, char *filepath)&#123; int fd = 0; fd = open(filepath, O_CREAT | O_RDWR | O_SYNC, S_IRWXU); if(fd &lt; 0)&#123; fprintf(stdout, &quot;Error occurred when opening file!&quot;); return; &#125; char *buf_ext = (char *)malloc(sizeof(char) * blocksize); for(int i = 0; i &lt; ROUND; i++)&#123; read(fd, buf_ext, blocksize); if(isrand)&#123; lseek(fd, rand() % ((blocksize - 1) * ROUND), SEEK_SET); &#125; &#125; free(buf_ext); lseek(fd, 0, SEEK_SET); close(fd); &#125; 写入操作与读取操作类似。我们首先构造一个64Bytes的字符串作为写入的最小单位，随后使用strcat函数将重复拼接到指定的写入大小，并通过write系统调用将其写入文件系统即可： 123456789101112131415161718192021222324#define BUFSIZE (64) char buffer[BUFSIZE] = &quot;This is a 6KB block!&quot;; void write_file(int blocksize, bool isrand, char *filepath)&#123; int fd = 0; fd = open(filepath, O_CREAT | O_RDWR | O_SYNC, S_IRWXU); if(fd &lt; 0)&#123; fprintf(stdout, &quot;Error occurred when opening file!&quot;); return; &#125; char *buf_ext = (char *)malloc(sizeof(char) * blocksize); for(int i = 0; i &lt; blocksize / BUFSIZE; i++)&#123; strcat(buf_ext, buffer); &#125; for(int i = 0; i &lt; ROUND; i++)&#123; write(fd, buf_ext, blocksize); if(isrand)&#123; lseek(fd, rand() % ((blocksize - 1) * ROUND), SEEK_SET); &#125; &#125; lseek(fd, 0, SEEK_SET); close(fd); &#125; 由于现代存储媒介大多已经可以应付较高的读写请求，为了最大程度测试DISK盘和RAM盘的性能，我们使用多线程并发读写的方式来尽可能地使磁盘吞吐达到饱和。经实测，在写入块大小为4KB时， RAM和DISK盘的吞吐在并发数为16～20左右时基本达到了饱和： 考虑到SSD磁盘的读写硬件特性，我们将并发数设置为15。对于读写块大小，我们以2倍为步长，以测试从64Bytes到8KB时的情况： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#define MAXSTR 100 #define CONCURRENCY 15 char *path_format[2] = &#123;&quot;/root/myram/disk_%d.txt&quot;, &quot;/usr/disk_%d.txt&quot;&#125;; //Irrelevant code double get_time_left(struct timeval starttime, struct timeval endtime)&#123; return ((endtime.tv_sec * 1000 + endtime.tv_usec / 1000) - (starttime.tv_sec * 1000 + starttime.tv_usec / 1000)) / 1000.0; &#125; int main() &#123; srand(time(0)); for (int j = 0; j &lt; 2; j++) &#123; if (j == 0) printf(&quot;RAM:\\n&quot;); else printf(&quot;Disk:\\n&quot;); int block_size = 64; for (int k = 0; k &lt; 8; k++) &#123; struct timeval start_time, end_time; gettimeofday(&amp;start_time, NULL); for (int i = 0; i &lt; CONCURRENCY; i++) &#123; char *filepath = (char *) malloc(sizeof(char) * MAXSTR); sprintf(filepath, path_format[j], i); if (fork() == 0) &#123; /* 顺序读取 */ read_file(block_size, false, filepath); /* 随机读取 */ //read_file(block_size, true, filepath); /* 顺序写入 */ //write_file(block_size, false, filepath); /* 随机写入 */ //write_file(block_size, true, filepath); exit(1); &#125; &#125; for (int i = 0; i &lt; CONCURRENCY; i++) &#123; wait(NULL); &#125; gettimeofday(&amp;end_time, NULL); double time_cost = get_time_left(start_time, end_time); double write_size = block_size * ROUND * CONCURRENCY / 1024.0 / 1024; printf(&quot;Blocksize: %d Bytes, Writesize: %f MB, Time: %f s\\n&quot;, block_size, write_size, time_cost); block_size *= 2; &#125; &#125; return 0; &#125; 测试结果分析 将测试程序编译并多次运行后，我们得到了一组RAM盘和DISK盘在不同块大小下各种读写情况时的运行时间。通过数据大小/运行时间，我们就可大致得到磁盘的平均读写速度。结果如下： 可以发现，随着操作块大小的增加，RAM盘和DISK盘的吞吐量也逐渐增加。在各种读写场景下，RAM盘的读写速度显著高于Disk盘，这与其实现原理及在计算机体系结构中的层级位置相一致： 此外，由于我们使用了SSD（PCI-Express协议）作为磁盘存储媒介，可以看到当块大小为4KB时，DISK盘的吞吐量激增。这是由于在使用SSD磁盘时，系统通常会对其进行4K对齐优化以延长磁盘使用寿命，而4KB的读写块大小正好为一个磁盘块大小，因此磁盘控制器可以快速响应所需的请求。 总结 在本实验中，我们在Minix3系统下分别划分了一块DISK盘空间与RAM盘空间，并通过一系列不同读写方式的组合测试了DISK盘和RAM盘的读写速度与特性，更加直观的认识了系统对于RAM和DISK存储媒介的不同管理方式及其在系统构架中的巨大传输速度差异，从而感受到了现代计算机系统构架的合理性。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Operating-System","slug":"Operating-System","permalink":"http://gonggongjohn.me/tags/Operating-System/"}]},{"title":"操作系统实验 进程调度EDF","slug":"os/os-exp-chrt","date":"2021-04-27T03:54:46.000Z","updated":"2022-03-06T14:13:47.592Z","comments":true,"path":"2021/04/27/os/os-exp-chrt/","link":"","permalink":"http://gonggongjohn.me/2021/04/27/os/os-exp-chrt/","excerpt":"","text":"目的 修改MINIX3系统内核，增加一个系统调用chrt，并在其中实现EDF(Earlist-Deadline-First)进程调度算法。 内容与设计思想 提供设置进程执行期限的系统调度chrt(long deadline)，用于将调用该系统调用的进程设为实时进程，其执行的期限为：从调用处开始deadline秒。例如： 1234#include&lt;unistd.h&gt; ...chrt(10); /* 该程序将可以运行的最长时间为10秒，若没有运行结束，则强制结束 */ ... 在内核进程表中需要增加一个条目，用于表示进程的实时属性；修改相关代码，新增一个系统调用chrt，用于设置其进程表中的实时属性。 修改proc.c和proc.h中相关的调度代码，实现最早deadline的用户进程相对于其它用户进程具有更高的优先级，从而被优先调度运行。 在用户程序中，可以在不同位置调用多次chrt系统调用，在未到deadline之前，调用chrt将会改变该程序的deadline。 未调用chrt的程序将以普通的用户进程(非实时进程)在系统中运行。 实验过程 MINIX系统构架 作为一个微内核构架系统，Minix将系统进程分为了4层：内核层、驱动管理层、服务器进程层、用户进程层，其中内核层运行在系统内核态，而后三层均运行在用户态。 在Minix中，层与层之间的消息传递通过系统调用来完成，而这又分为了System Call和Kernel Call。System Call用于应用层向服务层的消息传递，Kernel Call则用于服务层向内核层的消息传递。 消息传递本质上是进程间通讯，从内存角度看即为内存地址间的内容拷贝。幸运的是，Minix已经帮我们封装好了这些调用的底层实现，我们只需要传入正确的参数，系统会自动托管底层内存拷贝的相关事务：（minix/lib/libc/sys/syscall.c） 1234567891011121314151617int _syscall(endpoint_t who, int syscallnr, message *msgptr) &#123; int status; msgptr-&gt;m_type = syscallnr; status = ipc_sendrec(who, msgptr); if (status != 0) &#123; /* &#x27;ipc_sendrec&#x27; itself failed. */ /* XXX - strerror doesn&#x27;t know all the codes */ msgptr-&gt;m_type = status; &#125; if (msgptr-&gt;m_type &lt; 0) &#123; errno = -msgptr-&gt;m_type; return(-1); &#125; return(msgptr-&gt;m_type); &#125; （minix/lib/libsys/kernel_call.c） 123456int _kernel_call(int syscallnr, message *msgptr) &#123; msgptr-&gt;m_type = syscallnr; do_kernel_call(msgptr); return(msgptr-&gt;m_type); &#125; Minix系统采用了一种多级调度算法，通过维护16个进程队列并赋予其不同的队列优先级来实现进程的分级。其中，0号队列用于放置时钟及系统任务，系统会允许其持续运行直到阻塞（但如果其运行时间过长，系统会设置一个罚时将其暂时移出队列以防止其他进程发生饥饿），7号队列用于放置用户进程，15号队列用于放置闲置进程。在每个进程队列内部，系统采用了时间片轮转的方式使得进程可以公平的分配到运行时间。 EDF调度实现 要实现EDF调度算法，需要记录每个进程的截止时间。为此，我们在进程控制块（Process Control Block）的结构定义中新增一个p_deadline项：（minix/kernel/proc.h） 1234567struct proc &#123; //Unrelated codes long p_deadline; /* Deadline of the process */ //Unrelated codes &#125;; 由于Minix采用多级进程队列，我们可以选择其中的一个进程队列，并在其中使用EDF算法进行调度。由于要保证所有调用chrt系统调用的进程都使用该调度规则，所选择的进程队列的整体优先级要高于用户进程所在的队列，但同时又不能影响系统进程的运作。这里我们选择优先级为5的队列作为EDF调度队列（事实上，4号队列也可以作为要替换的目标队列，但为了防止驱动或系统进程临时调度到这一队列，在此我们将其留出作为缓冲）。 对于一般的进程，我们在进程初始化时将p_deadline置为0。这样在进程调度时，若检测到p_deadline&gt;0，即可得知其为调用了chrt系统调用的进程，我们便将其加入优先级为5的队列中：（minix/kernel/proc.h） 12345678910111213141516171819void enqueue( register struct proc *rp /* this process is now runnable */ ) &#123; //Unrelated codes if(rp-&gt;p_deadline &gt; 0)&#123; rp-&gt;p_priority = 5; &#125; //Unrelated codes &#125; static void enqueue_head(struct proc *rp) &#123; //Unrelated codes if(rp-&gt;p_deadline &gt; 0)&#123; rp-&gt;p_priority = 5; &#125; //Unrelated codes &#125; 在调度时，我们要找出队列中p_deadline最小的进程并返回。一个可行的办法是维护一个优先队列，按照p_deadline对进程控制结构建立小根堆，其可以在 \\(\\mathcal{O}(\\lg n)\\) 的时间内返回目标进程，但这样做需要修改整个进程队列的数据结构，操作起来过于复杂，也不符合Minix3的原始设计风格。由于进入该队列的进程是由用户指定的，其规模通常较小，因此我们可以直接遍历整个队列，其效率仍然是可以接受的。实现代码如下：（minix/kernel/proc.c） 1234567891011121314151617181920212223242526static struct proc * pick_proc(void) &#123; //Unrelated codes for (q=0; q &lt; NR_SCHED_QUEUES; q++) &#123; //Unrelated codes //EDF algorithm if(q == 5)&#123; rp = rdy_head[q]; struct proc *cur = rp-&gt;p_nextready; //Traverse the queue while(cur != NULL) &#123; if(proc_is_runnable(cur) &amp;&amp; (cur-&gt;p_deadline &gt; 0)) &#123; if (rp-&gt;p_deadline &gt; cur-&gt;p_deadline) &#123; rp = cur; &#125; else if (rp-&gt;p_deadline == 0)&#123; rp = cur; &#125; &#125; cur = cur-&gt;p_nextready; &#125; &#125; //Unrelated codes return rp; &#125; return NULL; &#125; 应用层实现 在应用层中，我们需要实现面向用户的chrt函数，并将用户指定的进程和截止时间传入服务层。 首先我们在POSIX规定的操作系统API头文件中定义chrt的函数原型：（include/unistd.h） 1int chrt(long deadline); // 0 - Normal process; &gt;0 - Realtime process; &lt;0 - Unsuccessful 用户指定的截止时间是一个相对时间，即从该语句执行时刻向后deadline秒，因此我们需要将其转为绝对时间（事实上是相对系统时钟当前时刻的时间）。Minix系统提供了一个clock_gettime函数用于获取系统的时间戳，因此我们可以直接调用该函数来算出当前进程所指定deadline对应的绝对时刻：（minix/lib/libc/sys/chrt.c） 1234567891011121314151617181920#include &lt;sys/cdefs.h&gt; #include &quot;namespace.h&quot; #include &lt;lib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;time.h&gt; int chrt(long deadline)&#123; message m; struct timespec now; memset(&amp;m, 0, sizeof(m)); //Unrelated codes if(deadline &lt; 0) return 0; else if(deadline &gt; 0)&#123; clock_gettime(CLOCK_REALTIME, &amp;now); deadline = now.tv_sec + deadline; &#125; //Unrelated codes &#125; 此外，我们还需要对传入的deadline参数做一些边界处理，并通过alarm系统调用将超时响应的应用提前结束。随后我们便可以将其放入一个消息结构体中，并通过 **System Call（_syscall函数）** 将消息传入服务层中：（minix/lib/libc/sys/chrt.c） 1234567int chrt(long deadline)&#123; //Unrelated codes alarm((unsigned int) deadline); //Unrelated codes m.m2_l1 = deadline; return _syscall(PM_PROC_NR, PM_CHRT, &amp;m); &#125; 服务层实现 对于要实现的chrt系统调用来说，服务层起到了消息传递的作用。在Minix3系统中，这需要两步来完成，先接受应用层传来的消息，再将消息重新打包并通过Kernel Call传入内核中。 首先我们来实现消息接受的功能。在应用层中，我们通过调用标识符为PM_CHRT的System Call将消息发到了服务层中，于是我们需要在服务层中申明这一System Call并将其与消息接收函数相关联：（minix/include/minix/callnr.h） 123#define PM_CHRT (PM_BASE + 48) #define NR_PM_CALLS 49 /* highest number from base plus one */ （minix/servers/pm/table.c） 123int (* const call_vec[NR_PM_CALLS])(void) = &#123; CALL(PM_CHRT) = do_chrt, /* chrt */ &#125;; （minix/servers/pm/proto.h） 12/* chrt.c */ int do_chrt(); 至于消息接收函数的实现，我们只需要将发来消息的进程号和发来的消息传递给承接服务层向内核进行消息传递的函数即可：（minix/servers/pm/chrt.c） 1234567891011#include &quot;pm.h&quot; #include &lt;signal.h&gt; #include &lt;sys/time.h&gt; #include &lt;minix/com.h&gt; #include &lt;minix/callnr.h&gt; #include &quot;mproc.h&quot; int do_chrt()&#123; sys_chrt(who_p, m_in.m2_l1); return OK; &#125; 随后我们来实现服务层向内核层的消息传递。首先我们定义消息传递函数的原型：（minix/include/minix/syslib.h） 1int sys_chrt(endpoint_t proc_ep, long deadline); 对于该函数我们只需要将传入的函数重新打包为一个新的消息，并通过**Kernel Call（_kernel_call函数）将其传入内核即可：（minix/lib/libsys/sys_chrt.c）** 123456789#include &quot;syslib.h&quot; int sys_chrt(endpoint_t proc_ep, long deadline) &#123; message m; m.m2_i1 = proc_ep; m.m2_l1 = deadline; return _kernel_call(SYS_CHRT, &amp;m); &#125; 内核层实现 首先我们定义服务层中调用的SYS_CHRT内核调用，并将其与内核实现函数相关联：（minix/include/minix/com.h） 1234# define SYS_CHRT (KERNEL_CALL + 58) /* sys_chrt() */ /* Total */ #define NR_SYS_CALLS 59 /* number of kernel calls */ （minix/kernel/system.c） 1map(SYS_CHRT, do_chrt); /* chrt */ 随后我们定义实现函数的原型，并在内核中默认启用它：（minix/kernel/config.h） 1#define USE_CHRT 1 /* chrt */ （minix/kernel/system.h） 1234int do_chrt(struct proc * caller, message *m_ptr); #if ! USE_CHRT #define do_chrt NULL #endif 内核的任务就是把上层传递下来的消息解包，并将目标进程的截止时间设置为用户所指定的时间：（minix/kernel/system/do_chrt.c） 123456789101112131415161718192021#include &quot;kernel/system.h&quot; #include &quot;kernel/vm.h&quot; #include &lt;signal.h&gt; #include &lt;string.h&gt; #include &lt;assert.h&gt; #include &lt;minix/endpoint.h&gt; #include &lt;minix/u64.h&gt; #if USE_CHRT int do_chrt(struct proc *caller, message *m_ptr)&#123; struct proc *rp; long deadline; deadline = m_ptr-&gt;m2_l1; rp = proc_addr(m_ptr-&gt;m2_i1); rp-&gt;p_deadline = deadline; return OK; &#125; #endif /* USE_FORK */ 功能测试 我们使用以下代码来对实现的功能进行测试： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;string.h&gt; #include &lt;signal.h&gt; #include &lt;sys/wait.h&gt; #include &lt;sys/types.h&gt; #include &lt;lib.h&gt; #include &lt;time.h&gt; void proc(int id); int main(void) &#123; //创建三个子进程，并赋予子进程id for (int i = 1; i &lt; 4; i++) &#123; if (fork() == 0) &#123; proc(i); &#125; &#125; return 0; &#125; void proc(int id) &#123; int loop; switch (id) &#123; case 1: //子进程1，设置deadline=20 chrt(20); printf(&quot;proc1 set success\\n&quot;); //sleep(1); break; case 2: //子进程2，设置deadline=15 chrt(15); printf(&quot;proc2 set success\\n&quot;); //sleep(1); break; case 3: //子进程3，普通进程 chrt(0); printf(&quot;proc3 set success\\n&quot;); break; &#125; for (loop = 1; loop &lt; 40; loop++) &#123; //子进程1在5s后设置deadline=5 if (id == 1 &amp;&amp; loop == 5) &#123; long tmp; tmp = chrt(5); printf(&quot;Status of CHRT: %d\\n&quot;, tmp); printf(&quot;Change proc1 deadline to 5s\\n&quot;); &#125; //子进程3在10s后设置deadline=3 if (id == 3 &amp;&amp; loop == 10) &#123; chrt(3); printf(&quot;Change proc3 deadline to 3s\\n&quot;); &#125; sleep(1); //睡眠，否则会打印很多信息 printf(&quot;prc%d heart beat %d\\n&quot;, id, loop); &#125; exit(0); &#125; 该程序创建了3个子进程，并对其分别设置了不同的截止时间，其运行结果如下： 可以看到，程序中chrt系统调用的返回值为0，表明其成功将消息传入了内核，且程序行为与预期相符，表明了实现的正确性。 总结 在本实验中，我们通过修改Minix3的系统源码，实现了一个完整的系统调用，并在进程调度中实现了EDF算法，极大的加深了我们对一个微内核操作系统的系统调用、消息传递及进程调度机制的理解。 --&gt;","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Operating-System","slug":"Operating-System","permalink":"http://gonggongjohn.me/tags/Operating-System/"}]},{"title":"离散型随机变量整理","slug":"math-prob-stat/prob-drv","date":"2021-04-21T09:56:35.000Z","updated":"2022-02-09T10:32:53.238Z","comments":true,"path":"2021/04/21/math-prob-stat/prob-drv/","link":"","permalink":"http://gonggongjohn.me/2021/04/21/math-prob-stat/prob-drv/","excerpt":"二项分布 定义 Definition: 若一个离散型随机变量 \\(X\\) 的分布列满足 \\[ P(X=k) = \\binom{n}{k} p^k (1-p)^{1-k} \\] 其中 \\(n \\in \\mathbb{N}^+, k \\in \\{0,1,2,...,n\\}, p \\in [0,1]\\)，则称随机变量 \\(X\\) 满足二项分布，记为 \\(X \\sim B(n, p)\\)","text":"二项分布 定义 Definition: 若一个离散型随机变量 \\(X\\) 的分布列满足 \\[ P(X=k) = \\binom{n}{k} p^k (1-p)^{1-k} \\] 其中 \\(n \\in \\mathbb{N}^+, k \\in \\{0,1,2,...,n\\}, p \\in [0,1]\\)，则称随机变量 \\(X\\) 满足二项分布，记为 \\(X \\sim B(n, p)\\) 适用场景：在 \\(n\\) 次伯努利试验中，若每次成功的概率均为 \\(p\\)，求成功 \\(k\\) 次的概率 二项分布的累积分布函数为 \\[ F(k) = P(X \\leq k)= \\left\\{ \\begin{aligned} \\sum_\\limits{i=0}^{\\lfloor k \\rfloor} \\binom{n}{k}p^k(1-p)^{1-k}&amp;,&amp;k \\geq 0 \\\\ 0&amp;,&amp; k &lt; 0 \\end{aligned} \\right. \\] 若引入不完全Beta函数，则其累积分布函数的非负部分还可表示为 \\[ \\begin{aligned} F(k) &amp;= I_{1-p} (n-k, k+1) \\\\ &amp;= \\frac{\\textrm{B} (1-p;n-k,k+1)}{\\textrm{B} (n-k,k+1)} \\\\ &amp;=\\frac{\\int_0^{1-p} t^{n-k-1}(1-t)^k dt}{\\int_0^1 t^{n-k-1}(1-t)^k dt} \\ , k \\geq 0 \\end{aligned} \\] 期望和方差 由于每一次伯努利试验均为独立的，因此我们可以将 \\(n\\) 次试验分解为 \\(n\\) 个单次试验，即若定义 \\[ Y_i = \\left\\{ \\begin{aligned} 1,&amp; Succeed \\ \\ in \\ \\ i^{th} \\ \\ exp \\\\ 0,&amp; Fail \\ \\ in \\ \\ i^{th} \\ \\ exp \\end{aligned} \\right. \\] 则 \\(X=\\sum\\limits_{i = 1}^n Y_i\\) （此时 \\(Y_i\\) 服从的分布即 \\(B(1,p)\\) 也被称为二点分布或0-1分布） 于是我们可以快速求出二项分布的期望 \\[ \\begin{aligned} E(X) &amp;= E \\left( \\sum_{i = 1}^n Y_i \\right) \\\\ &amp;= \\sum_{i = 1}^n E(Y_i) \\\\ &amp;= \\sum_{i = 1}^n p \\\\ &amp;=np \\end{aligned} \\] 同理，由 \\[Var(Y_i) = (1-p)^2 p + (0-p)^2(1-p)=p(1-p)\\] 可知二项分布的方差为 \\[ \\begin{aligned} Var(X) &amp;= Var(\\sum_\\limits{i=1}^n Y_i) \\\\ &amp;= \\sum_\\limits{i=1}^n Var(Y_i) \\\\ &amp;= \\sum_\\limits{i=1}^n p(1-p) \\\\ &amp;= np(1-p) \\end{aligned} \\] 另解（纯分析法求二项分布期望及方差）： \\[ \\begin{aligned} E(X) &amp;= \\sum_\\limits{k = 0}^n k \\binom{n}{k} p^k (1-p)^{n-k} \\\\ &amp;= \\sum_\\limits{k = 1}^n k \\binom{n}{k} p^k (1-p)^{n-k} \\\\ \\end{aligned} \\] 由于 \\[ \\begin{aligned} k\\binom{n}{k} &amp;= k \\cdot \\frac{n!}{k!(n-k)!} \\\\ &amp;=\\frac{n!}{(k-1)!(n-k)!} \\\\ &amp;=n \\cdot \\frac{(n-1)!}{(k-1)!(n-k)!} \\\\ &amp;=n \\binom{n-1}{k-1} \\end{aligned} \\] 因此 \\[ \\begin{aligned} E(X) &amp;= \\sum_\\limits{k = 1}^n n \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;=np \\sum_\\limits{k = 1}^n \\binom{n-1}{k-1} p^{k-1} (1-p)^{n-k} \\\\ &amp;=np \\sum_\\limits{m = 0}^{n-1} \\binom{n-1}{m} p^m (1-p)^{n-1-m} \\\\ &amp;=np \\cdot (p+1-p)^{n-1} \\\\ &amp;=np \\end{aligned} \\] 又由 \\[ \\begin{aligned} E(X^2) &amp;= \\sum_\\limits{k = 0}^n k^2 \\binom{n}{k} p^k (1-p)^{n-k} \\\\ &amp;= n \\cdot \\sum_\\limits{k = 1}^n k \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;= n \\cdot \\sum_\\limits{k = 1}^n (k - 1 + 1) \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;= n \\cdot \\left[ \\sum_\\limits{k = 1}^n (k - 1) \\binom{n-1}{k-1} p^k (1-p)^{n-k} + \\sum_\\limits{k = 1}^n \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\right] \\\\ &amp;=n \\cdot \\sum_\\limits{k = 2}^n (n - 1) \\binom{n-2}{k-2} p^k (1-p)^{n-k} + n \\cdot \\sum_\\limits{k = 1}^n \\binom{n-1}{k-1} p^k (1-p)^{n-k} \\\\ &amp;= n(n-1)p^2 + np \\end{aligned} \\] 可知 \\[ \\begin{aligned} Var(X) &amp;= E(X^2) - E^2(X) \\\\ &amp;=n(n-1)p^2 + np - n^2p^2 \\\\ &amp;=n^2p^2-np^2+ np - n^2p^2 \\\\ &amp;=np(1-p) \\end{aligned} \\] 泊松分布 定义 Definition: 若一个离散型随机变量 \\[X\\] 的分布列满足 \\[ P(X=k) = \\frac{\\lambda^k}{k!} e^{-\\lambda} \\] 其中 \\[k \\in \\{0,1,2,3,...\\}, \\lambda&gt;0\\]，则称随机变量 \\[X\\] 满足泊松分布，记为 \\[X \\sim P(\\lambda)\\] 适用场景：求一段固定长度的时间中事件发生了 \\[k\\] 次的概率 泊松分布的累积分布函数为 \\[ F(k) = P(X \\leq k) = \\left\\{ \\begin{aligned} \\sum_{i = 0}^{\\lfloor k \\rfloor} \\frac{\\lambda^i}{i!}e^{-\\lambda}&amp;,&amp; k \\geq 0 \\\\ 0&amp;,&amp; k &lt; 0 \\end{aligned} \\right. \\] 若引入不完全伽马函数，则其累积分布函数的非负部分还可表示为 \\[ \\begin{aligned} F(k) &amp;= \\frac{\\Gamma(\\lfloor k + 1\\rfloor, \\lambda)}{\\Gamma(\\lfloor k +1 \\rfloor)} \\\\ &amp;=Q(\\lfloor k + 1\\rfloor, \\lambda) \\end{aligned} \\] 期望和方差 利用 \\[e^x = \\sum_\\limits{k = 0}^\\infty \\frac{x^k}{k!}\\] 可快速求出泊松分布的期望 \\[ \\begin{aligned} E(X) &amp;= \\sum_{k = 0}^\\infty k \\cdot \\frac{\\lambda^k}{k!} e^{-\\lambda} \\\\ &amp;=e^{-\\lambda} \\cdot \\sum_{k = 1}^\\infty k \\cdot \\frac{\\lambda^k}{k!} \\\\ &amp;=\\lambda e^{-\\lambda} \\cdot \\sum_{k = 1}^\\infty \\frac{\\lambda^{k-1}}{(k-1)!} \\\\ &amp;=\\lambda e^{-\\lambda} e^\\lambda \\\\ &amp;=\\lambda \\end{aligned} \\] 又由 \\[ \\begin{aligned} E(X^2) &amp;= \\sum_{k = 0}^\\infty k^2 \\cdot \\frac{\\lambda^k}{k!} e^{-\\lambda} \\\\ &amp;=e^{-\\lambda} \\sum_{k = 1}^\\infty k^2 \\cdot \\frac{\\lambda^k}{k!} \\\\ &amp;=\\lambda e^{-\\lambda} \\sum_{k = 1}^\\infty k \\cdot \\frac{\\lambda^{k-1}}{(k-1)!} \\\\ &amp;=\\lambda e^{-\\lambda} \\sum_{k = 1}^\\infty (k-1+1) \\cdot \\frac{\\lambda^{k-1}}{(k-1)!} \\\\ &amp;=\\lambda e^{-\\lambda} \\left( \\sum_{k = 2}^\\infty (k-1) \\cdot \\frac{\\lambda^{k-1}}{(k-1)!} + \\sum_{k = 1}^\\infty \\frac{\\lambda^{k-1}}{(k-1)!} \\right) \\\\ &amp;=\\lambda e^{-\\lambda} \\left( \\lambda \\sum_{k = 2}^\\infty \\frac{\\lambda^{k-2}}{(k-2)!} + \\sum_{k = 1}^\\infty \\frac{\\lambda^{k-1}}{(k-1)!} \\right) \\\\ &amp;=\\lambda e^{-\\lambda} \\left( \\lambda e^\\lambda + e^\\lambda \\right) \\\\ &amp;=\\lambda^2 + \\lambda \\end{aligned} \\] 可知其方差为 \\[ \\begin{aligned} Var(X) &amp;= E(X^2) - E^2(X) \\\\ &amp;= \\lambda^2 + \\lambda - \\lambda^2 \\\\ &amp;=\\lambda \\end{aligned} \\] 泊松分布与二项分布 泊松分布与二项分布有如下定理成立： Theorem(Poisson): 设 \\[k \\leq n \\in N, \\lambda &gt; 0\\]，\\[\\{p_n\\}\\] 是一个与 \\[n\\] 有关的序列且 \\[0 \\leq p_n \\leq 1\\]，\\[np_n \\to \\lambda (n \\to \\infty)\\]，则 \\[ \\lim_{n \\to \\infty} \\binom{n}{k} p_n^k(1-p_n)^{n-k} = \\frac{\\lambda^k}{k!} e^{-\\lambda} \\] Proof: 令 \\[np_n = \\lambda_n\\] 故由 \\[np_n \\to \\lambda(n \\to \\infty)\\] 可知 \\[\\lambda_n \\to \\lambda(n \\to \\infty)\\] 故 \\[ \\begin{aligned} \\binom{n}{k} p_n^k(1-p_n)^{n-k} &amp;= \\binom{n}{k} (\\frac{\\lambda_n}{n})^k \\left( 1-\\frac{\\lambda_n}{n} \\right)^{n-k} \\\\ &amp;= \\frac{n(n-1) \\cdots (n-k-1)}{k!} \\cdot \\frac{\\lambda_n^k}{n^k} \\cdot \\left( 1-\\frac{\\lambda_n}{n} \\right)^{n-k} \\\\ &amp;=\\frac{\\lambda_n^k}{k!} \\cdot \\frac{n-1}{n} \\cdot \\frac{n-2}{n} \\cdots \\frac{n-k-1}{n} \\cdot \\left( 1-\\frac{\\lambda_n}{n} \\right)^{n-k} \\end{aligned} \\] 又 \\[ \\lim_{n \\to \\infty} \\frac{n-1}{n} \\cdot \\frac{n-2}{n} \\cdots \\frac{n-k-1}{n} = 1^k = 1 \\\\ \\lim_{n \\to \\infty} \\left( 1-\\frac{\\lambda_n}{n} \\right)^{n-k} = e^{-\\lambda} \\] 因此 \\[ \\begin{aligned} \\lim_{n \\to \\infty} \\binom{n}{k} p_n^k(1-p_n)^{n-k} &amp;= \\lim_{n \\to \\infty} \\frac{\\lambda_n^k}{k!} \\cdot \\frac{n-1}{n} \\cdot \\frac{n-2}{n} \\cdots \\frac{n-k-1}{n} \\cdot \\left( 1-\\frac{\\lambda_n}{n} \\right)^{n-k} \\\\ &amp;=\\frac{\\lambda^k}{k!} e^{-\\lambda} \\end{aligned} \\] 由上面的定理可以看出，泊松分布可以看作是一个二项分布当 \\[n\\] 趋于无穷时的极限情况（此时泊松分布中的参数 \\[\\lambda\\] 即为二项分布的期望 \\[np\\]），因此对于一个二项分布 \\[B(n,p)\\] 来说，当 \\[n\\] 充分大且 \\[p\\] 充分小时，其对应点的值可使用泊松分布的值来近似。即若随机变量 \\[X \\sim B(n,p)\\]，则 \\[ P(X=k) \\approx \\frac{n^kp^k}{k!} e^{-np} \\] 一般来说，当 \\[n \\geq 20, p \\leq 0.05\\] 时，泊松分布就可作为二项分布的一个可用的近似；当 \\[n \\geq 100, np \\leq 10\\] 时，泊松分布就是二项分布的一个较为精准的近似了。 几何分布 定义 Definition: 若一个离散型随机变量 \\[X\\] 的分布列满足 \\[ P(X=k) = (1-p)^{k-1} p \\] 其中 \\[k \\in \\{1,2,3,...\\}, p \\in [0,1]\\]，则称随机变量 \\[X\\] 满足几何分布，记为 \\[X \\sim Ge(p)\\] 适用场景：在一组伯努利实验中，若每次成功的概率为 \\[p\\]，求当进行到第 \\[k\\] 次试验时才第一次成功的概率 几何分布的累积分布函数为 \\[ \\begin{aligned} F(k) &amp;= P(X \\leq k) \\\\ &amp;= \\sum_{i =1}^{\\lfloor k \\rfloor} (1-p)^{i-1}p \\\\ &amp;=p \\cdot \\frac{1-(1-p)^{\\lfloor k \\rfloor}}{p} \\\\ &amp;=1-(1-p)^{\\lfloor k \\rfloor}, k \\geq 1 \\end{aligned} \\] 无记忆性 几何分布有如下的性质成立： Theorem: 若 \\[X \\sim Ge(p)\\]，则对任意 \\[m,n \\geq 1\\]，有 \\[ P(X &gt; m+n | X &gt; m) = P(X &gt; n) \\] Proof: 由于 \\[ \\begin{aligned} P(X &gt; m) &amp;= \\sum_{k = m+1}^\\infty (1-p)^{k-1} p \\\\ &amp;= p \\cdot \\frac{(1-p)^m}{p} \\\\ &amp;=(1-p)^m \\end{aligned} \\] 故 \\[ \\begin{aligned} P(X &gt; m+n | X &gt; m) &amp;= \\frac{P(X&gt;m+n,X&gt;m)}{P(X&gt;m)} \\\\ &amp;=\\frac{P(X&gt;(m+n))}{P(X&gt;m)} \\\\ &amp;=\\frac{(1-p)^{m+n}}{(1-p)^m} \\\\ &amp;=(1-p)^{n} \\\\ &amp;=P(X&gt;n) \\end{aligned} \\] 该定理表明，在一串伯努利试验中若前 \\[m\\] 次试验均不成功，则后续试验每一次成功的概率与重新从第一次开始计数试验成功的概率相同，即前 \\[m\\] 次试验并不对接下来的结果造成任何影响。 事实上，几何分布是离散型分布中唯一具有无记忆性的分布： Theorem: 设 \\[X\\] 为一个离散随机变量，其取值范围为 \\[\\{1,2,3,...\\}\\]，若对任意 \\[m,n \\geq 1 \\in \\mathbb{N}\\]，有 \\[P(X&gt;m+n | X&gt;m) = P(X&gt;n)\\]，则存在 \\[0 \\leq p \\leq 1\\]，使得 \\[X \\sim Ge(p)\\] Proof: 令 \\[F(x) = P(X&gt;x)\\] 则原条件可写为对任意 \\[m,n \\geq 1 \\in \\mathbb{N}\\]，有 \\[ \\frac{F(m+n)}{F(m)} = F(n) \\] 即 \\[F(m+n) = F(m)F(n)\\] 令 \\[m = n = 1\\]，则 \\[F(2) = F^2(1)\\] 再令 \\[m=2, n =1\\]，则 \\[F(3) = F^3(1)\\] 如此递推，可得 \\[F(m) = F^m(1)\\] 令 \\[P(X=1) = p\\] 则 \\[ \\begin{aligned} F(1) &amp;= P(X&gt;1) \\\\ &amp;=1-P(X=1) \\\\ &amp;=1-p \\end{aligned} \\] 由此可知对任意 \\[m \\geq 1 \\in \\mathbb{N}\\]，有 \\[ \\begin{aligned} P(X=m) &amp;= P(X&gt;m-1) - P(X&gt;m) \\\\ &amp;=F(m-1) - F(m) \\\\ &amp;=F^{m-1}(1) - F^m(1) \\\\ &amp;=(1-p)^{m-1} - (1-p)^m \\\\ &amp;=(1-p)^{m-1}p \\end{aligned} \\] 即 \\[X \\sim Ge(p)\\] 期望和方差 利用几何分布的无记忆性，我们可以快速求出几何分布的期望和方差。 易见 \\[E(X|X=1) = 1\\] 而 \\[ \\begin{aligned} E(X|X&gt;1) &amp;= \\sum_{k = 2}^\\infty k \\cdot P(X=k|X&gt;1) \\\\ &amp;= \\sum_{k = 2}^\\infty k \\cdot P(X=k-1) \\\\ &amp;= \\sum_{k = 2}^\\infty (k-1) \\cdot P(X=k-1) + \\sum_{k = 2}^\\infty P(X=k-1) \\\\ &amp;=E(X) + 1 \\end{aligned} \\] 故由全期望公式可知 \\[ \\begin{aligned} E(X) &amp;= P(X=1)E(X|X=1) + P(X&gt;1)E(X|X&gt;1) \\\\ &amp;=p + (1-p) (E(X) + 1) \\\\ &amp;=(1-p) \\cdot E(X) + 1 \\end{aligned} \\] 即几何分布的期望 \\[E(X) = \\frac{1}{p}\\] 同理，\\[E(X^2|X = 1) = 1\\] \\[ \\begin{aligned} E(X^2|X&gt;1) &amp;= \\sum_{k = 2}^\\infty k^2 \\cdot P(X=k|X&gt;1) \\\\ &amp;= \\sum_{k = 2}^\\infty k^2 \\cdot P(X=k-1) \\\\ &amp;= \\sum_{k = 2}^\\infty (k-1)^2 \\cdot P(X=k-1) + 2 \\cdot \\sum_{k = 2}^\\infty (k-1) \\cdot P(X=k-1) + \\sum_{k = 2}^\\infty P(X=k-1) \\\\ &amp;=E(X^2) + 2E(X) + 1 \\end{aligned} \\] 故 \\[ \\begin{aligned} E(X^2) &amp;= P(X = 1)E(X^2|X=1) + P(X&gt;1)E(X^2|X&gt;1) \\\\ &amp;= p + (1-p)(E(X^2) + 2E(X) + 1) \\\\ &amp;= (1-p)E(X^2) + 2(1-p)E(X) + 1 \\\\ &amp;=(1-p)E(X^2) + \\frac{2}{p} - 1 \\end{aligned} \\] 于是 \\[E(X^2) = \\frac{2-p}{p^2}\\] 因此几何分布的方差 \\[ \\begin{aligned} Var(X) &amp;= E(X^2) - E^2(X) \\\\ &amp;=\\frac{2-p}{p^2} - \\frac{1}{p^2} \\\\ &amp;=\\frac{1-p}{p^2} \\end{aligned} \\] 另解（纯分析法求几何分布期望和方差）： 首先我们对其表达式进行化简： \\[ \\begin{aligned} E(X) &amp;= \\sum_{k = 1}^\\infty k(1-p)^{k-1} p \\\\ &amp;=p \\cdot \\sum_{k = 1}^\\infty k(1-p)^{k-1} \\\\ &amp;=p \\cdot \\sum_{k = 1}^\\infty \\left( -\\frac{d}{dp} (1-p)^k \\right) \\end{aligned} \\] 由于几何级数一致收敛于其极限值，故 \\[ \\sum_{k = 1}^\\infty \\frac{d}{dp} \\left( (1-p)^k \\right) = \\frac{d}{dp} \\sum_{k = 1}^\\infty \\left( (1-p)^k \\right) \\] 因此几何分布的期望为 \\[ \\begin{aligned} E(X) &amp;=-p \\cdot \\frac{d}{dp} \\left( \\sum_{k = 1}^\\infty (1-p)^k \\right) \\\\ &amp;= -p \\cdot \\left( - \\frac{1}{p^2}\\right) \\\\ &amp;=\\frac{1}{p} \\end{aligned} \\] 同理可知 \\[ \\begin{aligned} E(X^2) &amp;= \\sum_{k = 1}^\\infty k^2 (1-p)^{k-1} p \\\\ &amp;=p \\sum_{k = 1}^\\infty k(k+1-1) (1-p)^{k-1} \\\\ &amp;=p \\left( \\sum_{k = 1}^\\infty \\left(\\frac{d^2}{dp^2} \\left( (1-p)^{k+1} \\right) \\right) - \\sum_{k = 1}^\\infty \\left( \\frac{d}{dp} \\left( (1-p)^k \\right) \\right) \\right) \\\\ &amp;=p \\left( \\frac{d^2}{dp^2} \\left( \\sum_{k = 1}^\\infty \\left( (1-p)^{k+1} \\right) \\right) - \\frac{d}{dp} \\left( \\sum_{k = 1}^\\infty \\left( (1-p)^k \\right) \\right) \\right) \\\\ &amp;=p \\left(\\frac{d^2}{dp^2} \\left( \\frac{1}{p}-2+p \\right) - \\frac{d}{dp} \\left( \\frac{1}{p} - 1 \\right) \\right) \\\\ &amp;=\\frac{2}{p^2} - \\frac{1}{p} \\end{aligned} \\] 因此其方差为 \\[ \\begin{aligned} Var(X) &amp;= E(X^2) - E^2(X) \\\\ &amp;=\\frac{2}{p^2} - \\frac{1}{p} - \\frac{1}{p^2} \\\\ &amp;=\\frac{1-p}{p^2} \\end{aligned} \\] 负二项分布 定义 Definition: 若一个离散型随机变量 \\[X\\] 的分布列满足 \\[ P(X=k) = \\binom{k-1}{r-1} p^r (1-p)^{k-r} \\] 其中 \\[r \\leq k \\in \\{1,2,3,...\\}, p \\in [0,1]\\]，则称随机变量 \\[X\\] 满足负二项分布，记为 \\[X \\sim Nb(r, p)\\] 适用场景：在一组伯努利实验中，若每次成功的概率为 \\[p\\]，求第 \\[r\\] 次成功时总共进行的试验次数 \\[k\\] 负二项分布的累积分布函数 \\[ F(k) = P(X \\leq k) = \\left\\{ \\begin{aligned} \\sum_{i = 1}^k \\binom{i-1}{r-1} p^r (1-p)^{i-r}&amp;,&amp; k \\geq r \\\\ 0&amp;,&amp; k &lt; r \\end{aligned} \\right. \\] 若引入不完全Beta函数，则其累积分布函数的非负部分还可表示为 \\[ \\begin{aligned} F(k) &amp;= I_{1-p}(r, k-r+1) \\\\ &amp;=\\frac{B(1-p;r,k-r+1)}{B(r,k-r+1)} \\end{aligned} \\] 负二项分布与几何分布 从直观上来看，几何分布描述的是一组伯努利实验中第一次成功的实验次数，而负二项分布描述的是一组伯努利实验中第 \\[r\\] 次成功的实验次数，自然的，几何分布可以被负二项分布所包含。事实上，对于一个负二项分布，当 \\[r = 1\\] 时，其分布列退化为 \\[ P(X=k)=(1-p)^{k - 1}p \\] 此即为几何分布的分布列。由此可知 \\[Ge(p) = Nb(1,p)\\] 期望和方差 与二项分布类似，我们可将负二项分布拆分成一系列相互独立的事件以简化期望和方差的计算。注意到负二项分布与几何分布的关系，我们可将一个负二项分布中的实验拆分为 \\[r\\] 个独立成功的实验，而每次实验服从一个几何分布。 令 \\[X_i\\] 为第 \\[i\\] 次实验成功所用次数的随机变量 \\[(1 \\leq i \\leq r)\\]，\\[X\\] 为前 \\[r\\] 次实验成功所用次数的随机变量 此时 \\[1 \\leq \\forall i \\neq j \\leq r\\]，\\[X_i\\] 与 \\[X_j\\] 独立，且 \\[X_i \\sim Ge(p), X \\sim Nb(r, p), X = \\sum_\\limits{i = 1}^r X_i\\] 于是由几何分布的期望可知 \\[ \\begin{aligned} E(X) &amp;= E(\\sum_{i = 1}^r X_i) \\\\ &amp;=\\sum_{i = 1}^r E(X_i) \\\\ &amp;=\\sum_{i = 1}^r \\frac{1}{p} \\\\ &amp;=\\frac{r}{p} \\end{aligned} \\] 同理 \\[ \\begin{aligned} Var(X) &amp;= Var(\\sum_{i = 1}^r X_i) \\\\ &amp;=\\sum_{i = 1}^r Var(X_i) \\\\ &amp;=\\sum_{i = 1}^r \\frac{1-p}{p^2} \\\\ &amp;=\\frac{r(1-p)}{p^2} \\end{aligned} \\] 另解（纯分析法求负二项分布的期望和方差）： \\[ \\begin{aligned} E(X) &amp;= \\sum_{k = r}^{\\infty} k \\binom{k-1}{r-1} p^r (1-p)^{k-r} \\\\ &amp;= \\sum_{k = r}^{\\infty} \\frac{k!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} \\\\ &amp;=\\frac{r}{p} \\sum_{k = r}^{\\infty} \\frac{k!}{r!(k-r)!} p^{r+1}(1-p)^{k-r} \\\\ &amp;=\\frac{r}{p} \\sum_{k = r}^{\\infty} \\binom{k}{r} p^{r+1}(1-p)^{k-r} \\\\ &amp;=\\frac{r}{p} \\end{aligned} \\] 又 \\[ \\begin{aligned} E(X^2) &amp;= \\sum_{k = r}^{\\infty} k^2 \\binom{k-1}{r-1} p^r (1-p)^{k-r} \\\\ &amp;= \\sum_{k = r}^{\\infty} (k+1-1) \\cdot \\frac{k!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} \\\\ &amp;= \\sum_{k = r}^{\\infty} \\frac{(k+1)!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} - \\sum_{k = r}^{\\infty} \\frac{k!}{(r-1)!(k-r)!} p^r(1-p)^{k-r} \\\\ &amp;= \\frac{r(r+1)}{p^2} \\sum_{k = r}^{\\infty} \\frac{(k+1)!}{(r+1)!(k-r)!} p^{r+2} (1-p)^{k-r} - \\frac{r}{p} \\sum_{k = r}^{\\infty} \\frac{k!}{r!(k-r)!} p^{r+1}(1-p)^{k-r} \\\\ &amp;= \\frac{r(r+1)}{p^2} \\sum_{k = r}^{\\infty} \\binom{k+1}{r+1} p^{r+2} (1-p)^{k-r} - \\frac{r}{p} \\sum_{k = r}^{\\infty} \\binom{k}{r} p^{r+1}(1-p)^{k-r} \\\\ &amp;=\\frac{r^2+r}{p^2} - \\frac{r}{p} \\\\ \\end{aligned} \\] 故 \\[ \\begin{aligned} Var(X) &amp;= E(X^2) - E^2(X) \\\\ &amp;= \\frac{r^2+r}{p^2} - \\frac{r}{p} - \\frac{r^2}{p^2} \\\\ &amp;=\\frac{r(1-p)}{p^2} \\end{aligned} \\] 广义负二项分布与泊松分布 在负二项分布中，参数 \\[r\\] 的取值范围要求为正整数，而在某些情况下，我们需要将负二项分布中的 \\[r\\] 的取值范围拓展到一切正实数。为了做到这一点，我们需要借助Gamma函数对其中的组合式进行拓展。 由于有 \\[\\Gamma(n) = (n-1)!\\]，故 \\[ \\binom{k-1}{r-1} = \\frac{(k-1)!}{(r-1)!(k-r)!} = \\frac{(k-1)!}{\\Gamma(r)\\Gamma(k-r+1)} \\] 因此我们可以将广义负二项分布的分布列定义为： \\[ P(X=k)=\\frac{(k-1)!}{\\Gamma(r)\\Gamma(k-r+1)}p^r(1-p)^{k-r}, k \\in \\{1,2,...\\},r \\in \\mathbb{R} \\] 事实上，在实际使用中，一个更常用的负二项分布的分布列定义为 \\[ P(X=k) = \\binom{k+r-1}{r-1}p^r(1-p)^k, k \\in \\{0,1,2,...\\} \\] 这里的 \\[k\\] 代表第 \\[r\\] 次实验成功前实验失败的次数。 基于该定义进行拓展，我们就能得到广义负二项分布的标准定义：（该分布也被称为Polya分布） Definition: 若一个离散型随机变量 \\[X\\] 的分布列满足 \\[ P(X=k) = \\frac{\\Gamma(k+r)}{k!\\Gamma(r)}p^r (1-p)^k \\] 其中 \\[k \\in \\{0,1,2,...\\}, r \\in \\mathbb{R}, p \\in [0,1]\\]，则称随机变量 \\[X\\] 服从广义负二项分布 广义负二项分布与泊松分布有如下定理成立： Theorem: 设 \\[k \\in \\mathbb{N}, \\lambda &gt; 0, r \\in \\mathbb{R}\\]，则有 \\[ \\lim_{r \\to \\infty} \\frac{\\Gamma(k+r)}{k!\\Gamma(r)} \\left( \\frac{\\lambda}{r+\\lambda} \\right)^r \\left(\\frac{r}{r+\\lambda} \\right)^{k} = \\frac{\\lambda^k}{k!} e^{-\\lambda} \\] Proof: //待补全 由上述定理可知，当 \\[r\\] 很大时，广义负二项分布可以作为泊松分布的一个很好的近似。 \\[(a,b)\\] 分布类 事实上，二项分布、负二项分布、泊松分布的概率密度函数均满足以下的递推关系： \\[ p_n = p_{n-1} \\left(a + \\frac{b}{n} \\right), n \\geq 1 \\] 其中，\\[a,b \\in \\mathbb{R}\\] 为常数（该递推式被称为Panjer递推式） 我们称概率密度函数满足上述递推关系的离散分布为 \\[(a,b)\\] 分布，所有\\[(a,b)\\] 分布构成的集合被称为 \\[(a,b)\\] 分布类 。 \\[(a,b)\\] 分布类在精算领域的损失模型中有着十分重要的应用。 事实上，二项分布、负二项分布、泊松分布是 \\[(a,b)\\] 分布类中的所有分布，这是因为有如下定理： Theorem: 若一个 \\[(a,b)\\] 分布为非退化分布，则其必为二项分布、负二项分布、泊松分布中的一种 Proof: //待补全 超几何分布 定义 Definition: 若一个离散型随机变量 \\[X\\] 的分布列满足 \\[ P(X=k) = \\frac{\\binom{N_1}{k} \\binom{N-N_1}{n-k}}{\\binom{N}{n}} \\] 其中 \\[k \\leq n,N_1 \\leq N \\in \\{0,1,2,...\\}\\]，则称随机变量 \\[X\\] 满足超几何分布，记为 \\[X \\sim H(N, N_1, n)\\] 适用场景：在一个袋子中有两种共 \\[N\\] 个物品，其中物品 \\[A\\] 有 \\[N_1\\] 个，物品 \\[B\\] 有 \\[N-N_1\\] 个，现从袋子中抽出 \\[n\\] 个物品，求抽出的物品中 \\[A\\] 的个数 \\[k\\] 超几何分布的累积分布函数为 \\[ F(k) = P(X=k) = \\left\\{ \\begin{aligned} \\sum_{i = 0}^k \\frac{\\binom{N_1}{i} \\binom{N-N_1}{n-i}}{\\binom{N}{n}}&amp;,&amp; k \\geq 0 \\\\ 0&amp;,&amp; k &lt; 0 \\end{aligned} \\right. \\] 若引入广义超几何函数，则其非负部分还可表示为 \\[ F(k) = 1 - \\frac{\\binom{n}{k+1}\\binom{N-n}{N_1-k-1}}{\\binom{N}{N_1}} \\cdot _3F_2 \\left( \\begin{aligned} 1, k+1-N_1, k+1-n \\\\ k+2, N+k+2-N_1-n \\end{aligned}; 1 \\right), k \\geq 0 \\] 期望和方差 我们可以用与负二项分布类似的分析技巧导出超几何分布的期望和方差 \\[ \\begin{aligned} E(X) &amp;= \\sum_{k = 0}^{N_1} k \\cdot \\frac{\\binom{N_1}{k} \\binom{N-N_1}{n-k}}{\\binom{N}{n}} \\\\ &amp;= \\frac{n}{N} \\sum_{k = 1}^{N_1} \\frac{k \\binom{N_1}{k} \\binom{N-N_1}{n-k}}{\\binom{N-1}{n-1}} \\\\ &amp;= \\frac{n \\cdot N_1}{N} \\sum_{k = 1}^{N_1} \\frac{\\binom{N_1 - 1}{k - 1} \\binom{N-N_1}{n-k}}{\\binom{N-1}{n-1}} \\\\ &amp;=\\frac{n \\cdot N_1}{N} \\end{aligned} \\] 又 \\[ \\begin{aligned} E(X^2) &amp;= \\sum_{k = 0}^{N_1} k^2 \\cdot \\frac{\\binom{N_1}{k} \\binom{N-N_1}{n-k}}{\\binom{N}{n}} \\\\ &amp;= \\sum_{k = 1}^{N_1} k(k-1) \\cdot \\frac{\\binom{N_1}{k} \\binom{N-N_1}{n-k}}{\\binom{N}{n}} + \\sum_{k = 1}^{N_1} k \\cdot \\frac{\\binom{N_1}{k} \\binom{N-N_1}{n-k}}{\\binom{N}{n}} \\\\ &amp;= \\frac{n(n-1)N_1(N_1-1)}{N(N-1)} \\cdot \\sum_{k = 2}^{N_1} \\frac{\\binom{N_1-2}{k-2} \\binom{N-N_1}{n-k}}{\\binom{N-2}{n-2}} + \\frac{n \\cdot N_1}{N} \\\\ &amp;= \\frac{n(n-1)N_1(N_1-1)}{N(N-1)} + \\frac{n \\cdot N_1}{N} \\end{aligned} \\] 故 \\[ \\begin{aligned} Var(X) &amp;= E(X^2) - E^2(X) \\\\ &amp;= \\frac{n(n-1)N_1(N_1-1)}{N(N-1)} + \\frac{n \\cdot N_1}{N} - \\frac{n^2N_1^2}{N^2} \\\\ &amp;= \\frac{n(N-n)(N-N_1)}{N^2(N-1)} \\end{aligned} \\]","categories":[{"name":"概率论","slug":"概率论","permalink":"http://gonggongjohn.me/categories/%E6%A6%82%E7%8E%87%E8%AE%BA/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"Probability","slug":"Probability","permalink":"http://gonggongjohn.me/tags/Probability/"}]},{"title":"新闻搜索网站构建记录","slug":"web/search-site","date":"2021-04-18T10:26:25.000Z","updated":"2021-04-30T06:30:39.187Z","comments":true,"path":"2021/04/18/web/search-site/","link":"","permalink":"http://gonggongjohn.me/2021/04/18/web/search-site/","excerpt":"服务部署 请按照如下流程部署本项目： 在news_search目录下安装所需的依赖插件：（国内请使用淘宝源安装nodejieba） 12&gt; npm install request iconv-lite cheerio mysql jschardet moment&gt; npm install nodejieba --registry=https://registry.npm.taobao.org --nodejieba_binary_host_mirror=https://npm.taobao.org/mirrors/nodejieba","text":"服务部署 请按照如下流程部署本项目： 在news_search目录下安装所需的依赖插件：（国内请使用淘宝源安装nodejieba） 12&gt; npm install request iconv-lite cheerio mysql jschardet moment&gt; npm install nodejieba --registry=https://registry.npm.taobao.org --nodejieba_binary_host_mirror=https://npm.taobao.org/mirrors/nodejieba 启动本地MySQL服务，修改news_search/mysql.js中的相关信息为数据库登录信息： 123456var pool = mysql.createPool(&#123; host: &#x27;#数据库地址&#x27;, user: &#x27;#本地数据库连接用户名&#x27;, password: &#x27;#本地数据库连接密码&#x27;, database: &#x27;#目标数据库名&#x27;&#125;); 登陆数据库管理系统，在控制台中设置相关变量以防止后续连接池堵塞： 123&gt; set global wait_timeout&#x3D;10;&gt; set global max_connections&#x3D;5000;&gt; set session wait_timeout&#x3D;10; 在数据库管理系统中创建所需的表结构： 1234567891011121314151617&gt; CREATE TABLE &#96;news&#96; ( &#96;id&#96; INT NOT NULL AUTO_INCREMENT, &#96;origin&#96; TEXT NOT NULL, &#96;category&#96; TEXT NOT NULL, &#96;title&#96; TEXT NOT NULL, &#96;time&#96; TEXT, &#96;source&#96; TEXT, &#96;abstract&#96; TEXT, &#96;content&#96; TEXT, PRIMARY KEY (&#96;id&#96;));&gt; CREATE TABLE &#96;indices&#96; ( &#96;id&#96; INT NOT NULL AUTO_INCREMENT, &#96;word&#96; TEXT, &#96;docs&#96; TEXT, PRIMARY KEY (&#96;id&#96;)); 执行爬虫脚本爬取新闻内容： 12&gt; node crawler.js&gt; node create_indices.js P.S: 在测试环境下，若希望快速得到效果，可打开news_research/crawler.js文件，并将如下行 1var total_pages = 8; //Modify to a smaller number to speed up in demo environment 改为 1var total_pages = 1; //Modify to a smaller number to speed up in demo environment 保存后再执行上述代码。 在news_site目录下安装所需的依赖：（国内请使用淘宝源安装nodejieba） 12&gt; npm install express moment&gt; npm install nodejieba --registry=https://registry.npm.taobao.org --nodejieba_binary_host_mirror=https://npm.taobao.org/mirrors/nodejieba 启动网站后端服务： 1&gt; node bin/www 使用浏览器访问网站前端： 1http:&#x2F;&#x2F;localhost:3000 源内容抓取 新闻网站解析 网易新闻 网易新闻的主体分为国内和国际两个模块，其网站结构大体相同，因此我们集中针对这两个板块进行内容爬取。 分析新闻索引页面的HTML结构我们可以发现，新闻条目被放在了类名为newsdata_wrap的div标签下。然而由于网易新闻使用了动态加载新闻条目的方式，若我们使用GET请求直接获取页面的HTML时，该标签下的内容为空，因此我们无法直接通过解析网站的HTML数据获得具体的新闻信息。 继续分析访问网站时的文件传输流我们会发现网站的新闻条目是由一个叫cm_guonei.js（cm_guoji.js）的文件动态装载的，其原始路径为https://temp.163.com/special/00804KVA/cm_guonei.js。跟踪页面我们发现同级目录下还有cm_guonei_02.jscm_guonei_08.js（cm_guoji_02.jscm_guoji_08.js）共8个文件用于流式加载所有需要加载的新闻条目。打开文件发现其为一个类JSON结构，其中按条目存储了新闻页面的标题、网址、关键字、时间等基本信息。由此我们可以通过直接解析这些文件来获得所有需要爬取的新闻页面。 1234567891011121314151617181920212223242526[ &#123; &quot;title&quot;:&quot;“港独”周竖峰出逃加拿大，曾辱骂内地生为“支那人”&quot;, &quot;digest&quot;:&quot;&quot;, &quot;docurl&quot;:&quot;https://www.163.com/news/article/G8GJUT8700019B3E.html&quot;, &quot;commenturl&quot;:&quot;https://comment.tie.163.com/G8GJUT8700019B3E.html&quot;, &quot;tienum&quot;:5276, &quot;tlastid&quot;:&quot;&lt;a href=&#x27;http://news.163.com/&#x27;&gt;新闻&lt;/a&gt;&quot;, &quot;tlink&quot;:&quot;https://www.163.com/news/article/G8GJUT8700019B3E.html&quot;, &quot;label&quot;:&quot;其它&quot;, &quot;keywords&quot;:[ &#123;&quot;akey_link&quot;:&quot;https://news.163.com/keywords/5/6/54687ad65cf0/1.html&quot;,&quot;keyname&quot;:&quot;周竖峰&quot;&#125;, &#123;&quot;akey_link&quot;:&quot;https://news.163.com/keywords/6/2/6e2f72ec/1.html&quot;,&quot;keyname&quot;:&quot;港独&quot;&#125;, &#123;&quot;akey_link&quot;:&quot;https://news.163.com/keywords/5/a/52a062ff5927/1.html&quot;,&quot;keyname&quot;:&quot;加拿大&quot;&#125;], &quot;time&quot;:&quot;04/26/2021 10:19:15&quot;, &quot;newstype&quot;:&quot;article&quot;, &quot;pics3&quot;:[], &quot;channelname&quot;:&quot;guonei&quot;, &quot;source&quot;:&quot;观察者网&quot;, &quot;point&quot;:&quot;60&quot;, &quot;imgurl&quot;:&quot;http://cms-bucket.ws.126.net/2021/0426/bc6435dep00qs5fri00kkc000s600e3c.png&quot;, &quot;add1&quot;:&quot;&quot;, &quot;add2&quot;:&quot;&quot;, &quot;add3&quot;:&quot;&quot; &#125;] 接下来我们分析新闻内容页面。该页面的具体内容是静态加载的，因此我们可以直接对其HTML内容进行抽取。然而随着进一步的分析我们会发现新闻页面的编码并不统一，分为UTF-8和GBK两种。为了得到网站的编码方式，我们使用了一个名为jschardet的插件。该插件可以通过分析文本的二进制编码给出其最可能的编码方法。由于目标网站只有两种编码方式，因此我们可以保证使用该插件检测得到的结果是可靠的。 分析页面的HTML结构我们可以发现新闻内容被封装在了类名为post_main的div标签下，其中新闻标题类名为post_title，时间、来源的类名为post_info，正文的类名为post_body。我们首先使用iconv-lite插件对页面进行解码，随后利用Cheerio模块即可快速从网站的DOM结构中抽取出所需的内容。 123456789101112131415161718192021var coding = chardet.detect(body)[&#x27;encoding&#x27;]var $ = cheerio.load(iconv.decode(body, coding).toString());var title = $(&#x27;.post_title&#x27;).text();if(title != &#x27;&#x27;)&#123; var body_text = &quot;&quot;; if($(&quot;.content.all-txt&quot;).length &gt; 0)&#123; body_text = $(&#x27;.content.all-txt &gt; p&#x27;); &#125; else if($(&#x27;.newscontents&#x27;).length &gt; 0)&#123; body_text = $(&#x27;.newscontents &gt; p&#x27;); &#125; else&#123; body_text = $(&#x27;.post_body &gt; p&#x27;); &#125; var content = &quot;&quot;; body_text.each((index, item) =&gt; &#123; if($(item).text() != &quot;&quot;)&#123; content = content + $(item).text() + &#x27;\\n&#x27;; &#125; &#125;);&#125; 环球网 与网易新闻类似，环球网同样分为国内和国际两个模块，且采用了动态装载新闻条目的方式。通过追踪其文件传输流，我们发现其新闻源数据地址分别为https://china.huanqiu.com/api/list?offset=0&amp;limit=20和https://world.huanqiu.com/api/list?offset=0&amp;limit=20，其基本结构为： 1234567891011121314151617181920212223242526272829303132&#123; &quot;list&quot;:[ &#123; &quot;aid&quot;:&quot;42vOMMYVUm3&quot;, &quot;title&quot;:&quot;前国脚张恩华去世，享年48周岁&quot;, &quot;summary&quot;:&quot;张恩华的职业生涯大部分时间是在大连实德以及前身大连万达队度过的，是大连实德队主力后卫，也是大连夺得联赛“七冠王”和多次杯赛冠军的主要功臣之一&quot;, &quot;addltype&quot;:&quot;normal&quot;, &quot;typedata&quot;:&#123; &quot;audio&quot;:&#123; &quot;members&quot;:[] &#125;, &quot;video&quot;:&#123; &quot;members&quot;:[] &#125;, &quot;gallery&quot;:&#123; &quot;members&quot;:[] &#125; &#125;, &quot;source&quot;:&#123; &quot;url&quot;:null, &quot;name&quot;:&quot;环球时报&quot; &#125;, &quot;ext_displaytime&quot;:&quot;&quot;, &quot;ext_defertime&quot;:&quot;&quot;, &quot;ctime&quot;:&quot;1619721799662&quot;, &quot;xtime&quot;:&quot;1619721799662&quot;, &quot;cover&quot;:&quot;&quot;, &quot;host&quot;:&quot;china.huanqiu.com&quot;, &quot;ext-serious&quot;:&quot;1&quot; &#125; ]&#125; 环球网的新闻内容页根路径分别为https://china.huanqiu.com/article/和https://world.huanqiu.com/article/，因此我们只需使用该路径加上索引数据中的aid号，即可得到新闻页的完整网址。 分析其新闻内容页的HTML结构我们可以发现其正文的外层包裹分别有一个类名为l-con clear的div标签，一个article标签以及一个section标签，于是我们同样可以使用Cheerio插件快速将其内容从结构中抽取出来： 12345678910111213141516var coding = chardet.detect(body)[&#x27;encoding&#x27;]var $ = cheerio.load(iconv.decode(body, coding).toString());var title = $(&#x27;.t-container-title&#x27;).text();if(title != &#x27;&#x27;)&#123; var body_text = &quot;&quot; if($(&quot;.l-con.clear&quot;).length &gt; 0)&#123; body_text = $(&#x27;.l-con.clear &gt; article &gt; section &gt; p&#x27;); var content = &quot;&quot;; body_text.each((index, item) =&gt; &#123; if($(item).text() != &quot;&quot;)&#123; var para = $(item).text(); content = content + para + &#x27;\\n&#x27;; &#125; &#125;); &#125;&#125; 数据库构建 提取出网站的内容后，我们需要将其以一定结构存放在一个可外部访问的空间内。为此，我们首先创建一个名为netease_news的数据库： 1CREATE DATABASE netease_news; 并在其中构建一张名为news的表用于结构化存储新闻的各种信息。对于本项目，我们设计了8个表项，分别为：id（新闻的唯一标识符）、origin（新闻源网址）、category（分类：国内/国外）、title（标题）、time（创建时间）、source（来源）、abstract（内容摘要）、content（新闻内容）。我们将id设为主键，并设置其在每次插入时自增，这样在实际插入时我们只需插入其他7项即可，并能自动分配到一个唯一的id。 123456789101112CREATE TABLE &#96;news&#96; ( &#96;id&#96; INT NOT NULL AUTO_INCREMENT, &#96;origin&#96; TEXT NOT NULL, &#96;category&#96; TEXT NOT NULL, &#96;title&#96; TEXT NOT NULL, &#96;time&#96; TEXT, &#96;source&#96; TEXT, &#96;keyword&#96; TEXT, &#96;heat&#96; INT, &#96;content&#96; TEXT, PRIMARY KEY (&#96;id&#96;)); 基本爬虫逻辑 根据上面的分析，我们可以快速设计出爬虫的基本逻辑，其基本流程如下： 在实际实现中，我们首先封装了一套mysql的读写工具： 123456789101112131415161718192021222324252627282930313233var mysql = require(&quot;mysql&quot;);var pool = mysql.createPool(&#123; host: &#x27;127.0.0.1&#x27;, user: &#x27;root&#x27;, password: &#x27;root&#x27;, database: &#x27;netease_news&#x27;&#125;);var query = function(sql, sqlparam, callback) &#123; pool.getConnection(function(err, conn) &#123; if (err) &#123; callback(err, null, null); &#125; else &#123; conn.query(sql, sqlparam, function(qerr, vals, fields) &#123; conn.release(); callback(qerr, vals, fields); &#125;); &#125; &#125;);&#125;;var query_noparam = function(sql, callback) &#123; pool.getConnection(function(err, conn) &#123; if (err) &#123; callback(err, null, null); &#125; else &#123; conn.query(sql, function(qerr, vals, fields) &#123; conn.release(); callback(qerr, vals, fields); &#125;); &#125; &#125;);&#125;;exports.query = query;exports.query_noparam = query_noparam; 对于爬虫任务，我们将其封装为了六个函数，其中traverseNeteaseIndices用于遍历网易新闻的索引文件，phaseNeteaseLinkList用于解析网易新闻列表，phaseNeteaseNews用于解析网易新闻页的具体内容，另外三个函数traverseHQWIndices、phaseHQWLinkList和phaseHQWNews用于获取环球网新闻数据时的对应行为（具体实现见crawler.js）。 这里需要注意的是，由于request请求和mysql操作均为异步操作，程序执行的顺序无法确定，在同一时刻内，mysql服务器中可能同时有上千个连接，且当连接释放后，连接池不会立即关闭相应连接，这样就会造成连接池堵塞。为解决这一问题，我们首先在数据库控制台中缩小闲置连接回收间隔，并增大连接限制数： 123&gt; set global wait_timeout&#x3D;10;&gt; set global max_connections&#x3D;5000;&gt; set session wait_timeout&#x3D;10; 随后我们通过在爬虫逻辑中使用setTimeout函数延迟发送数据库请求，将数据库操作任务平摊到多个时间戳上，这样就有效避免了连接池堵死的情况发生 12345678910111213for(var i = 1; i &lt;= pages; i++)&#123; //Irrelevant code omitted setTimeout(function()&#123; phaseNeteaseLinkList(url, category, i, pages); &#125;, 3000 * (i - 1));&#125;for(var i = 0; i &lt;= pages; i++)&#123; //Irrelevant code omitted setTimeout(() =&gt; &#123; phaseHQWLinkList(url, pred, category, i, pages, last_flag); &#125;, 5000 * i);&#125; 布隆过滤器与去重 当我们需要多次执行爬虫任务时，就可能会遇到重复爬取同一网站的情况。为此，我们需要一套快速判断是否已经爬取过一个网址的方法。通常情况下，我们可以使用以下两种办法做到这一点： 每次爬取一个页面前，在数据库中使用SELECT命令查询该网址是否已经存在 对新闻网址建立哈希表，每次爬取前查询该表以判断网址是否已经存在 若使用第一种方法，根据不同数据库的存储及查询方法，其单次查询的时间复杂度在 \\[\\mathcal{O}(\\lg n)\\] 和 \\[\\mathcal{O(n)}\\] 之间，\\[k\\] 次查询的时间复杂度最坏可能退化到 \\[O(kn)\\]；若使用第二种方法，尽管其单次查询的时间复杂度可以保证为 \\[\\mathcal{O}(1)\\]，但对于一个含有 \\[n\\] 个网址的数据库，其空间复杂度为 \\[O(n)\\]。由此可见，随着爬虫规模的扩大，两种去重方法均有着一定的弊端，不利于任务的扩展。 为解决此问题，我们引入一种名为布隆过滤器（Bloom Filter）的数据结构（见filter.js）。布隆过滤器的核心思想为通过一串哈希函数将关键字映射到一个比特位串。查询时，先将目标关键字通过同样的哈希函数找到对应的索引位，若索引位存在映射，则表明目标关键字可能存在；若所有索引位均不存在映射，则表明目标关键字一定不存在。 布隆过滤器是一种概率型数据结构，其误判率约为 \\[\\left(1 - e^{-\\frac{kn}{m}}\\right)^k\\]。在实际使用场景下，只要当我们选择合适的 \\[k\\] 和 \\[m\\] 值，就可以让误判率几乎不影响业务逻辑。这可以由如下公式给出： \\[ k = \\frac{m}{n} \\ln 2 , m = - \\frac{n \\ln p}{\\ln^2 2} \\] 其中 \\[k\\] 为哈希函数的个数，\\[m\\] 为位串长度，\\[p\\] 为预期的误报率。 布隆过滤器增加和查询时间复杂度均为 \\[\\mathcal{O}(k)\\]（ \\[k\\] 为哈希函数的个数），空间复杂度为 \\[\\mathcal{O}(m)\\]（\\[m\\] 为比特位长度），相比前两种方法可以很好的平衡存储空间和查询效率。 分词与倒排索引 当用户发起搜索请求时，我们需要从数据库中快速找出所有内容含有用户所请求关键字的新闻条目。若使用全文搜索的方法，随着数据规模增大，会造成极大的延迟。为解决此问题，我们在爬取文章的时候，对文章内容进行分词，并使用词关键字对文章建立倒排索引，在搜索时，只需要将关键字使用同样的方法进行分词，并在倒排索引表中查询对应的文档编号即可。 为此，我们首先在数据库中再建立一张索引表： 123456CREATE TABLE &#96;indices&#96; ( &#96;id&#96; INT NOT NULL AUTO_INCREMENT, &#96;word&#96; TEXT, &#96;docs&#96; TEXT, PRIMARY KEY (&#96;id&#96;)); 随后我们读取news表中的新闻内容，并使用nodejieba插件对其进行分词。由于文章中还有部分特殊符号及无意义词，我们通过一个停用词表来将其去除。为保证词关键字的唯一性，我们维护一个集合，将每个文档分词后的结果依次插入该集合，并将结果插入数据库中：（见create_indices.js） 1234567891011121314var word_set = new Set();var para = item.content;//Cut wordvar para_filtered = para.replace(&quot; &quot;, &quot;&quot;).replace(&quot;\\n&quot;, &quot;&quot;).replace(&quot; &quot;, &quot;&quot;);para_filtered = para_filtered.replace(&quot;，&quot;, &quot;&quot;).replace(&quot;。&quot;, &quot;&quot;).replace(&quot;,&quot;, &quot;&quot;);var word_list = jieba.cut(para_filtered);for(var i = 0; i &lt; word_list.length; i++)&#123; word_set.add(word_list[i]);&#125;word_set.forEach((word) =&gt; &#123; if(!stop_list.includes(word))&#123; //Insert the result to the database &#125;&#125; 网站构建 基本构架 接下来我们来构建新闻搜索网站。新闻搜索网站的主要行为是提供一个可供用户输入的界面，当用户输入关键字后，系统从数据库中检索出带有用户所指定关键字的新闻条目，并将结果以一定的顺序生成相应的内容页面返回给用户。我们使用Express脚手架来构建网站的后端。对于网站路由，我们共设计了4个入口，其中根目录为浏览器访问入口，用于呈现相应的HTML页面，其他三个入口/query、/qcontent和/qheat分别用于前端请求关键字结果、完整正文内容及关键字热度分析结果。 对于网站前端，我们使用了Bootstrap框架来生成所需的样式。搜索引擎页面设计的一个核心宗旨即为简洁，因此在搜索界面，我们参考了百度和Google的设计样式，通过卡片的方式将目标条目呈现给用户。在一张卡片中，我们呈现了新闻条目的标题、事件、来源、摘要及类别，以方便用户初步预览新闻的大致内容。 由于卡片的内容是由后端返回的结果动态决定的，因此我们不能直接将其写死在HTML中，而需要通过Javascript脚本动态生成并将其添加至HTML的DOM结构中：（见public/index.html） 1234567891011121314151617181920212223242526272829303132333435function appendCard(father, title, id, time, source, abstract, cat)&#123; var card = document.createElement(&#x27;div&#x27;); card.class = &#x27;card&#x27;; var card_body = document.createElement(&#x27;div&#x27;); card_body.class = &#x27;card-body&#x27;; var card_link = document.createElement(&#x27;a&#x27;); card_link.class = &#x27;card-link&#x27;; //Irrelevant code omitted card_link.innerText = title; card_link.style.fontSize = &quot;large&quot;; card_body.appendChild(card_link); var card_info = document.createElement(&quot;p&quot;); if(source != null)&#123; card_info.innerText = time + &quot; &quot; + source; &#125; else&#123; card_info.innerText = time; &#125; card_body.appendChild(card_info); var card_abstract = document.createElement(&quot;p&quot;); card_abstract.innerText = abstract; card_abstract.style.fontSize = &quot;small&quot;; card_body.appendChild(card_abstract); var card_cat = document.createElement(&quot;p&quot;); if(cat == &quot;domestic&quot;)&#123; card_cat.innerText = &quot;类别：国内&quot;; &#125; else if(cat == &quot;world&quot;)&#123; card_cat.innerText = &quot;类别：国外&quot;; &#125; card_body.appendChild(card_cat); card.appendChild(card_body); var page_elem = document.getElementById(&#x27;page-list&#x27;); page_elem.appendChild(card);&#125; 当用户点击一个条目后，将跳转到一个新的页面，页面将向后端请求该新闻条目的完整内容。我们可以通过URL含参跳转的方法来实现这一跳转请求操作： 123456//index.htmlfunction appendCard(father, title, id, time, source, abstract, cat)&#123; //Irrelevant code omitted card_link.href = &#x27;/content.html?id=&#x27; + id; //Irrelevant code omitted&#125; 1234567891011//content.htmlfunction GetUrlParam(name)&#123; var reg = new RegExp(&quot;(^|&amp;)&quot;+ name +&quot;=([^&amp;]*)(&amp;|$)&quot;); var r = window.location.search.substr(1).match(reg); if(r!=null)return r[2]; return null;&#125;var id = GetUrlParam(&quot;id&quot;);$.get(&quot;/qcontent?id=&quot; + id, function(data)&#123; //Irrelevant code omitted&#125;); 对于内容的呈现，我们同样使用了动态方法将正文添加至页面上：（见public/content.html） 123456789101112var title = document.createElement(&#x27;h1&#x27;);title.align = &quot;center&quot;;title.innerText = data.title;var info = document.createElement(&#x27;h5&#x27;);info.style.color = &quot;#808080&quot;;info.innerText = data.time + &quot; 来源：&quot; + data.source;var para = document.createElement(&#x27;p&#x27;); para.innerText = data.content;var page_elem = document.getElementById(&#x27;news-content&#x27;);page_elem.appendChild(title);page_elem.appendChild(info);page_elem.appendChild(para); 搜索提示 在现代搜索引擎中，我们希望系统能够即时根据当前的输入智能推测用户想要搜索的完整内容。为实现这一功能，我们需要监听输入框的内容变化事件，并在每次这一事件发生时向后端发送搜索请求：（见public/index.html） 12345678910111213141516171819function search(callback, mode)&#123; let keywords = $(&quot;:input[name=&#x27;keywords&#x27;]&quot;).val(); $.get(&quot;/query?keywords=&quot; + keywords + &quot;&amp;mode=&quot; + mode, callback);&#125;function middleSearch()&#123; //Irrelevant code omitted search(function(data)&#123; var recList = []; for(var i = 0; i &lt; Math.min(10, data.length); i++)&#123; recList.push(data[i].title); &#125; //Irrelevant code omitted &#125;, &quot;middle&quot;);&#125;$(&quot;:input[name=&#x27;keywords&#x27;]&quot;).on(&#x27;input&#x27;, function()&#123; middleSearch();&#125;); 由于搜索提示要求即时响应，因此我们通过向后端传入一个mode参数来决定搜索的响应精度和速度。对于提示用搜索请求（mode=middle），后端将只扫描数据库新闻标题（title）列中含有目标关键字的条目，并只返回前10条结果。（事实上，若使用预训练的关键词关联库，我们可以引入更为智能的搜索提示，不过由于本项目为新闻搜索网站，这一功能并不实用） 对于前端，我们使用了JQuery-UI框架实现了补全列表的界面。通过JQuery语句在搜索框后附加autocomplete属性，即可使得列表中的内容随着用户的输入自动改变：（见public/index.html） 1234567891011$(&quot;:input[name=&#x27;keywords&#x27;]&quot;).autocomplete(&#123; source: function(query, response)&#123; search(function(data)&#123; var recList = []; for(var i = 0; i &lt; Math.min(10, data.length); i++)&#123; recList.push(data[i].title); &#125; return response(recList); &#125;, &quot;middle&quot;); &#125;&#125;); 关键词热度分析 最后，我们来实现对用户的搜索关键词进行时间热度分析的逻辑。由于在爬虫过程中我们抓取了文章的创建时间，并对正文内容进行了倒排索引，我们可以快速实现这一功能。 与显示新闻正文时的逻辑类似，当用户选择热度分析后，页面将含参跳转到一个新的页面，并向后端的/qheat入口请求热度分析结果。后端首先从news和indices表中分别找出包含目标关键词的新闻条目，并抽取出它们的时间信息。随后，我们按月份对其进行统计，并将其按时间排序，最终将结果封装为JSON字符串传回给前端：（见routes/index.js） 12345678910111213141516//Irrelevant code omittedvar seq = &#123;&#125;;result.forEach((item) =&gt; &#123; if(seq.hasOwnProperty(item.time.slice(0, 7)))&#123; seq[item.time.slice(0, 7)] += 1; &#125; else&#123; seq[item.time.slice(0, 7)] = 1; &#125;&#125;);var sortedKeys = Object.keys(seq).sort();var seq_sort = &#123;&#125;;sortedKeys.forEach((item) =&gt; &#123; seq_sort[item] = seq[item];&#125;);//Irrelevant code omitted 对于分析类功能，图表是一个较为直观的呈现形式。在这里我们使用了HighCharts图表框架来根据后端返回的数据快速生成这一样式： 12345678910111213Highcharts.chart(&#x27;chart&#x27;, &#123; title: &#123; text: &quot;关键词时间热度分布&quot; &#125;, xAxis: &#123; categories: Object.keys(data) &#125;, series: [&#123; data: value_list, type: &quot;line&quot;, name: &quot;关键词：&quot; + sdecodeURI(keyword) &#125;]&#125;); 最终的显示效果如下：","categories":[],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Web","slug":"Web","permalink":"http://gonggongjohn.me/tags/Web/"},{"name":"Frontend","slug":"Frontend","permalink":"http://gonggongjohn.me/tags/Frontend/"}]},{"title":"数据科学与工程数学基础 作业3","slug":"dase-math/dase-math-assignment-3","date":"2021-04-12T02:00:00.000Z","updated":"2022-02-10T08:37:20.703Z","comments":true,"path":"2021/04/12/dase-math/dase-math-assignment-3/","link":"","permalink":"http://gonggongjohn.me/2021/04/12/dase-math/dase-math-assignment-3/","excerpt":"","text":"一 分别求下面向量的1-范数、2-范数和无穷范数 \\[ a_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}, a_2 = \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\end{pmatrix}, a_3 = \\begin{pmatrix} -2 \\\\ 1 \\\\ 1 \\end{pmatrix} \\] \\[ \\begin{aligned} ||a_1||_1 &amp;= |1| + |2| + |1| = 4 \\\\ ||a_1||_2 &amp;= \\sqrt{1^2+2^2+1^2} = \\sqrt{6} \\\\ ||a_1||_\\infty &amp;= \\max\\{|1|,|2|,|1|\\} = 2 \\\\ \\end{aligned} \\] \\[ \\begin{aligned} ||a_2||_1 &amp;= |-1| + |0| + |1| = 2 \\\\ ||a_2||_2 &amp;= \\sqrt{(-1)^2+0^2+1^2} = \\sqrt{2} \\\\ ||a_2||_\\infty &amp;= \\max\\{|-1|,|0|,|1|\\} = 1 \\\\ \\end{aligned} \\] \\[ \\begin{aligned} ||a_2||_1 &amp;= |-2| + |1| + |1| = 4 \\\\ ||a_2||_2 &amp;= \\sqrt{(-2)^2+1^2+1^2} = \\sqrt{6} \\\\ ||a_2||_\\infty &amp;= \\max\\{|-2|,|1|,|1|\\} = 2 \\\\ \\end{aligned} \\] 二 证明函数 \\(F: \\mathbb{R}^n \\to \\mathbb{R}, F(x) = \\sqrt{\\langle x, x \\rangle }\\) 是向量范数 非负性：易见任取 \\(\\textbf{x} \\in \\mathbb{R}^n\\) \\[ F(\\mathbf{x}) = \\sqrt{\\langle \\mathbf{x}, \\mathbf{x}\\rangle} = \\sqrt{\\sum_\\limits{i = 1}^n x_i^2} \\geq 0 \\] 且 \\(F(\\mathbf{x}) = 0 \\leftrightarrow \\forall i \\in \\{1,2,...,n\\}, x_i = 0\\)，即 \\(F(\\textbf{x}) = 0\\) 当且仅当 \\(\\textbf{x} = \\textbf{0}\\) 齐次性：任取 \\(\\textbf{x} \\in \\mathbb{R}^n, \\lambda \\in \\mathbb{R}\\) \\[ \\begin{aligned} F(\\lambda \\textbf{x}) &amp;= \\sqrt{\\langle \\lambda \\textbf{x}, \\lambda \\textbf{x}\\rangle} \\\\ &amp;=\\sqrt{(\\lambda \\textbf{x})^T\\lambda \\textbf{x}} \\\\ &amp;=\\sqrt{\\lambda^2 \\textbf{x}^T \\textbf{x}} \\\\ &amp;=|\\lambda| \\sqrt{\\textbf{x}^T \\textbf{x}} \\\\ &amp;=|\\lambda| F(\\textbf{x}) \\end{aligned} \\] 三角不等式：任取 \\(\\textbf{x}, \\textbf{y} \\in \\mathbb{R}^n\\) \\[ \\begin{aligned} F^2(\\textbf{x} + \\textbf{y}) &amp;= (\\textbf{x} + \\textbf{y})^T(\\textbf{x} + \\textbf{y}) \\\\ &amp;=(\\textbf{x}^T + \\textbf{y}^T)(\\textbf{x} + \\textbf{y}) \\\\ &amp;= \\textbf{x}^T \\textbf{x} + \\textbf{y}^T \\textbf{x} + \\textbf{x}^T \\textbf{y} + \\textbf{y}^T \\textbf{y} \\\\ \\end{aligned} \\] 由Cauchy-Schwarz不等式可知 \\(\\forall \\textbf{x}, \\textbf{y} \\in \\mathbb{R}^n, | \\langle \\textbf{x}, \\textbf{y} \\rangle | \\leq ||\\textbf{x}||_2 \\cdot \\||\\textbf{y}||_2\\) 故 \\[ \\begin{aligned} F^2(\\textbf{x} + \\textbf{y}) &amp;\\leq \\textbf{x}^T \\textbf{x} + |\\textbf{y}^T \\textbf{x}| + |\\textbf{x}^T \\textbf{y}| + \\textbf{y}^T \\textbf{y} \\\\ &amp;\\leq \\textbf{x}^T \\textbf{x} + 2 \\sqrt{\\textbf{x}^T \\textbf{x} \\textbf{y}^T \\textbf{y}} + \\textbf{y}^T \\textbf{y} \\\\ &amp;=\\left( \\sqrt{\\textbf{x}^T \\textbf{x}} + \\sqrt{\\textbf{y}^T \\textbf{y}} \\right)^2 \\\\ &amp;=\\left(F(\\textbf{x}) + F(\\textbf{y})\\right)^2 \\end{aligned} \\] 于是由非负性可知 \\[ F(\\textbf{x} + \\textbf{y}) \\leq F(\\textbf{x}) + F(\\textbf{y}) \\] 因此 \\(F(\\mathbf{x}) = \\sqrt{\\langle \\mathbf{x}, \\mathbf{x}\\rangle}\\) 是向量范数 三 对任给的 \\(x = (x_1, x_2, x_3)^T \\in \\mathbb{C}^3\\)，试问如下实值函数是否构成向量范数？ \\[ f_1(x) = |x_1|^4 + |x_2|^4 + |x_3|^4 \\\\ f_2(x) = |x_1| + 3 |x_2| + 2 |x_3| \\] (1) 任取 \\(\\textbf{x} = (x_1, x_2, x_3)^T \\in \\mathbb{C}^3, \\lambda \\in \\mathbb{R}\\) \\[ \\begin{aligned} f_1(\\lambda \\textbf{x}) &amp;=|\\lambda x_1|^4 + |\\lambda x_2|^4 + |\\lambda x_3|^4 \\\\ &amp;= |\\lambda|^4 |x_1|^4 + |\\lambda|^4 |x_2|^4 + |\\lambda|^4 |x_3|^4 \\\\ \\end{aligned} \\] 故 \\(f_1\\) 不满足齐次性，因此 \\(f_1\\) 不构成向量范数 (2) 任取 \\(\\textbf{x}, \\textbf{y} \\in \\mathbb{C}^3, \\lambda \\in \\mathbb{R}\\) 易见 \\[ f_2(\\textbf{x}) = |x_1| + 3 |x_2| + 2|x_3| \\geq 0 \\] 且 \\(f_2(\\textbf{x}) = 0 \\leftrightarrow x_1=x_2=x_3 = 0\\) \\[ \\begin{aligned} f_2(\\lambda \\textbf{x}) &amp;= |\\lambda x_1| + 3 |\\lambda x_2| + 2 |\\lambda x_3| \\\\ &amp;=|\\lambda| (|x_1| + 3 |x_2| + 2 |x_3|) \\\\ &amp;=|\\lambda| f_2 (\\textbf{x}) \\end{aligned} \\] \\[ \\begin{aligned} f_2(\\textbf{x} + \\textbf{y}) &amp;= |x_1+y_1| + 3 |x_2+y_2| + 2|x_3 + y_3| \\\\ &amp;\\leq |x_1| + |y_1| + 3|x_2| + 3|y_2| + 2|x_3| + 2|y_3| \\\\ &amp;=f_2(\\textbf{x}) + f_2(\\textbf{y}) \\end{aligned} \\] 因此 \\(f_2\\) 构成向量范数 四 证明如下定义的函数 \\(\\langle \\cdot, \\cdot \\rangle: \\mathbb{R}^2 \\times \\mathbb{R}^2 \\to \\mathbb{R}\\) 是内积： \\[ \\langle x, y \\rangle := x_1 y_1 - (x_1 y_2 + x_2 y_1) + 2 x_2 y_2 \\] \\(\\forall \\textbf{x}, \\textbf{y}, \\textbf{z} \\in \\mathbb{R}^2, \\lambda \\in \\mathbb{R}\\) 非负性： \\[ \\begin{aligned} \\langle \\textbf{x}, \\textbf{x} \\rangle &amp;= x_1^2+2x_2^2-2x_1x_2 \\\\ &amp;=(x_1-x_2)^2+x_2^2 \\geq 0 \\end{aligned} \\] \\(\\langle \\textbf{x}, \\textbf{x} \\rangle = 0 \\leftrightarrow x_1=x_2 = 0 \\leftrightarrow \\textbf{x} = 0\\) 对称性：\\(\\langle \\textbf{x}, \\textbf{y} \\rangle = x_1y_1 - x_2y_1 - x_1y_2 + 2x_2y_2 = y_1x_1-y_2x_1-y_1x_2+2y_2x_2= \\langle \\textbf{y}, \\textbf{x}\\rangle\\) 齐次性： \\[ \\begin{aligned} \\langle \\lambda\\textbf{x}, \\textbf{y} \\rangle &amp;=\\lambda x_1y_1 - (\\lambda x_1y_2 + \\lambda x_2y_1) + 2 \\lambda x_2y_2 \\\\ &amp;=\\lambda (x_1y_1 - x_1y_2 - x_2y_1 + 2x_2y_2) \\\\ &amp;=\\lambda \\langle \\textbf{x}, \\textbf{y} \\rangle \\end{aligned} \\] 线性性： \\[ \\begin{aligned} \\langle \\textbf{x} + \\textbf{y}, \\textbf{z} \\rangle &amp;= (x_1 + y_1) z_1 - [(x_1 + y_1)z_2 + (x_2 + y_2) z_1] + 2 (x_2 + y_2) z_2 \\\\ &amp;=x_1z_1 + y_1z_1 - x_1z_2 - y_1z_2 + x_2z_1 + y_2z_1 + 2x_2z_2 + 2y_2z_2 \\\\ &amp;= \\langle \\textbf{x}, \\textbf{z} \\rangle + \\langle \\textbf{y}, \\textbf{z} \\rangle \\end{aligned} \\] 因此 \\(\\langle \\textbf{x}, \\textbf{y} \\rangle = x_1y_1 - (x_1y_2 + x_2y_1) + 2x_2y_2\\) 是一个内积 五 分别求下面矩阵1-范数、2-范数和无穷范数 \\[ A_1 = \\begin{pmatrix} 1 &amp; 2 \\\\ 1 &amp; 0 \\end{pmatrix}, A_2 = \\begin{pmatrix} -1 &amp; 0 \\\\ 1 &amp; 2 \\end{pmatrix} \\] \\[ \\begin{aligned} ||A_1||_1 &amp;= \\max \\{|1| + |1|, |2| + |0|\\} = 2 \\\\ ||A_1||_2 &amp;= \\sqrt{\\max\\{3 + \\sqrt{5}, 3 - \\sqrt{5}\\}} = \\frac{1+\\sqrt{5}}{\\sqrt{2}} \\\\ ||A_1||_\\infty &amp;= \\max\\{|1| + |2|, |1| + |0| \\} = 3 \\\\ \\end{aligned} \\] \\[ \\begin{aligned} ||A_2||_1 &amp;= \\max \\{|-1| + |1|, |0| + |2|\\} = 2 \\\\ ||A_2||_2 &amp;= \\sqrt{\\max\\{3 + \\sqrt{5}, 3 - \\sqrt{5}\\}} = \\frac{1+\\sqrt{5}}{\\sqrt{2}} \\\\ ||A_2||_\\infty &amp;= \\max\\{|-1| + |0|, |1| + |2| \\} = 3 \\end{aligned} \\] 六 求矩阵 \\(\\begin{pmatrix} 1 &amp; -1 &amp; 0 \\\\ 2 &amp; 4 &amp; 1 \\\\ 4 &amp; 2 &amp; 1 \\end{pmatrix}\\) 的行空间、列空间、零空间和左零空间。 设 \\(A = \\begin{pmatrix} 1 &amp; -1 &amp; 0 \\\\ 2 &amp; 4 &amp; 1 \\\\ 4 &amp; 2 &amp; 1\\end{pmatrix}\\) 设 \\(\\alpha_1 = (1, 2, 4)^T, \\alpha_2 = (-1, 4, 2)^T, \\alpha_3 = (0, 1, 1)^T\\) 故 \\[ \\textbf{Col}(A) = \\textbf{span} \\{\\alpha_1, \\alpha_2, \\alpha_3\\} = \\{ k_1 \\alpha_1 + k_2 \\alpha_2 + k_3 \\alpha_3 : k_1, k_2, k_3 \\in \\mathbb{R} \\} \\] 设 \\(r_1 = (1, -1, 0)^T, r_2 = (2, 4, 1)^T, r_3 = (4, 2, 1)^T\\) 故 \\[ \\textbf{Row}(A) = \\textbf{span} \\{r_1, r_2, r_3 \\} = \\{k_1 r_1 + k_2 r_2 + k_3 r_3: k_1, k_2, k_3 \\in \\mathbb{R} \\} \\] 对 \\(A\\) 作行初等变换 \\[ A \\xrightarrow[r_3-4_1]{r_2-2r_1} \\begin{pmatrix} 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 6 &amp; 1 \\\\ 0 &amp; 6 &amp; 1 \\end{pmatrix} \\xrightarrow{r_3-r_2} \\begin{pmatrix} 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 6 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow{\\frac{1}{6}r_2} \\begin{pmatrix} 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 1 &amp; \\frac{1}{6} \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow{r_1+r_2} \\begin{pmatrix} 1 &amp; 0 &amp; \\frac{1}{6} \\\\ 0 &amp; 1 &amp; \\frac{1}{6} \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\] 故令 \\(\\alpha = (-1, -1, 6)^T\\)，则 \\[ \\textbf{Null}(A) = \\textbf{span}(\\alpha) = \\{k\\alpha: k \\in \\mathbb{R} \\} \\] 对 \\(A^T\\) 作行初等变换 \\[ \\begin{aligned} A^T \\xrightarrow{r_2+r_1} \\begin{pmatrix} 1 &amp; 2 &amp; 4 \\\\ 0 &amp; 6 &amp; 6 \\\\ 0 &amp; 1 &amp; 1 \\end{pmatrix} \\xrightarrow{\\frac{1}{6}r_2} \\begin{pmatrix} 1 &amp; 2 &amp; 4 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 1 \\end{pmatrix} \\xrightarrow{r_3-r_2} \\begin{pmatrix} 1 &amp; 2 &amp; 4 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow{r_1-2r_2} \\begin{pmatrix} 1 &amp; 0 &amp; 2 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\end{aligned} \\] 故令 \\(\\beta = (-2, -1, 1)^T\\)，则 \\[ \\textbf{Null}(A^T) = \\textbf{span}(\\beta) = \\{k \\beta: k \\in \\mathbb{R} \\} \\] 七 求由向量 \\(\\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\\\ 2 \\end{pmatrix}\\) 张成的子空间的正交补空间。 由 \\[ \\begin{pmatrix} 1 &amp; 2 &amp; 0 \\\\ 0 &amp; 1 &amp; 2 \\end{pmatrix} \\xrightarrow{r_1-2r_2} \\begin{pmatrix} 1 &amp; 0 &amp; -4 \\\\ 0 &amp; 1 &amp; 2 \\end{pmatrix} \\] 可知 \\[ \\textbf{span}^{\\bot} \\left\\{ \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\\\ 2 \\end{pmatrix} \\right\\} = \\textbf{span} \\left\\{ \\begin{pmatrix} 4 \\\\ -2 \\\\ 1 \\end{pmatrix} \\right\\} \\] 八 写出一个与子空间 \\(\\textrm{span} \\left\\{(1,2,1)^T \\right\\}\\) 正交的子空间。 由于 \\[ (-1,0,1) \\cdot (1,2,1)^T = 0 \\] 故 \\[ \\textbf{span} \\left\\{ (-1,0,1)^T \\right\\} \\bot \\ \\textbf{span} \\left\\{ (1,2,1)^T \\right\\} \\] 九 求向量 \\((1,1,1)^T\\) 投影到一维子空间 \\(\\textrm{span} \\left\\{(1,-1,1)^T \\right\\}\\) 的正交投影。 设 \\(\\alpha = (1,-1,1)^T, x = (1,1,1)^T\\) 则 \\(\\textbf{span}\\left\\{(1,-1,1)^T\\right\\}\\) 的投影矩阵为 \\[ P_\\pi = \\frac{\\alpha \\alpha^T}{\\alpha^T \\alpha} = \\frac{1}{3} \\begin{pmatrix} 1 &amp; -1 &amp; 1 \\\\ -1 &amp; 1 &amp; -1 \\\\ 1 &amp; -1 &amp; 1 \\end{pmatrix} \\] 于是 \\(x\\) 在 \\(\\textbf{span}\\left\\{(1,-1,1)^T\\right\\}\\) 中的正交投影为 \\[ \\pi(x) = P_\\pi \\cdot x = \\left( \\frac{1}{3},-\\frac{1}{3},\\frac{1}{3} \\right)^T \\] 十 求向量 \\((1,1,1)^T\\) 投影到仿射空间 \\(\\textrm{span} \\left\\{(1,-1,1)^T , (1,1,0)^T \\right\\} + (1,2,1)^T\\) 的正交投影。 设 \\(\\alpha_1 = (1, -1, 1)^T, \\alpha_2 = (1,1,0)^T, \\beta = (1,2,1)^T, x = (1,1,1)^T, x_0 = x - \\beta = (0,-1,0)^T\\) 于是令 \\(B = (\\alpha_1, \\alpha_2) = \\begin{pmatrix} 1 &amp; 1 \\\\ -1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix}\\) 因此 \\[ B^TB = \\begin{pmatrix} 3 &amp; 0 \\\\ 0 &amp; 2 \\end{pmatrix}, B^Tx_0 = (1,-1)^T \\] 故由 \\(B^TB\\lambda = B^Tx_0\\) 可知，\\(\\lambda = (\\frac{1}{3}, -\\frac{1}{2})^T\\) 故 \\[ \\pi(x_0) = B \\lambda = (-\\frac{1}{6}, -\\frac{5}{6}, \\frac{1}{3})^T \\] 于是 \\[ \\pi(x) = \\pi(x_0) + \\beta = (\\frac{5}{6}, \\frac{7}{6}, \\frac{4}{3})^T \\] 十一 设 \\[ a_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ -1 \\end{pmatrix}, a_2 = \\begin{pmatrix} -1 \\\\ 3 \\\\ 1 \\end{pmatrix}, a_3 = \\begin{pmatrix} 4 \\\\ -1 \\\\ 0 \\end{pmatrix} \\] ，试将向量组 \\((a_1, a_2, a_3)\\) 标准正交化。 令 \\[ \\begin{aligned} b_1 &amp;= a_1 = (1,2,-1)^T \\\\ b_2 &amp;= a_2 - \\frac{\\langle b_1, a_2 \\rangle}{\\langle b_1,b_1 \\rangle} b_1 = \\frac{5}{3}(-1,1,1)^T \\\\ b_3 &amp;= a_3 - \\frac{\\langle b_1, a_3 \\rangle}{\\langle b_1,b_1 \\rangle} b_1 - \\frac{\\langle b_2, a_3 \\rangle}{\\langle b_2,b_2 \\rangle} b_2 = 2(1, 0, 1)^T \\end{aligned} \\] 故 \\[ \\begin{aligned} e_1 &amp;= \\textbf{e}_{b_1} = \\frac{1}{\\sqrt{6}} (1,2,-1)^T \\\\ e_2 &amp;= \\textbf{e}_{b_2} = \\frac{1}{\\sqrt{3}}(-1,1,1)^T \\\\ e_3 &amp;= \\textbf{e}_{b_3} = \\frac{1}{\\sqrt{2}}(1,0,1)^T \\end{aligned} \\] 因此 \\((a_1, a_2, a_3)\\) 标准正交化后的向量组为 \\((e_1, e_2, e_3)\\) 十二 复现Lec6例13的结果。其中负例为 \\((1.5,2), (1.7, 1.5), (2,2), (1.5,2.5)\\)，正例为 \\((1,2),(0.3,0.3), (2,1), (1,1)\\)，分别采用了欧式距离和曼哈顿距离两种距离度量方式。 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import numpy as npimport mathimport matplotlib.pyplot as plt# 数据集p=[[1,0.3,2,1], [2,0.3,1,1]]n=[[1.5,1.7,2,1.5], [2,1.5,2,2.5]]p=np.array(p)n=np.array(n)def divide(dist,k,X,Y): # dist为一距离函数，k为KNN的参数，(X,Y)为数据的坐标 ans_p=[np.sort(dist(p[0]-X[i],p[1]-Y[i]))for i in range(len(X))] ans_n=[np.sort(dist(n[0]-X[i],n[1]-Y[i]))for i in range(len(X))] t=[ans_p[i][int((k-1)/2)]&gt;ans_n[i][int((k-1)/2)]for i in range(len(ans_p))] return np.array(t) # 返回分类结果def dist1(x,y): # Euclid distance result = [] for i in range(len(x)): result.append(math.sqrt(x[i] * x[i] + y[i] * y[i])) return np.array(result)def dist2(x,y): # Manhattan distance return np.abs(x) + np.abs(y)def example_dist(x,y): # Minkovski distance return np.max([np.abs(x),np.abs(y)],axis=0)def plot(dist,k,ax): # 画图 N=200 # 在平面上生成 N x N个点 X=np.linspace(-0,3,N) # 生成横坐标 Y=X # 生成纵坐标 X,Y=np.meshgrid(X,Y) # 生成 N x N个点 X=X.reshape(1,N*N)[0] # 将横坐标化为向量形式 Y=Y.reshape(1,N*N)[0] # 将纵坐标化为向量形式 predict=divide(dist, k, X, Y) ax.contourf(X.reshape(N,N), Y.reshape(N,N), predict.reshape(N,N), cmap=plt.cm.Spectral,alpha=0.3) # 此函数将根据预测值和对应坐标生成图像 ax.plot(p[0],p[1],&#x27;rx&#x27;) ax.plot(n[0],n[1],&#x27;bo&#x27;) plt.text(0.5,2.5,&quot;k=&quot;+str(k)) plt.show()fig, ax = plt.subplots()plot(dist2, 3, ax) 输出结果：（欧几里得距离） 输出结果：（曼哈顿距离）","categories":[{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"}]},{"title":"数据科学与工程数学基础 作业2","slug":"dase-math/dase-math-assignment-2","date":"2021-03-16T02:00:00.000Z","updated":"2022-02-09T15:43:05.269Z","comments":true,"path":"2021/03/16/dase-math/dase-math-assignment-2/","link":"","permalink":"http://gonggongjohn.me/2021/03/16/dase-math/dase-math-assignment-2/","excerpt":"","text":"一 设 \\(A, B\\) 为两可逆矩阵，令 \\(X=\\begin{pmatrix} O &amp; A \\\\ B &amp; O \\end{pmatrix}\\) 求 \\(X^{-1}\\)。 由 \\(A,B\\) 为两可逆矩阵可知 \\(A, B\\) 均为方阵 设 \\(A \\in M^{m \\times m}, B \\in M_{n \\times n}\\) 故由 \\[ \\begin{pmatrix} O &amp; A \\\\ B &amp; O \\end{pmatrix} \\begin{pmatrix} O &amp; B^{-1} \\\\ A^{-1} &amp; O \\end{pmatrix} = I_{(m+n) \\times (m+n)} \\] 可知 \\[ X^{-1} = \\begin{pmatrix} O &amp; B^{-1} \\\\ A^{-1} &amp; O \\end{pmatrix} \\] 二 求解线性方程组 \\[ \\begin{pmatrix} 1 &amp; 2 &amp; 3 \\\\ 2 &amp; -2 &amp; 1 \\\\ 3 &amp; -1 &amp; -1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 1 \\\\ 1 \\end{pmatrix} \\] 对原方程组的增广矩阵做行初等变换 \\[ \\begin{aligned} &amp;\\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 6 \\\\ 2 &amp; -2 &amp; 1 &amp; 1 \\\\ 3 &amp; -1 &amp; -1 &amp; 1 \\end{pmatrix} \\xrightarrow[r_3-3r_1]{r_2-2r_1} \\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 6 \\\\ 0 &amp; -6 &amp; -5 &amp; -11 \\\\ 0 &amp; -7 &amp; -10 &amp; -17 \\end{pmatrix} \\xrightarrow{r_3-2r_2} \\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 6 \\\\ 0 &amp; -6 &amp; -5 &amp; -11 \\\\ 0 &amp; 5 &amp; 0 &amp; 5 \\end{pmatrix} \\xrightarrow{\\frac{1}{5}r_3} \\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 6 \\\\ 0 &amp; -6 &amp; -5 &amp; -11 \\\\ 0 &amp; 1 &amp; 0 &amp; 1 \\end{pmatrix} \\\\ \\xrightarrow{r_2 \\leftrightarrow r_3} &amp;\\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 6 \\\\ 0 &amp; 1 &amp; 0 &amp; 1 \\\\ 0 &amp; -6 &amp; -5 &amp; -11 \\end{pmatrix} \\xrightarrow[r_3+6r_2]{r_1-2r_2} \\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 6 \\\\ 0 &amp; 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; -5 &amp; -5 \\end{pmatrix} \\xrightarrow{-\\frac{1}{5}r_3} \\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 6 \\\\ 0 &amp; 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\end{pmatrix} \\xrightarrow{r_1-3r_3} \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\end{pmatrix} \\end{aligned} \\] 故原方程组的解为 \\(\\begin{pmatrix}x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\\) 三 证明：\\(\\mathbb{R}^{m \\times m}\\) 中的对称矩阵按照矩阵的加法与数乘在数域 \\(\\mathbb{R}\\) 上构成一个线性空间。(如果矩阵 \\(A\\) 是对称矩阵，则有 \\(A^T = A\\)。) 记 \\(R^{m \\times m}\\) 上对称矩阵的全体为 \\(S^{m \\times m}\\) 由 \\((R^{m \\times m}, +, \\cdot)\\) 为一个 \\(\\mathbb{R}\\) 上的线性空间可知 任取 \\(M, N, P \\in R^{m \\times m}, k_1, k_2 \\in \\mathbb{R}\\)，有 \\(M + N = N + M\\) \\((M + N) + P = M + (N + P)\\) 存在 \\(\\textbf{0} \\in R^{m \\times m}\\) 使得 \\(M + \\textbf{0} = M\\) 对于任一个 \\(M\\)，存在 \\(Q \\in R^{m \\times m}\\) 使得 \\(M + Q = \\textbf{0}\\) 存在 \\(1 \\in \\mathbb{R}\\)，使得 \\(1 \\cdot M = M\\) \\((k_1 \\cdot k_2) \\cdot M = k_1 \\cdot (k_2 \\cdot M)\\) \\((k_1 + k_2) \\cdot M = k_1 \\cdot M + k_2 \\cdot M\\) \\(k_1 \\cdot (M + N) = k_1 \\cdot M + k_1 \\cdot N\\) 由于 \\(S^{m \\times m} \\subset R^{m \\times m}\\)，故 \\(S^{m \\times m}\\) 对于矩阵加法及 \\(\\mathbb{R}\\) 上的数乘运算同样满足以上性质 又 \\(\\textbf{0} \\in S^{m \\times m}\\)，且任取 \\(A = (a_{ij})_{m \\times m} \\in S^{m \\times m}\\)，显然 \\(-A = (-a_{ij})_{m \\times m}\\in S^{m \\times m}\\) 因此我们仅需证明 \\(S^{m \\times m}\\) 对矩阵加法和数乘封闭即可 任取 \\(A, B \\in S^{m \\times m}, k \\in \\mathbb{R}\\)，其中 \\[ A = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} \\\\ a_{12} &amp; a_{22} &amp; \\cdots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{1n} &amp; a_{2n} &amp; \\cdots &amp; a_{nn} \\end{pmatrix}, B = \\begin{pmatrix} b_{11} &amp; b_{12} &amp; \\cdots &amp; b_{1n} \\\\ b_{12} &amp; b_{22} &amp; \\cdots &amp; b_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ b_{1n} &amp; b_{2n} &amp; \\cdots &amp; b_{nn} \\end{pmatrix} \\] 则 \\[ A+B = \\begin{pmatrix} a_{11} + b_{11} &amp; a_{12} + b_{12} &amp; \\cdots &amp; a_{1n} + b_{1n} \\\\ a_{12} + b_{12} &amp; b_{22} + b_{22} &amp; \\cdots &amp; a_{2n} + b_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{1n} + b_{1n} &amp; a_{1n} + b_{2n} &amp; \\cdots &amp; a_{nn} + b_{nn} \\end{pmatrix} \\\\ kA = \\begin{pmatrix} ka_{11} &amp; ka_{12} &amp; \\cdots &amp; ka_{1n} \\\\ ka_{12} &amp; ka_{22} &amp; \\cdots &amp; ka_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ ka_{1n} &amp; ka_{2n} &amp; \\cdots &amp; ka_{nn} \\end{pmatrix} \\] 易见 \\(A+B, kA \\in S^{m \\times m}\\) 故 \\(R^{m \\times m}\\) 中的对称矩阵按照矩阵的加法和数乘在数域 \\(\\mathbb{R}\\) 上构成一个线性空间 四 令 \\(\\beta = (1,2,1,1)^T, \\alpha_1 = (1,1,1,1)^T, \\alpha_2 = (1,1,-1,-1)^T, \\alpha_3 = (1,-1,1,-1)^T, \\alpha_4 = (1,-1,-1,1)^T\\)，试将向量 \\(\\beta\\) 表示成 \\(\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4\\) 的线性组合。 \\[ \\begin{aligned} &amp;\\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; -1 &amp; -1 &amp; 2 \\\\ 1 &amp; -1 &amp; 1 &amp; -1 &amp; 1 \\\\ 1 &amp; -1 &amp; -1 &amp; 1 &amp; 1 \\end{pmatrix} \\xrightarrow[\\begin{array} .r_3 - r_1 \\\\ r_4 -r_1 \\end{array}]{r_2 - r_1} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; 0 \\\\ 0 &amp; -2 &amp; -2 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow{r_2 \\leftrightarrow r_3} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; 0 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; -2 &amp; -2 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow[r_4 - r_3]{r_4 - r_2} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; 0 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 4 &amp; -1 \\end{pmatrix} \\\\ &amp;\\xrightarrow{\\frac{1}{4} \\cdot r_4} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; 0 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{4} \\end{pmatrix} \\xrightarrow[\\begin{array} .r_3 + 2 \\cdot r_4 \\\\ r_2 + 2 \\cdot r_4 \\end{array}]{r_1 - r_4} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 0 &amp; \\frac{5}{4} \\\\ 0 &amp; -2 &amp; 0 &amp; 0 &amp; -\\frac{1}{2} \\\\ 0 &amp; 0 &amp; -2 &amp; 0 &amp; \\frac{1}{2} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{4} \\end{pmatrix} \\xrightarrow{-\\frac{1}{2} \\cdot r_3} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 0 &amp; \\frac{5}{4} \\\\ 0 &amp; -2 &amp; 0 &amp; 0 &amp; -\\frac{1}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -\\frac{1}{4} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{4} \\end{pmatrix} \\xrightarrow{r_1 - r_3} \\\\ &amp;\\begin{pmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{3}{2} \\\\ 0 &amp; -2 &amp; 0 &amp; 0 &amp; -\\frac{1}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -\\frac{1}{4} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{4} \\end{pmatrix} \\xrightarrow{-\\frac{1}{2} \\cdot r_2} \\begin{pmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{3}{2} \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{1}{4} \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -\\frac{1}{4} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{4} \\end{pmatrix} \\xrightarrow{r_1 - r_2} \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\frac{5}{4} \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{1}{4} \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -\\frac{1}{4} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{4} \\end{pmatrix} \\end{aligned} \\] 故 \\[ \\beta = \\frac{5}{4} \\alpha_1 + \\frac{1}{4} \\alpha_2 - \\frac{1}{4} \\alpha_3 - \\frac{1}{4} \\alpha_4 \\] 五 设 \\(\\epsilon_{1}=\\left(\\begin{array}{l} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{array}\\right), \\epsilon_{2}=\\left(\\begin{array}{c} 1 \\\\ 1 \\\\ -1 \\\\ -1 \\end{array}\\right), \\epsilon_{3}=\\left(\\begin{array}{c} 1 \\\\ -1 \\\\ 1 \\\\ -1 \\end{array}\\right), \\epsilon_{1}=\\left(\\begin{array}{c} 1 \\\\ -1 \\\\ -1 \\\\ -1 \\end{array}\\right), a=\\left(\\begin{array}{c} 1 \\\\ 2 \\\\ -1 \\\\ 1 \\end{array}\\right)\\)，试求 \\(a\\) 在基 \\(\\epsilon_1, \\epsilon_2, \\epsilon_3, \\epsilon_4\\) 下的坐标。 \\[ \\begin{aligned} &amp;\\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; -1 &amp; -1 &amp; 2 \\\\ 1 &amp; -1 &amp; 1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 &amp; 1 \\end{pmatrix} \\xrightarrow[\\begin{array} .r_3 - r_1 \\\\ r_4 -r_1 \\end{array}]{r_2 - r_1} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; -2 \\\\ 0 &amp; -2 &amp; -2 &amp; -2 &amp; 0 \\end{pmatrix} \\xrightarrow{r_2 \\leftrightarrow r_3} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; -2 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; -2 &amp; -2 &amp; -2 &amp; 0 \\end{pmatrix} \\xrightarrow[r_4 - r_3]{r_4 - r_2} \\\\ &amp;\\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; -2 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 2 &amp; 1 \\end{pmatrix} \\xrightarrow{\\frac{1}{2} \\cdot r_4} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; -2 &amp; 0 &amp; -2 &amp; -2 \\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{pmatrix} \\xrightarrow[\\begin{array} .r_2 + 2 \\cdot r_4 \\\\ r_3 + 2 \\cdot r_4 \\end{array}]{r_1 - r_4} \\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 0 &amp; \\frac{1}{2} \\\\ 0 &amp; -2 &amp; 0 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; -2 &amp; 0 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{pmatrix} \\xrightarrow{-\\frac{1}{2} \\cdot r_3} \\\\ &amp;\\begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 0 &amp; \\frac{1}{2} \\\\ 0 &amp; -2 &amp; 0 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{pmatrix} \\xrightarrow{r_1 - r_3} \\begin{pmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{3}{2} \\\\ 0 &amp; -2 &amp; 0 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{pmatrix} \\xrightarrow{-\\frac{1}{2} \\cdot r_2} \\begin{pmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{3}{2} \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{1}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{pmatrix} \\xrightarrow{r_1 - r_2} \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\frac{1}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{pmatrix} \\end{aligned} \\] 故 \\[ a = \\epsilon_1 + \\frac{1}{2} \\epsilon_2 - \\epsilon_3 + \\frac{1}{2} \\epsilon_4 \\] 即 \\(a\\) 在基 \\(\\epsilon_1, \\epsilon_2, \\epsilon_3, \\epsilon_4\\) 下的坐标为 \\[ (1, \\frac{1}{2}, -1, \\frac{1}{2}) \\] 六 记数域 \\(\\mathbb{R}\\) 上的对称矩阵按照矩阵的加法与数乘构成的线性空间为 \\(V\\)。证明：映射 \\(\\sigma_{Q}: V \\rightarrow V, \\sigma_{Q}(A)=Q^{T} A Q\\) 为线性映射。其中 \\(Q\\) 为正交矩阵，即 \\(Q^T Q = I\\)。 任取 \\(A,B \\in V, k_1, k_2 \\in \\mathbb{R}\\) \\[ \\begin{aligned} \\sigma_Q(k_1 \\cdot A + k_2 \\cdot B) &amp;= Q^T (k_1 \\cdot A + K_2 \\cdot B) Q \\\\ &amp;=k_1 \\cdot Q^TAQ + k_2 \\cdot Q^TBQ \\\\ &amp;=k_1 \\cdot \\sigma_Q(A) + k_2 \\cdot \\sigma_Q(B) \\end{aligned} \\] 故映射 \\(\\sigma_Q\\) 对 \\(V\\) 中的两种运算保持不变 由此可知，\\(\\sigma_Q: V \\to V, \\sigma_Q(A)=Q^TAQ\\) 为线性映射 七 求矩阵 \\(A=\\left(\\begin{array}{ccc} 1 &amp; 1 &amp; -1 \\\\ 1 &amp; 0 &amp; 1 \\\\ -1 &amp; 1 &amp; 0 \\end{array}\\right)\\) 对应二次型的标准型。 矩阵 \\(A\\) 对应的二次型为 \\(f = x_1^2 + 2x_1x_2 -2x_1x_3+2x_2x_3\\) 下用配方法将其化为标准型 \\[ \\begin{aligned} f(x_1,x_2,x_3) &amp;= x_1^2 + 2x_1x_2 -2x_1x_3+2x_2x_3 \\\\ &amp;=(x_1+x_2-x_3)^2 - 4x_2x_3-x_2^2-x_3^2 \\\\ &amp;=(x_1+x_2-x_3)^2-(x_2+2x_3)^2+3x_3^2 \\end{aligned} \\] 令 \\[ \\left\\{ \\begin{aligned} &amp;y_1 = x_1+x_2-x_3 \\\\ &amp;y_2 = x_2+2x_3 \\\\ &amp;y_3 = x_3 \\end{aligned} \\right. \\] 解得 \\[ \\left\\{ \\begin{aligned} &amp;x_1 = y_1-y_2+3y_3 \\\\ &amp;x_2 = y_2-2y_3 \\\\ &amp;x_3 = y_3 \\end{aligned} \\right. \\] 由此可得标准型为 \\(f = y_1^2-y_2^2+3y_3^2\\)，所用变换矩阵为 \\[ C=\\begin{pmatrix} 1 &amp; -1 &amp; 3 \\\\ 0 &amp; 1 &amp; -2 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] 八 试判断下列哪些矩阵是正定矩阵。 \\[ A_{1}=\\left(\\begin{array}{ll} 2 &amp; 1 \\\\ 1 &amp; 1 \\end{array}\\right) \\quad A_{2}=\\left(\\begin{array}{llll} 5 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 4 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 7 &amp; 2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\end{array}\\right) \\quad A_{3}=\\left(\\begin{array}{ll} 2 &amp; 3 \\\\ 3 &amp; 1 \\end{array}\\right) \\quad A_{4}=\\left(\\begin{array}{lll} 2 &amp; 3 &amp; 1 \\\\ 3 &amp; 1 &amp; 2 \\\\ 1 &amp; 2 &amp; 1 \\end{array}\\right) \\] 由 \\[ D_{11} = 2 &gt;0, D_{12} = \\begin{vmatrix} 2 &amp; 1 \\\\ 1 &amp; 1 \\end{vmatrix} =1 &gt; 0 \\] 可知 \\(A_1 = \\begin{pmatrix} 2 &amp; 1 \\\\ 1 &amp; 1\\end{pmatrix}\\) 的顺序主子式均大于0，因此 \\(A_1\\) 是正定矩阵 由 \\[ D_{21} = 5 &gt; 0, D_{22} = \\begin{vmatrix} 5 &amp; 1 \\\\ 1 &amp; 4 \\end{vmatrix} = 19 &gt; 0, D_{23} = \\begin{vmatrix} 5 &amp; 1 &amp; 0 \\\\ 1 &amp; 4 &amp; 0 \\\\ 0 &amp; 0 &amp; 7 \\end{vmatrix} = 133 &gt; 0, D_{24} = \\begin{vmatrix} 5 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 4 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 7 &amp; 2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\end{vmatrix} = 456 &gt; 0 \\] 可知 \\(A_2 = \\begin{pmatrix} 5 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 4 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 7 &amp; 2 \\\\ 0 &amp; 0 &amp; 2 &amp; 4 \\end{pmatrix}\\) 的顺序主子式均大于0，因此 \\(A_2\\) 是正定矩阵 由 \\[ D_{32} = \\begin{vmatrix} 2 &amp; 3 \\\\ 3 &amp; 1 \\end{vmatrix} =-7 &lt; 0 \\] 可知 \\(A_3 = \\begin{pmatrix} 2 &amp; 3 \\\\ 3 &amp; 1 \\end{pmatrix}\\) 的顺序主子式不全大于0，因此 \\(A_3\\) 不是正定矩阵 由 \\[ D_{42} = \\begin{vmatrix} 2 &amp; 3 \\\\ 3 &amp; 1 \\end{vmatrix} =-7 &lt; 0 \\] 可知 \\(A_4 = \\begin{pmatrix} 2 &amp; 3 &amp; 1\\\\ 3 &amp; 1 &amp; 2 \\\\ 1 &amp; 2 &amp; 1\\end{pmatrix}\\) 的顺序主子式不全不大于0，因此 \\(A_4\\) 不是正定矩阵 九 求矩阵 \\(A = \\begin{pmatrix} 1 &amp; 4 &amp; 2 \\\\ 0 &amp; -3 &amp; 4 \\\\ 0 &amp; 4 &amp; 3 \\end{pmatrix}\\) 的特征值与对应的特征向量。 由 \\[ \\begin{aligned} |\\lambda I - A | &amp;= \\begin{vmatrix} \\lambda -1 &amp; -4 &amp; -2 \\\\ 0 &amp; \\lambda + 3 &amp; -4 \\\\ 0 &amp; -4 &amp; \\lambda - 3 \\end{vmatrix} \\\\ &amp;= (\\lambda - 1)(\\lambda + 3)(\\lambda - 3) - 16(\\lambda - 1) \\\\ &amp;=(\\lambda-1)(\\lambda-5)(\\lambda+5) = 0 \\end{aligned} \\] 解得 \\(\\lambda_1 = 1, \\lambda_2 = 5, \\lambda_3 = -5\\) 对于 \\(\\lambda_1 = 1\\) \\[ \\begin{aligned} \\begin{pmatrix} 0 &amp; -4 &amp; -2 \\\\ 0 &amp; 4 &amp; -4 \\\\ 0 &amp; -4 &amp; -2 \\end{pmatrix} \\xrightarrow[r_3-r_1]{r_2+r_1} \\begin{pmatrix} 0 &amp; -4 &amp; -2 \\\\ 0 &amp; 0 &amp; -6 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow{-\\frac{1}{6} \\cdot r_2} \\begin{pmatrix} 0 &amp; -4 &amp; -2 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow{r_1+2 \\cdot r_2} \\begin{pmatrix} 0 &amp; -4 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow{-\\frac{1}{4} \\cdot r_1} \\begin{pmatrix} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\end{aligned} \\] 因此 \\(\\alpha_1 = (1,0,0)^T\\)，\\(A\\) 的属于 \\(\\lambda_1\\) 的特征向量全体为 \\(k_1 \\alpha_1 (k_1 \\neq 0\\in \\mathbb{R})\\) 对于 \\(\\lambda_2 = 5\\) \\[ \\begin{aligned} \\begin{pmatrix} 4 &amp; -4 &amp; -2 \\\\ 0 &amp; 8 &amp; -4 \\\\ 0 &amp; -4 &amp; 2 \\end{pmatrix} \\xrightarrow{\\frac{1}{4} \\cdot r_2} \\begin{pmatrix} 4 &amp; -4 &amp; -2 \\\\ 0 &amp; 2 &amp; -1 \\\\ 0 &amp; -4 &amp; 2 \\end{pmatrix} \\xrightarrow[r_3+2 \\cdot r_2]{r_1 + 2 \\cdot r_2} \\begin{pmatrix} 4 &amp; 0 &amp; -4 \\\\ 0 &amp; 2 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow[\\frac{1}{2} \\cdot r_2]{\\frac{1}{4} \\cdot r_1} \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; -\\frac{1}{2} \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\end{aligned} \\] 因此 \\(\\alpha_2 = (2,1,2)^T\\)，\\(A\\) 的属于 \\(\\lambda_2\\) 的特征向量全体为 \\(k_2\\alpha_2(k_2 \\neq 0 \\in \\mathbb{R})\\) 对于 \\(\\lambda_3 = -5\\) \\[ \\begin{aligned} \\begin{pmatrix} -6 &amp; -4 &amp; -2 \\\\ 0 &amp; -2 &amp; -4 \\\\ 0 &amp; -4 &amp; -8 \\end{pmatrix} \\xrightarrow[r_3 - 2 \\cdot r_2]{r_1 - 2 \\cdot r_2} \\begin{pmatrix} -6 &amp; 0 &amp; 6 \\\\ 0 &amp; -2 &amp; -4 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\xrightarrow[-\\frac{1}{2} \\cdot r_2]{-\\frac{1}{6} r_1} \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\end{aligned} \\] 因此 \\(\\alpha_3 = (1,-2,1)^T\\)，\\(A\\) 的属于 \\(\\lambda_3\\) 的特征向量全体为 \\(k_3\\alpha_3 (k_3 \\neq 0 \\in \\mathbb{R})\\) 十 设已知 \\(A = \\begin{pmatrix} 2 &amp; 1 &amp; 1 \\\\ 1 &amp; 2 &amp; 1 \\\\ 1 &amp; 1 &amp; 2 \\end{pmatrix}\\)，且 \\(x = \\begin{pmatrix} 1 \\\\ k \\\\ 1 \\end{pmatrix}\\)是矩阵 \\(A^{-1}\\) 的一个特征向量，求 \\(k\\)。 设 \\(x = (1,k,1)^T\\) 为 \\(A^{-1}\\) 属于 \\(\\lambda_0\\) 的一个特征向量 则 \\(x\\) 为 \\(A\\) 属于 \\(\\frac{1}{\\lambda_0}\\) 的一个特征向量 由 \\[ \\begin{aligned} |\\lambda I - A | &amp;= \\begin{vmatrix} \\lambda -2 &amp; -1 &amp; -1 \\\\ -1 &amp; \\lambda -2 &amp; -1 \\\\ -1 &amp; -1 &amp; \\lambda - 2 \\end{vmatrix} =(\\lambda-4)(\\lambda-1)^2 \\end{aligned} \\] 可知 \\(\\lambda_1 = 4\\)，\\(\\lambda_2 = 1\\)（二重根） 对于 \\(\\lambda_1 = 4\\) \\[ \\begin{pmatrix} 2 &amp; -1 &amp; -1 \\\\ -1 &amp; 2 &amp; -1 \\\\ -1 &amp; -1 &amp; 2 \\end{pmatrix} \\rightarrow \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\] 解得 \\(\\alpha_1 = (1, 1, 1)^T\\)，\\(A\\) 的属于 \\(\\lambda_1\\) 的特征向量的全体构成的集合为 \\(E_1 = \\{k_1 \\alpha_1 : k_1 \\neq 0 \\in \\mathbb{R} \\}\\) 若 \\(x \\in E_1\\)，则 \\(k=1\\) 对于 \\(\\lambda_2 = 1\\) \\[ \\begin{pmatrix} -1 &amp; -1 &amp; -1 \\\\ -1 &amp; -1 &amp; -1 \\\\ -1 &amp; -1 &amp; -1 \\end{pmatrix} \\rightarrow \\begin{pmatrix} 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\] 解得 \\(\\alpha_2 = (-1,0,1)^T, \\alpha_3 = (-1,1,0)^T\\)，\\(A\\) 的属于 \\(\\lambda_2\\) 的特征向量的全体构成的集合为 \\(E_2 = \\{k_2\\alpha_2 + k_3 \\alpha_3 : k_2,k_3 \\in \\mathbb{R} \\land (k_2\\neq 0 \\lor k_3 \\neq 0)\\}\\) 若 \\(x \\in E_2\\)，则 \\(k=-2\\) 十一 使用Python将一张图片旋转一定⻆度。 提交时需要提交原来的图片和旋转后的图片以及补全的代码。 原图片： 逆时针旋转： 顺时针旋转： 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839from PIL import Imageimport matplotlib.pyplot as pltimport matplotlibimport numpy as npmatplotlib.use(&quot;TkAgg&quot;)img_origin = Image.open(&#x27;origin.jpg&#x27;)img_origin = img_origin.convert(&#x27;RGB&#x27;)img = np.array(img_origin)theta = 30/180*np.picos_theta = np.cos(theta)sin_theta = np.sin(theta)center_i = len(img)/2center_j = len(img[0])/2imgr = np.zeros_like(img)for i in range(len(img)): for j in range(len(img[0])): yi = int(cos_theta * (i - center_i) - sin_theta * (j - center_j) + center_i) yj = int(sin_theta * (i - center_i) + cos_theta * (j - center_j) + center_j) if yi &lt; 0 or yj &lt; 0 or yi &gt;= len(img) or yj &gt;= len(img[0]): continue for k in range(3): imgr[yi][yj][k] = img[i][j][k]plt.imshow(imgr)plt.axis(&#x27;off&#x27;)plt.savefig(&#x27;fig1.jpg&#x27;)plt.clf()imgR = np.zeros_like(img)for i in range(len(img)): for j in range(len(img[0])): xi = int(cos_theta * (i - center_i) + sin_theta * (j - center_j) + center_i) xj = int(-sin_theta * (i - center_i) + cos_theta * (j - center_j) + center_j) if xi &lt; 0 or xj &lt; 0 or xi &gt;= len(img) or xj &gt;= len(img[0]): continue for k in range(3): imgR[xi][xj][k] = img[i][j][k]plt.imshow(imgR)plt.axis(&#x27;off&#x27;)plt.savefig(&#x27;fig2.jpg&#x27;)","categories":[{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"}]},{"title":"数据科学与工程数学基础 作业1","slug":"dase-math/dase-math-assignment-1","date":"2021-03-12T02:00:00.000Z","updated":"2022-02-09T14:55:19.972Z","comments":true,"path":"2021/03/12/dase-math/dase-math-assignment-1/","link":"","permalink":"http://gonggongjohn.me/2021/03/12/dase-math/dase-math-assignment-1/","excerpt":"","text":"一 卷积神经网络是一类典型的处理图像的模型，其中卷积是其中一种非常重要的函数操作。试计算下列输入和卷积核做卷积的结果。（注意：此处卷积操作无需旋转180度） \\[ \\textrm{Input} = \\begin{pmatrix} 1 &amp; 3 &amp; 0 &amp; -1 \\\\ 3 &amp; 0 &amp; -1 &amp; 2 \\\\ 1 &amp; -1 &amp; 2 &amp; 0 \\end{pmatrix}, \\textrm{Kernel} = \\begin{pmatrix} -1 &amp; 1 \\\\ -1 &amp; 1 \\end{pmatrix} \\] 由卷积运算公式可知 \\[ \\begin{aligned} output_{11} &amp;= 1 \\cdot (-1) + 3 \\cdot 1 + 3 \\cdot (-1) + 0 \\cdot 1 = -1 \\\\ output_{12} &amp;= 3 \\cdot (-1) + 0 \\cdot 1 + 0 \\cdot (-1) + (-1) \\cdot 1 = -4 \\\\ output_{13} &amp;= 0 \\cdot (-1) + (-1) \\cdot 1 + (-1) \\cdot (-1) + 2 \\cdot 1 = 2 \\\\ output_{21} &amp;= 3 \\cdot (-1) + 0 \\cdot 1 + 1 \\cdot (-1) + (-1) \\cdot 1 = -5 \\\\ output_{22} &amp;= 0 \\cdot (-1) + (-1) \\cdot 1 + (-1) \\cdot (-1) + 2 \\cdot 1 = 2 \\\\ output_{23} &amp;= (-1) \\cdot (-1) + 2 \\cdot 1 + 2 \\cdot (-1) + 0 \\cdot 1 = 1 \\\\ \\end{aligned} \\] 故 \\[ \\textrm{Output} = \\begin{pmatrix} -1 &amp; -4 &amp; 2 \\\\ -5 &amp; 2 &amp; 1 \\end{pmatrix} \\] 二 现有一组图片数据集，任务目标是将这些图片分类。其中图片中包含的类别有：猫、狗、鹦鹉、人。试用One-Hot向量将类别表示为向量。 \\[ \\begin{aligned} 猫 &amp;\\xlongequal{def} [1,0,0,0]^T \\\\ 狗 &amp;\\xlongequal{def} [0,1,0,0]^T \\\\ 鹦鹉 &amp;\\xlongequal{def} [0,0,1,0]^T \\\\ 人 &amp;\\xlongequal{def} [0,0,0,1]^T \\end{aligned} \\] 三 现有文本集（一行为一个文本）如下。试计算，该文本集中各个单词（不区分大小写）在各文本中的TF-IDF值。 1234I know.You know.I know that you know.I know that you know that I know. 首先计算整个文档中各个词语的IDF值 \\[ \\begin{aligned} IDF_{(I)} &amp;= \\ln \\frac{4}{3} \\\\ IDF_{(know)} &amp;= \\ln \\frac{4}{4} = 0 \\\\ IDF_{(you)} &amp;= \\ln \\frac{4}{3} \\\\ IDF_{(that)} &amp;= \\ln \\frac{4}{2} = \\ln 2 \\end{aligned} \\] 随后分别计算各个文档中各个词语的TF值 \\[ TF_{(I,1)} = \\frac{1}{2} , TF_{(know,1)} = \\frac{1}{2} \\\\ TF_{(you,2)} = \\frac{1}{2} , TF_{(know,2)} = \\frac{1}{2} \\\\ TF_{(I,3)} = \\frac{1}{5} , TF_{(you,3)} = \\frac{1}{5},TF_{(know,3)} = \\frac{2}{5} , TF_{(that,2)} = \\frac{1}{5} \\\\ TF_{(I,4)} = \\frac{1}{4} , TF_{(you,4)} = \\frac{1}{8},TF_{(know,4)} = \\frac{3}{8} , TF_{(that,4)} = \\frac{1}{4} \\] 由此可得各个单词在各文本中的TF-IDF值 \\[ TF-IDF_{(I,1)} = \\frac{1}{2} \\cdot \\ln \\frac{4}{3} \\approx 0.1438 \\\\ TF-IDF_{(know,1)} = \\frac{1}{2} \\cdot 0 = 0 \\\\ TF-IDF_{(you,2)} = \\frac{1}{2} \\cdot \\ln \\frac{4}{3} \\approx 0.1438 \\\\ TF-IDF_{(know,2)} = \\frac{1}{2} \\cdot 0 = 0 \\\\ TF-IDF_{(I,3)} = \\frac{1}{5} \\cdot \\ln \\frac{4}{3} \\approx 0.0575 \\\\ TF-IDF_{(you,3)} = \\frac{1}{5} \\cdot \\ln \\frac{4}{3} \\approx 0.0575 \\\\ TF-IDF_{(know,3)} = \\frac{2}{5} \\cdot 0 = 0 \\\\ TF-IDF_{(that,3)} = \\frac{1}{5} \\cdot \\ln 2 \\approx 0.1386 \\\\ TF-IDF_{(I,4)} = \\frac{1}{4} \\cdot \\ln \\frac{4}{3} \\approx 0.0719 \\\\ TF-IDF_{(you,4)} = \\frac{1}{8} \\cdot \\ln \\frac{4}{3} \\approx 0.0360 \\\\ TF-IDF_{(know,4)} = \\frac{3}{8} \\cdot 0 = 0 \\\\ TF-IDF_{(that,4)} = \\frac{1}{4} \\cdot \\ln 2 \\approx 0.1733 \\\\ \\] 四 现有一个数据集有5个数据，分别被分类在 \\((0,1)^T, (0,1)^T, (0,1)^T, (1,0)^T, (1,0)^T\\)，而一个模型给出的评分分别为 \\((2,8)^T, (1,9)^T, (3,2)^T, (1,5)^T, (2,0)^T\\)，试给出此时模型给各个数据的概率评分以及交叉熵损失的值。 由 \\[ Softmax(x_i) = \\frac{e^{x_i}}{\\sum_\\limits{j=1}^n e^{x_j}} \\] 可知各个数据的概率评分为 \\[ \\begin{aligned} &amp;\\begin{pmatrix} e^2/(e^2+e^8) \\\\ e^8/(e^2+e^8) \\end{pmatrix}, \\begin{pmatrix} e^1/(e^1+e^9) \\\\ e^9/(e^1+e^9) \\end{pmatrix}, \\begin{pmatrix} e^3/(e^3+e^2) \\\\ e^2/(e^3+e^2) \\end{pmatrix}, \\begin{pmatrix} e^1/(e^1+e^5) \\\\ e^5/(e^1+e^5) \\end{pmatrix}, \\begin{pmatrix} e^2/(e^2+e^0) \\\\ e^0/(e^2+e^0) \\end{pmatrix} \\\\ \\approx &amp;\\begin{pmatrix} 0.0025 \\\\ 0.9975 \\end{pmatrix}, \\begin{pmatrix} 0.0003 \\\\ 0.9997 \\end{pmatrix}, \\begin{pmatrix} 0.7311 \\\\ 0.2689 \\end{pmatrix}, \\begin{pmatrix} 0.0180 \\\\ 0.9820 \\end{pmatrix}, \\begin{pmatrix} 0.8808 \\\\ 0.1192 \\end{pmatrix} \\end{aligned} \\] 又由交叉熵损失计算公式 \\[ L=-\\sum_{c=1}^K y_c \\log (p_c) \\] 可知各个数据的交叉熵损失为 \\[ L_1 = - (0 \\cdot \\log 0.0025 + 1 \\cdot \\log 0.9975) \\approx 0.0036 \\\\ L_2 = - (0 \\cdot \\log 0.0003 + 1 \\cdot \\log 0.9997) \\approx 0.0004 \\\\ L_3 = - (0 \\cdot \\log 0.7311 + 1 \\cdot \\log 0.2689) \\approx 1.8949 \\\\ L_4 = - (1 \\cdot \\log 0.0180 + 0 \\cdot \\log 0.9820) \\approx 5.7959 \\\\ L_5 = - (1 \\cdot \\log 0.8808 + 0 \\cdot \\log 0.1192) \\approx 0.1831 \\] 五 设数据集为 \\(x_1, x_2, \\cdots, x_n\\) 其中被分为两类 \\(y_1, y_2\\)。如果使用线性分类器，试给出一个考虑结构风险的损失函数的公式。 线性分类器的评分函数可表示为（使用Softmax作为概率评分函数） \\[ f(W,b,\\textbf{x}) = Softmax(W \\textbf{x} + b) \\] 若使用交叉熵作为基础损失函数，使用 \\(L_2\\) 范数作为正则化项，则最终的损失函数可以定义为 \\[ J =- \\sum_{i = 1}^2 y_c \\log (p_c) + \\lambda ||\\textbf{W}||_2^2 \\] 其中 \\(y_c\\) 为分类结果指示函数，\\(p_c\\) 为模型给出当前分类的概率评分 六 利用Python将一张黑白图片或彩色图片转化为矩阵或张量，并使图片水平翻转。 翻转结果： 实现代码： 12345678910from PIL import Imageimport numpy as nporigin_path = &#x27;origin.jpg&#x27;image = Image.open(origin_path)tensor = np.asarray(image)tensor_flipped = np.flip(tensor, 1)image_flipped = Image.fromarray(tensor_flipped)image_flipped = image_flipped.convert(&#x27;RGB&#x27;)image_flipped.save(&#x27;flipped.jpg&#x27;)","categories":[{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"}]},{"title":"操作系统实验 Shell及系统调用","slug":"os/os-exp-shell","date":"2021-03-02T03:54:46.000Z","updated":"2022-02-09T14:20:55.949Z","comments":true,"path":"2021/03/02/os/os-exp-shell/","link":"","permalink":"http://gonggongjohn.me/2021/03/02/os/os-exp-shell/","excerpt":"","text":"目的 在MINIX环境下通过系统调用实现一个基本的Shell。 内容与设计思想 Shell能解析的命令行如下: 带参数的程序运行功能。 1program arg1 arg2 ... argN 重定向功能，将文件作为程序的输入/输出。 “&gt;”表示覆盖写 1program arg1 arg2 ... argN &gt; output-file “&gt;&gt;”表示追加写 1program arg1 arg2 ... argN &gt;&gt; output-file “&lt;”表示文件输入 1program arg1 arg2 ... argN &lt; input-file 管道符号“|”，在程序间传递数据。 1programA arg1 ... argN | programB arg1 ... argN 后台符号&amp;，表示此命令将以后台运行的方式执行。 1program arg1 arg2 ... argN &amp; 工作路径移动命令：cd。 程序运行统计：mytop。 shell退出命令：exit。 显示最近执行的n条指令：history n。 实验过程 Shell主体 首先我们来实现Shell的基本结构。一个Shell的基本行为是不断接收用户的输入，并根据指令执行相应的操作。因此我们可以快速写出其main函数： 123456789101112131415161718192021222324252627#define MAXCMD 1024 //Max number of commands that can be recorded #define MAXLINE 1024 //Max number of characters a command line can have char cmd_list[MAXCMD][MAXLINE]; void eval(char *cmdline); int main(int argc, char **argv)&#123; char cmdline[MAXLINE]; //Command line string cmd_cnt = 0; while(1)&#123; printf(&quot;shell: %s %% &quot;, getcwd(NULL, NULL)); //Read the command line from stdin if(fgets(cmdline, MAXLINE, stdin) == NULL) &#123; print_message(&quot;Error occurred when reading command line!&quot;); continue; &#125; strcpy(cmd_list[cmd_cnt], cmdline); cmd_cnt++; //Evaluate the command line eval(cmdline); &#125; return 0; &#125; 由于后续需要通过history指令查询用户输入过的指令，这里我们设置了一个全局变量来记录用户每次输入的指令字符串。 指令输入解析 接下来我们对用户输入的指令进行结构化解析。我们使用一个二维字符串数组来存储用户输入的指令及参数流，这个数组的结构如下： 随后我们通过一个结构体来存储每行指令的全局特性（输入输出重定向，是否后台运行等）： 123456789101112131415161718192021#define MAXPROG 16 //Max program that can be connected by pipe #define MAXARGS 128 //Max number of arguments a command can have void parseline(char *cmdline, char *argv[MAXPROG][MAXARGS], struct cmd_feature *feature); struct cmd_feature&#123; int is_error; //Error flag, 0 - No error, 1 - Error in cmdline int bg; //Background flag, 1 - Background, 0 - Foreground int prog_num; //Number of program connected by pipe (0 means no pipe feature) int input_mode; //Overall input mode, 0 - Standard Input, 1 - File Input int output_mode; //Overall output mode, 0 - Standard Output, 1 - File Output (Overrride), 2 - File Output (Append) char *infile; //Path of input file char *outfile; //Path of output file &#125;; void eval(char *cmdline)&#123; char *argv[MAXPROG][MAXARGS]; //Argument strings struct cmd_feature line_feature; //Feature of the cmdline //Parse the command line parseline(cmdline, argv, &amp;line_feature); &#125; 现在我们来实现具体的指令解析逻辑。由于用户的指令是一次性输入的，因此我们需要考虑所有可能的情况。总的来说，对于一行指令，可能出现的内容有如下几个： (1) 由管道连接符相连接的一组待执行的程序 (2) 每个待执行程序附带的若干参数 (3) 输入重定向 (4) 输出重定向 (5) 后台运行标识符 我们分情况讨论所有的这些情况，并将它们结构化存储到相应的数组和结构体中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192void parseline(char *cmdline, char *argv[MAXPROG][MAXARGS], struct cmd_feature *feature)&#123; char *delim; // Points to first space delimiter int argc; // Number of arguments int prog_cnt; //Counter of programs cmdline[strlen(cmdline) - 1] = &#x27; &#x27;; // Replace trailing &#x27;\\n&#x27; with space while (*cmdline &amp;&amp; (*cmdline == &#x27; &#x27;)) // Ignore leading spaces cmdline++; // Build the argv list feature-&gt;is_error = 0; feature-&gt;input_mode = 0; feature-&gt;output_mode = 0; prog_cnt = 0; argc = 0; delim = strchr(cmdline, &#x27; &#x27;); while (delim) &#123; char *arg_tmp = strtok(cmdline, &quot; &quot;); if(!strcmp(arg_tmp, &quot;&lt;&quot;))&#123; *delim = &#x27;\\0&#x27;; cmdline = delim + 1; while (*cmdline &amp;&amp; (*cmdline == &#x27; &#x27;)) // Ignore redundant spaces cmdline++; delim = strchr(cmdline, &#x27; &#x27;); if(!delim)&#123; print_message(&quot;Missing I/O File Path!&quot;); feature-&gt;is_error = 1; return; &#125; feature-&gt;input_mode = 1; feature-&gt;infile = strtok(cmdline, &quot; &quot;); &#125; else if(!strcmp(arg_tmp, &quot;&gt;&quot;))&#123; *delim = &#x27;\\0&#x27;; cmdline = delim + 1; while (*cmdline &amp;&amp; (*cmdline == &#x27; &#x27;)) // Ignore redundant spaces cmdline++; delim = strchr(cmdline, &#x27; &#x27;); if(!delim)&#123; print_message(&quot;Missing I/O File Path!&quot;); feature-&gt;is_error = 1; return; &#125; feature-&gt;output_mode = 1; feature-&gt;outfile = strtok(cmdline, &quot; &quot;); &#125; else if(!strcmp(arg_tmp, &quot;&gt;&gt;&quot;))&#123; *delim = &#x27;\\0&#x27;; cmdline = delim + 1; while (*cmdline &amp;&amp; (*cmdline == &#x27; &#x27;)) // Ignore redundant spaces cmdline++; delim = strchr(cmdline, &#x27; &#x27;); if(!delim)&#123; print_message(&quot;Missing I/O File Path!&quot;); feature-&gt;is_error = 1; return; &#125; feature-&gt;output_mode = 2; feature-&gt;outfile = strtok(cmdline, &quot; &quot;); &#125; else if(!strcmp(arg_tmp, &quot;|&quot;))&#123; argc++; argv[prog_cnt][argc] = NULL; prog_cnt++; argc = 0; &#125; else&#123; argv[prog_cnt][argc] = arg_tmp; argc++; &#125; *delim = &#x27;\\0&#x27;; cmdline = delim + 1; while (*cmdline &amp;&amp; (*cmdline == &#x27; &#x27;)) // Ignore redundant spaces cmdline++; delim = strchr(cmdline, &#x27; &#x27;); &#125; argv[prog_cnt][argc] = NULL; feature-&gt;prog_num = prog_cnt + 1; // Figure out whether the job should be run in foreground or background if(argc == 0)&#123; feature-&gt;bg = 0; &#125; else if(!strcmp(argv[prog_cnt][argc - 1], &quot;&amp;&quot;)) feature-&gt;bg = 1; else feature-&gt;bg = 0; if (feature-&gt;bg != 0) &#123; argc--; argv[prog_cnt][argc] = NULL; &#125; &#125; 内置指令 我们的Shell中包含4条内置指令，当检测到用户输入这四条指令时，我们需要立即执行并给出相应的反馈。这里我们分别使用函数对4条内置指令的实现进行封装，并将判断是否为内置指令的过程封装为另一个函数以供主函数调用： 1234567891011121314151617181920//Judge whether the command is a builtin command, 1 - Builtin command, 0 - Other command builtin_cmd(char **argv)&#123; if(!strcmp(argv[0], &quot;cd&quot;))&#123; change_dir(argv); return 1; &#125; else if(!strcmp(argv[0], &quot;history&quot;))&#123; print_history(); return 1; &#125; else if(!strcmp(argv[0], &quot;mytop&quot;))&#123; perform_top(); return 1; &#125; else if(!strcmp(argv[0], &quot;exit&quot;))&#123; exit(0); &#125; else return 0;&#125; 对于exit指令，我们只需要直接退出程序即可。 对于cd指令，我们可以通过使用chdir系统调用来更改工作目录： 12345void change_dir(char **argv)&#123; if(chdir(argv[1]) &lt; 0)&#123; print_message(&quot;Error when changing working directory!&quot;); &#125;; &#125; 对于history指令，由于前面我们已经通过cmd_list全局变量保存了每次输入的指令，这里我们只需要遍历这一数组打印指令即可： 12345void print_history()&#123; for(int i = 0; i &lt; cmd_cnt; i++)&#123; fprintf(stdout, &quot;%s&quot;, cmd_list[i]); &#125; &#125; 对于mytop指令，由于逻辑相对较为复杂，我们放在后文中讨论。 任务流管理 若用户输入的不为内置指令，则Shell需要执行相应的任务序列。由于允许后台程序，Shell中可能会同时存在多个子任务，因此我们需要将每个任务相互隔离开来。考虑到后续管道的建立，我们将使用如下的进程结构图： 首先我们使用fork函数创建一个子进程用于托管当前指令流的任务，随后对于任务序列中的每条指令，我们再分别fork一个单独的进程用于执行程序。由于任务序列中的任务为顺序执行的，因此我们需要使用waitpid函数等待上一任务执行完毕再新建下一任务进程。这里需要注意的是，由于我们是在托管进程中再新开子进程执行程序的，托管进程在子任务全部结束后并不会自动退出，这样父进程中的后续代码同样会被托管进程执行，造成无限嵌套，因此我们必须在子任务结束后手动结束托管进程。相关代码实现如下： 123456789101112131415161718192021222324252627282930313233343536373839void waitfg(pid_t pid)&#123; int state; waitpid(pid, &amp;state, 0); &#125; void eval(char *cmdline)&#123; char *argv[MAXPROG][MAXARGS]; //Argument strings struct cmd_feature line_feature; //Feature of the cmdline pid_t pid; //PID of the latest child //Parse the command line parseline(cmdline, argv, &amp;line_feature); //Command line error if(line_feature.is_error == 1) return; //Blank space if(argv[0][0] == NULL) return; if (!builtin_cmd(argv[0])) &#123; if ((pid = fork()) == 0) &#123; for (int i = 0; i &lt; line_feature.prog_num; i++) &#123; if ((pid = fork()) == 0) &#123; //Subsequent logic goes here if (execvp(argv[i][0], argv[i]) &lt; 0) &#123; fprintf(stdout, &quot;%s: Program not found.\\n&quot;, argv[i][0]); exit(0); &#125; &#125; else &#123; waitfg(pid); &#125; &#125; exit(0); //Subsequent logic goes here &#125; &#125; &#125; 当用户输入的指令带有&lt;、&gt;或&gt;&gt;时，则需要将程序的输入输出流重定向到用户指定的文件中。由于在前面的解析中我们已经将需要的参数记录了下来，这里我们只需要根据结构化的信息打开文件，并利用dup函数将其文件描述符赋给标准输入/输出即可： 12345678910111213141516171819202122232425262728293031323334353637void eval(char *cmdline)&#123; struct cmd_feature line_feature; //Feature of the cmdline pid_t pid; //PID of the latest child //Other codes omitted if (!builtin_cmd(argv[0])) &#123; //Other codes omitted if ((pid = fork()) == 0) &#123; for (int i = 0; i &lt; line_feature.prog_num; i++) &#123; //Other codes omitted if ((pid = fork()) == 0) &#123; //Input redirection if (i == 0 &amp;&amp; line_feature.input_mode == 1) &#123; int fd = open(line_feature.infile, O_RDONLY); close(STDIN_FILENO); dup(fd); &#125; //Output redirection(Override file) else if (i == (line_feature.prog_num - 1) &amp;&amp; line_feature.output_mode == 1) &#123; int fd = open(line_feature.outfile, O_CREAT | O_WRONLY | O_TRUNC, S_IREAD | S_IWRITE); close(STDOUT_FILENO); dup(fd); &#125; //Output redirection(Append to the end of file) else if (i == (line_feature.prog_num - 1) &amp;&amp; line_feature.output_mode == 2) &#123; int fd = open(line_feature.outfile, O_CREAT | O_WRONLY | O_APPEND, S_IREAD | S_IWRITE); close(STDOUT_FILENO); dup(fd); &#125; //Other codes omitted &#125; //Other codes omitted &#125; //Other codes omitted &#125; //Other codes omitted &#125; &#125; 管道连接 当用户输入的指令中包含多于一个程序时，我们需要通过管道将前一个程序的输出与后一个程序的输入相连接。我们可以使用pipe函数来创建管道。对于一根管道，我们需要传入一个大小为2的一维数组作为管道的输入和输出端文件描述符，由于一条指令中可能含有多个程序，因此我们使用一个二维数组来为每两个程序间分别开辟一根管道以实现程序通讯的隔离： 现在，我们只需要使用上文中输入输出重定向的方式将程序的输入输出分别重定向到管道的入口和出口即可。需要注意的是，在任务托管进程中，我们需要关闭管道的输入端，以防止父子进程间的管道交互： 12345678910111213141516171819202122232425262728293031323334353637383940414243#define MAXPROG 16 //Max program that can be connected by pipe void eval(char *cmdline)&#123; struct cmd_feature line_feature; //Feature of the cmdline pid_t pid; //PID of the latest child int pipe_gate[MAXPROG][2]; //Other codes omitted if (!builtin_cmd(argv[0])) &#123; //Other codes omitted if ((pid = fork()) == 0) &#123; for (int i = 0; i &lt; line_feature.prog_num; i++) &#123; pipe(pipe_gate[i]); if ((pid = fork()) == 0) &#123; //Other codes omitted //Pipe connection if (line_feature.prog_num &gt; 1) &#123; if (i == 0) &#123; close(STDOUT_FILENO); close(pipe_gate[i][0]); dup(pipe_gate[i][1]); &#125; else if (i == line_feature.prog_num - 1) &#123; close(STDIN_FILENO); close(pipe_gate[i - 1][1]); dup(pipe_gate[i - 1][0]); &#125; else &#123; close(STDIN_FILENO); close(pipe_gate[i - 1][1]); dup(pipe_gate[i - 1][0]); close(STDOUT_FILENO); close(pipe_gate[i][0]); dup(pipe_gate[i][1]); &#125; &#125; //Other codes omitted &#125; else &#123; close(pipe_gate[i][1]); waitfg(pid); &#125; &#125; //Other codes omitted &#125; //Other codes omitted &#125; 后台运行 当用户输入的指令最后含有&amp;时，表明用户希望该任务流在后台执行。对于Shell主进程来说，我们只需要让其不等待子进程结束直接进入下一轮循环即可。但若直接这样做，则当子进程运行结束后将成为僵尸进程占用系统资源，因此我们需要使用信号系统将其交给MINIX系统托管。此外，为了防止子进程受到终端输入输出的影响，我们需要将其输入输出流重定向到/dev/null下。同样的，由于前面我们已经保存了当前指令是否要后台执行的信息，这里我们只需要直接读取前文结构体中的相关字段即可： 1234567891011121314151617181920212223242526272829303132333435void eval(char *cmdline)&#123; struct cmd_feature line_feature; //Feature of the cmdline pid_t pid; //PID of the latest child //Other codes omitted if (!builtin_cmd(argv[0])) &#123; if(line_feature.bg)&#123; signal(SIGCHLD, SIG_IGN); &#125; else&#123; signal(SIGCHLD, SIG_DFL); &#125; if ((pid = fork()) == 0) &#123; for (int i = 0; i &lt; line_feature.prog_num; i++) &#123; //Other codes omitted if ((pid = fork()) == 0) &#123; //Other codes omitted //Background command if (i == (line_feature.prog_num - 1) &amp;&amp; line_feature.bg) &#123; int fd = open(&quot;/dev/null&quot;, O_RDWR); close(STDIN_FILENO); dup(fd); close(STDOUT_FILENO); dup(fd); &#125; //Other codes omitted &#125; //Other codes omitted &#125; //Other codes omitted &#125; else &#123; if (!line_feature.bg) &#123; waitfg(pid); &#125; &#125; &#125; 系统资源查看 现在我们来实现mytop指令的逻辑。当用户输入mytop指令时，Shell需要打印出当前系统的内存使用情况及CPU占用率。我们可以在MINIX系统的/proc目录下查询到这些信息。 对于内存使用情况，我们需要打开proc目录下的meminfo文件。该文件中共有5个参数，分别对应页面大小、总页数量、空闲页数量、最大页数量以及缓存页数量。我们只需将其依次读入，并将页面大小与其他几个参数依次向乘，即可得到内存的相应使用情况： 1234567891011121314151617181920212223242526272829303132#define MAXBUF 1024 //Max buffer size for an file read operation void get_memory(int *total_size, int *free_size, int *cached_size)&#123; int mem_f; //File descriptor of memory info int bufsize; //Actual size of bytes read char buf[MAXBUF]; //Buffer for reading from file int page_size, total_page, free_page, largest_page, cached_page; mem_f = open(MEMPATH, O_RDONLY); //Open memory info file bufsize = read(mem_f, buf, sizeof(buf)); //Read memory info if(bufsize == -1)&#123; print_message(&quot;Error reading memory info!&quot;); &#125; else&#123; page_size = atoi(strtok(buf, &quot; &quot;)); total_page = atoi(strtok(NULL, &quot; &quot;)); free_page = atoi(strtok(NULL, &quot; &quot;)); largest_page = atoi(strtok(NULL, &quot; &quot;)); cached_page = atoi(strtok(NULL, &quot; &quot;)); *total_size = (page_size * total_page) / 1024; *free_size = (page_size * free_page) / 1024; *cached_size = (page_size * cached_page) / 1024; &#125; &#125; void perform_top()&#123; int total_size, free_size, cached_size; //Info of memory get_memory(&amp;total_size, &amp;free_size, &amp;cached_size); fprintf(stdout, &quot;Total: %dK, Free: %dK, Cached: %dK\\n&quot;, total_size, free_size, cached_size); //Other codes omitted &#125; CPU占用率的获取方式相对较为复杂。首先我们需要从proc目录下的kinfo文件中获取进程和任务的总数量： 1234567891011121314151617181920212223242526#define PROCPATH &quot;/proc/kinfo&quot;unsigned int nr_procs, nr_tasks; int nr_total; //Number of process + task void getkinfo() &#123; int fd; //File descriptor of kinfo int bufsize; //Actual buffer size char buf[MAXBUF], pathbuf[MAXBUF]; //Buffer for file reading fd = open(PROCPATH, O_RDONLY); if (fd == -1) &#123; print_message(&quot;Reading kinfo file error!&quot;); exit(1); &#125; bufsize = read(fd, buf, sizeof(buf)); //Read process info if(bufsize == -1)&#123; print_message(&quot;Error reading total process info!&quot;); &#125; else &#123; nr_procs = (unsigned int) atoi(strtok(buf, &quot; &quot;)); //Number of process nr_tasks = (unsigned int) atoi(strtok(NULL, &quot; &quot;)); //Number of tasks close(fd); nr_total = (int) (nr_procs + nr_tasks); &#125; &#125; 随后我们需要遍历整个proc目录以获取各个进程的具体信息。对于一个进程号为PID的进程，其信息被保存在/proc/PID/psinfo的文件下，该文件中的前13个参数分别为版本号、类型（T - Task，S - System，U - User）、端点、进程名字、进程状态（S - Sleep，W - Wait，Zombie - Z，R - Run，T - Stop）、阻塞状态、动态优先级、滴答、高周期、低周期、内存、有效用户和静态优先级。为了方便起见我们定义一个结构体用于保存每个进程的各项参数： 1234567891011121314151617const char *cputimenames[] = &#123; &quot;user&quot;, &quot;ipc&quot;, &quot;kernelcall&quot; &#125;; //CPU cycle types #define CPUTIMENAMES (sizeof(cputimenames)/sizeof(cputimenames[0])) struct proc &#123; int p_flags; int p_endpoint; pid_t p_pid; uint64_t p_cpucycles[CPUTIMENAMES]; int p_priority; int p_blocked; time_t p_user_time; long unsigned int p_memory; uid_t p_effuid; int p_nice; char p_name[17]; &#125;; 并定义一组宏方便后续对各项参数的处理： 12345678910111213141516171819202122232425262728#define INFOPATH &quot;/proc&quot; #define CPUTIME(m, i) (m &amp; (1L &lt;&lt; (i))) #define USED 0x1 #define IS_TASK 0x2 #define IS_SYSTEM 0x4 #define BLOCKED 0x8 /* Process types. */ #define TYPE_TASK &#x27;T&#x27; #define TYPE_SYSTEM &#x27;S&#x27; #define TYPE_USER &#x27;U&#x27; /* General process states. */ #define STATE_SLEEP &#x27;S&#x27; #define STATE_WAIT &#x27;W&#x27; #define STATE_ZOMBIE &#x27;Z&#x27; #define STATE_RUN &#x27;R&#x27; #define STATE_STOP &#x27;T&#x27; /* Kernel tasks. These all run in the same address space. */ #define ASYNCM ((int) -5) /* notifies about finished async sends */ #define IDLE ((int) -4) /* runs when no one else can run */ #define CLOCK ((int) -3) /* alarms and other clock functions */ #define SYSTEM ((int) -2) /* request system functionality */ #define KERNEL ((int) -1) /* pseudo-process for IPC and scheduling */ #define HARDWARE KERNEL /* for hardware interrupt handlers */ 由于每个进程中保存的信息均为自该程序启动之时到当前时间戳的统计信息，因此为了获取即时的占用信息，我们需要在极短的时间内对每个进程信息文件读取两次，并通过计算差值的方式来获得即时的占用信息。为此我们分别申明两个结构体用于存储两次读取到的信息，并在主函数中读取两次进程信息： 12345678910111213141516171819202122232425262728293031323334353637struct proc *proc = NULL, *prev_proc = NULL; void parse_file(pid_t pid); void parse_dir(); void get_procs() &#123; struct proc *p; int i; p = prev_proc; prev_proc = proc; proc = p; if (proc == NULL) &#123; proc = malloc(nr_total * sizeof(proc[0])); //Allocate a new process structure //Allocate failed if (proc == NULL) &#123; fprintf(stderr, &quot;Out of memory!\\n&quot;); exit(1); &#125; &#125; //Initialize all the entry ranging in the total process+task num for (i = 0; i &lt; nr_total; i++) proc[i].p_flags = 0; parse_dir(); &#125; void perform_top()&#123; //Other codes omitted getkinfo(); get_procs(); if (prev_proc == NULL) get_procs(); //Other codes omitted &#125; 一个进程的CPU占用时间可以从两次读取到的CPU周期之差得到，不过需要注意的是，MINIX进程信息文件中保存的分别是周期的高32位及低32位，我们需要首先将他们拼接成一个完整的64位整数才能进行后续的计算： 1234uint64_t make_cycle(unsigned long lo, unsigned long hi) &#123; return ((uint64_t)hi &lt;&lt; 32) | (uint64_t)lo; &#125; 现在我们可以来实现遍历proc目录的函数了： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111void parse_file(pid_t pid) &#123; char path[MAXBUF], name[256], type, state; int version, endpt, effuid; unsigned long cycles_hi, cycles_lo; FILE *fp; struct proc *p; int i; sprintf(path, &quot;/proc/%d/psinfo&quot;, pid); if ((fp = fopen(path, &quot;r&quot;)) == NULL) return; if (fscanf(fp, &quot;%d&quot;, &amp;version) != 1) &#123; fclose(fp); return; &#125; if (fscanf(fp, &quot; %c %d&quot;, &amp;type, &amp;endpt) != 2) &#123; fclose(fp); return; &#125; slot++; if(slot &lt; 0 || slot &gt;= nr_total) &#123; fprintf(stderr, &quot;Unreasonable endpoint number %d\\n&quot;, endpt); fclose(fp); return; &#125; p = &amp;proc[slot]; if (type == TYPE_TASK) p-&gt;p_flags |= IS_TASK; else if (type == TYPE_SYSTEM) p-&gt;p_flags |= IS_SYSTEM; p-&gt;p_endpoint = endpt; p-&gt;p_pid = pid; if (fscanf(fp, &quot; %255s %c %d %d %lu %*u %lu %lu&quot;, name, &amp;state, &amp;p-&gt;p_blocked, &amp;p-&gt;p_priority, &amp;p-&gt;p_user_time, &amp;cycles_hi, &amp;cycles_lo) != 7) &#123; fclose(fp); return; &#125; strncpy(p-&gt;p_name, name, sizeof(p-&gt;p_name)-1); p-&gt;p_name[sizeof(p-&gt;p_name)-1] = 0; if (state != STATE_RUN) p-&gt;p_flags |= BLOCKED; p-&gt;p_cpucycles[0] = make_cycle(cycles_lo, cycles_hi); p-&gt;p_memory = 0L; if (!(p-&gt;p_flags &amp; IS_TASK)) &#123; int j; if ((j=fscanf(fp, &quot; %lu %*u %*u %*c %*d %*u %u %*u %d %*c %*d %*u&quot;, &amp;p-&gt;p_memory, &amp;effuid, &amp;p-&gt;p_nice)) != 3) &#123; fclose(fp); return; &#125; p-&gt;p_effuid = effuid; &#125; else p-&gt;p_effuid = 0; for(i = 1; i &lt; CPUTIMENAMES; i++) &#123; if(fscanf(fp, &quot; %lu %lu&quot;, &amp;cycles_hi, &amp;cycles_lo) == 2) &#123; p-&gt;p_cpucycles[i] = make_cycle(cycles_lo, cycles_hi); &#125; else &#123; p-&gt;p_cpucycles[i] = 0; &#125; &#125; if ((p-&gt;p_flags &amp; IS_TASK)) &#123; if(fscanf(fp, &quot; %lu&quot;, &amp;p-&gt;p_memory) != 1) &#123; p-&gt;p_memory = 0; &#125; &#125; p-&gt;p_flags |= USED; fclose(fp); &#125; void parse_dir() &#123; DIR *p_dir; //Pointer of directory struct dirent *p_ent; //Info of the directory pid_t pid; //Name of sub directory(PID) char *end; if ((p_dir = opendir(INFOPATH)) == NULL) &#123; exit(1); &#125; //Traverse the directory for (p_ent = readdir(p_dir); p_ent != NULL; p_ent = readdir(p_dir)) &#123; pid = strtol(p_ent-&gt;d_name, &amp;end, 10); //Get the name of sub directory if (!end[0] &amp;&amp; pid != 0) parse_file(pid); &#125; closedir(p_dir); &#125; 到此，我们已经将所需要的进程信息结构化存储至了结构体中，接下来我们来计算CPU占用率。CPU的总使用时间为用户进程、系统进程及空闲进程的占用时间之和，由此可知要得到CPU占用率，我们只要统计出总使用时间、用户进程占用时间和系统进程占用时间即可。对于每个进程，我们可以利用其CPU周期之差算出其滴答： 12345678910111213141516uint64_t cputicks(struct proc *p1, struct proc *p2, int timemode) &#123; int i; uint64_t t = 0; for(i = 0; i &lt; CPUTIMENAMES; i++) &#123; if(!CPUTIME(timemode, i)) continue; if(p1-&gt;p_endpoint == p2-&gt;p_endpoint) &#123; t = t + p2-&gt;p_cpucycles[i] - p1-&gt;p_cpucycles[i]; &#125; else &#123; t = t + p2-&gt;p_cpucycles[i]; &#125; &#125; return t; &#125; 随后我们遍历所有的有效进程，再结合进程类型及进程状态，即可得到所要的三个信息，再通过用户进程占用时间加系统进程占用时间与CPU总使用时间做比值，即可得到最终的CPU占用率： 123456789101112131415161718192021222324252627282930313233343536373839404142434445float print_procs(struct proc *proc1, struct proc *proc2, int cputimemode) &#123; int p, nprocs; uint64_t systemticks = 0; uint64_t userticks = 0; uint64_t total_ticks = 0; static struct tp *tick_procs = NULL; if (tick_procs == NULL) &#123; tick_procs = malloc(nr_total * sizeof(tick_procs[0])); if (tick_procs == NULL) &#123; fprintf(stderr, &quot;Out of memory!\\n&quot;); exit(1); &#125; &#125; for (p = nprocs = 0; p &lt; nr_total; p++) &#123; uint64_t uticks; if (!(proc2[p].p_flags &amp; USED)) continue; tick_procs[nprocs].p = proc2 + p; tick_procs[nprocs].ticks = cputicks(&amp;proc1[p], &amp;proc2[p], cputimemode); uticks = cputicks(&amp;proc1[p], &amp;proc2[p], 1); total_ticks = total_ticks + uticks; if(!(proc2[p].p_flags &amp; IS_TASK)) &#123; if(proc2[p].p_flags &amp; IS_SYSTEM) systemticks = systemticks + tick_procs[nprocs].ticks; else userticks = userticks + tick_procs[nprocs].ticks; &#125; nprocs++; &#125; if (total_ticks == 0) return 0.0; return 100.0 * (systemticks + userticks) / total_ticks; &#125; void perform_top()&#123; //Other codes omitted float idle = print_procs(prev_proc, proc, 1); fprintf(stdout, &quot;CPU Usage: %f%%\\n&quot;, idle); &#125; 运行结果 我们使用实验要求中的测试用例在MINIX环境下对Shell进行测试： 可以发现，程序的行为均与预期相同。除此之外，我们再结合多重管道、输出重定向及后台运行符对Shell进行更为复杂的测试： Shell同样可以正确的解析命令并执行相应的操作。 总结 在本实验中，我们从零开始在MINIX环境下完整实现了一个基本的Shell终端，这其中综合了系统调用、文件管理、进程管理及I/O交互的大量理论知识。通过该实验，极大的加深了我们对这些系统知识的理解。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Operating-System","slug":"Operating-System","permalink":"http://gonggongjohn.me/tags/Operating-System/"}]},{"title":"实数集不可数的证明","slug":"math-analysis/real-number-uncountability","date":"2021-02-27T14:37:37.000Z","updated":"2021-02-27T14:38:48.142Z","comments":true,"path":"2021/02/27/math-analysis/real-number-uncountability/","link":"","permalink":"http://gonggongjohn.me/2021/02/27/math-analysis/real-number-uncountability/","excerpt":"实数集是不可数集这一结论的证明是近代集合论研究的一大重要标志。随着近代分析学的发展，这一结论可以从许多不同的角度推导而出。这些方法融合了许多重要的分析思想及数学技巧，在此进行一个简单的整理和总结。","text":"实数集是不可数集这一结论的证明是近代集合论研究的一大重要标志。随着近代分析学的发展，这一结论可以从许多不同的角度推导而出。这些方法融合了许多重要的分析思想及数学技巧，在此进行一个简单的整理和总结。 Theorem: 实数集 \\[\\mathbb{R}\\] 不可数 对角线法 若 \\[\\mathbb{R}\\] 可数，则区间 \\[[0,1] \\subset \\mathbb{R}\\] 必然可数 因此必然可以使用十进制表示法将 \\[[0,1]\\] 中的每一个数一一列出： \\[ r_1 = 0.d_{11} d_{12} d_{13} d_{14} ... \\\\ r_2 = 0.d_{21} d_{22} d_{23} d_{24} ... \\\\ r_3 = 0.d_{31} d_{32} d_{33} d_{34} ... \\\\ r_4 = 0.d_{41} d_{42} d_{43} d_{44} ... \\\\ ... \\] 其中 \\[d_{ij} \\in \\{0, 1, 2, ..., 9\\}\\] 现构造一新的实数 \\[r = 0.d_1 d_2 d_3 d_4 ...\\]，使得 \\[ d_i = \\left\\{ \\begin{aligned} 4, \\ if \\ d_{ii} \\neq 4 \\\\ 5, \\ if \\ d_{ii} = 4 \\end{aligned} \\right. \\] 显然 \\[r \\in [0, 1]\\] 而由于对任意 \\[i \\in \\mathbb{N}^+\\]，\\[r\\] 与 \\[r_i\\] 的第 \\[i\\] 位数字均不相同，因此 \\[r \\neq r_i\\] 由此我们构造出了一个未被列出的实数，这与 \\[[0,1]\\] 中的每一个数均可被列出矛盾 故 \\[[0,1]\\] 为不可数集，进而可知 \\[\\mathbb{R}\\] 为不可数集。 区间套法 Lemma: 若 \\[\\{[a_n, b_n]\\}\\] 形成一闭区间套，则存在唯一的实数 \\[\\xi\\] 属于所有的闭区间 \\[[a_n, b_n]\\]，且 \\[\\xi = \\lim_\\limits{n \\to \\infty} a_n = \\lim_\\limits{n \\to \\infty} b_n\\] 若 \\[\\mathbb{R}\\] 可数，则区间 \\[[0,1] \\subset \\mathbb{R}\\] 必然可数 因此我们可将 \\[[0,1]\\] 写为一数列 \\[r_1, r_2, ...,r_n,...\\] 现将 \\[[0,1]\\] 三等分，则必存在某个区间 \\[[a_1, b_1] \\subset [0,1]\\]，使得 \\[r_1 \\notin [a_1, b_1]\\] 接着继续将 \\[[a_1, b_1]\\] 三等分，则必存在某一子区间 \\[[a_2, b_2] \\subset [a_1, b_1]\\]，使得 \\[r_2 \\notin [a_2, b_2]\\] 如此进行下去，可得一闭区间套 \\[\\{[a_n, b_n]\\}\\]，且满足对任意 \\[i \\in \\mathbb{N^+}\\]，有 \\[r_i \\notin [a_i, b_i]\\] 故由闭区间套定理可知，存在 \\[\\xi \\in \\mathbb{R}\\]，使得对任意 \\[n \\in \\mathbb{N^+}\\]，有 \\[\\xi \\in [a_n, b_n]\\] 于是存在 \\[\\xi \\in [0,1]\\]，使得对任意 \\[i \\in \\mathbb{R}^+\\]，有 \\[\\xi \\neq r_i\\]，与 \\[[0,1]\\] 中每一个数均可被列出矛盾 故 \\[[0,1]\\] 为不可数集，进而可知 \\[\\mathbb{R}\\] 为不可数集。 外测度法 对于 \\[\\mathbb{R}\\] 上的任意闭区间 \\[I=[a,b]\\]，其体积 \\[V(I)=b-a\\] 故由外测度定义 \\[ m(S) = \\inf \\{ \\sum_{i=1}^\\infty V(I_i) \\big| S \\subset \\bigcup_{i \\in \\mathbb{N}} I_i \\} \\] 可知 \\[m(I) = b-a\\] 而对任意可数集 \\[S\\]，\\[m(S) = 0\\] 因此 \\[\\mathbb{R}\\] 不可数 Baire纲定理 Lemma: 设 \\[(X, d)\\] 是一个完备的度量空间，则 若 \\[(F_n)_{n=0}^\\infty\\] 是一列无处稠密的闭集，则它的并的内部是空的 若 \\[(O_n))_{n=0}^\\infty\\] 是一列在 \\[X\\] 中稠密的开集，则它的交在也 \\[X\\] 中稠密 Baire纲定理指出，一个完备的度量空间不能写成可数个无处稠密的集合的并 由于 \\[\\mathbb{R}\\] 是完备的，且在其上有自然度量 \\[d(x,y) = |x-y|\\]，因此其为一个完备的度量空间 若 \\[\\mathbb{R}\\] 可数，则其可以表示为可数个单点集的并，而单点集的闭包即为它本身，也即是无处稠密的 这与Baire纲定理矛盾，因此 \\[\\mathbb{R}\\] 必不可数","categories":[{"name":"分析学","slug":"分析学","permalink":"http://gonggongjohn.me/categories/%E5%88%86%E6%9E%90%E5%AD%A6/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"Analysis","slug":"Analysis","permalink":"http://gonggongjohn.me/tags/Analysis/"}]},{"title":"Shell Lab实验记录","slug":"computer-system/csapp-shlab","date":"2021-01-29T15:48:59.000Z","updated":"2021-01-29T17:30:27.575Z","comments":true,"path":"2021/01/29/computer-system/csapp-shlab/","link":"","permalink":"http://gonggongjohn.me/2021/01/29/computer-system/csapp-shlab/","excerpt":"简单来说就是用C语言以及各种系统调用实现一个简单的Unix Shell，说的更直白点就是把CSAPP书上第八章提到的关于Shell的内容全部实现一遍，因此最快的办法应该就是先搭一个基本的框架出来，然后跟着trace的要求把功能一个个补齐。","text":"简单来说就是用C语言以及各种系统调用实现一个简单的Unix Shell，说的更直白点就是把CSAPP书上第八章提到的关于Shell的内容全部实现一遍，因此最快的办法应该就是先搭一个基本的框架出来，然后跟着trace的要求把功能一个个补齐。 概览 首先我们来看一下Lab的具体要求和操作流程。 在Lab下的tsh.c文件里给出了一个Shell的基本框架，我们的任务就是要完成如下几个函数的具体实现： eval：解析并执行用户输入的命令 builtin_cmd：识别并解析Shell的内置函数 do_bgfg：内置函数bg和fg的功能实现 waitfg：等待前台任务完成 sigchld_handler：SIGCHLD信号处理 sigint_handler：SIGINT信号处理 sigstp_handler：SIGSTP信号处理 其中，内置函数包括如下几个： quit：结束当前的Shell进程 jobs：列出所有当前的后台任务 bg &lt;jobs&gt;：向被挂起的前台任务发送SIGCONT信号，并将其转到后台运行 fg &lt;jobs&gt;：向被挂起的后台任务发送SIGCONT信号，并将其转到前台运行 任务要求我们必须回收所有的僵尸孩子进程，并对相应的信号给出正确的反馈。 为了方便起见，tsh.c文件中提供了一些已封装完成的函数可供我们使用：（仅列出了需要使用到的函数） parseline：解析命令行字符串 addjob：向任务列表添加任务 deletejob：从任务列表移除任务 listjobs：输出任务列表中所有任务的信息 fgpid：获取当前前台任务的PID getjobpid/getjobjid：使用PID/Job ID获取任务实例 pid2jid：PID号转Job ID号 unix_error：发送错误信息并退出 Lab设计了16个Trace任务用于测试给出的Shell，我们可以使用Lab中提供的sdriver.pl工具测试我们的Shell代码： 1&gt; ./sdriver.pl -t traceXX.txt -s ./tsh -a &quot;-p&quot; # XX代表要使用的trace编号 作为参考，我们可以将每个Trace的输出结果与tshref.out中的相应内容进行比对以验证功能是否正确。 基本功能 eval及builtin_cmd 我们先从eval和builtin_cmd函数入手。对于eval函数，其基本的逻辑如下： 使用parseline函数解析命令行 边界判断（判断输入命令是否为空或仅有一个&amp;符号） 判断是否为内置函数，若是，则直接执行并返回 创建子进程并执行命令 将任务加入任务列表 若为前台任务，则等待其执行完成；否则输出信息并返回 于是我们可以快速写出其对应的代码实现： 12345678910111213141516171819202122232425262728293031323334353637void eval(char *cmdline) &#123; char *argv[MAXARGS]; //参数列表 int bg; //前后台标识符 pid_t pid; //最近创建子任务的PID号 //解析命令行 bg = parseline(cmdline, argv); //特判 if(argv[0] == NULL) return; if(!strcmp(argv[0], &quot;&amp;&quot;)) return; //内置函数判断 if(!builtin_cmd(argv))&#123; //创建子进程 if((pid = fork()) == 0)&#123; //执行任务 if(execve(argv[0], argv, environ) &lt; 0)&#123; printf(&quot;%s: Command not found.\\n&quot;, argv[0]); exit(0); &#125; &#125; //将任务加入任务列表 if(bg) addjob(jobs, pid, BG, cmdline); else addjob(jobs, pid, FG, cmdline); //前后台任务处理 if(bg)&#123; printf(&quot;[%d] (%d) %s&quot;, pid2jid(pid), pid, cmdline); &#125; else&#123; waitfg(pid); &#125; &#125; return;&#125; builtin_cmd函数的功能仅为判断命令是否为内置函数并调用对应的函数，因此其实现更为简单： 123456789101112131415161718192021222324int builtin_cmd(char **argv) &#123; //处理quit指令 if(!strcmp(argv[0], &quot;quit&quot;))&#123; exit(0); &#125; //处理jobs指令 else if(!strcmp(argv[0], &quot;jobs&quot;))&#123; listjobs(jobs); return 1; &#125; //处理bg指令 else if(!strcmp(argv[0], &quot;bg&quot;))&#123; do_bgfg(argv); return 1; &#125; //处理fg指令 else if(!strcmp(argv[0], &quot;fg&quot;))&#123; do_bgfg(argv); return 1; &#125; else return 0;&#125; do_bgfg 随后我们来处理内置函数bg和fg的实现。当用户输入bg或fg时，需要切换指定任务的运行状态。首先我们来看一下job实例的结构： 123456struct job_t &#123; pid_t pid; // 任务PID int jid; // 任务Job ID int state; // 任务状态：UNDEF（未定义）, BG（后台）, FG（前台）, or ST（停止） char cmdline[MAXLINE]; // 命令行字符串&#125;; 由此可知我们只需要切换job实例中的state变量即可。这一逻辑可以通过下面这段代码实现： 12345if(!strcmp(argv[0], &quot;fg&quot;))&#123; job-&gt;state = FG; //转为前台任务&#125;else&#123; job-&gt;state = BG; //转为后台任务&#125; 因此我们需要根据用户的输入获取到对应的job实例。用户可以通过PID或Job ID来指定要操作的任务，不过根据题目要求，我们需要讨论所有的输入情况： 1234567891011121314151617181920212223242526272829int jid;struct job_t *job;pid_t pid;//无参数的情况if(argv[1] == NULL)&#123; printf(&quot;%s command requires PID or %%jobid argument\\n&quot;, argv[0]); return;&#125;//输入Job ID的情况if(sscanf(argv[1], &quot;%%%d&quot;, &amp;jid) &gt; 0)&#123; job = getjobjid(jobs, jid); if(job == NULL || job-&gt;state == UNDEF)&#123; printf(&quot;%s: No such job\\n&quot;, argv[1]); return; &#125;&#125;//输入PID的情况else if(sscanf(argv[1], &quot;%d&quot;, &amp;pid) &gt; 0)&#123; job = getjobpid(jobs, pid); if(job == NULL || job-&gt;state == UNDEF)&#123; printf(&quot;(%s): No such process\\n&quot;, argv[1]); return; &#125;&#125;//输入其他字符的情况else&#123; printf(&quot;%s: argument must be a PID or %%jobid\\n&quot;, argv[0]); return;&#125; 随后我们需要向任务发送SIGCONT信号。需要注意的是，我们需要向任务及其子任务同时发送信号，因此我们需要在创建任务时将其自身和后续的子任务打包到一个独立的进程组中，这可以通过setpgid函数来实现： 1234567891011void eval(char *cmdline) &#123; ... if(!builtin_cmd(argv))&#123; if((pid = fork()) == 0)&#123; setpgid(0, 0); //将自身及子进程放入一个以自身PID为组号的进程组中 ... &#125; ... &#125;&#125; 现在我们就可以使用kill函数向整个进程组发送信号了： 1kill(-pid, SIGCONT); //向pid进程组发送SIGCONT信号 随后的行为和eval中类似，只需分情况处理前台或后台任务即可： 12345if(!strcmp(argv[0], &quot;fg&quot;))&#123; waitfg(pid);&#125;else&#123; printf(&quot;[%d] (%d) %s&quot;, job-&gt;jid, pid, job-&gt;cmdline);&#125; waitfg waitfg的作用基本就是在前台任务终止前锁住Shell进程的指令执行。我们可以使用while+pause语句来快速实现这一功能： 123456void waitfg(pid_t pid)&#123; while(pid == fgpid(jobs))&#123; pause(); &#125;&#125; 信号处理 SIGINT及SIGTSTP 首先我们来处理SIGINT和SIGTSTP信号。这两种信号的处理方式完全一致，均为向前台任务的整个进程组发送相应的信号： 1234pid_t pid = fgpid(jobs);if(pid != 0)&#123; kill(-pid, sig);&#125; 由于这一过程中可能会由于出现另外的异常而改变errno的值，因此我们需要在刚进入函数时保存errno的值，再在函数返回前将其恢复： 123int old_errno = errno;...errno = old_errno; SIGCHLD 按照实验要求，共有三种可能的情况会触发SIGCHLD信号： 子任务正常结束 前台任务被信号终止 前台任务被信号暂停 因此我们需要分情况处理： 1234567891011121314151617181920212223242526void sigchld_handler(int sig) &#123; int old_errno = errno; pid_t pid; int state; //子进程结束状态码 struct job_t *job; //对所有已终止或暂停的子进程进行操作 while((pid = waitpid(-1, &amp;state, WNOHANG | WUNTRACED)) &gt; 0)&#123; //正常退出的情况 if(WIFEXITED(state))&#123; deletejob(jobs, pid); &#125; //被信号终止的情况 else if(WIFSIGNALED(state))&#123; printf(&quot;Job [%d] (%d) terminated by signal %d\\n&quot;, pid2jid(pid), pid, WTERMSIG(state)); deletejob(jobs, pid); &#125; //被信号暂停的情况 else if(WIFSTOPPED(state))&#123; job = getjobpid(jobs, pid); job-&gt;state = ST; //将子进程设置为暂停状态 printf(&quot;Job [%d] (%d) stopped by signal %d\\n&quot;, job-&gt;jid, pid, WSTOPSIG(state)); &#125; &#125; errno = old_errno;&#125; 同样的，我们需要备份errno以防止破坏其他的操作。 调度排查 现在我们的程序已经能够通过绝大部分的Trace任务，但由于进程调度机制的存在，某些操作的执行顺序可能并不会如我们所愿，这样在某些情况下可能会导致竞争或死锁的问题，因此我们需要排查这些情况并解决。 首先在任务的添加和删除时，由于要修改全局变量jobs，我们不希望有其他信号处理函数打断这一过程导致jobs被修改，因此在执行这些函数时我们要屏蔽所有的信号接收： 12345678910111213141516171819202122232425262728void eval(char *cmdline) &#123; sigset_t mask_all, mask_prev; ... if(!builtin_cmd(argv))&#123; sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK, &amp;mask_all, &amp;mask_prev); ... if(bg) addjob(jobs, pid, BG, cmdline); else addjob(jobs, pid, FG, cmdline); sigprocmask(SIG_SETMASK, &amp;mask_prev, NULL); ... &#125;&#125;void sigchld_handler(int sig) &#123; sigset_t mask_all, mask_prev; ... sigfillset(&amp;mask_all); while((pid = waitpid(-1, &amp;state, WNOHANG | WUNTRACED)) &gt; 0)&#123; sigprocmask(SIG_BLOCK, &amp;mask_all, &amp;mask_prev); ... sigprocmask(SIG_SETMASK, &amp;mask_prev, NULL); &#125; ...&#125; 同理，在修改任务状态时我们也需要屏蔽所有信号： 1234567891011void do_bgfg(char **argv) &#123; ... sigset_t mask_all, mask_prev; ... sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK, &amp;mask_all, &amp;mask_prev); ... sigprocmask(SIG_SETMASK, &amp;mask_prev, NULL); ...&#125; 接着，我们继续检查eval函数，发现如果子进程在addjob函数被执行前便已终止，则sigchld_handler中的deletejob便无法正确删除相应的任务，因此我们需要在addjob被执行前屏蔽SIGCHLD信号： 123456789101112void eval(char *cmdline) &#123; ... sigset_t mask_one, mask_prev; ... if(!builtin_cmd(argv))&#123; sigemptyset(&amp;mask_one); sigaddset(&amp;mask_one, SIGCHLD); sigprocmask(SIG_BLOCK, &amp;mask_one, &amp;mask_prev); ... &#125;&#125; 然而，这一操作可能会使得子进程也无法接收到SIGCHLD信号，因此我们需要在创建子进程后恢复信号的接收： 1234567891011void eval(char *cmdline) &#123; ... if(!builtin_cmd(argv))&#123; if((pid = fork()) == 0)&#123; sigprocmask(SIG_SETMASK, &amp;mask_prev, NULL); ... &#125; ... &#125;&#125; 最后，我们考察waitfg函数，发现经过上面的修改后Shell进程已无法正确接受SIGCHLD指令。此时尽管我们可以暂时放开SIGCHLD信号的接收，但如果程序刚放开信号进程调度程序便调度至子进程并运行至子进程退出，则pause指令永远无法正确接收到SIGCHLD信号，此时便会出现死锁的情况。因此我们需要使用sigsuspend函数来代替以保证其不会被打断： 123456789void waitfg(pid_t pid)&#123; sigset_t empty_mask; sigemptyset(&amp;empty_mask); while(pid == fgpid(jobs))&#123; sigsuspend(&amp;empty_mask); &#125;&#125;","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"http://gonggongjohn.me/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Computer-System","slug":"Computer-System","permalink":"http://gonggongjohn.me/tags/Computer-System/"}]},{"title":"求解最大团","slug":"algorithm/course-exp/algorithm-exp13","date":"2021-01-08T03:45:00.000Z","updated":"2021-12-09T02:07:51.049Z","comments":true,"path":"2021/01/08/algorithm/course-exp/algorithm-exp13/","link":"","permalink":"http://gonggongjohn.me/2021/01/08/algorithm/course-exp/algorithm-exp13/","excerpt":"内容与设计思想 给定一个图，如下所示。请找出这个图的最大团。","text":"内容与设计思想 给定一个图，如下所示。请找出这个图的最大团。 clique 实现代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;algorithm&gt;#include &lt;set&gt;#include &lt;vector&gt;using namespace std;int adj[10][10] = &#123;0&#125;, n;vector&lt;set&lt;int&gt;&gt; cliques;void find_clique(set&lt;int&gt; r, set&lt;int&gt; p, set&lt;int&gt; x)&#123; if(p.empty() &amp;&amp; x.empty())&#123; cliques.push_back(r); &#125; else if (p.empty())&#123; return; &#125; set&lt;int&gt; p_mut = p; for(int iter : p)&#123; set&lt;int&gt; r_tmp = r, p_tmp, x_tmp, adj_tmp; r_tmp.insert(iter); for (int i = 0; i &lt; n; i++) if(adj[iter][i] == 1) adj_tmp.insert(i); set_intersection(begin(p_mut), end(p_mut), begin(adj_tmp), end(adj_tmp), inserter(p_tmp, p_tmp.begin())); set_intersection(begin(x), end(x), begin(adj_tmp), end(adj_tmp), inserter(x_tmp, x_tmp.begin())); find_clique(r_tmp, p_tmp, x_tmp); p_mut.erase(iter); x.insert(iter); &#125;&#125;int main() &#123; ifstream fin(&quot;data.txt&quot;); set&lt;int&gt; r, p, x; fin&gt;&gt;n; while(!fin.eof())&#123; int fe, te; fin&gt;&gt;fe&gt;&gt;te; adj[fe][te] = 1; adj[te][fe] = 1; &#125; for(int i = 0; i &lt; n; i++) p.insert(i); find_clique(r, p, x); unsigned int max_cs = 0; for(int i = 0; i &lt; cliques.size(); i++) &#123; if(cliques[i].size() &gt; max_cs) max_cs = cliques[i].size(); &#125; for(int i = 0; i &lt; cliques.size(); i++) &#123; if(cliques[i].size() == max_cs)&#123; for(int iter: cliques[i])&#123; cout&lt;&lt;iter&lt;&lt;&quot; &quot;; &#125; cout&lt;&lt;endl; &#125; &#125; fin.close(); return 0;&#125; 算法正确性 使用Bron-Kerbosch算法，维护三个不相交的顶点集 \\(P,R,X\\)，其中 \\(P\\) 代表待搜索的元素，\\(R\\) 代表当前极大环中的元素，\\(X\\) 代表被排除的元素。从图中的某个点开始，递归的遍历所有其邻接顶点，当 \\(P\\) 为空集时，若 \\(X\\) 也为空集，则表明找到了一个极大团，否则回溯到上一节点，并将其从\\(P\\) 中除去加入 \\(X\\) 中。最终即可找到所有极大团，进而比较找出整张图中的最大环。 总结 求最大团问题是一个NPC问题，即无法确定其是否存在多项式时间算法的可归约问题。Bron-Kerbosch算法的时间复杂度约为 \\(\\mathcal{O}(3^n)\\)，随着数据规模增大运行时间会显著增加。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"K-Means聚类与层次聚类","slug":"machine-learning/clustering","date":"2020-12-30T13:22:44.000Z","updated":"2022-02-11T08:00:32.128Z","comments":true,"path":"2020/12/30/machine-learning/clustering/","link":"","permalink":"http://gonggongjohn.me/2020/12/30/machine-learning/clustering/","excerpt":"Cluster Analysis Cluster analysis or clustering is a task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups. It is a main task of exploratory data mining, and a common technique for statistical data analysis which is used in many fields including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.","text":"Cluster Analysis Cluster analysis or clustering is a task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups. It is a main task of exploratory data mining, and a common technique for statistical data analysis which is used in many fields including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning. There are various clustering algorithms that differ significantly in their understanding of what constitutes a cluster and how to effectively find them, which proved to be useful in different scenarios. K-means Clustering Concept K-means clustering is a partition-based method that can be used to partition a dataset into a fixed number of clusters. We can use the famous priest-villager model to illustrate the main idea of K-means algorithm. There are four priests preaching in the countryside. At first, they chose four preaching points arbitrarily, and told villagers to take the preaching course that is nearest to their own house. After the first class, some villagers complained that the preaching points were still too far from their home, so each of the priests collected the home addresses of all the villagers that came to his class and move the preaching point to the center of all the addresses. Since the update of preaching points, some villagers found that another preaching points became closer to their house than the previous one, so they chose to take the course at the new preaching point. In this way, the priests updated their preaching points every week, and villagers decided which course to take according to the distance of each preaching points. After several weeks, the preaching points became stable and both the villagers and the priests got satisfied. In formal words, K-means algorithm can be described as follows: Choose a set of \\[K\\] initial points \\[\\{c_1, c_2, ..., c_K\\}\\] that denotes the centroid of each cluster Iteratively execute the following steps until all the centroid points stop to change (or hit some global restriction): For each sample points in the dataset, compute the distances from it to every centroids and assign it to the centroid with the smallest distance Recompute the position of each centroid according to the positions of all the samples assigned to it Mathematical Details Intuitively, we want to find a set of centroids and an assignment of every instances in the dataset to these centroids so that every centroid covers the most reasonable amount of instances and anchors at exactly the average point of all the instances that assigned to it. We can use a mathematical trick to convert this intuition into an optimization problem. If we define an indicator variable \\[r_{nk}\\] to describe which cluster an instance is in, which is \\[ r_{nk} = \\left\\{ \\begin{aligned} &amp;1, &amp;if \\ n \\ is \\ assigned \\ to \\ k \\\\ &amp;0, &amp;otherwise \\end{aligned} \\right. \\] , then the sum of the distance of all the instances in the dataset to their centroids can be written as \\[ J = \\sum_{n=1}^N \\sum_{k=1}^K r_{nk} \\cdot dist(x_n, c_k) \\] where \\[N\\] is the size of the dataset, \\[K\\] is the number of clusters, \\[x_n\\] is the \\[n^{th}\\] instance in the dataset, \\[c_k\\] is the \\[k^{th}\\] centroid, \\[dist(a, b)\\] is the distance between \\[a\\] and \\[b\\]. Specifically, if the dataset is in the Euclidean space, then we can use the square of Euclidean distance as the distance function (square is for the convenience of derivation operations), which is \\[ dist(x_n, c_k) = ||x_n - c_k||^2 = (x_{n1}-c_{k1})^2 + (x_{n2}-c_{k2})^2 + ... + (x_{nm}-c_{km})^2 \\] where \\[x_{ni}\\] and \\[c_{ki}\\] is the \\[i^{th}\\] component of \\[x\\] and \\[c\\] respectively. If the dataset denotes some broader set (usually text data), we can also use the Jaccard distance as the distance function, which is defined as \\[ dist(A, B) = \\frac{A \\Delta B}{|A \\cup B|} = \\frac{|A \\cup B - A \\cap B|}{|A \\cup B|} \\] where \\[A, B\\] are two sets and \\[|S|\\] is the size of set \\[S\\]. Therefore, our goal becomes to minimize the function \\[J\\]. A famous solution to this kind of problems is the EM(Expectation-Maximization) Algorithm where optimizing \\[r_{nk}\\] is the expectation step and minimizing \\[dist(x_n, c_k)\\] is the maximization step. First we optimize \\[r_{nk}\\]. Since \\[J\\] is the linear function of \\[r_{nk}\\], we can simply assigned every instance to the centroid \\[k\\] if the distance between them is the smallest among all centroids to get the minimum \\[J\\] when the centroids are fixed. Then we try to minimize the distance function. Here we only consider the situation when we use the Euclidean distance as the distance metrics. More specifically, our goal is to minimize \\[ J = \\sum_{n=1}^N \\sum_{k=1}^K r_{nk} ||x_n - c_k||^2 \\] when \\[r_{nk}\\] is fixed (This function are also called the sum of squared error function). Since each cluster is independent, we can optimize each cluster respectively to get the global minimum, which is to minimize the following expression \\[ J_k = \\sum_{n=1}^N r_{nk} \\cdot ||x_n-c_k||^2 \\] for every \\[k\\] from \\[1\\] to \\[K\\]. We can notice that this is a quadratic function of \\[c_k\\], so we can simply set its derivative function to \\[0\\] and solve for \\[c_k\\] to get the minimum point. From this we can get the final formula to find the position of \\[c_k\\] \\[ c_k = \\frac{\\sum_\\limits{n=1}^N r_{nk}x_n}{\\sum_\\limits{n=1}^N r_{nk}} \\] Since both of the two steps aims at reducing \\[J\\] while \\[J\\] is always greater than \\[0\\], we can prove that the function will finally converges. Complexity Analysis We can implement K-means algorithm in pseudo-code: 1234567891011121314K-MEANS(K, t, s): &#x2F;&#x2F;The paramaters denote the number of clusters, the iteration times and the dataset respectivelyInitialize c[K] &#x2F;&#x2F;Denote the centroid setWhile t For i in s min_dist &#x3D; INF For j &#x3D; 1 to K d &#x3D; Distance between i and c[j] If d &lt; min_dist min_dist &#x3D; d min_index &#x3D; j Append i into the cluster set of c[min_index] For i &#x3D; 1 to K c[i].pos &#x3D; Mean position of all the points in the cluster set of c[i]return c If we use the standard Euclidean distance (\\[L_2\\] norm) as the distance metrics, then the time complexity of K-means algorithm is \\[\\mathcal{O}(tknm)\\] where \\[t\\] is the iteration times, \\[k\\] is the number of clusters, \\[n\\] is the size of the dataset and \\[m\\] is the dimension of each sample in the dataset. Similarly, if the samples of the dataset and the centroids are all in \\[m\\]-dimensional Euclidean space, than the space complexity of K-means algorithm is \\[\\mathcal{O}((n+k) \\cdot m)\\] where \\[n\\] is the size of the dataset, \\[k\\] is the number of clusters. Applications Due to its simplicity, K-means clustering algorithm has been successfully used in many domains such as market segmentation, computer vision and astronomy. It is also used as a preprocessing step before many other alogirithms to find a starting configuration. For example, in computer graphics, there is a task called color quantization which is to reduce the color palette of a picture into a fixed number. K-means algorithm can easily been used for this task and often produces a competitive result. As an unsupervised learning algorithm, K-means algorithm is also widely used to explore the implicit features of a dataset before applying subsequent learning algorithms in data mining area, which can be very useful in some NLP(Natural Language Processing) and computer vision tasks. Pros And Cons The advantage of K-means algorithm is that it has a relatively low time and space complexity, and has a good flexibility even when applying to a large dataset. However, there are also some drawbacks of it: The algorithm may converges to a local minimum, which is counterintuitive in some situation. Unable to get a correct partition when the clusters is not spherical or non-convex. The algorithm is sensitive to the cluster number K and the initial point of the centroids. Hierarchical Clustering Concept As its name suggests, hierarchical clustering is a hierarchical-based method to group similar objects into clusters. Its main idea is to build a hierarchical tree (or dendrogram) to represent the nested group relations. In general, there are two different strategies to achieve this goal: Agglomerative Hierarchical Clustering and Divisive Hierarchical Clustering. Agglomative method is a bottom-up method, which is to regard each of the instances as a single cluster at first and then keep merging the most similar clusters until there is only one cluster left. In comparison, divisive method is a top-down method, which consider the whole dataset as a big cluster and keep splitting down until each of the clusters have only one instance in it. Complexity Analysis Agglomerative hierarchical clustering algorithm can be implemented as follow: 123456789101112131415AHC(s): &#x2F;&#x2F;s denotes the datasetInitialize c &#x2F;&#x2F;Denote the clusters at the current levelAppend every instance from s to cWhile c.length !&#x3D; 1 min_dist &#x3D; INF For i in c For j in c If i !&#x3D; j d &#x3D; Distance between i and j If d &lt; min_dist min_dist &#x3D; d min_cp &#x3D; i, j cm &#x3D; merge(min_cp) Remove min_cp from c Append cm to c The basic structure of Divisive hierarchical clustering algorithm is the same as the agglomerative one, except the divisive one needs to split the farthest sub-clusters from the larger cluster in every loop. If we use the Euclidean distance as the distance metrics, then the time complexity of hierarchical clustering is \\[\\mathcal{O}(mn^3)\\] where \\[m\\] is the dimension of each sample in the dataset and \\[n\\] is the size of the dataset. Since every cluster needs to record its member and its sub-clusters, the space complexity of hierarchical clustering is \\[\\mathcal{O}(n^2)\\] Applications Hierarchical clustering is an ideal methods to find the hierarchical relations between instances. These instances often differ from each other in some aspects, but not to the extent that we should put them into two mutual exclusive groups. For instance, we can use hierarchical clustering to find the members of each party in America senate. To achieve this, we can define how much one senator agrees with another's words as a metrics, and implement hierarchical clustering algorithm on all senator's twitter accounts. Pros And Cons A conspicuous benefit for hierarchical clustering is that it can get the whole cluster information once-and-for-all. Once we get the hierarchical relation tree of a dataset, we can probe the cluster information in different granularity and get the fittest cluster results we want to get. However, the defects of it is equally distinct. The huge cost of computing distance between every two clusters and storing hierarchical information makes it unsuitable to handle large dataset. Once a cluster partition or congregation is determined, it is not easy to change since every subsequent judgement is based on clusters existed, which gives the algorithm a poor flexibility. Moreover, the strategy for merging or splitting the clusters is a greedy strategy, which may leads to an local-optimum result. K-means V.S. Hierarchical Clustering In view of their different features, K-means and hierarchical clustering are often used in different scenarios. K-means can be easily adapted to a large or dense dataset thanks to its simplity and low computational cost. When it is uneasy to determine how many clusters in the dataset or the instance relations are unambiguous, hierarchical clustering proves to be a better choice. In practice, we often perform K-means clustering first to get a rough understanding of a dataset and reduce the data size. Then we perform hierarchical clustering to explore the deeper interrelationships among the dataset.","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://gonggongjohn.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"http://gonggongjohn.me/tags/Machine-Learning/"}]},{"title":"单源最短路径","slug":"algorithm/course-exp/algorithm-exp12","date":"2020-12-25T03:45:00.000Z","updated":"2021-12-09T02:07:41.756Z","comments":true,"path":"2020/12/25/algorithm/course-exp/algorithm-exp12/","link":"","permalink":"http://gonggongjohn.me/2020/12/25/algorithm/course-exp/algorithm-exp12/","excerpt":"内容与设计思想 川西风光几枚，以下图片是川西路线图。张三是旅游爱好者，他从成都出发自驾到西藏江达。","text":"内容与设计思想 川西风光几枚，以下图片是川西路线图。张三是旅游爱好者，他从成都出发自驾到西藏江达。 travel_map 从成都到江达的最短自驾路线是什么？可以用Dijkstra算法来求解。 张三把理塘列为必游之地。怎么规划路线，使得总行程最短？ 张三觉得理塘风景很美，道孚也不错，两个地方如果能够去一个地方的话就心满意足了。应该怎么安排行程使得总行程最短？ 张三在规划线路的时候，发现不同路况行驶速度不一样。地图中粗的路径表示平均时速可以达到80公里每小时，而细的路径表示平均时速仅仅有每小时60公里每小时。那么用时最短的路径是哪一条？ （思考题）考虑到Dijkstra算法仅仅从一段开始寻找路径，效率不高。李教授想到一个高招，就是同时从出发地和目的地进行搜索，扩展搜索节点，然后两个方向扩展的路径会在中途相遇，则拼接起来的路径就是最短路径。如何实现李教授这个想法？ 实现代码 从成都到江达的最短路 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;stack&gt;#include &lt;cstring&gt;#include &lt;map&gt;#define SUP 100000005using namespace std;int graph[50][50], d[50], visit[50] = &#123;0&#125;, pred[50] = &#123;0&#125;;//Procedure of finding the shortest pathvoid find_path(int from, int to, int n)&#123; int flag = 0; for(int i = 0; i &lt; n; i++) d[i] = SUP; for(int i = 0; i &lt; n; i++) visit[i] = 0; d[from] = 0; while (!flag)&#123; int min_dist = SUP, min_idx = -1; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; d[i] &lt; min_dist)&#123; min_dist = d[i]; min_idx = i; &#125; &#125; visit[min_idx] = 1; if(min_idx == to) break; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; graph[min_idx][i] != SUP)&#123; if(d[i] &gt; d[min_idx] + graph[min_idx][i]) &#123; d[i] = d[min_idx] + graph[min_idx][i]; pred[i] = min_idx; &#125; &#125; &#125; flag = 1; for (int i = 0; i &lt; n; i++) &#123; if (visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125;&#125;int main() &#123; ifstream fin(&quot;data.txt&quot;); stack&lt;int&gt; path; map&lt;string, int&gt; location_index; map&lt;int, string&gt; inv_location_index; int n = 0, start, end, flag = 0; string start_city, end_city; for(int i = 0; i &lt; 50; i++) for(int j = 0; j &lt; 50; j++) &#123; graph[i][j] = SUP; graph[j][i] = SUP; &#125; //Read in data &amp; build the graph while(!fin.eof())&#123; string from, to; int from_index, to_index, distance, speed; fin&gt;&gt;from&gt;&gt;to&gt;&gt;distance&gt;&gt;speed; if (location_index.find(from) == location_index.end())&#123; from_index = n; location_index[from] = from_index; inv_location_index[from_index] = from; n++; &#125; else&#123; from_index = location_index[from]; &#125; if (location_index.find(to) == location_index.end())&#123; to_index = n; location_index[to] = to_index; inv_location_index[to_index] = to; n++; &#125; else&#123; to_index = location_index[to]; &#125; graph[from_index][to_index] = distance; graph[to_index][from_index] = distance; &#125; start_city = &quot;成都&quot;; end_city = &quot;江达&quot;; start = location_index[start_city]; end = location_index[end_city]; find_path(start, end, n); //Recall the path int cur = end; path.push(end); while(cur != start)&#123; path.push(pred[cur]); cur = pred[cur]; &#125; cout&lt;&lt;&quot;路径：&quot;; while(!path.empty()) &#123; cout &lt;&lt; inv_location_index[path.top()] &lt;&lt; &quot; &quot;; path.pop(); &#125; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total: &quot;&lt;&lt;d[end]&lt;&lt;&quot;km&quot;&lt;&lt;endl; fin.close(); return 0;&#125; 从成都经过理塘再到江达的最短路 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;stack&gt;#include &lt;cstring&gt;#include &lt;map&gt;#define SUP 100000005using namespace std;int graph[50][50], d[50], visit[50] = &#123;0&#125;, pred[50] = &#123;0&#125;;void find_path(int from, int to, int n)&#123; int flag = 0; for(int i = 0; i &lt; n; i++) d[i] = SUP; for(int i = 0; i &lt; n; i++) visit[i] = 0; d[from] = 0; while (!flag)&#123; int min_dist = SUP, min_idx = -1; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; d[i] &lt; min_dist)&#123; min_dist = d[i]; min_idx = i; &#125; &#125; visit[min_idx] = 1; if(min_idx == to) break; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; graph[min_idx][i] != SUP)&#123; if(d[i] &gt; d[min_idx] + graph[min_idx][i]) &#123; d[i] = d[min_idx] + graph[min_idx][i]; pred[i] = min_idx; &#125; &#125; &#125; flag = 1; for (int i = 0; i &lt; n; i++) &#123; if (visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125;&#125;int main() &#123; ifstream fin(&quot;data.txt&quot;); stack&lt;int&gt; path; int tot_dist = 0; map&lt;string, int&gt; location_index; map&lt;int, string&gt; inv_location_index; int n = 0, start, mid, end; string start_city, mid_city, end_city; for(int i = 0; i &lt; 50; i++) for(int j = 0; j &lt; 50; j++) &#123; graph[i][j] = SUP; graph[j][i] = SUP; &#125; while(!fin.eof())&#123; string from, to; int from_index, to_index, distance, speed; fin&gt;&gt;from&gt;&gt;to&gt;&gt;distance&gt;&gt;speed; if (location_index.find(from) == location_index.end())&#123; from_index = n; location_index[from] = from_index; inv_location_index[from_index] = from; n++; &#125; else&#123; from_index = location_index[from]; &#125; if (location_index.find(to) == location_index.end())&#123; to_index = n; location_index[to] = to_index; inv_location_index[to_index] = to; n++; &#125; else&#123; to_index = location_index[to]; &#125; graph[from_index][to_index] = distance; graph[to_index][from_index] = distance; &#125; start_city = &quot;成都&quot;; mid_city = &quot;理塘&quot;; end_city = &quot;江达&quot;; start = location_index[start_city]; mid = location_index[mid_city]; end = location_index[end_city]; find_path(mid, end, n); int cur = end; path.push(end); while(cur != mid)&#123; path.push(pred[cur]); cur = pred[cur]; &#125; tot_dist += d[end]; find_path(start, mid, n); cur = pred[mid]; path.push(pred[mid]); while(cur != start)&#123; path.push(pred[cur]); cur = pred[cur]; &#125; cout&lt;&lt;&quot;路径：&quot;; while(!path.empty())&#123; cout&lt;&lt;inv_location_index[path.top()]&lt;&lt;&quot; &quot;; path.pop(); &#125; tot_dist += d[mid]; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total: &quot;&lt;&lt;tot_dist&lt;&lt;&quot;km&quot;&lt;&lt;endl; fin.close(); return 0;&#125; 从成都经过理塘或道孚再到江达的最短路 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstring&gt;#include &lt;stack&gt;#include &lt;map&gt;#define SUP 100000005using namespace std;int graph[50][50], d[50], visit[50] = &#123;0&#125;, pred[50] = &#123;0&#125;;void find_path(int from, int to, int n)&#123; int flag = 0; for(int i = 0; i &lt; n; i++) d[i] = SUP; for(int i = 0; i &lt; n; i++) visit[i] = 0; d[from] = 0; while (!flag)&#123; int min_dist = SUP, min_idx = -1; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; d[i] &lt; min_dist)&#123; min_dist = d[i]; min_idx = i; &#125; &#125; visit[min_idx] = 1; if(min_idx == to) break; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; graph[min_idx][i] != SUP)&#123; if(d[i] &gt; d[min_idx] + graph[min_idx][i]) &#123; d[i] = d[min_idx] + graph[min_idx][i]; pred[i] = min_idx; &#125; &#125; &#125; flag = 1; for (int i = 0; i &lt; n; i++) &#123; if (visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125;&#125;int main() &#123; ifstream fin(&quot;data.txt&quot;); stack&lt;int&gt; path_1, path_2; int tot_dist_1 = 0, tot_dist_2 = 0; map&lt;string, int&gt; location_index; map&lt;int, string&gt; inv_location_index; int n = 0, start, mid_1, mid_2, end; string start_city, mid_city_1, mid_city_2, end_city; for(int i = 0; i &lt; 50; i++) for(int j = 0; j &lt; 50; j++) &#123; graph[i][j] = SUP; graph[j][i] = SUP; &#125; while(!fin.eof())&#123; string from, to; int from_index, to_index, distance, speed; fin&gt;&gt;from&gt;&gt;to&gt;&gt;distance&gt;&gt;speed; if (location_index.find(from) == location_index.end())&#123; from_index = n; location_index[from] = from_index; inv_location_index[from_index] = from; n++; &#125; else&#123; from_index = location_index[from]; &#125; if (location_index.find(to) == location_index.end())&#123; to_index = n; location_index[to] = to_index; inv_location_index[to_index] = to; n++; &#125; else&#123; to_index = location_index[to]; &#125; graph[from_index][to_index] = distance; graph[to_index][from_index] = distance; &#125; start_city = &quot;成都&quot;; mid_city_1 = &quot;理塘&quot;; mid_city_2 = &quot;道孚&quot;; end_city = &quot;江达&quot;; start = location_index[start_city]; mid_1 = location_index[mid_city_1]; mid_2 = location_index[mid_city_2]; end = location_index[end_city]; //Find path 1 find_path(mid_1, end, n); int cur = end; path_1.push(end); while(cur != mid_1)&#123; path_1.push(pred[cur]); cur = pred[cur]; &#125; tot_dist_1 += d[end]; find_path(start, mid_1, n); cur = pred[mid_1]; path_1.push(pred[mid_1]); while(cur != start)&#123; path_1.push(pred[cur]); cur = pred[cur]; &#125; tot_dist_1 += d[mid_1]; //Find path 2 find_path(mid_2, end, n); cur = end; path_2.push(end); while(cur != mid_2)&#123; path_2.push(pred[cur]); cur = pred[cur]; &#125; tot_dist_2 += d[end]; find_path(start, mid_2, n); cur = pred[mid_2]; path_2.push(pred[mid_2]); while(cur != start)&#123; path_2.push(pred[cur]); cur = pred[cur]; &#125; tot_dist_2 += d[mid_2]; //Compare and print the smaller one if(tot_dist_1 &lt;= tot_dist_2)&#123; cout&lt;&lt;&quot;途径：理塘&quot;&lt;&lt;endl; cout&lt;&lt;&quot;路径：&quot;; while(!path_1.empty())&#123; int p = path_1.top(); cout&lt;&lt;inv_location_index[p]&lt;&lt;&quot; &quot;; path_1.pop(); &#125; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total: &quot;&lt;&lt;tot_dist_1&lt;&lt;&quot;km&quot;&lt;&lt;endl; &#125; else&#123; cout&lt;&lt;&quot;途径：道孚&quot;&lt;&lt;endl; cout&lt;&lt;&quot;路径：&quot;; while(!path_2.empty())&#123; int p = path_2.top(); cout&lt;&lt;inv_location_index[p]&lt;&lt;&quot; &quot;; path_2.pop(); &#125; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total: &quot;&lt;&lt;tot_dist_2&lt;&lt;&quot;km&quot;&lt;&lt;endl; &#125; fin.close(); return 0;&#125; 有时速限制时的最短路 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;stack&gt;#include &lt;cstring&gt;#include &lt;map&gt;#define SUP 100000005using namespace std;double graph[50][50], d[50];int graph_dist[50][50], visit[50] = &#123;0&#125;, pred[50] = &#123;0&#125;;void find_path(int from, int to, int n)&#123; int flag = 0; for(int i = 0; i &lt; n; i++) d[i] = SUP; for(int i = 0; i &lt; n; i++) visit[i] = 0; d[from] = 0; while (!flag)&#123; double min_dist = SUP; int min_idx = -1; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; d[i] &lt; min_dist)&#123; min_dist = d[i]; min_idx = i; &#125; &#125; visit[min_idx] = 1; if(min_idx == to) break; for(int i = 0; i &lt; n; i++)&#123; if (visit[i] == 0 &amp;&amp; graph[min_idx][i] != SUP)&#123; if(d[i] &gt; d[min_idx] + graph[min_idx][i]) &#123; d[i] = d[min_idx] + graph[min_idx][i]; pred[i] = min_idx; &#125; &#125; &#125; flag = 1; for (int i = 0; i &lt; n; i++) &#123; if (visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125;&#125;int main() &#123; ifstream fin(&quot;data.txt&quot;); stack&lt;int&gt; path; map&lt;string, int&gt; location_index; map&lt;int, string&gt; inv_location_index; int n = 0, start, end, flag = 0, tot_dist = 0; string start_city, end_city; for(int i = 0; i &lt; 50; i++) for(int j = 0; j &lt; 50; j++) &#123; graph[i][j] = SUP; graph[j][i] = SUP; graph_dist[i][j] = SUP; graph_dist[j][i] = SUP; &#125; while(!fin.eof())&#123; string from, to; int from_index, to_index, distance, speed; fin&gt;&gt;from&gt;&gt;to&gt;&gt;distance&gt;&gt;speed; if (location_index.find(from) == location_index.end())&#123; from_index = n; location_index[from] = from_index; inv_location_index[from_index] = from; n++; &#125; else&#123; from_index = location_index[from]; &#125; if (location_index.find(to) == location_index.end())&#123; to_index = n; location_index[to] = to_index; inv_location_index[to_index] = to; n++; &#125; else&#123; to_index = location_index[to]; &#125; graph[from_index][to_index] = (double)distance / speed; graph[to_index][from_index] = (double)distance / speed; graph_dist[from_index][to_index] = distance; graph_dist[to_index][from_index] = distance; &#125; for(int i = 0; i &lt; n; i++) d[i] = SUP; start_city = &quot;成都&quot;; end_city = &quot;江达&quot;; start = location_index[start_city]; end = location_index[end_city]; find_path(start, end, n); int cur = end; path.push(end); while(cur != start)&#123; path.push(pred[cur]); tot_dist += graph_dist[cur][pred[cur]]; cur = pred[cur]; &#125; cout&lt;&lt;&quot;路径：&quot;; while(!path.empty()) &#123; cout &lt;&lt; inv_location_index[path.top()] &lt;&lt; &quot; &quot;; path.pop(); &#125; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total: &quot;&lt;&lt;tot_dist&lt;&lt;&quot;km&quot;&lt;&lt;endl; fin.close(); return 0;&#125; 分别从两边开始搜索的最短路 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;stack&gt;#include &lt;cstring&gt;#include &lt;map&gt;#define SUP 100000005using namespace std;int graph[50][50], d1[50], d2[50], visit_1[50], visit_2[50], pred_1[50] = &#123;0&#125;, pred_2[50] = &#123;0&#125;, inter_idx;void find_path(int from, int to, int n)&#123; int flag = 0; for(int i = 0; i &lt; n; i++) d1[i] = SUP; for(int i = 0; i &lt; n; i++) d2[i] = SUP; for(int i = 0; i &lt; n; i++) visit_1[i] = 0; for(int i = 0; i &lt; n; i++) visit_2[i] = 0; d1[from] = 0; d2[to] = 0; while (!flag)&#123; int min_dist = SUP, min_idx_1 = -1, min_idx_2 = -1; for(int i = 0; i &lt; n; i++)&#123; if (visit_1[i] == 0 &amp;&amp; d1[i] &lt; min_dist)&#123; min_dist = d1[i]; min_idx_1 = i; &#125; &#125; visit_1[min_idx_1] = 1; min_dist = SUP; for(int i = 0; i &lt; n; i++)&#123; if (visit_2[i] == 0 &amp;&amp; d2[i] &lt; min_dist)&#123; min_dist = d2[i]; min_idx_2 = i; &#125; &#125; visit_2[min_idx_2] = 1; if(visit_1[min_idx_2] == 1 || visit_2[min_idx_1] == 1) &#123; inter_idx = visit_1[min_idx_2] ? min_idx_2 : min_idx_1; break; &#125; if(min_idx_1 == to || min_idx_2 == from) break; for(int i = 0; i &lt; n; i++)&#123; if (visit_1[i] == 0 &amp;&amp; graph[min_idx_1][i] != SUP)&#123; if(d1[i] &gt; d1[min_idx_1] + graph[min_idx_1][i]) &#123; d1[i] = d1[min_idx_1] + graph[min_idx_1][i]; pred_1[i] = min_idx_1; &#125; &#125; &#125; for(int i = 0; i &lt; n; i++)&#123; if (visit_2[i] == 0 &amp;&amp; graph[min_idx_2][i] != SUP)&#123; if(d2[i] &gt; d1[min_idx_2] + graph[min_idx_2][i]) &#123; d2[i] = d1[min_idx_2] + graph[min_idx_2][i]; pred_2[i] = min_idx_2; &#125; &#125; &#125; flag = 1; for (int i = 0; i &lt; n; i++) &#123; if (visit_1[i] == 0 || visit_2[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125;&#125;int main() &#123; ifstream fin(&quot;data.txt&quot;); stack&lt;int&gt; path; map&lt;string, int&gt; location_index; map&lt;int, string&gt; inv_location_index; int n = 0, start, end, flag = 0, tot_dist = 0; string start_city, end_city; for(int i = 0; i &lt; 50; i++) for(int j = 0; j &lt; 50; j++) &#123; graph[i][j] = SUP; graph[j][i] = SUP; &#125; while(!fin.eof())&#123; string from, to; int from_index, to_index, distance, speed; fin&gt;&gt;from&gt;&gt;to&gt;&gt;distance&gt;&gt;speed; if (location_index.find(from) == location_index.end())&#123; from_index = n; location_index[from] = from_index; inv_location_index[from_index] = from; n++; &#125; else&#123; from_index = location_index[from]; &#125; if (location_index.find(to) == location_index.end())&#123; to_index = n; location_index[to] = to_index; inv_location_index[to_index] = to; n++; &#125; else&#123; to_index = location_index[to]; &#125; graph[from_index][to_index] = distance; graph[to_index][from_index] = distance; &#125; start_city = &quot;成都&quot;; end_city = &quot;江达&quot;; start = location_index[start_city]; end = location_index[end_city]; find_path(start, end, n); int cur = inter_idx; path.push(inter_idx); while(cur != start)&#123; path.push(pred_1[cur]); cur = pred_1[cur]; &#125; tot_dist += d1[inter_idx]; cout&lt;&lt;&quot;路径：&quot;; while(!path.empty()) &#123; cout &lt;&lt; inv_location_index[path.top()] &lt;&lt; &quot; &quot;; path.pop(); &#125; cur = inter_idx; while(cur != end)&#123; cout&lt;&lt;inv_location_index[pred_2[cur]]&lt;&lt;&quot; &quot;; cur = pred_2[cur]; &#125; tot_dist += d2[inter_idx]; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total: &quot;&lt;&lt;tot_dist&lt;&lt;&quot;km&quot;&lt;&lt;endl; fin.close(); return 0;&#125; 算法正确性 从成都到江达的最短路 使用Dijkstra算法思想，每次从未完成点集中选择离源点距离最短的加入已完成点集，并更新与其相邻所有点到源点的最短距离及对应的前继节点编号，最终即可得到源点到目标点的最短路径。 从成都经过理塘再到江达的最短路 使用(1)的算法先找出成都到理塘的最短路径，再以理塘为起点找出到江达的最短路径，拼在一起即为满足要求的最短路。 从成都经过理塘或道孚再到江达的最短路 使用(2)的方法先找出成都经过理塘到江达的最短路径，再找出成都经过道孚到江达的最短路径，比较两者路径长度选择更短的即可。 有时速限制时的最短路 在建图时，将最短行驶时间（路程/时速限制）作为每条边的权值，再使用(1)的算法搜索即可。 分别从两边开始搜索的最短路 使用(1)的算法，分别从两边开始遍历图。当其中一个遍历过程遍历到另一个的路径上时，记录相遇节点并停止遍历。再分别回溯即可拼接成完整的最短路径。 总结 旅行路径规划问题本质上即为单源最短路问题，可使用Dijkstra算法在 \\(\\mathcal{O}(E^2)\\) 的时间内找到最短路。 第(1)(3)(4)(5)问的最短路径结果如下： 1 第(2)的最短路径结果如下： 2","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"最小生成树","slug":"algorithm/course-exp/algorithm-exp11","date":"2020-12-18T03:45:00.000Z","updated":"2021-12-09T01:54:08.303Z","comments":true,"path":"2020/12/18/algorithm/course-exp/algorithm-exp11/","link":"","permalink":"http://gonggongjohn.me/2020/12/18/algorithm/course-exp/algorithm-exp11/","excerpt":"内容与设计思想 国家电网公司想在全国布局超高压输电网络，联通所有省会城市。为了降低成本，并且达到某些硬性要求，国家电网按照以下五种策略进行规划布局。 要求整个电网的长度最短。 要求在西宁与郑州拉一根直达专线的情况下，使得整个电网长度最短 要求不仅在西宁与郑州之间拉直达专线，还在杭州与长沙之间拉直达专线的情况下，使得整个电网长度最短。 在香港与澳门、澳门与广州不拉直达线路的前提之下，使得整个电网的长度最短。 山东、河南、山西、甘肃、青海、新疆以及比他们更北的省份称为北方省份，其余省份称为南方省份。如果在南方省份和北方省份之间仅规划一条直通专线，如何使得整个电网的长度最短。","text":"内容与设计思想 国家电网公司想在全国布局超高压输电网络，联通所有省会城市。为了降低成本，并且达到某些硬性要求，国家电网按照以下五种策略进行规划布局。 要求整个电网的长度最短。 要求在西宁与郑州拉一根直达专线的情况下，使得整个电网长度最短 要求不仅在西宁与郑州之间拉直达专线，还在杭州与长沙之间拉直达专线的情况下，使得整个电网长度最短。 在香港与澳门、澳门与广州不拉直达线路的前提之下，使得整个电网的长度最短。 山东、河南、山西、甘肃、青海、新疆以及比他们更北的省份称为北方省份，其余省份称为南方省份。如果在南方省份和北方省份之间仅规划一条直通专线，如何使得整个电网的长度最短。 请分别根据这五种情况计算最优情况。 china_map 提示： 如无特殊约定，各个城市之间均可拉专线，其长度是直线长度。 地球上任意两点之间的距离计算方法可以参照以下文件：https://www.cnblogs.com/ycsfwhh/archive/2010/12/20/1911232.html 摘录如下： 地球是一个近乎标准的椭球体，它的赤道半径为 \\(6378.140\\) 千米，极半径为 \\(6356.755\\) 千米，平均半径 \\(6371.004\\) 千米。如果我们假设地球是一个完美的球体，那么它的半径就是地球的平均半径，记为 \\(R\\)。如果以 \\(0\\) 度经线为基 准，那么根据地球表面任意两点的经纬度就可以计算出这两点间的地表距离（这里忽略地球表面地形对计算带来的误差，仅仅是理论上的估算值）。设第一点 \\(A\\) 的经纬度为 \\((LonA, LatA)\\)，第二点 \\(B\\) 的经纬度为 \\((LonB, LatB)\\)，按照 \\(0\\) 度经线的基准，东经取经度的正值(Longitude)，西经取经度负值(-Longitude)，北纬取90-纬度值(90- Latitude)，南纬取90+纬度值(90+Latitude)，则经过上述处理过后的两点被计为 \\((MLonA, MLatA)\\) 和 \\((MLonB, MLatB)\\)。那么根据三角推导，可以得到计算两点距离的如下公式： $$ C = (MLatA) (MLatB) (MLonA-MLonB) + (MLatA) (MLatB) \\ Distance = R* (C) $$ 这里，R和Distance单位是相同，如果是采用 \\(6371.004\\) 千米作为半径，那么Distance就是千米为单位，如果要使用其他单位，比如mile，还需要做单位换算，1千米=0.621371192mile 如果仅对经度作正负的处理，而不对纬度作90-Latitude(假设都是北半球，南半球只有澳洲具有应用意义)的处理，那么公式将是： $$ C = (LatA) (LatB) + (LatA) (LatB) (MLonA-MLonB) \\ Distance = R (C) $$ 以上通过简单的三角变换就可以推出。 全国省会城市的经纬度如下所示。 城市,经度,纬度 沈阳市,123.429092,41.796768 长春市,125.324501,43.886841 哈尔滨市,126.642464,45.756966 北京市,116.405289,39.904987 天津市,117.190186,39.125595 呼和浩特市,111.751990,40.841490 银川市,106.232480,38.486440 太原市,112.549248,37.857014 石家庄市,114.502464,38.045475 济南市,117.000923,36.675808 郑州市,113.665413,34.757977 西安市,108.948021,34.263161 武汉市,114.298569,30.584354 南京市,118.76741,32.041546 合肥市,117.283043,31.861191 上海市,121.472641,31.231707 长沙市,112.982277,28.19409 南昌市,115.892151,28.676493 杭州市,120.15358,30.287458 福州市,119.306236,26.075302 广州市,113.28064,23.125177 台北市,121.5200760,25.0307240 海口市,110.199890,20.044220 南宁市,108.320007,22.82402 重庆市,106.504959,29.533155 昆明市,102.71225,25.040609 贵阳市,106.713478,26.578342 成都市,104.065735,30.659462 兰州市,103.834170,36.061380 西宁市,101.777820,36.617290 拉萨市,91.11450,29.644150 乌鲁木齐市,87.616880,43.826630 香港,114.165460,22.275340 澳门,113.549130,22.198750 实现代码 整个电网的长度最短 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#define R 6371.004#define SUP 100000005using namespace std;struct city&#123; string name; double longitude; double latitude;&#125;;struct edge&#123; int from; int to; double weight;&#125;;double rad(double angle)&#123; return angle * M_PI / 180;&#125;//Only correct when the positions are in the north-eastern hemispheredouble earth_dist(city *pos_a, city *pos_b)&#123; double long_a = rad(pos_a-&gt;longitude); double lat_a = rad(pos_a-&gt;latitude); double long_b = rad(pos_b-&gt;longitude); double lat_b = rad(pos_b-&gt;latitude); double c = sin(lat_a) * sin(lat_b) + cos(lat_a) * cos(lat_b) * cos(long_b - long_a); return R * acos(c);&#125;int main() &#123; city c[35]; edge chosen[35], low_cost[35]; double graph[35][35] = &#123;SUP&#125;; int visit[35] = &#123;0&#125;, flag = 0, n = 0, last_visit, cnt = 0; ifstream fin(&quot;position.txt&quot;); while (!fin.eof())&#123; fin&gt;&gt;c[n].name&gt;&gt;c[n].longitude&gt;&gt;c[n].latitude; n++; &#125; //Build the graph for(int i = 0; i &lt; n; i++) for(int j = 0; j &lt; n; j++) if(i == j) graph[i][j] = 0; else &#123; double dist = earth_dist(&amp;c[i], &amp;c[j]); graph[i][j] = dist; graph[j][i] = dist; &#125; for(int i = 0; i &lt; n; i++)&#123; low_cost[i] = &#123;-1, -1, SUP&#125;; &#125; visit[0] = 1; last_visit = 0; //Procedure of searching the MST while (!flag)&#123; flag = 1; //Update the lowest-cost edge set for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; int min_edge_idx = -1; double min_edge_dist = SUP; //Search for the smallest edge for (int i = 0; i &lt; n; i++) &#123; if(low_cost[i].weight != -1.0 &amp;&amp; low_cost[i].weight &lt; min_edge_dist)&#123; min_edge_dist = low_cost[i].weight; min_edge_idx = i; &#125; &#125; chosen[cnt] = low_cost[min_edge_idx]; visit[min_edge_idx] = 1; low_cost[min_edge_idx] = &#123;-1, -1, -1.0&#125;; last_visit = min_edge_idx; cnt++; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125; double sum = 0.0; for(int i = 0; i &lt; cnt; i++)&#123; cout&lt;&lt;c[chosen[i].from].name&lt;&lt;&quot;-&gt;&quot;&lt;&lt;c[chosen[i].to].name&lt;&lt;&quot; &quot;&lt;&lt;chosen[i].weight&lt;&lt;&quot;km&quot;&lt;&lt;endl; sum += chosen[i].weight; &#125; cout&lt;&lt;&quot;总长度: &quot;&lt;&lt;sum&lt;&lt;&quot;km&quot;&lt;&lt;endl; return 0;&#125; 在西宁与郑州拉一根直达专线的情况下，使得整个电网长度最短 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#define R 6371.004#define SUP 100000005using namespace std;struct city&#123; string name; double longitude; double latitude;&#125;;struct edge&#123; int from; int to; double weight;&#125;;double rad(double angle)&#123; return angle * M_PI / 180;&#125;//Only correct when the positions are on the north-eastern hemispheredouble earth_dist(city *pos_a, city *pos_b)&#123; double long_a = rad(pos_a-&gt;longitude); double lat_a = rad(pos_a-&gt;latitude); double long_b = rad(pos_b-&gt;longitude); double lat_b = rad(pos_b-&gt;latitude); double c = sin(lat_a) * sin(lat_b) + cos(lat_a) * cos(lat_b) * cos(long_b - long_a); return R * acos(c);&#125;int main() &#123; city c[35]; edge chosen[35], low_cost[35]; double graph[35][35] = &#123;SUP&#125;; int visit[35] = &#123;0&#125;, flag = 0, n = 0, last_visit, cnt = 0; int xi_ning_idx, zheng_zhou_idx; ifstream fin(&quot;position.txt&quot;); while (!fin.eof())&#123; fin&gt;&gt;c[n].name&gt;&gt;c[n].longitude&gt;&gt;c[n].latitude; if (c[n].name == &quot;西宁市&quot;) xi_ning_idx = n; else if (c[n].name == &quot;郑州市&quot;) zheng_zhou_idx = n; n++; &#125; //Build the graph for(int i = 0; i &lt; n; i++) for(int j = 0; j &lt; n; j++) if(i == j) graph[i][j] = 0; else &#123; double dist = earth_dist(&amp;c[i], &amp;c[j]); graph[i][j] = dist; graph[j][i] = dist; &#125; for(int i = 0; i &lt; n; i++)&#123; low_cost[i] = &#123;-1, -1, SUP&#125;; &#125; chosen[0].from = xi_ning_idx; chosen[0].to = zheng_zhou_idx; chosen[0].weight = graph[xi_ning_idx][zheng_zhou_idx]; cnt++; visit[xi_ning_idx] = 1; visit[zheng_zhou_idx] = 1; last_visit = xi_ning_idx; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; last_visit = zheng_zhou_idx; while (!flag)&#123; flag = 1; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; int min_edge_idx = -1; double min_edge_dist = SUP; for (int i = 0; i &lt; n; i++) &#123; if(low_cost[i].weight != -1.0 &amp;&amp; low_cost[i].weight &lt; min_edge_dist)&#123; min_edge_dist = low_cost[i].weight; min_edge_idx = i; &#125; &#125; chosen[cnt] = low_cost[min_edge_idx]; visit[min_edge_idx] = 1; low_cost[min_edge_idx] = &#123;-1, -1, -1.0&#125;; last_visit = min_edge_idx; cnt++; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125; double sum = 0.0; for(int i = 0; i &lt; cnt; i++)&#123; cout&lt;&lt;c[chosen[i].from].name&lt;&lt;&quot;-&gt;&quot;&lt;&lt;c[chosen[i].to].name&lt;&lt;&quot; &quot;&lt;&lt;chosen[i].weight&lt;&lt;&quot;km&quot;&lt;&lt;endl; sum += chosen[i].weight; &#125; cout&lt;&lt;&quot;总长度: &quot;&lt;&lt;sum&lt;&lt;&quot;km&quot;&lt;&lt;endl; return 0;&#125; 不仅在西宁与郑州之间拉直达专线，还在杭州与长沙之间拉直达专线的情况下，使得整个电网长度最短 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#define R 6371.004#define SUP 100000005using namespace std;struct city&#123; string name; double longitude; double latitude;&#125;;struct edge&#123; int from; int to; double weight;&#125;;double rad(double angle)&#123; return angle * M_PI / 180;&#125;//Only correct when the positions are on the north-eastern hemispheredouble earth_dist(city *pos_a, city *pos_b)&#123; double long_a = rad(pos_a-&gt;longitude); double lat_a = rad(pos_a-&gt;latitude); double long_b = rad(pos_b-&gt;longitude); double lat_b = rad(pos_b-&gt;latitude); double c = sin(lat_a) * sin(lat_b) + cos(lat_a) * cos(lat_b) * cos(long_b - long_a); return R * acos(c);&#125;int main() &#123; city c[35]; edge chosen[35], low_cost[35]; double graph[35][35] = &#123;SUP&#125;; int visit[35] = &#123;0&#125;, flag = 0, n = 0, last_visit, cnt = 0; int xi_ning_idx, zheng_zhou_idx, hang_zhou_idx, chang_sha_idx; ifstream fin(&quot;position.txt&quot;); while (!fin.eof())&#123; fin&gt;&gt;c[n].name&gt;&gt;c[n].longitude&gt;&gt;c[n].latitude; if (c[n].name == &quot;西宁市&quot;) xi_ning_idx = n; else if (c[n].name == &quot;郑州市&quot;) zheng_zhou_idx = n; else if (c[n].name == &quot;杭州市&quot;) hang_zhou_idx = n; else if (c[n].name == &quot;长沙市&quot;) chang_sha_idx = n; n++; &#125; //Build the graph for(int i = 0; i &lt; n; i++) for(int j = 0; j &lt; n; j++) if(i == j) graph[i][j] = 0; else &#123; double dist = earth_dist(&amp;c[i], &amp;c[j]); graph[i][j] = dist; graph[j][i] = dist; &#125; for(int i = 0; i &lt; n; i++)&#123; low_cost[i] = &#123;-1, -1, SUP&#125;; &#125; chosen[0].from = xi_ning_idx; chosen[0].to = zheng_zhou_idx; chosen[0].weight = graph[xi_ning_idx][zheng_zhou_idx]; cnt ++; visit[xi_ning_idx] = 1; visit[zheng_zhou_idx] = 1; last_visit = xi_ning_idx; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; last_visit = zheng_zhou_idx; while (!flag)&#123; flag = 1; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; int min_edge_idx = -1; double min_edge_dist = SUP; for (int i = 0; i &lt; n; i++) &#123; if(low_cost[i].weight != -1.0 &amp;&amp; low_cost[i].weight &lt; min_edge_dist)&#123; min_edge_dist = low_cost[i].weight; min_edge_idx = i; &#125; &#125; chosen[cnt] = low_cost[min_edge_idx]; visit[min_edge_idx] = 1; low_cost[min_edge_idx] = &#123;-1, -1, -1.0&#125;; last_visit = min_edge_idx; cnt++; if(last_visit == hang_zhou_idx &amp;&amp; visit[chang_sha_idx] == 0)&#123; chosen[cnt].from = hang_zhou_idx; chosen[cnt].to = chang_sha_idx; chosen[cnt].weight = graph[hang_zhou_idx][chang_sha_idx]; visit[chang_sha_idx] = 1; low_cost[chang_sha_idx] = &#123;-1, -1, -1.0&#125;; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; cnt++; last_visit = chang_sha_idx; &#125; else if(last_visit == chang_sha_idx &amp;&amp; visit[hang_zhou_idx] == 0)&#123; chosen[cnt].from = chang_sha_idx; chosen[cnt].to = hang_zhou_idx; chosen[cnt].weight = graph[chang_sha_idx][hang_zhou_idx]; visit[hang_zhou_idx] = 1; low_cost[hang_zhou_idx] = &#123;-1, -1, -1.0&#125;; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; cnt++; last_visit = hang_zhou_idx; &#125; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125; double sum = 0.0; for(int i = 0; i &lt; cnt; i++)&#123; cout&lt;&lt;c[chosen[i].from].name&lt;&lt;&quot;-&gt;&quot;&lt;&lt;c[chosen[i].to].name&lt;&lt;&quot; &quot;&lt;&lt;chosen[i].weight&lt;&lt;&quot;km&quot;&lt;&lt;endl; sum += chosen[i].weight; &#125; cout&lt;&lt;&quot;总长度: &quot;&lt;&lt;sum&lt;&lt;&quot;km&quot;&lt;&lt;endl; return 0;&#125; 在香港与澳门、澳门与广州不拉直达线路的前提之下，使得整个电网的长度最短 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#define R 6371.004#define SUP 100000005using namespace std;struct city&#123; string name; double longitude; double latitude;&#125;;struct edge&#123; int from; int to; double weight;&#125;;double rad(double angle)&#123; return angle * M_PI / 180;&#125;//Only correct when the positions are on the north-eastern hemispheredouble earth_dist(city *pos_a, city *pos_b)&#123; double long_a = rad(pos_a-&gt;longitude); double lat_a = rad(pos_a-&gt;latitude); double long_b = rad(pos_b-&gt;longitude); double lat_b = rad(pos_b-&gt;latitude); double c = sin(lat_a) * sin(lat_b) + cos(lat_a) * cos(lat_b) * cos(long_b - long_a); return R * acos(c);&#125;int main() &#123; city c[35]; edge chosen[35], low_cost[35]; double graph[35][35] = &#123;SUP&#125;; int visit[35] = &#123;0&#125;, flag = 0, n = 0, last_visit, cnt = 0; int hong_kong_idx, macao_idx, guang_zhou_idx; ifstream fin(&quot;position.txt&quot;); while (!fin.eof())&#123; fin&gt;&gt;c[n].name&gt;&gt;c[n].longitude&gt;&gt;c[n].latitude; if (c[n].name == &quot;香港&quot;) hong_kong_idx = n; else if (c[n].name == &quot;澳门&quot;) macao_idx = n; else if (c[n].name == &quot;广州市&quot;) guang_zhou_idx = n; n++; &#125; //Build the graph for(int i = 0; i &lt; n; i++) for(int j = 0; j &lt; n; j++) if(i == j) graph[i][j] = 0; else &#123; double dist = earth_dist(&amp;c[i], &amp;c[j]); graph[i][j] = dist; graph[j][i] = dist; &#125; for(int i = 0; i &lt; n; i++)&#123; low_cost[i] = &#123;-1, -1, SUP&#125;; &#125; visit[0] = 1; last_visit = 0; while (!flag)&#123; flag = 1; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; bool spec_1, spec_2; spec_1 = (last_visit == hong_kong_idx &amp;&amp; i == macao_idx) || (last_visit == macao_idx &amp;&amp; i == hong_kong_idx); spec_2 = (last_visit == macao_idx &amp;&amp; i == guang_zhou_idx) || (last_visit == guang_zhou_idx &amp;&amp; i == macao_idx); if (!spec_1 &amp;&amp; !spec_2) &#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; &#125; int min_edge_idx = -1; double min_edge_dist = SUP; for (int i = 0; i &lt; n; i++) &#123; if(low_cost[i].weight != -1.0 &amp;&amp; low_cost[i].weight &lt; min_edge_dist)&#123; min_edge_dist = low_cost[i].weight; min_edge_idx = i; &#125; &#125; chosen[cnt] = low_cost[min_edge_idx]; visit[min_edge_idx] = 1; low_cost[min_edge_idx] = &#123;-1, -1, -1.0&#125;; last_visit = min_edge_idx; cnt++; for(int i = 0; i &lt; n; i++)&#123; if(visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125; double sum = 0.0; for(int i = 0; i &lt; cnt; i++)&#123; cout&lt;&lt;c[chosen[i].from].name&lt;&lt;&quot;-&gt;&quot;&lt;&lt;c[chosen[i].to].name&lt;&lt;&quot; &quot;&lt;&lt;chosen[i].weight&lt;&lt;&quot;km&quot;&lt;&lt;endl; sum += chosen[i].weight; &#125; cout&lt;&lt;&quot;总长度: &quot;&lt;&lt;sum&lt;&lt;&quot;km&quot;&lt;&lt;endl; return 0;&#125; 在南方省份和北方省份之间仅规划一条直通专线，使得整个电网的长度最短 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#include &lt;map&gt;#define R 6371.004#define SUP 100000005using namespace std;struct city&#123; string name; double longitude; double latitude;&#125;;struct edge&#123; int from; int to; double weight;&#125;;double rad(double angle)&#123; return angle * M_PI / 180;&#125;//Only correct when the positions are on the north-eastern hemispheredouble earth_dist(city *pos_a, city *pos_b)&#123; double long_a = rad(pos_a-&gt;longitude); double lat_a = rad(pos_a-&gt;latitude); double long_b = rad(pos_b-&gt;longitude); double lat_b = rad(pos_b-&gt;latitude); double c = sin(lat_a) * sin(lat_b) + cos(lat_a) * cos(lat_b) * cos(long_b - long_a); return R * acos(c);&#125;int main() &#123; string north_province[15] = &#123;&quot;济南市&quot;, &quot;石家庄市&quot;, &quot;天津市&quot;, &quot;北京市&quot;, &quot;沈阳市&quot;, &quot;长春市&quot;, &quot;哈尔滨市&quot;, &quot;郑州市&quot;, &quot;太原市&quot;, &quot;西安市&quot;, &quot;呼和浩特市&quot;, &quot;兰州市&quot;, &quot;银川市&quot;, &quot;西宁市&quot;, &quot;乌鲁木齐市&quot;&#125;; map&lt;int, int&gt; region_map; city c[35]; edge chosen[35], low_cost[35]; double graph[35][35] = &#123;SUP&#125;; int visit[35] = &#123;0&#125;, flag = 0, n = 0, last_visit, cnt = 0, north_tag; ifstream fin(&quot;position.txt&quot;); while (!fin.eof())&#123; fin&gt;&gt;c[n].name&gt;&gt;c[n].longitude&gt;&gt;c[n].latitude; north_tag = 0; for (int i = 0; i &lt; 15; i++)&#123; if (north_province[i] == c[n].name)&#123; region_map[n] = 0; north_tag = 1; break; &#125; &#125; if (north_tag == 0) region_map[n] = 1; n++; &#125; //Build the graph for(int i = 0; i &lt; n; i++) for(int j = 0; j &lt; n; j++) if(i == j) graph[i][j] = 0; else &#123; double dist = earth_dist(&amp;c[i], &amp;c[j]); graph[i][j] = dist; graph[j][i] = dist; &#125; for(int i = 0; i &lt; n; i++)&#123; low_cost[i] = &#123;-1, -1, SUP&#125;; &#125; visit[0] = 1; last_visit = 0; //Connect northern city while (!flag)&#123; flag = 1; for(int i = 0; i &lt; n; i++)&#123; if(region_map[i] == 0 &amp;&amp; visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; int min_edge_idx = -1; double min_edge_dist = SUP; for (int i = 0; i &lt; n; i++) &#123; if(low_cost[i].weight != -1.0 &amp;&amp; low_cost[i].weight &lt; min_edge_dist)&#123; min_edge_dist = low_cost[i].weight; min_edge_idx = i; &#125; &#125; chosen[cnt] = low_cost[min_edge_idx]; visit[min_edge_idx] = 1; low_cost[min_edge_idx] = &#123;-1, -1, -1.0&#125;; last_visit = min_edge_idx; cnt++; for(int i = 0; i &lt; n; i++)&#123; if(region_map[i] == 0 &amp;&amp; visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125; flag = 0; for(int i = 0; i &lt; n; i++)&#123; low_cost[i] = &#123;-1, -1, SUP&#125;; &#125; visit[12] = 1; last_visit = 12; //Connect southern city while (!flag)&#123; flag = 1; for(int i = 0; i &lt; n; i++)&#123; if(region_map[i] == 1 &amp;&amp; visit[i] == 0 &amp;&amp; graph[last_visit][i] &lt; low_cost[i].weight)&#123; low_cost[i].from = last_visit; low_cost[i].to = i; low_cost[i].weight = graph[last_visit][i]; &#125; &#125; int min_edge_idx = -1; double min_edge_dist = SUP; for (int i = 0; i &lt; n; i++) &#123; if(low_cost[i].weight != -1.0 &amp;&amp; low_cost[i].weight &lt; min_edge_dist)&#123; min_edge_dist = low_cost[i].weight; min_edge_idx = i; &#125; &#125; chosen[cnt] = low_cost[min_edge_idx]; visit[min_edge_idx] = 1; low_cost[min_edge_idx] = &#123;-1, -1, -1.0&#125;; last_visit = min_edge_idx; cnt++; for(int i = 0; i &lt; n; i++)&#123; if(region_map[i] == 1 &amp;&amp; visit[i] == 0)&#123; flag = 0; break; &#125; &#125; &#125; int min_from, min_to; double min_dist = SUP; for (int i = 0; i &lt; n; i++) for(int j = 0; j &lt; i; j++)&#123; int spec = (region_map[i] == 0 &amp;&amp; region_map[j] == 1) || (region_map[i] == 1 &amp;&amp; region_map[j] == 0); if (spec &amp;&amp; graph[i][j] &lt; min_dist)&#123; min_from = i; min_to = j; min_dist = graph[i][j]; &#125; &#125; chosen[cnt].from = min_from; chosen[cnt].to = min_to; chosen[cnt].weight = min_dist; cnt++; double sum = 0.0; for(int i = 0; i &lt; cnt; i++)&#123; cout&lt;&lt;c[chosen[i].from].name&lt;&lt;&quot;-&gt;&quot;&lt;&lt;c[chosen[i].to].name&lt;&lt;&quot; &quot;&lt;&lt;chosen[i].weight&lt;&lt;&quot;km&quot;&lt;&lt;endl; sum += chosen[i].weight; &#125; cout&lt;&lt;&quot;总长度: &quot;&lt;&lt;sum&lt;&lt;&quot;km&quot;&lt;&lt;endl; return 0;&#125; 算法正确性 整个电网的长度最短 利用Prim算法，每次选择已连通节点集到未连通相邻节点集中最小的边连通，并更新相邻节点集及对应的最小边，最终即可得到长度最短的电网图。 在西宁与郑州拉一根直达专线的情况下，使得整个电网长度最短 先将西宁到郑州的边加入电网图，并更新西宁和郑州的相邻节点，再以西宁或郑州为起点执行(1)的步骤。 不仅在西宁与郑州之间拉直达专线，还在杭州与长沙之间拉直达专线的情况下，使得整个电网长度最短 在(2)的基础上，当电网图扩展到杭州或长沙时，将杭州到长沙的边加入电网图，并更新杭州和长沙的相邻节点，再以杭州或长沙为起点继续扩展电网图。 在香港与澳门、澳门与广州不拉直达线路的前提之下，使得整个电网的长度最短 在(1)的基础上，当电网图扩展到香港、澳门或广州时，不更新其禁连通节点的最小边，即可避免算法选择非法边。 在南方省份和北方省份之间仅规划一条直通专线，使得整个电网的长度最短 将南方省份和北方省份分别看作两张图，并使用(1)的方法分别生成两张电网图，最后找出南方省份中到北方省份最近的一条边加入电网图，即可得到一张全连通的电网图。由于初始位置对Prim算法没有影响，故可以保证得到的电网长度最短。 输出各组实验的电网数据表，以及电网总长度，并且通过可视化方式进行呈现 整个电网的长度最短 沈阳市-&gt;长春市 279.076km 长春市-&gt;哈尔滨市 232.473km 沈阳市-&gt;天津市 605.429km 天津市-&gt;北京市 109.744km 天津市-&gt;石家庄市 262.662km 石家庄市-&gt;太原市 172.534km 石家庄市-&gt;济南市 268.228km 太原市-&gt;呼和浩特市 338.861km 太原市-&gt;郑州市 358.809km 郑州市-&gt;西安市 435.687km 郑州市-&gt;合肥市 465.513km 合肥市-&gt;南京市 141.475km 南京市-&gt;杭州市 235.447km 杭州市-&gt;上海市 164.04km 合肥市-&gt;武汉市 317.307km 武汉市-&gt;南昌市 262.154km 南昌市-&gt;长沙市 289.531km 南昌市-&gt;福州市 444.143km 福州市-&gt;台北市 250.622km 西安市-&gt;兰州市 505.96km 兰州市-&gt;西宁市 194.278km 兰州市-&gt;银川市 343.112km 长沙市-&gt;广州市 564.43km 广州市-&gt;澳门 106.634km 澳门-&gt;香港 64.0048km 澳门-&gt;海口市 421.967km 海口市-&gt;南宁市 365.228km 南宁市-&gt;贵阳市 447.881km 贵阳市-&gt;重庆市 329.197km 重庆市-&gt;成都市 265.982km 贵阳市-&gt;昆明市 435.472km 成都市-&gt;拉萨市 1249.67km 西宁市-&gt;乌鲁木齐市 1441.9km 总长度: 12369.5km 1 在西宁与郑州拉一根直达专线的情况下，使得整个电网长度最短 西宁市-&gt;郑州市 1092.57km 西宁市-&gt;兰州市 194.278km 兰州市-&gt;银川市 343.112km 郑州市-&gt;太原市 358.809km 太原市-&gt;石家庄市 172.534km 石家庄市-&gt;天津市 262.662km 天津市-&gt;北京市 109.744km 石家庄市-&gt;济南市 268.228km 太原市-&gt;呼和浩特市 338.861km 郑州市-&gt;西安市 435.687km 郑州市-&gt;合肥市 465.513km 合肥市-&gt;南京市 141.475km 南京市-&gt;杭州市 235.447km 杭州市-&gt;上海市 164.04km 合肥市-&gt;武汉市 317.307km 武汉市-&gt;南昌市 262.154km 南昌市-&gt;长沙市 289.531km 南昌市-&gt;福州市 444.143km 福州市-&gt;台北市 250.622km 长沙市-&gt;广州市 564.43km 广州市-&gt;澳门 106.634km 澳门-&gt;香港 64.0048km 澳门-&gt;海口市 421.967km 海口市-&gt;南宁市 365.228km 南宁市-&gt;贵阳市 447.881km 贵阳市-&gt;重庆市 329.197km 重庆市-&gt;成都市 265.982km 贵阳市-&gt;昆明市 435.472km 天津市-&gt;沈阳市 605.429km 沈阳市-&gt;长春市 279.076km 长春市-&gt;哈尔滨市 232.473km 成都市-&gt;拉萨市 1249.67km 西宁市-&gt;乌鲁木齐市 1441.9km 总长度: 12956.1km 2 不仅在西宁与郑州之间拉直达专线，还在杭州与长沙之间拉直达专线的情况下，使得整个电网长度最短 西宁市-&gt;郑州市 1092.57km 西宁市-&gt;兰州市 194.278km 兰州市-&gt;银川市 343.112km 郑州市-&gt;太原市 358.809km 太原市-&gt;石家庄市 172.534km 石家庄市-&gt;天津市 262.662km 天津市-&gt;北京市 109.744km 石家庄市-&gt;济南市 268.228km 太原市-&gt;呼和浩特市 338.861km 郑州市-&gt;西安市 435.687km 郑州市-&gt;合肥市 465.513km 合肥市-&gt;南京市 141.475km 南京市-&gt;杭州市 235.447km 杭州市-&gt;长沙市 733.531km 杭州市-&gt;上海市 164.04km 长沙市-&gt;南昌市 289.531km 南昌市-&gt;武汉市 262.154km 南昌市-&gt;福州市 444.143km 福州市-&gt;台北市 250.622km 长沙市-&gt;广州市 564.43km 广州市-&gt;澳门 106.634km 澳门-&gt;香港 64.0048km 澳门-&gt;海口市 421.967km 海口市-&gt;南宁市 365.228km 南宁市-&gt;贵阳市 447.881km 贵阳市-&gt;重庆市 329.197km 重庆市-&gt;成都市 265.982km 贵阳市-&gt;昆明市 435.472km 天津市-&gt;沈阳市 605.429km 沈阳市-&gt;长春市 279.076km 长春市-&gt;哈尔滨市 232.473km 成都市-&gt;拉萨市 1249.67km 西宁市-&gt;乌鲁木齐市 1441.9km 总长度: 13372.3km 3 在香港与澳门、澳门与广州不拉直达线路的前提之下，使得整个电网的长度最短 沈阳市-&gt;长春市 279.076km 长春市-&gt;哈尔滨市 232.473km 沈阳市-&gt;天津市 605.429km 天津市-&gt;北京市 109.744km 天津市-&gt;石家庄市 262.662km 石家庄市-&gt;太原市 172.534km 石家庄市-&gt;济南市 268.228km 太原市-&gt;呼和浩特市 338.861km 太原市-&gt;郑州市 358.809km 郑州市-&gt;西安市 435.687km 郑州市-&gt;合肥市 465.513km 合肥市-&gt;南京市 141.475km 南京市-&gt;杭州市 235.447km 杭州市-&gt;上海市 164.04km 合肥市-&gt;武汉市 317.307km 武汉市-&gt;南昌市 262.154km 南昌市-&gt;长沙市 289.531km 南昌市-&gt;福州市 444.143km 福州市-&gt;台北市 250.622km 西安市-&gt;兰州市 505.96km 兰州市-&gt;西宁市 194.278km 兰州市-&gt;银川市 343.112km 长沙市-&gt;广州市 564.43km 广州市-&gt;香港 131.027km 广州市-&gt;海口市 467.756km 海口市-&gt;南宁市 365.228km 海口市-&gt;澳门 421.967km 南宁市-&gt;贵阳市 447.881km 贵阳市-&gt;重庆市 329.197km 重庆市-&gt;成都市 265.982km 贵阳市-&gt;昆明市 435.472km 成都市-&gt;拉萨市 1249.67km 西宁市-&gt;乌鲁木齐市 1441.9km 总长度: 12797.6km 4 在南方省份和北方省份之间仅规划一条直通专线，使得整个电网的长度最短 与(1)结果相同 总结 电网规划问题本质上就是求最小生成树。由于两两城市均可连通，故为一张稠密图，因此使用Prim算法更加合适。Prim算法可在 \\(\\mathcal{O}(n^2)\\) 的时间内求出一张对应的最小生成树，而实验中对特殊情况处理的时间复杂度均未超过 \\(\\mathcal{O}(n^2)\\)，因此总时间代价仍为 \\(\\mathcal{O}(n^2)\\)。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"Malloc Lab实验记录","slug":"computer-system/csapp-malloclab","date":"2020-12-15T14:15:13.000Z","updated":"2021-04-17T11:14:33.865Z","comments":true,"path":"2020/12/15/computer-system/csapp-malloclab/","link":"","permalink":"http://gonggongjohn.me/2020/12/15/computer-system/csapp-malloclab/","excerpt":"Malloc Lab要求我们利用CSAPP中9.9节所介绍的技术设计一个简单的动态内存分配器，并且尽可能的使得分配效率最高且空间利用率最大。一个基本的思路便是先构建一个内存分配器的框架，并在此基础上不断优化使得效率和空间使用率均相对达到最优。","text":"Malloc Lab要求我们利用CSAPP中9.9节所介绍的技术设计一个简单的动态内存分配器，并且尽可能的使得分配效率最高且空间利用率最大。一个基本的思路便是先构建一个内存分配器的框架，并在此基础上不断优化使得效率和空间使用率均相对达到最优。 概览 首先我们来看一下Lab的基本情况。在Lab的mm.c文件中提供了一个最简单的动态内存分配器，我们需要实现以下四个函数以实现更加高效紧凑的内存分配： mm_init：初始化堆 mm_malloc：在堆中申请一段空间 mm_free：在堆中释放一段之前申请的空间 mm_realloc：重新调整之前申请的空间大小 为了方便起见，Lab在memlib.c中为我们提供了一些封装好的基础函数可供我们调用： mem_sbrk：改变堆大小（仅能扩张堆） mem_heap_lo：返回指向堆首的指针 mem_heap_hi：返回指向堆尾的指针 mem_heapsize：返回当前的堆大小 mem_pagesize：返回系统页大小 我们可以使用Lab为我们提供的mdriver工具装载预先设计好的Trace文件测试我们的内存分配器效率和空间使用率： 1&gt; ./mdriver -V -f shortX-bal.rep # X代表Trace文件编号 基本功能 宏定义 首先我们仿照CSAPP中9.9.12的例子定义一组宏以方便后续的使用： 1234567891011121314151617181920212223242526#define WSIZE 4 //字大小（Bytes）#define DSIZE 8 //双字大小（Bytes）#define CHUNKSIZE (1&lt;&lt;12) //扩展堆的最小大小（Bytes）#define MAX(x,y) ((x) &gt; (y)? (x):(y)) //求二者最大值//将块大小和使用标识符组合进一个字中#define PACK(size,alloc) ((size) | (alloc))//将任意指针转为一个字指针#define GET(p) (*(unsigned int *)(p))//在指针位置放入长度为一个字的值#define PUT(p,val) (*(unsigned int *)(p)=(val))//将任意指针转为通用指针#define GET_ADDRESS(p) (*(void **)(p))//从头部获取块大小#define GET_SIZE(p) (GET(p) &amp; ~0x7)//从头部获取使用标识符#define GET_ALLOC(p) (GET(p) &amp; 0x1)//计算块头部位置#define HDRP(bp) ((char *)(bp)-WSIZE)//计算块尾部位置#define FTRP(bp) ((char *)(bp)+ GET_SIZE(HDRP(bp))-DSIZE)//计算有效载荷大小#define GET_PAYLOAD(bp) (GET_SIZE(HDRP(bp))-DSIZE) //计算后一个块的位置#define NEXT_BLKP(bp) ((char *)(bp)+GET_SIZE(((char *)(bp)-WSIZE)))//计算前一个块的位置#define PREV_BLKP(bp) ((char *)(bp)-GET_SIZE(((char *)(bp)-DSIZE))) 堆初始化 堆初始化的一个基本作用就是向内存系统申请一块初始空间并标识为空闲状态。不过我们会发现，这一行为和后续当需要额外向系统申请新的空间时的行为完全相同，因此我们可以将这一逻辑封装为一个单独的函数： 12345678910111213141516static void *extend_heap(size_t words)&#123; char *bp; //新空间的起始指针 size_t size; //向上对齐为双字的倍数 size=(words %2)? (words+1)*WSIZE: words*WSIZE; //向系统申请空间 if((long)(bp = mem_sbrk(size)) == -1) return NULL; //设置块头部 PUT(HDRP(bp),PACK(size,0)); //设置块尾部 PUT(FTRP(bp),PACK(size,0)); return (void *)bp;&#125; 于是初始化函数可以被写成这样： 12345678int mm_init(void)&#123; if(extend_heap(CHUNKSIZE/WSIZE)==NULL) &#123; return -1; &#125; return 0;&#125; 申请空间 现在我们来考虑如何响应用户的空间申请。由于堆需要保持双字对其，我们必须将用户的申请要求向上对齐为双字大小。而由于一个块还需要额外的双字空间用于存放块头部和块尾部，因此一次申请的空间必须为四字以上。随后我们需要找到合适的位置分配给用户的这一申请，由于后续我们需要不断优化分配的算法，因此我们将这一过程单独封装。此外，如果当前堆中找不到合适的位置分配给用户，我们还需要申请额外的空间以满足用户的需求。于是空间申请函数的基本构架就可以写成这样： 12345678910111213141516171819202122232425262728293031void *mm_malloc(size_t size)&#123; size_t asize; //实际分配的大小 size_t extendsize; //扩展堆大小 char *bp; //申请空间大小为0的情况 if(size==0) &#123; return NULL; &#125; //向上对齐 if(size&lt;=DSIZE) asize=2*DSIZE; else asize=DSIZE*((size+(DSIZE)+(DSIZE-1))/DSIZE); //寻找合适的位置并分配空间 if((bp=find_fit(asize))!=NULL) &#123; place(bp,asize); return bp; &#125; //当空间不够使扩展堆大小 extendsize = MAX(asize, CHUNKSIZE); if((bp=extend_heap(extendsize/WSIZE))==NULL) &#123; return NULL; &#125; //分配空间 place(bp,asize); return bp;&#125; 释放空间 释放空间本质上就是把块头部的使用标识符从已使用改为空闲状态，因此我们可以快速实现出这一函数： 12345678void mm_free(void *ptr)&#123; size_t size=GET_SIZE(HDRP(ptr)); //块大小 //将头部设置为空闲状态 PUT(HDRP(ptr),PACK(size,0)); //将尾部设置为空闲状态 PUT(FTRP(ptr),PACK(size,0));&#125; 不过进一步思考我们会发现，当有多个连续的空闲块时，我们需要在释放时将其合并。由于空闲块可能在新释放的块之前或之后，因此我们需要讨论所有情况： 1234567891011121314151617181920212223242526272829303132333435static void *coalesce(void *bp)&#123; size_t prev_alloc=GET_ALLOC(FTRP(PREV_BLKP(bp))); //前一个块是否空闲 size_t next_alloc=GET_ALLOC(HDRP(NEXT_BLKP(bp))); //后一个块是否空闲 size_t size=GET_SIZE(HDRP(bp)); //块大小 //前后都不空闲 if(prev_alloc &amp;&amp; next_alloc) &#123; return bp; &#125; //前一个块空闲 else if(prev_alloc &amp;&amp; !next_alloc) &#123; size+=GET_SIZE(HDRP(NEXT_BLKP(bp))); PUT(HDRP(bp),PACK(size,0)); PUT(FTRP(bp),PACK(size,0)); return bp; &#125; //后一个块空闲 else if(!prev_alloc &amp;&amp; next_alloc) &#123; size+=GET_SIZE(FTRP(PREV_BLKP(bp))); PUT(FTRP(bp),PACK(size,0)); PUT(HDRP(PREV_BLKP(bp)),PACK(size,0)); return PREV_BLKP(bp); &#125; //前后都空闲 else &#123; size+=(GET_SIZE(HDRP(NEXT_BLKP(bp)))+GET_SIZE(FTRP(PREV_BLKP(bp)))); PUT(FTRP(NEXT_BLKP(bp)),PACK(size,0)); PUT(HDRP(PREV_BLKP(bp)),PACK(size,0)); return PREV_BLKP(bp); &#125;&#125; 在合并的过程中，我们还需要考虑遇到堆的前后边界时的情况。我们可以利用CSAPP中介绍的通过在堆首和堆尾引入首位块的方法规避这一问题： 1234567891011121314151617int mm_init(void)&#123; //申请空间存放首位块 if((head_listp = mem_sbrk(4*WSIZE)) == (void *)-1) return -1; //填充 PUT(head_listp,0); //序言块首 PUT(head_listp+(1*WSIZE),PACK(DSIZE,1)); //序言块尾 PUT(head_listp+(2*WSIZE),PACK(DSIZE,1)); //结尾块首 PUT(head_listp+(3*WSIZE),PACK(0,1)); //堆首指针指向序言块 head_listp += (2*WSIZE); ...&#125; 此外，在扩展堆大小的时候，我们也需要考虑到合并的情况： 12345static void *extend_heap(size_t words)&#123; ... return coalesce(bp);&#125; 调整空间大小 当用户需要调整空间的大小时，我们需要考虑所有可能的情况。如果这一行为相当于申请更大的空间，我们可以先使用合并空闲块的思想将前后的空闲块合并进来，当合并后的空间大小还不够时，我们就需要重新在堆中申请一块更大的空间，并将原本空间中的数据复制过去： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107void *mm_realloc(void *ptr, size_t size)&#123; //如果没有原始位置，相当于申请一块新的空间 if(ptr==NULL) return mm_malloc(size); //如果新空间大小为0，相当于释放原本的空间 if(size==0) &#123; mm_free(ptr); return ptr; &#125; size_t asize=0; //实际分配大小 //对齐处理 if(size&lt;=DSIZE) asize=2*DSIZE; else asize=DSIZE*((size+(DSIZE)+(DSIZE-1))/DSIZE); if(ptr!=NULL) &#123; size_t oldsize=GET_PAYLOAD(ptr); //获取原本的有效载荷大小 //原本大小小于新申请空间的大小 if(oldsize&lt;size) &#123; void* newptr=recoalesce(ptr,asize); //尝试合并前后块 //合并空间无法满足需求，申请额外的空间 if(newptr==NULL) &#123; newptr=mm_malloc(asize); //申请新空间 memcpy(newptr,ptr,oldsize); //复制数据 mm_free(ptr); //释放原空间 return newptr; &#125; //合并后空间能够满足需求 else &#123; return newptr; &#125; &#125; //原本大小和新空间大小一致 else if(oldsize==size) &#123; return ptr; &#125; //原本大小大于新空间大小 else &#123; return ptr; &#125; &#125; return NULL;&#125;//合并前后空闲块static void *recoalesce(void *bp,size_t needsize)&#123; size_t prev_alloc=GET_ALLOC(FTRP(PREV_BLKP(bp))); //前一个块是否空闲 size_t next_alloc=GET_ALLOC(HDRP(NEXT_BLKP(bp))); //后一个块是否空闲 size_t size=GET_SIZE(HDRP(bp)); //当前块大小 //前后都不空闲 if(prev_alloc &amp;&amp; next_alloc) &#123; return NULL; &#125; //后一个块空闲 else if(prev_alloc &amp;&amp; !next_alloc) &#123; size += GET_SIZE(HDRP(NEXT_BLKP(bp))); //合并后一个块后的大小 if(size&lt;needsize) return NULL; else &#123; PUT(HDRP(bp),PACK(size,1)); PUT(FTRP(bp),PACK(size,1)); return bp; &#125; &#125; //前一个块空闲 else if(!prev_alloc &amp;&amp; next_alloc) &#123; size += GET_SIZE(HDRP(PREV_BLKP(bp))); if(size&lt;needsize) return NULL; else &#123; size_t thissize=GET_PAYLOAD(bp); //当前有效载荷大小 void* prev_point=PREV_BLKP(bp); //前一个块的位置 PUT(FTRP(bp),PACK(size,1)); PUT(HDRP(prev_point),PACK(size,1)); memcpy(prev_point,bp,thissize); //向前复制数据 return prev_point; &#125; &#125; //前后都空闲 else &#123; size += (GET_SIZE(HDRP(NEXT_BLKP(bp)))+GET_SIZE(FTRP(PREV_BLKP(bp)))); if(size&lt;needsize) return NULL; else &#123; size_t thissize=GET_PAYLOAD(bp); void* prev_point=PREV_BLKP(bp); PUT(FTRP(NEXT_BLKP(bp)),PACK(size,1)); PUT(HDRP(PREV_BLKP(bp)),PACK(size,1)); memcpy(prev_point,bp,thissize); return prev_point; &#125; &#125;&#125; 性能优化 前面我们使用隐式链表的方式实现了内存分配器的基本逻辑。但以这种方式实现的内存分配器效率极低且会产生大量的外部碎片，因此我们需要对其逐步优化。 显式分离存储 在使用隐式链表存储块信息的情况下，搜索一个空闲块的平均时间复杂度为 \\[\\mathcal{O}(n)\\]，当块的数量很大或空闲块分布较为稀疏时，搜索效率就会变得极低。如果我们显式地将空闲块连在一起，搜索效率会得到一定的提高，然而，每当我们需要释放一段空间时，就需要在空闲链表中搜索合适的位置放置新的空闲块，这一操作有可能使得总时间复杂度再次退化到 \\[\\mathcal{O}(n)\\]，因此我们还需要使用CSAPP中介绍的分离链表的方式存储不同规模的空闲块。我们可以按照2的幂来划分每个空闲链表的大小范围，这里一共划分成了10类：\\[(0,8],(9,16],(17,32],(33,64],(65,128],(129,256],(257,512],(513,2048],(2049,4096],(4097, +\\infty)\\] 我们可以通过一个指针数据来保存每张链表的头位置： 12static int MAX_SIZE=10;static void* linkhead[10]=&#123;NULL&#125;; 随后我们实现一个根据块大小计算属于哪一张链表的辅助函数： 1234567891011121314151617181920212223static int findlink(size_t size)&#123; if(size&lt;=8) return 0; else if(size&lt;=16) return 1; else if(size&lt;=32) return 2; else if(size&lt;=64) return 3; else if(size&lt;=128) return 4; else if(size&lt;=256) return 5; else if(size&lt;=512) return 6; else if(size&lt;=2048) return 7; else if(size&lt;=4096) return 8; else return 9;&#125; 现在我们就可以实现空闲块的插入和删除逻辑了： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//向对应的空闲链表中插入空闲块static void placefree(void* bp)&#123; int index=findlink(GET_SIZE(HDRP(bp))); //空闲链表头下标 void* head=linkhead[index]; //空闲链表入口 //相应链表未初始化时 if(head==NULL) &#123; //把当前块作为标首 linkhead[index]=bp; GET_ADDRESS(PRED(bp))=NULL; GET_ADDRESS(SUCC(bp))=NULL; &#125; else &#123; size_t bpsize=GET_SIZE(HDRP(bp)); //当前块大小 void* temp=NULL; //移动到链表中和当前块大小最接近的元素前 while(head!=NULL) &#123; temp=head; if(GET_SIZE(HDRP(head))&gt;=bpsize) break; head=GET_ADDRESS(SUCC(head)); &#125; //插入当前块 if(head==NULL) &#123; GET_ADDRESS(SUCC(temp))=bp; GET_ADDRESS(PRED(bp))=temp; GET_ADDRESS(SUCC(bp))=NULL; &#125; else &#123; if(head==linkhead[index]) &#123; GET_ADDRESS(PRED(head))=bp; GET_ADDRESS(SUCC(bp))=head; GET_ADDRESS(PRED(bp))=NULL; linkhead[index]=bp; &#125; else &#123; GET_ADDRESS(SUCC(GET_ADDRESS(PRED(head))))=bp; GET_ADDRESS(PRED(bp))=GET_ADDRESS(PRED(head)); GET_ADDRESS(SUCC(bp))=head; GET_ADDRESS(PRED(head))=bp; &#125; &#125; &#125;&#125;//从对应的空闲链表中删除块static void deletefree(void* bp)&#123; int index=findlink(GET_SIZE(HDRP(bp))); //特判 if(linkhead[index]==NULL) printf(&quot;Freelist is empty!&quot;); //链表中仅有一个元素时 if(GET_ADDRESS(PRED(bp))==NULL &amp;&amp; GET_ADDRESS(SUCC(bp))==NULL) &#123; linkhead[index]=NULL; &#125; //当前元素为表首元素时 else if(GET_ADDRESS(PRED(bp))==NULL &amp;&amp; GET_ADDRESS(SUCC(bp))!=NULL) &#123; GET_ADDRESS(PRED(GET_ADDRESS(SUCC(bp))))=NULL; linkhead[index]=GET_ADDRESS(SUCC(bp)); GET_ADDRESS(SUCC(bp))=NULL; &#125; //当前元素为表尾元素时 else if(GET_ADDRESS(PRED(bp))!=NULL &amp;&amp; GET_ADDRESS(SUCC(bp))==NULL) &#123; GET_ADDRESS(SUCC(GET_ADDRESS(PRED(bp))))=NULL; GET_ADDRESS(PRED(bp))=NULL; &#125; //当前元素在表的中间位置时 else &#123; GET_ADDRESS(SUCC(GET_ADDRESS(PRED(bp))))=GET_ADDRESS(SUCC(bp)); GET_ADDRESS(PRED(GET_ADDRESS(SUCC(bp))))=GET_ADDRESS(PRED(bp)); GET_ADDRESS(PRED(bp))=GET_ADDRESS(SUCC(bp))=NULL; &#125;&#125; 随后我们需要在合并空闲块时引入这一管理机制： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263static void *coalesce(void *bp)&#123; ... if(prev_alloc &amp;&amp; next_alloc) &#123; placefree(bp); //向空闲链表插入当前块 ... &#125; else if(prev_alloc &amp;&amp; !next_alloc) &#123; deletefree(NEXT_BLKP(bp)); //从空闲链表中删除后一个块 ... placefree(bp); &#125; else if(!prev_alloc &amp;&amp; next_alloc) &#123; deletefree(PREV_BLKP(bp)); //从空闲链表中删除前一个块 ... placefree(PREV_BLKP(bp)); //向空闲链表插入更新过的前一个块 &#125; else &#123; deletefree(PREV_BLKP(bp)); //从空闲链表中删除前一个块 deletefree(NEXT_BLKP(bp)); //从空闲链表中删除后一个块 ... placefree(PREV_BLKP(bp)); //向空闲链表插入更新过的前一个块 ... &#125;&#125;static void *recoalesce(void *bp,size_t needsize)&#123; ... else if(prev_alloc &amp;&amp; !next_alloc) &#123; ... else &#123; deletefree(NEXT_BLKP(bp)); ... &#125; &#125; else if(!prev_alloc &amp;&amp; next_alloc) &#123; ... else &#123; ... deletefree(prev_point); ... &#125; &#125; else &#123; ... else &#123; ... deletefree(prev_point); deletefree(NEXT_BLKP(bp)); ... &#125; &#125;&#125; 分离适配 有了分离存储的结构后，我们就可以使用分离适配的方法来寻找合适的块分配给用户的每一次空间请求了。其具体思路就是当用户申请某个大小的空间时，我们在其对应空间大小范围的链表中搜索，一旦搜索到一块不小于用户申请大小的块，就将其分配给用户。不过需要注意的是，如果分配给用户的块剩下的大小还可以单独形成一个新的空闲块，则需要将其分割成两个块。用代码实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344//寻找合适的块static void *find_fit(size_t size)&#123; //遍历对应的链表 for(int index=findlink(size);index&lt;MAX_SIZE;++index) &#123; void* bp=linkhead[index]; while(bp!=NULL) &#123; //在找到第一个不小于用户申请大小的块时返回 if(GET_SIZE(HDRP(bp))&gt;=size) return bp; bp=GET_ADDRESS(SUCC(bp)); &#125; &#125; //如果找不到合适的空间则返回空 return NULL;&#125;//在块中分配空间static void place(void* bp,size_t asize)&#123; //剩余块大小 size_t left=GET_SIZE(HDRP(bp))-asize; int alloc=GET_ALLOC(HDRP(bp)); //如果块为空闲状态，则把它从空闲链表中移除 if(alloc==0) deletefree(bp); //剩余空间可以构成一个新块 if(left&gt;=(DSIZE*2)) &#123; PUT(HDRP(bp),PACK(asize,1)); PUT(FTRP(bp),PACK(asize,1)); PUT(HDRP(NEXT_BLKP(bp)),PACK(left,0)); PUT(FTRP(NEXT_BLKP(bp)),PACK(left,0)); coalesce(NEXT_BLKP(bp)); &#125; //剩余空间不能构成一个新块 else &#123; size_t allsize=GET_SIZE(HDRP(bp)); PUT(HDRP(bp),PACK(allsize,1)); PUT(FTRP(bp),PACK(allsize,1)); &#125;&#125; 可以证明，这种方法的空间利用率近似于对整个堆做最佳适配搜索，且其搜索效率明显优于对整个堆做最佳适配搜索。","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"http://gonggongjohn.me/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Computer-System","slug":"Computer-System","permalink":"http://gonggongjohn.me/tags/Computer-System/"}]},{"title":"贪心算法","slug":"algorithm/course-exp/algorithm-exp10","date":"2020-12-11T03:45:00.000Z","updated":"2021-09-05T15:53:15.718Z","comments":true,"path":"2020/12/11/algorithm/course-exp/algorithm-exp10/","link":"","permalink":"http://gonggongjohn.me/2020/12/11/algorithm/course-exp/algorithm-exp10/","excerpt":"内容与设计思想 最优打印等待问题 某个班级有 \\(m\\) 位同学一起去打印店打印实验报告。这个打印店只有一台打印机。由于各实验报告的厚薄不同，所需打印时间也不相同。同学 \\(i\\) 需要的打印时间为 \\(t_i(1 \\leq i \\leq m)\\)。应该应如何安排这些同学的打印次序使得平均等待时间最小？ 输入数据格式：在文件students.txt中。第 \\(1\\) 行是正整数 \\(m\\)，表示有 \\(m\\) 位同学。接下来的一行中有 \\(m\\) 个正整数，表示 \\(m\\) 个同学所需要的打印时间。 输出数据格式：将最小平均等待时间输出到文件waittime.txt。 零钱找零问题 张阿姨是超市售货员，经常需要给客户找零。为了买卖便利，张阿姨在找零钱的过程中通常返回最少张（枚）数零钱，市面上流通的钱币有 \\(100, 50, 20, 10, 5, 1, 0.5, 0.1\\) 元等各种样式，若某顾客购物消费 \\(m\\) 元，付款 $ 1.05m / 10$，则找零钱使用的最少钱币数量是？ 输入数据格式：在文件customer.txt中。第 \\(1\\) 行是正整数 \\(a\\)，表示顾客有几次消费。第 \\(2\\) 行有 \\(a\\) 个整数，表示这些顾客的消费 \\(1\\)。 输出数据格式：将找零策略输出到文件output.txt中。共有 \\(a\\) 行。每行 \\(8\\) 个数字，分别表示不同面值钱币的数量。","text":"内容与设计思想 最优打印等待问题 某个班级有 \\(m\\) 位同学一起去打印店打印实验报告。这个打印店只有一台打印机。由于各实验报告的厚薄不同，所需打印时间也不相同。同学 \\(i\\) 需要的打印时间为 \\(t_i(1 \\leq i \\leq m)\\)。应该应如何安排这些同学的打印次序使得平均等待时间最小？ 输入数据格式：在文件students.txt中。第 \\(1\\) 行是正整数 \\(m\\)，表示有 \\(m\\) 位同学。接下来的一行中有 \\(m\\) 个正整数，表示 \\(m\\) 个同学所需要的打印时间。 输出数据格式：将最小平均等待时间输出到文件waittime.txt。 零钱找零问题 张阿姨是超市售货员，经常需要给客户找零。为了买卖便利，张阿姨在找零钱的过程中通常返回最少张（枚）数零钱，市面上流通的钱币有 \\(100, 50, 20, 10, 5, 1, 0.5, 0.1\\) 元等各种样式，若某顾客购物消费 \\(m\\) 元，付款 $ 1.05m / 10$，则找零钱使用的最少钱币数量是？ 输入数据格式：在文件customer.txt中。第 \\(1\\) 行是正整数 \\(a\\)，表示顾客有几次消费。第 \\(2\\) 行有 \\(a\\) 个整数，表示这些顾客的消费 \\(1\\)。 输出数据格式：将找零策略输出到文件output.txt中。共有 \\(a\\) 行。每行 \\(8\\) 个数字，分别表示不同面值钱币的数量。 实现代码 最优打印等待问题 12345678910111213141516171819202122232425#include &lt;fstream&gt;#include &lt;algorithm&gt;using namespace std;int a[1000005];int main() &#123; ifstream fin(&quot;students.txt&quot;); ofstream fout(&quot;waittime.txt&quot;); int m, sum, pre; double mean; fin&gt;&gt;m; for(int i = 0; i &lt; m; i++) fin&gt;&gt;a[i]; sort(a, a + m); sum = 0; pre = 0; for(int i = 0; i &lt; m - 1; i++)&#123; pre += a[i]; sum += pre; &#125; mean = (double)sum / m; fout&lt;&lt;mean; fin.close(); fout.close(); return 0;&#125; 零钱找零问题 123456789101112131415161718192021222324252627282930#include&lt;fstream&gt;#include&lt;cmath&gt;#include&lt;cstring&gt;using namespace std;int m[1000005];int main()&#123; ifstream fin(&quot;customer.txt&quot;); ofstream fout(&quot;output.txt&quot;); int a, rec[8]; double nom[8] = &#123;100, 50, 20, 10, 5, 1, 0.5, 0.1&#125;; double res; fin&gt;&gt;a; for(int i = 0; i &lt; a; i++)&#123; fin&gt;&gt;m[i]; res = floor(1.05 * m[i] * 10) / 10 - m[i]; memset(rec, 0, sizeof(rec)); for(int j = 0; j &lt; 8; j++)&#123; if(res / nom[j] &gt;= 1)&#123; rec[j] = floor(res / nom[j]); res -= nom[j] * rec[j]; &#125; if(res &lt; 0.1) break; &#125; for(int w = 0; w &lt; 8; w++) fout&lt;&lt;rec[w]&lt;&lt;&quot; &quot;; fout&lt;&lt;endl; &#125; fin.close(); fout.close(); return 0;&#125; 算法正确性 最优打印等待问题 算法思路 将打印时间从小到大排序，打印时间小的先开始打印。 正确性证明 设排好序的打印时间序列为 \\(\\left&lt; a_1,a_2,…,a_n \\right&gt;(a_1 \\leq a_2 \\leq \\cdots \\leq a_n)\\) 则所有人的总等待时间 \\[ T = \\sum_{k = 1}^{n} \\sum_{i = 0}^{k - 1} a_i \\] 由于平均等待时间 \\(\\bar{T}=T / n\\)，故要证 \\(\\bar{T}\\) 最小，即要证 \\(T\\) 最小 下证该打印序列的总等待时间最小 任取 \\(p \\neq q \\in \\{1,2,…,n \\}\\)，将 \\(a_p\\) 与 \\(a_q\\) 互换 不妨设 \\(p&lt;q\\)，则此时所有人的总等待时间 \\[ \\begin{aligned} T&#39; &amp;= \\sum_{k=1}^p \\sum_{i=0}^{k-1} a_i + \\sum_{k=p+1}^q \\left( \\sum_{i=0}^{p-1} a_i + a_q + \\sum_{i=p+1}^{k-1} a_i \\right) + \\sum_{k=q+1}^n \\sum_{i=0}^{k-1} a_i \\\\ &amp;= \\sum_{k=1}^p \\sum_{i=0}^{k-1} a_i + \\sum_{k=q+1}^n \\sum_{i=0}^{k-1} a_i + \\sum_{k=p+1}^q \\sum_{i=0}^{p-1} a_i + \\sum_{k=p+1}^q \\sum_{i=p+1}^{k-1} a_i + (q-p) a_q \\end{aligned} \\] 而 \\[ T = \\sum_{k = 1}^p \\sum_{i = 0}^{k - 1} a_i + \\sum_{k = q+1}^n \\sum_{i = 0}^{k - 1} a_i + \\sum_{k = p+1}^q \\sum_{i = 0}^{p - 1}a_i + \\sum_{k = p+1}^q \\sum_{i = p+1}^{k - 1}a_i + (q-p)a_p \\] 又由于 \\(a_p \\leq a_q\\)，故 \\(T&#39; \\geq T\\) 因此互换序列中任意两人的打印顺序所得的总等待时间均不小于原序列的总等待时间 即原序列的总等待时间最小 零钱找零问题 算法思路 将纸币的面值从大到小排序，当大的纸币单张面额超过剩下的找零时再用更小的纸币继续找零 正确性证明 设钱币面额分别为 \\(\\left&lt; a_1, a_2, \\cdots, a_8 \\right&gt; (a_1 &gt; a_2 &gt; \\cdots &gt; a_8)\\)，需要找零的数额 \\(r = \\lfloor 1.05m \\times 10 \\rfloor / 10 - m\\)，贪心算法下对应的找零钱币个数为 \\(k_1, k_2, \\cdots, k_8\\)。则 \\[ r = \\sum_{i = 1}^8 k_i a_i \\] 下证明 \\(s = \\sum_{i = 1}^8 k_i\\) 最小 若在某一种面额的钱币上少用一张换作更小面额的钱币，即 \\(k_p&#39; = k_p - 1 (p \\in \\{1, 2, \\cdots, 8\\})\\)，则 \\[ r = \\sum_{i = 1}^{p - 1} k_i a_i + k_p a_p - a_p + \\sum_{i = p+1}^8 k_i&#39; a_i \\] 由于 \\(a_i &lt; a_p (i &gt; p)\\)，故 \\(\\sum_{i = p+1}^8 (k_i&#39; k_i) &gt; 1\\) 故 \\(s&#39; = \\sum_{i = 1}^8 k_i&#39; &gt; s\\) 故使用贪心算法生成的找零钱币个数总和最小。 运行结果 最优打印等待问题 输入：（students.txt） 10 8 7 5 2 19 6 20 8 1 15 输出：（waittime.txt） 23.6 零钱找零问题 输入：（customer.txt） 8 111 222 333 567 234 256 666 789 输出：（output.txt） 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 3 0 2 0 0 0 1 0 1 1 1 0 0 0 1 0 2 1 3 0 0 1 1 0 3 0 2 0 0 1 1 1 4 0 3 总结 通过实验发现，最优打印等待问题和零钱找零问题均可以使用贪心算法得到正确的结果，文中也从数学上严格证明了贪心算法的正确性。相比动态规划算法，使用贪心算法解决这两个问题的运行效率更高，可以更快的求解出所需的结果。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"动态表","slug":"algorithm/course-exp/algorithm-exp9","date":"2020-12-04T03:45:00.000Z","updated":"2021-09-05T15:53:37.129Z","comments":true,"path":"2020/12/04/algorithm/course-exp/algorithm-exp9/","link":"","permalink":"http://gonggongjohn.me/2020/12/04/algorithm/course-exp/algorithm-exp9/","excerpt":"内容与设计思想 有一个公司想开发一个关于花卉的百科全书，用户只要输入花卉的名称，就能够输出花卉的详细信息。花卉包括：牡丹、芍药、茶花、菊花、梅花、兰花、月季、杜鹃花、郁金香、茉莉花、海棠、荷花、栀子花、莲花、百合、康乃馨、玫瑰、格桑花等1000种。这个公司想提升花卉检索和存储效率，打算采用动态表（Dynamic Table）来实现。由于花卉的数量可能会增加，也可能会减少，所实现的动态表需要有如下功能： 1. 能够插入数据 能够删除数据 能够检索数据 能够按照参数扩展规模或者缩减规模","text":"内容与设计思想 有一个公司想开发一个关于花卉的百科全书，用户只要输入花卉的名称，就能够输出花卉的详细信息。花卉包括：牡丹、芍药、茶花、菊花、梅花、兰花、月季、杜鹃花、郁金香、茉莉花、海棠、荷花、栀子花、莲花、百合、康乃馨、玫瑰、格桑花等1000种。这个公司想提升花卉检索和存储效率，打算采用动态表（Dynamic Table）来实现。由于花卉的数量可能会增加，也可能会减少，所实现的动态表需要有如下功能： 1. 能够插入数据 能够删除数据 能够检索数据 能够按照参数扩展规模或者缩减规模 实现代码 数据生成器 123456789101112131415#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;using namespace std;int main()&#123; ofstream fout(&quot;data.txt&quot;); srand(time(0)); int n; cin&gt;&gt;n; fout&lt;&lt;n&lt;&lt;&quot; &quot;; for(int i = 0; i &lt; n; i++) fout&lt;&lt;rand() % n&lt;&lt;&quot; &quot;; fout.close(); return 0;&#125; 动态表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;using namespace std;int a[5000000];struct table_info&#123; int *p; int size; int num;&#125;;table_info *insert(table_info *table, int description)&#123; if (table-&gt;size == 0)&#123; table-&gt;p = new int[1]; table-&gt;size = 1; &#125; if (table-&gt;num == table-&gt;size)&#123; int *ntable = new int[2 * table-&gt;size]; for (int i = 0; i &lt; table-&gt;num; i++)&#123; ntable[i] = table-&gt;p[i]; &#125; delete[] table-&gt;p; table-&gt;p = ntable; table-&gt;size = 2 * table-&gt;size; &#125; table-&gt;p[table-&gt;num] = description; table-&gt;num++; return table;&#125;// You can add a parameter to insert the actual flower infostable_info *multi_insert(table_info *table, int n)&#123; int t = table-&gt;num; for (int i = 0; i &lt; n; i++)&#123; insert(table, t + i); &#125; return table;&#125;table_info *remove(table_info *table)&#123; if (table-&gt;size == 0)&#123; return table; &#125; if (table-&gt;num &lt;= table-&gt;size / 2)&#123; int *ntable = new int[table-&gt;size / 2]; for (int i = 0; i &lt; table-&gt;num; i++)&#123; ntable[i] = table-&gt;p[i]; &#125; delete[] table-&gt;p; table-&gt;p = ntable; table-&gt;size = table-&gt;size / 2; &#125; table-&gt;num--; return table;&#125;table_info *multi_remove(table_info *table, int n)&#123; for (int i = 0; i &lt; n; i++) &#123; remove(table); &#125; return table;&#125;int query(table_info *table, int i)&#123; if (i &gt;= table-&gt;num) return 0; return table-&gt;p[i];&#125;int main() &#123; int op, num; ifstream fin(&quot;data.txt&quot;); clock_t start, stop; table_info t = &#123;nullptr, 0, 0&#125;; cin&gt;&gt;op&gt;&gt;num; if(op == 4)&#123; int n; fin&gt;&gt;n; multi_insert(&amp;t, n); for(int i = 0; i &lt; n; i++) fin&gt;&gt;a[i]; start = clock(); for(int i = 0; i &lt; n; i++)&#123; query(&amp;t, a[i]); &#125; stop = clock(); cout&lt;&lt;&quot;Time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; fin.close(); &#125; //op: 1 - insert; 2 - delete; 3 - query; 0 - exit else while (op != 0) &#123; if (op == 1)&#123; start = clock(); multi_insert(&amp;t, num); stop = clock(); cout&lt;&lt;&quot;Capacity: &quot;&lt;&lt;t.size&lt;&lt;endl; cout&lt;&lt;&quot;Time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; &#125; if (op == 2)&#123; start = clock(); multi_remove(&amp;t, num); stop = clock(); cout&lt;&lt;&quot;Capacity: &quot;&lt;&lt;t.size&lt;&lt;endl; cout&lt;&lt;&quot;Time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; &#125; if (op == 3)&#123; start = clock(); int r = query(&amp;t, num); stop = clock(); cout&lt;&lt;&quot;description: &quot;&lt;&lt;r&lt;&lt;endl; cout&lt;&lt;&quot;Time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; &#125; cin &gt;&gt; op &gt;&gt; num; &#125; return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 总结 动态表执行 \\(n\\) 次插入和删除操作的摊还代价为 \\(\\mathcal{O}(n)\\)，但在实际运行过程中，当插入或删除的数据规模越过 \\(2\\) 的幂次时，运行时间会发生显著的增长，且幂次越高，运行时间的增长幅度越大，这与实验结果相吻合。实验中使用了直接寻址表作为动态表的存储结构，故理论上可以在 \\(\\mathcal{O}(1)\\) 的时间内查询给定的花卉信息。考虑到不同存储单元的访问代价略有不同，实验结果基本与理论吻合。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"最优二叉搜索树","slug":"algorithm/course-exp/algorithm-exp8","date":"2020-11-27T03:45:00.000Z","updated":"2021-05-20T12:11:50.436Z","comments":true,"path":"2020/11/27/algorithm/course-exp/algorithm-exp8/","link":"","permalink":"http://gonggongjohn.me/2020/11/27/algorithm/course-exp/algorithm-exp8/","excerpt":"内容与设计思想 有一个公司想开发一个关于花卉的百科全书，用户只要输入花卉的名称，就能够输出花卉的详细信息。花卉包括：牡丹、芍药、茶花、菊花、梅花、兰花、月季、杜鹃花、郁金香、茉莉花、海棠、荷花、栀子花、莲花、百合、康乃馨、玫瑰、格桑花。公司也在试运行阶段发现这些花的访问频率不一，有些花经常性被访问，有些被访问的次数就少很多了。这18种花中，第1种的访问频率是6，第2-3种的访问频率是5，第4-6种的访问频率是4，第7-10种的访问频率是3，第11-15种的访问频率是2，第16-18种的访问频率是1。 这个公司想提升花卉检索效率，所以对比了三种方法。 构建优化的二叉搜索树（optimal BST），进行搜索。 将这些花卉按照访问频度从高到低放在一个数组中，并顺序访问来检索 构建哈希表来存储这些数据，并基于哈希表来检索数据。 请实现这三种方法，并且通过实验来比较这三种方法的优劣。","text":"内容与设计思想 有一个公司想开发一个关于花卉的百科全书，用户只要输入花卉的名称，就能够输出花卉的详细信息。花卉包括：牡丹、芍药、茶花、菊花、梅花、兰花、月季、杜鹃花、郁金香、茉莉花、海棠、荷花、栀子花、莲花、百合、康乃馨、玫瑰、格桑花。公司也在试运行阶段发现这些花的访问频率不一，有些花经常性被访问，有些被访问的次数就少很多了。这18种花中，第1种的访问频率是6，第2-3种的访问频率是5，第4-6种的访问频率是4，第7-10种的访问频率是3，第11-15种的访问频率是2，第16-18种的访问频率是1。 这个公司想提升花卉检索效率，所以对比了三种方法。 构建优化的二叉搜索树（optimal BST），进行搜索。 将这些花卉按照访问频度从高到低放在一个数组中，并顺序访问来检索 构建哈希表来存储这些数据，并基于哈希表来检索数据。 请实现这三种方法，并且通过实验来比较这三种方法的优劣。 实现代码 数据生成器 12345678910111213141516171819202122232425262728293031323334#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;#include&lt;cstring&gt;using namespace std;string a[10000005];int shuffle(int length)&#123; return rand() % length;&#125;int main()&#123; string flower[18] = &#123;&quot;paeoniaSA&quot;, &quot;paeoniaLP&quot;, &quot;camellia&quot;, &quot;chrysanthemum&quot;, &quot;plum&quot;, &quot;orchid&quot;, &quot;rose&quot;, &quot;azalea&quot;, &quot;tulip&quot;, &quot;jasmine&quot;, &quot;begonia&quot;, &quot;lotus&quot;, &quot;gardenia&quot;, &quot;lotus&quot;, &quot;lily&quot;, &quot;carnation&quot;, &quot;rose&quot;, &quot;gesang&quot;&#125;; int freq[18] = &#123;6, 5, 5, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1&#125;; srand(time(0)); ofstream fout(&quot;data.txt&quot;); int n; cin&gt;&gt;n; for(int i = 0; i &lt; 18; i++)&#123; for(int j = 0; j &lt; (n * freq[i] / 53); j++)&#123; int t = shuffle(n); while(a[t] != &quot;&quot;)&#123; t = shuffle(n); &#125; a[t] = flower[i]; &#125; &#125; for(int i = 0; i &lt; n; i++)&#123; fout&lt;&lt;a[i]&lt;&lt;&quot; &quot;; &#125; fout.close(); return 0;&#125; 最优二叉搜索树 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;#include&lt;map&gt;using namespace std;string a[10000005];int e[20][20], w[20][20], root[20][20];map&lt;string, int&gt; freq_table;int cnt = 0;struct node&#123; string name; string description; struct node *lchild; struct node *rchild;&#125;;void optimal_bst(int n, string *flower)&#123; for(int i = 1; i &lt;= n + 1; i++)&#123; e[i][i - 1] = 0; w[i][i - 1] = 0; &#125; for(int l = 1; l &lt;= n; l++)&#123; for(int i = 1; i &lt;= n - l + 1; i++)&#123; int j = i + l - 1; e[i][j] = 999999; w[i][j] = w[i][j - 1] + freq_table[flower[j - 1]]; for(int r = i; r &lt;= j; r++)&#123; int t = e[i][r - 1] + e[r + 1][j] + w[i][j]; if(t &lt; e[i][j])&#123; e[i][j] = t; root[i][j] = r; &#125; &#125; &#125; &#125;&#125;node *build_bst(string *flower, string *description, int i, int j)&#123; struct node *rnode = new node(); rnode-&gt;name = flower[root[i][j] - 1]; rnode-&gt;description = description[root[i][j] - 1]; if(i &gt;= j) return rnode; struct node *lc = build_bst(flower, description, i, root[i][j] - 1); struct node *rc = build_bst(flower, description, root[i][j] + 1, j); rnode-&gt;lchild = lc; rnode-&gt;rchild = rc; return rnode;&#125;string search(struct node *rnode,string *name)&#123; struct node *cur = rnode; while (cur)&#123; cnt++; if((*name) == cur-&gt;name) return cur-&gt;description; if (cur-&gt;lchild &amp;&amp; ((*name) &lt; cur-&gt;name)) cur = cur-&gt;lchild; else cur = cur-&gt;rchild; &#125;&#125;int main()&#123; string flower[18] = &#123;&quot;paeoniaSA&quot;, &quot;paeoniaLP&quot;, &quot;camellia&quot;, &quot;chrysanthemum&quot;, &quot;plum&quot;, &quot;orchid&quot;, &quot;rose&quot;, &quot;azalea&quot;, &quot;tulip&quot;, &quot;jasmine&quot;, &quot;begonia&quot;, &quot;lotus&quot;, &quot;gardenia&quot;, &quot;lotus&quot;, &quot;lily&quot;, &quot;carnation&quot;, &quot;rose&quot;, &quot;gesang&quot;&#125;; //Simulate the description of flowers string description[18] = &#123;&quot;DpaeoniaSA&quot;, &quot;DpaeoniaLP&quot;, &quot;Dcamellia&quot;, &quot;Dchrysanthemum&quot;, &quot;Dplum&quot;, &quot;Dorchid&quot;, &quot;Drose&quot;, &quot;Dazalea&quot;, &quot;Dtulip&quot;, &quot;Djasmine&quot;, &quot;Dbegonia&quot;, &quot;Dlotus&quot;, &quot;Dgardenia&quot;, &quot;Dlotus&quot;, &quot;Dlily&quot;, &quot;Dcarnation&quot;, &quot;Drose&quot;, &quot;Dgesang&quot;&#125;; int freq[18] = &#123;6, 5, 5, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1&#125;; for(int i = 0; i &lt; 18; i++)&#123; freq_table[flower[i]] = freq[i]; &#125; sort(flower, flower + 18); sort(description, description + 18); ifstream fin(&quot;data.txt&quot;); clock_t start, stop; int n = 0; while(!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; optimal_bst(18, flower); struct node *troot = build_bst(flower, description, 1, 18); start = clock(); for(int i = 0; i &lt; n; i++)&#123; string t = search(troot, &amp;a[i]); //cout&lt;&lt;t&lt;&lt;&quot; &quot;; &#125; stop = clock(); cout&lt;&lt;endl; cout&lt;&lt;&quot;Total count: &quot;&lt;&lt;cnt&lt;&lt;endl; cout&lt;&lt;&quot;Total time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;&quot;s&quot;&lt;&lt;endl; return 0;&#125; 线性查找 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;using namespace std;string a[10000005];int main() &#123; string flower[18] = &#123;&quot;paeoniaSA&quot;, &quot;paeoniaLP&quot;, &quot;camellia&quot;, &quot;chrysanthemum&quot;, &quot;plum&quot;, &quot;orchid&quot;, &quot;rose&quot;, &quot;azalea&quot;, &quot;tulip&quot;, &quot;jasmine&quot;, &quot;begonia&quot;, &quot;lotus&quot;, &quot;gardenia&quot;, &quot;lotus&quot;, &quot;lily&quot;, &quot;carnation&quot;, &quot;rose&quot;, &quot;gesang&quot;&#125;; //Simulate the description of flowers string description[18] = &#123;&quot;DpaeoniaSA&quot;, &quot;DpaeoniaLP&quot;, &quot;Dcamellia&quot;, &quot;Dchrysanthemum&quot;, &quot;Dplum&quot;, &quot;Dorchid&quot;, &quot;Drose&quot;, &quot;Dazalea&quot;, &quot;Dtulip&quot;, &quot;Djasmine&quot;, &quot;Dbegonia&quot;, &quot;Dlotus&quot;, &quot;Dgardenia&quot;, &quot;Dlotus&quot;, &quot;Dlily&quot;, &quot;Dcarnation&quot;, &quot;Drose&quot;, &quot;Dgesang&quot;&#125;; ifstream fin(&quot;data.txt&quot;); clock_t start, stop; int n = 0; while(!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; int cnt = 0; start = clock(); for(int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; 18; j++) &#123; cnt++; if (a[i] == flower[j]) &#123; string t = description[j]; //cout &lt;&lt; t &lt;&lt; &quot; &quot;; break; &#125; &#125; &#125; stop = clock(); cout&lt;&lt;endl; cout&lt;&lt;&quot;Total count: &quot;&lt;&lt;cnt&lt;&lt;endl; cout&lt;&lt;&quot;Total time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;&quot;s&quot;&lt;&lt;endl; return 0;&#125; 哈希表 123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cstring&gt;#include&lt;unordered_map&gt;using namespace std;string a[10000005];int main()&#123; string flower[18] = &#123;&quot;paeoniaSA&quot;, &quot;paeoniaLP&quot;, &quot;camellia&quot;, &quot;chrysanthemum&quot;, &quot;plum&quot;, &quot;orchid&quot;, &quot;rose&quot;, &quot;azalea&quot;, &quot;tulip&quot;, &quot;jasmine&quot;, &quot;begonia&quot;, &quot;lotus&quot;, &quot;gardenia&quot;, &quot;lotus&quot;, &quot;lily&quot;, &quot;carnation&quot;, &quot;rose&quot;, &quot;gesang&quot;&#125;; //Simulate the description of flowers string description[18] = &#123;&quot;DpaeoniaSA&quot;, &quot;DpaeoniaLP&quot;, &quot;Dcamellia&quot;, &quot;Dchrysanthemum&quot;, &quot;Dplum&quot;, &quot;Dorchid&quot;, &quot;Drose&quot;, &quot;Dazalea&quot;, &quot;Dtulip&quot;, &quot;Djasmine&quot;, &quot;Dbegonia&quot;, &quot;Dlotus&quot;, &quot;Dgardenia&quot;, &quot;Dlotus&quot;, &quot;Dlily&quot;, &quot;Dcarnation&quot;, &quot;Drose&quot;, &quot;Dgesang&quot;&#125;; unordered_map&lt;string, string&gt; flower_map; for(int i = 0; i &lt; 18; i++)&#123; flower_map[flower[i]] = description[i]; &#125; ifstream fin(&quot;data.txt&quot;); clock_t start, stop; int n = 0; while(!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; int cnt = 0; start = clock(); for(int i = 0; i &lt; n; i++)&#123; cnt++; string t = flower_map[a[i]]; //cout&lt;&lt;t&lt;&lt;&quot; &quot;; &#125; stop = clock(); cout&lt;&lt;endl; cout&lt;&lt;&quot;Total count: &quot;&lt;&lt;cnt&lt;&lt;endl; cout&lt;&lt;&quot;Total time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;&quot;s&quot;&lt;&lt;endl; return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 总结 由于每种鲜花被查询的频率不同，为了测试各算法的运行效率，实验中首先根据不同鲜花的查询频率生成了一串不同规模的查询序列，通过比较查询序列所花费的总时间来比较各算法的运行效率。 从实验中可以发现，通过构建哈希表来查询鲜花信息的运行效率最高，且随着数据规模的增大优势越发明显，这与哈希表 \\[\\mathcal{O}(1)\\] 的理论查询时间相符。然而，实验中通过构建最优二叉搜索树进行查询的运行效率不如线性访问的运行效率，这与理论分析不符。通过进一步记录两种算法的查询次数发现在最优二叉搜索树上查询的次数的确小于线性访问的查询次数。由于实验中最优二叉搜索树的每个结点均申请在了堆上，而线性访问时所用数组申请在了栈上，故推测是堆的访问效率不如栈的访问效率导致了其运行效率不如线性访问。 由此可见，在鲜花信息查询问题上，构建哈希表查询是一个最为高效且可行的算法。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"从主方法到Akra-Bazzi定理","slug":"algorithm/theory/akra-bazzi","date":"2020-11-25T03:34:14.000Z","updated":"2021-04-17T09:14:28.536Z","comments":true,"path":"2020/11/25/algorithm/theory/akra-bazzi/","link":"","permalink":"http://gonggongjohn.me/2020/11/25/algorithm/theory/akra-bazzi/","excerpt":"主方法 在算法分析中，当我们使用分治法求解问题时，通常会遇到以递归式定义的算法运行时间函数。要得到此类算法的时间复杂度，就必须求出该递归式的渐近表达式。通常情况下，我们可以通过如下公式直接得到大部分不太复杂的递归式的渐近解。《算法导论》一书中将该方法称为“主方法”。","text":"主方法 在算法分析中，当我们使用分治法求解问题时，通常会遇到以递归式定义的算法运行时间函数。要得到此类算法的时间复杂度，就必须求出该递归式的渐近表达式。通常情况下，我们可以通过如下公式直接得到大部分不太复杂的递归式的渐近解。《算法导论》一书中将该方法称为“主方法”。 Theorem: 设\\[a\\geq 1, b &gt;1\\]，\\[f(n)\\]为一定义在非负整数上的函数， \\[T(n)=aT\\left(\\frac{n}{b}\\right) + f(n)\\]（当 \\[\\frac{n}{b}\\] 不为整数时代表 \\[\\lfloor{\\frac{n}{b}\\rfloor}\\] 或 \\[\\lceil{\\frac{n}{b}\\rceil}\\]），则 若存在 \\[\\varepsilon &gt; 0\\]，使得 \\[f(n) = \\mathcal{O}\\left(n^{\\log_b a - \\varepsilon}\\right)\\]，则 \\[T(n) = \\Theta\\left(n^{\\log_b a}\\right)\\] 若存在 \\[k \\geq 0\\]，使得 \\[f(n) = \\Theta\\left(n^{\\log_b a} \\lg^k n\\right)\\]，则 \\[T(n) = \\Theta\\left(n^{\\log_b a} \\lg^{k+1} n\\right)\\] 若存在 \\[\\varepsilon &gt; 0\\]，使得 \\[f(n) = \\Omega\\left(n^{\\log_b a + \\varepsilon}\\right)\\]，且存在 \\[0&lt;c&lt;1\\]及正整数 \\[N\\]，使得当 \\[n&gt;N\\] 时，有 \\[af\\left(\\frac{n}{b}\\right) \\leq cf(n)\\]，则 \\[T(n) = \\Theta(f(n))\\] 通过该定理，我们可以快速得到一些算法的时间复杂度。 Example1: Strassen矩阵算法的运行时间函数 \\[T(n)=7T\\left(\\frac{n}{2}\\right) + \\Theta(n^2)\\]，求Strassen矩阵算法的时间复杂度 解：由 \\[\\log_2 7 &gt; \\log_2 4 = 2\\] 可知，存在 \\[\\varepsilon &gt; 0\\]，使得 \\[f(n) = \\Theta(n^2) = \\mathcal{O}(n^{\\log_2 7 - \\varepsilon})\\] 故由主定理可知，\\[T(n) = \\Theta(n^{\\log_2 7})\\] Example2: 归并排序算法的运行时间函数 \\[T(n) = 2T\\left(\\frac{n}{2}\\right) + \\Theta(n)\\]，求归并排序算法的时间复杂度 解：由 \\[\\log_2 2 = 1\\] 可知，存在 \\[k=0\\]，使得 \\[f(n) = \\Theta(n) = \\Theta(n^{\\log_2 2} \\lg^k n)\\] 故由主定理可知，\\[T(n) = \\Theta(n \\lg n)\\] Example3: 若一个算法的运行时间函数 \\[T(n)=2T\\left(\\frac{n}{2}\\right) + \\Theta(n^2)\\]，求该算法的时间复杂度 解：由 \\[\\log_2 2 = 1\\] 可知，存在 \\[\\varepsilon &gt; 0\\]，使得 \\[f(n) = \\Theta(n^2) = \\Omega(n^{\\log_2 2 + \\varepsilon})\\] 又由于 \\[af\\left(\\frac{n}{b}\\right) = 2 \\left(\\frac{n}{2}\\right)^2 = \\frac{n^2}{2}\\] 因此仅需取 \\[\\frac{1}{2} \\leq c &lt; 1\\]，则有 \\[af\\left(\\frac{n}{b}\\right) \\leq cf(n)\\] 故由主定理可知，\\[T(n) = \\Theta(n^2)\\] 主定理的证明 下面我们来尝试证明主定理。 主定理的证明思路如下：首先我们考虑当 \\[n\\] 为 \\[b\\] 的某个幂次时的情况，此时可以保证 \\[\\frac{n}{b}\\] 是一个整数，因此可以直接做递推并求出其阶数。随后，通过放缩，我们可以将其推广到一切正整数的情况上去。 首先我们考虑当 \\[n\\] 为 \\[b\\] 的 \\[k\\] 次幂时的情况。此时原递归式可写为 \\[ T(n)=\\left\\{ \\begin{aligned} &amp;\\Theta(1) &amp;, &amp;n = 1 \\\\ &amp;aT\\left(\\frac{n}{b}\\right)+f(n) &amp;, &amp;n=b^i(i=1,2,...,k) \\end{aligned} \\right. \\] 作递推，可得 \\[ \\begin{aligned} T(n)&amp;=aT\\left(\\frac{n}{b}\\right) + f(n) \\\\ &amp;=a^2T\\left(\\frac{n}{b^2}\\right) + af\\left(\\frac{n}{b}\\right) + f(n) \\\\ &amp;=a^3T\\left(\\frac{n}{b^3}\\right) + a^2f\\left(\\frac{n}{b^2}\\right) + af\\left(\\frac{n}{b}\\right) + f(n) \\\\ &amp;=... \\\\ &amp;=a^{\\log_b n} T(1) + \\sum_\\limits{i = 0}^{\\log_b n - 1} a^i f\\left(\\frac{n}{b^i}\\right) \\\\ &amp;=n^{\\log_b a} \\Theta(1) + \\sum_\\limits{i = 0}^{\\log_b n - 1} a^i f\\left(\\frac{n}{b^i}\\right) \\\\ &amp;=\\Theta \\left(n^{\\log_b a} \\right) + \\sum_\\limits{i = 0}^{\\log_b n - 1} a^i f\\left(\\frac{n}{b^i}\\right) \\end{aligned} \\] 因此我们只需要考察 \\[\\sum_\\limits{i = 0}^{\\log_b n - 1} a^i f\\left(\\frac{n}{b^i}\\right)\\] 的渐近表达式即可得到 \\[T(n)\\] 的渐近解。 现在我们来证明如下的的引理成立 Lemma: 设 \\[g(n) = \\sum_\\limits{i = 0}^{\\log_b n - 1} a^i f\\left(\\frac{n}{b^i}\\right)\\] （其中 \\[a \\geq 1, b &gt; 1\\]，\\[n=b^k\\]），则 若存在 \\[\\varepsilon &gt; 0\\]，使得 \\[f(n) = \\mathcal{O} \\left(n^{\\log_b a - \\varepsilon} \\right)\\]，则 \\[g(n) = \\mathcal{O}\\left(n^{\\log_b a}\\right)\\] 若存在 \\[k \\geq 0\\]，使得 \\[f(n) = \\Theta\\left(n^{\\log_b a} \\lg^k n\\right)\\]，则 \\[g(n) = \\Theta\\left(n^{\\log_b a} \\lg^{k+1} n\\right)\\] 若存在 \\[0&lt;c&lt;1\\]及正整数 \\[N\\]，使得当 \\[n&gt;N\\] 时，有 \\[af\\left(\\frac{n}{b}\\right) \\leq cf(n)\\]，则 \\[g(n) = \\Theta(f(n))\\] 证明：① 当 \\[f(n) = \\mathcal{O} \\left(n^{\\log_b a - \\varepsilon} \\right)\\] 时，\\[f\\left(\\frac{n}{b^i}\\right) = \\mathcal{O}\\left(\\left(\\frac{n}{b^i}\\right)^{\\log_b a - \\varepsilon}\\right)\\] 此时 \\[ \\begin{aligned} g(n) &amp;= \\sum_\\limits{i = 0}^{\\log_b n - 1} a^i \\cdot \\mathcal{O}\\left(\\left(\\frac{n}{b^i}\\right)^{\\log_b a - \\varepsilon}\\right) \\\\ &amp;=\\mathcal{O} \\left(\\sum_\\limits{i = 0}^{\\log_b n - 1} a^i \\cdot \\left(\\frac{n}{b^i}\\right)^{\\log_b a - \\varepsilon}\\right) \\\\ &amp;=\\mathcal{O} \\left(n^{\\log_b a - \\varepsilon} \\cdot \\sum_\\limits{i = 0}^{\\log_b n - 1} \\left(\\frac{a}{b^{\\log_b a - \\varepsilon}}\\right)^i\\right) \\\\ &amp;=\\mathcal{O} \\left(n^{\\log_b a - \\varepsilon} \\cdot \\sum_\\limits{i = 0}^{\\log_b n - 1} b^{i\\varepsilon}\\right) \\\\ &amp;=\\mathcal{O} \\left(n^{\\log_b a - \\varepsilon} \\cdot \\frac{n^\\varepsilon - 1}{b^\\varepsilon - 1}\\right) \\\\ &amp;=\\mathcal{O} \\left(\\frac{n^{\\log_b a}}{b^\\varepsilon - 1} - \\frac{n^{\\log_b a - \\varepsilon}}{b^\\varepsilon - 1}\\right) \\\\ &amp;=\\mathcal{O} \\left(n^{\\log_b a} \\right) \\end{aligned} \\] ② 当 \\[f(n) = \\Theta\\left(n^{\\log_b a} \\lg^k n\\right)\\] 时，\\[f\\left(\\frac{n}{b^i}\\right) = \\Theta \\left( \\left(\\frac{n}{b^i}\\right)^{\\log_b a} \\lg^k \\left(\\frac{n}{b^i}\\right)\\right)\\] 此时 \\[ \\begin{aligned} g(n) &amp;= \\sum_\\limits{i = 0}^{\\log_b n - 1} a^i \\cdot \\Theta\\left(\\left(\\frac{n}{b^i}\\right)^{\\log_b a} \\lg^k \\left(\\frac{n}{b^i}\\right)\\right) \\\\ &amp;= \\Theta \\left(\\sum_\\limits{i = 0}^{\\log_b n - 1} a^i\\left(\\frac{n}{b^i}\\right)^{\\log_b a} \\lg^k \\left(\\frac{n}{b^i}\\right)\\right) \\\\ &amp;=\\Theta \\left(n^{\\log_b a} \\cdot \\sum_\\limits{i = 0}^{\\log_b n - 1} \\lg^k \\left(\\frac{n}{b^i}\\right)\\right) \\\\ &amp;=\\Theta \\left(n^{\\log_b a} \\cdot \\sum_\\limits{i = 0}^{\\log_b n - 1} \\left(\\lg n - i \\lg b \\right)^k\\right) \\end{aligned} \\] 由二项式定理可知，\\[\\left(\\lg n - i \\lg b \\right)^k = \\lg^k n + \\mathcal{O}\\left(\\lg^k n\\right)\\] 故 \\[ \\begin{aligned} g(n) &amp;= \\Theta \\left(n^{\\log_b a} \\cdot \\sum_\\limits{i = 0}^{\\log_b n - 1} \\left(\\lg^k n + \\mathcal{O} \\left(\\lg^k n \\right)\\right)\\right) \\\\ &amp;= \\Theta \\left(n^{\\log_b a} \\cdot \\left(\\log_b n \\cdot \\lg^k n + \\log_b n \\cdot \\mathcal{O} \\left(\\lg^k n \\right)\\right)\\right) \\\\ &amp;=\\Theta \\left( n^{\\log_b a} \\cdot \\log_b n \\cdot \\lg^k n\\right) \\\\ &amp;=\\Theta \\left(n^{\\log_b a} \\lg^{k+1} n\\right) \\end{aligned} \\] ③ 由 \\[g(n) = f(n) + \\sum_\\limits{i = 1}^{\\log_b n - 1} a^i f\\left(\\frac{n}{b^i}\\right)\\] 可知 \\[g(n) = \\Omega(f(n))\\] 由条件存在 \\[c&lt;1\\]及正整数 \\[N\\]，使得当 \\[n&gt;N\\] 时，有 \\[af\\left(\\frac{n}{b}\\right) \\leq cf(n)\\] 作递推可知，当 \\[\\frac{n}{b^{i-1}}&gt;N\\] 时，有 \\[a^i f\\left(\\frac{n}{b^i}\\right) \\leq c^if(n)\\] 故 \\[ \\begin{aligned} g(n) &amp;= \\sum_\\limits{i = 0}^{\\log_b n - \\log_b N} a^i f \\left( \\frac{n}{b^i} \\right) + \\sum_\\limits{i = \\log_b n - \\log_b N + 1}^{\\log_b n - 1} a^i f \\left( \\frac{n}{b^i} \\right) \\\\ &amp;\\leq \\sum_\\limits{i = 0}^{\\log_b n - \\log_b N}c^if(n) + \\Theta(1) \\\\ &amp;=f(n) \\sum_\\limits{i = 0}^{\\log_b n - \\log_b N}c^i + \\Theta(1) \\\\ &amp;\\leq f(n) \\sum_\\limits{i = 0}^{\\infty}c^i + \\Theta(1) \\\\ &amp;=\\frac{1}{1-c} \\cdot f(n) + \\Theta(1) \\\\ &amp;=\\mathcal{O}(f(n)) \\end{aligned} \\] 由此可得 \\[g(n) = \\Theta(f(n))\\] 由于 \\[T(n)=\\Theta \\left(n^{\\log_b a} \\right) + \\sum_\\limits{i = 0}^{\\log_b n - 1} a^i f\\left(\\frac{n}{b^i}\\right)\\]，故根据引理我们就能快速得到 \\[n\\] 为 \\[b\\] 的 \\[k\\] 次幂时的主定理。 下面我们需要将 \\[n\\] 为 \\[b\\] 的 \\[k\\] 次幂时的主定理推广到 \\[n\\] 为一切整数时的情况以证明完整的主定理成立。 首先由于 \\[ \\begin{aligned} T(n)&amp;=aT\\left(\\lceil{\\frac{n}{b}\\rceil}\\right) + f(n) \\\\ &amp;\\geq aT\\left(\\frac{n}{b}\\right) + f(n) \\end{aligned} \\] 故根据 \\[n\\] 为 \\[b\\] 的幂次时的主定理可知当 \\[T(n)=aT\\left(\\lceil{\\frac{n}{b}\\rceil}\\right) + f(n)\\] 时，\\[T(n)=\\Omega(A)\\] （根据不同情况 \\[A\\] 取 \\[n^{\\log_b a}\\]、\\[n^{\\log_b a} \\lg^{k+1} n\\] 或 \\[f(n)\\]） 同理可得当 \\[T(n)=aT\\left(\\lfloor{\\frac{n}{b}\\rfloor}\\right) + f(n)\\] 时，\\[T(n)=\\mathcal{O}(A)\\] 下面我们来证明当 \\[T(n)=aT\\left(\\lceil{\\frac{n}{b}\\rceil}\\right) + f(n)\\] 时，\\[T(n)=\\mathcal{O}(A)\\] 令 \\[t_0 = n, t_1 = \\lceil{\\frac{t_0}{b} \\rceil}, t_2 = \\lceil{\\frac{t_1}{b} \\rceil}, ..., t_k = \\lceil{\\frac{t_{k - 1}}{b} \\rceil}=\\Theta(1)\\] 由于 \\[ \\begin{aligned} t_1 &amp;\\leq \\frac{n}{b} + 1 \\\\ t_2 &amp;\\leq \\frac{t_1}{b} + 1 \\leq \\frac{n}{b^2} + \\frac{1}{b} + 1 \\\\ ... \\\\ t_k &amp;\\leq \\frac{t_{k-1}}{b} + 1 \\leq \\frac{n}{b^k} + \\sum_\\limits{i = 0}^{k-1} \\frac{1}{b^i} \\end{aligned} \\] 故 \\[ \\begin{aligned} t_k &amp;\\leq \\frac{n}{b^k} + \\sum_\\limits{i = 0}^{\\infty} \\frac{1}{b^i} \\\\ &amp;=\\frac{n}{b^k} + \\frac{b}{b-1} \\end{aligned} \\] 由于当 \\[k = \\lfloor{\\log_b n\\rfloor}\\] 时有 \\[ \\frac{n}{b^k} + \\frac{b}{b-1} \\leq \\frac{n}{b^{\\log_b n - 1}} + \\frac{b}{b-1} = \\frac{b^2}{b-1} = \\Theta(1) \\] 故 \\[k \\leq \\lfloor{\\log_b n\\rfloor}\\] 故对原式作递推，可得 \\[ \\begin{aligned} T(n) &amp;= aT\\left(t_1\\right) + f(t_0) \\\\ &amp;= a^2T(t_2) + af(t_1) + f(t_0) \\\\ &amp;... \\\\ &amp;\\leq \\Theta \\left(n^{\\log_b a} \\right) + \\sum_\\limits{i = 0}^{\\lfloor{\\log_b n \\rfloor} - 1} a^i f\\left(t_i\\right) \\end{aligned} \\] 因此由上面 \\[n\\] 为 \\[b\\] 的幂次时主定理得推导过程同理可得，\\[T(n) \\leq \\Theta(A)\\]，即 \\[T(n) = \\mathcal{O}(A)\\] 类似的我们同样可以得到当 \\[T(n)=aT\\left(\\lfloor{\\frac{n}{b}\\rfloor}\\right) + f(n)\\] 时，\\[T(n)=\\Omega(A)\\] 于是综上所述，\\[T(n) = \\Theta(A)\\] 可推广到一切正整数，即主定理成立 主方法的局限性 通俗来说，若要使用主方法，\\[f(n)\\] 必须多项式意义上的小于或大于 \\[n^{\\log_b a}\\]（即 \\[f(n)\\] 与 \\[n^{\\log_b a}\\] 的阶数差能够被某个 \\[n^\\varepsilon\\] 控制住），或者 \\[f(n)\\] 仅比 \\[n^{\\log_b a}\\] 大 \\[\\log\\] 阶。而这三种情况并不能覆盖 \\[f(n)\\] 所有可能的函数特征，若 \\[f(n)\\] 的阶数在这三种情况之间，主方法就失效了。 例如当 \\[T(n) = 3T \\left(\\frac{n}{3}\\right) + \\frac{n}{\\lg n}\\] 时，对于 \\[f(n) = \\frac{n}{\\lg n}\\]，无法找到某个 \\[\\varepsilon &gt; 0\\] 使得 \\[f(n) = \\mathcal{O}(n)\\]，即 \\[f(n)\\] 不是多项式意义上的小于 \\[\\log_b a\\]，此时便无法使用主定理得到该递归式的渐近解。 此外，主方法要求递归式必须由平均划分的子式定义，而对于如 \\[T(n) = T\\left(\\frac{n}{2} \\right) + T\\left(\\frac{n}{4} \\right) + T\\left(\\frac{n}{8} \\right) + n\\] 这样非平均划分子式定义的递归式，同样无法使用主方法求解。 遇到此类问题，《算法导论》中推荐使用画递归树+数学归纳证明的方法解决。然而对于一些子问题情况较为复杂的递归式，这种方法的效率十分低下且容易出错，有时并不能很好的作为一种普适的办法使用。 Akra-Bazzi定理 Akra-Bazzi定理是由两位黎巴嫩数学家Mohamad Akra和Louay Bazzi于1998年提出的一种用于求解线性递归式的渐近解的定理。Akra-Bazzi定理相比主定理对递归式的要求更弱，其适用范围也远广于主定理。 为了引出Akra-Bazzi定理，我们需要定义一个多项式增长条件 Definition: 设 \\[g(x)\\] 为一定义在非负实数上的函数，\\[\\{b_k\\}\\] 为一个含有 \\[k\\] 项的数列且满足 \\[0 &lt; b_i&lt; 1\\]，若存在正常数 \\[c_1, c_2\\] 使得对任意 \\[x \\geq 1, 1 \\leq i \\leq k, u \\in [b_i x , x]\\]，均有 \\[c_1 g(x) \\leq g(u) \\leq c_2 g(x)\\] ，则称 \\[g(x)\\] 满足多项式增长条件 由定义可知，若存在 \\[c &gt; 0\\] ，使得 \\[|g&#39;(x)| \\in \\mathcal{O}(x^c)\\]，则 \\[g(x)\\] 满足多项式增长条件。例如，对任意 \\[\\alpha, \\beta \\in \\mathbb{R}\\]，\\[g(x) = x^{\\alpha} \\lg^{\\beta} x\\] 均满足多项式增长条件。 下面我们来叙述Akra-Bazzi定理： Theorem: 设 \\[g(x)\\] 为一非负函数， \\[T(x) = \\left\\{ \\begin{aligned} &amp;\\Theta(1)&amp;, &amp;1 \\leq x \\leq X_0 \\\\ &amp;\\sum_\\limits{i = 1}^k a_i T(b_i x) +g(x)&amp;, &amp;x &gt; X_0 \\end{aligned}\\right.\\]（其中 \\[k \\geq 1, a_i &gt; 0, 0 &lt; b_i &lt; 1\\]，\\[X_0\\] 满足对任意 \\[1 \\leq i \\leq k\\] 有 \\[X_0 &gt; \\frac{1}{b_i}\\] 且 \\[X_0&gt; \\frac{1}{1-b_i}\\]），若 \\[g(x)\\] 满足多项式增长条件，\\[p\\] 为方程 \\[\\sum_\\limits{i = 1}^k a_i b_i^p = 1\\] 的实数解，则 \\[ \\begin{aligned} T(x) &amp;= \\Theta \\left(x^p \\left( 1 + \\int_1^x \\frac{g(u)}{u^{p+1}} du\\right)\\right) \\end{aligned} \\] 通过该定理，我们可以快速求解许多主方法无法处理的递归式。 Example1: 设 \\[T(n) = 2T \\left( \\frac{n}{4}\\right) + 3T \\left(\\frac{n}{6} \\right) + n \\lg n\\]，求 \\[T(n)\\] 的渐近解 解：由 \\[\\frac{2}{4^p} + \\frac{3}{6^p} = 1\\] 可知 \\[p = 1\\] 故由Akra-Bazzi定理可知 \\[ \\begin{aligned} T(n) &amp;= \\Theta \\left(n \\left(1 + \\int_1^n \\frac{x \\lg x}{x^2} dx\\right)\\right) \\\\ &amp;=\\Theta \\left(n \\left(1 + \\frac{1}{2}\\lg^2 n \\right)\\right) \\\\ &amp;=\\Theta \\left(n \\lg^2 n \\right) \\end{aligned} \\] Example2: 设 \\[T(n) = 3T \\left( \\frac{n}{3}\\right) + \\frac{n}{\\lg n}\\]（\\[n \\geq 2\\]），求 \\[T(n)\\] 的渐近解 解：由 \\[\\left(\\frac{3}{3}\\right)^p = 1\\] 可知 \\[p = 1\\] 故由Akra-Bazzi定理可知 \\[ \\begin{aligned} T(n) &amp;= \\Theta \\left(n \\left( 1 + \\int_2^n \\frac{\\frac{x}{\\lg x}}{x^2} dx\\right)\\right) \\\\ &amp;=\\Theta \\left(n \\left( 1 + \\int_2^n \\frac{1}{x \\lg x} dx\\right)\\right) \\\\ &amp;=\\Theta \\left(n \\left( 1 + \\lg \\lg n \\right) \\right) \\\\ &amp;=\\Theta(n \\lg \\lg n) \\end{aligned} \\] Example3: 设 \\[T(n) = \\frac{1}{2} T \\left( \\frac{n}{2} \\right) + \\frac{1}{n}\\]，求 \\[T(n)\\] 的渐近解 解：由 \\[\\frac{1}{2} \\cdot \\left(\\frac{1}{2}\\right)^p = 1\\] 可知 \\[p = -1\\] 故由Akra-Bazzi定理可知 \\[ \\begin{aligned} T(n) &amp;= \\Theta \\left(n^{-1} \\left( 1 + \\int_1^n \\frac{\\frac{1}{x}}{x^0} dx \\right)\\right) \\\\ &amp;= \\Theta(\\left(n^{-1} \\left(1 + \\ln n \\right) \\right) \\\\ &amp;= \\Theta \\left(\\frac{\\ln n}{n}\\right) \\end{aligned} \\] Akra-Bazzi定理的证明 Akra-Bazzi的原始论文中使用了一种称为阶变换（Order Transform）的技巧来导出Akra-Bazzi定理，但完整过程篇幅较长且较为复杂。在已经知道结论的情况下，我们还可以使用数学归纳法来证明Akra-Bazzi定理，这种方法更加简洁且相对容易理解。 首先我们证明一个引理 Lemma: 若 \\[g(x)\\] 为一非负函数且满足多项式增长条件，则存在 \\[c_3, c_4 &gt; 0\\]，使得对任意 \\[x \\geq 1, 1 \\leq i \\leq k\\]，有 \\[ c_3 g(x) \\leq x^p \\int_{b_i x}^x \\frac{g(u)}{u^{p + 1}} du \\leq c_4 g(x) \\] 证明： \\[g(x)\\] 满足多项式增长条件，即存在正常数 \\[c_1, c_2\\] 使得对任意 \\[x \\geq 1, 1 \\leq i \\leq k, u \\in [b_i x , x]\\]，均有 \\[c_1 g(x) \\leq g(u) \\leq c_2 g(x)\\] 故 \\[ \\begin{aligned} x^p \\int_{b_i x}^x \\frac{g(u)}{u^{p + 1}} du &amp;\\leq c_2 x^p g(x) \\cdot \\int_{b_i x}^x \\frac{1}{u^{p + 1}} du \\\\ &amp;\\leq c_2 x^p g(x) \\cdot (x - b_i x) \\cdot \\max \\{ \\frac{1}{(b_i x)^{p+1}}, \\frac{1}{x^{p+1}}\\} \\\\ &amp;=c_2 \\cdot (1-b_i) \\cdot \\max \\{\\frac{1}{b_i^{p+1}}, 1 \\} \\cdot g(x) \\end{aligned} \\] 因此仅需令 \\[c_4 \\geq c_2 \\cdot (1-b_i) \\cdot \\max \\{\\frac{1}{b_i^{p+1}}, 1 \\}\\]，就有 \\[x^p \\int_{b_i x}^x \\frac{g(u)}{u^{p + 1}} du \\leq c_4 g(x)\\] 同理，令 \\[c_3 \\leq c_2 \\cdot (1-b_i) \\cdot \\min \\{\\frac{1}{b_i^{p+1}}, 1 \\} \\]，就有 \\[x^p \\int_{b_i x}^x \\frac{g(u)}{u^{p + 1}} du \\geq c_3 g(x)\\] 故原命题成立 下面我们使用数学归纳法证明存在 \\[c_5&gt;0, x_1 &gt; 1\\]，使得对任意 \\[x &gt; x_1\\]，有 \\[T(x) \\geq c_5 \\cdot x^p \\left( 1 + \\int_1^x \\frac{g(u)}{u^{p+1}} du\\right)\\] 由于 \\[T(x)\\] 的取值范围包含大于1的一切实数，我们不能直接对 \\[x\\] 进行归纳。 为了使用数学归纳法，我们令 \\[I_0 = [1, X_0], I_1 = (X_0+1, X_0+2], ..., I_j = (X_0 + j -1, X_0 + j]\\]。易见 \\[x\\] 必然落在某一个区间 \\[j_0\\] 内，且 \\[b_i x\\] 必然落在 \\[j_0\\] 前面的某一区间内，因此我们可以对 \\[I_j\\] 进行归纳。 当 \\[j=0\\] 时，由定义可知 \\[T(x) = \\Theta(1)\\]，结论显然成立 若结论对任意 \\[j &lt; j_0\\] 均成立，则当 \\[j=j_0\\] 时，有 \\[ \\begin{aligned} T(x) &amp;= \\sum_\\limits{i = 1}^k a_i T(b_i x) +g(x) \\\\ &amp;\\geq \\sum_\\limits{i = 1}^k a_i \\cdot c_5 \\cdot (b_i x)^p \\left( 1 + \\int_1^{b_i x} \\frac{g(u)}{u^{p+1}} du\\right) +g(x) \\\\ &amp;=c_5 x ^p \\sum_\\limits{i = 1}^k a_i \\cdot b_i^p \\left( 1 + \\int_1^{x} \\frac{g(u)}{u^{p+1}} du - \\int_{b_i x}^{x} \\frac{g(u)}{u^{p+1}} du\\right) +g(x) \\\\ &amp;\\geq c_5 x ^p \\cdot \\left( 1 + \\int_1^{x} \\frac{g(u)}{u^{p+1}} du - \\frac{c_4}{x_p}g(x)\\right) \\cdot \\sum_\\limits{i = 1}^k a_i b_i^p +g(x) \\\\ &amp;=c_5 x ^p \\cdot \\left( 1 + \\int_1^{x} \\frac{g(u)}{u^{p+1}} du - \\frac{c_4}{x_p}g(x)\\right) +g(x) \\\\ &amp;=c_5 x ^p \\cdot \\left( 1 + \\int_1^{x} \\frac{g(u)}{u^{p+1}} du \\right) - (c_4c_5 - 1) g(x) \\end{aligned} \\] 因此，只需令 \\[c_5 \\leq \\frac{1}{c_4}\\]，就有 \\[T(x) \\geq c_5 \\cdot x^p \\left( 1 + \\int_1^x \\frac{g(u)}{u^{p+1}} du\\right)\\] 成立 即 \\[T(x) = \\Omega \\left( x^p \\left( 1 + \\int_1^x \\frac{g(u)}{u^{p+1}} du\\right) \\right)\\] 同理可证得 \\[T(x) = \\mathcal{O} \\left( x^p \\left( 1 + \\int_1^x \\frac{g(u)}{u^{p+1}} du\\right) \\right)\\] 由此我们便证得了最终的结论 \\[T(x) = \\Theta \\left(x^p \\left( 1 + \\int_1^x \\frac{g(u)}{u^{p+1}} du\\right)\\right)\\] 推广的Akra-Bazzi定理 事实上，Tom Leighton还给出过一个更一般形式的Akra-Bazzi推广定理 Definition（推广的多项式增长条件）: 设 \\[g(x),h(x)\\] 均为定义在非负实数上的函数，\\[\\{b_k\\}\\] 为一个含有 \\[k\\] 项的数列且满足 \\[0 &lt; b_i&lt; 1\\]，若存在正常数 \\[c_1, c_2\\] 使得对任意 \\[x \\geq 1, 1 \\leq i \\leq k, u \\in [b_i x + h_i(x), x]\\]，均有 \\[c_1 g(x) \\leq g(u) \\leq c_2 g(x)\\] ，则称 \\[g(x)\\] 满足多项式增长条件 Theorem: 设 \\[g(x)\\] 为一非负函数， \\[T(x) = \\left\\{ \\begin{aligned} &amp;\\Theta(1)&amp;, &amp;1 \\leq x \\leq X_0 \\\\ &amp;\\sum_\\limits{i = 1}^k a_i T(b_i x + h_i(x)) +g(x)&amp;, &amp;x &gt; X_0 \\end{aligned}\\right.\\]，若满足以下四个条件： \\[k \\geq 1\\]，对任意 \\[1 \\leq i \\leq k\\]，有 \\[a_i &gt; 0, 0 &lt; b_i &lt; 1\\] \\[X_0\\] 为一足够大的常数，使得存在 \\[\\varepsilon &gt; 0\\]，对任意 \\[1 \\leq i \\leq k, x \\geq X_0\\]，满足以下四个条件： \\[ \\begin{aligned} &amp;(a) \\left( 1 - \\frac{1}{b_i \\lg^{1+\\varepsilon} x} \\right)^p \\left( 1 + \\frac{1}{\\lg^{\\frac{\\varepsilon}{2}} \\left( b_i x + \\frac{x}{\\lg^{1+\\varepsilon} x}\\right)} \\right) \\geq 1+ \\frac{1}{\\lg^{\\frac{\\varepsilon}{2}} x} \\\\ &amp;(b) \\left( 1 + \\frac{1}{b_i \\lg^{1+\\varepsilon} x} \\right)^p \\left( 1 - \\frac{1}{\\lg^{\\frac{\\varepsilon}{2}} \\left( b_i x + \\frac{x}{\\lg^{1+\\varepsilon} x}\\right)} \\right) \\leq 1- \\frac{1}{\\lg^{\\frac{\\varepsilon}{2}} x} \\\\ &amp;(c) \\frac{1}{2} \\left( 1 + \\frac{1}{\\lg^{\\frac{\\varepsilon}{2}} x}\\right) \\leq 1 \\\\ &amp;(d) 2 \\left( 1 - \\frac{1}{\\lg^{\\frac{\\varepsilon}{2}} x} \\right) \\geq 1 \\end{aligned} \\] 存在 \\[\\varepsilon &gt; 0\\] 使得对任意 \\[1 \\leq i \\leq k, x &gt; X_0\\]，均有 \\[|h_i(x)| \\leq \\frac{x}{\\lg^{1+\\varepsilon} x}\\] \\[g(x)\\] 满足多项式增长条件 若设 \\[p\\] 为方程 \\[\\sum_\\limits{i = 1}^k a_i b_i^p = 1\\] 的实数解，则 \\[ \\begin{aligned} T(x) &amp;= \\Theta \\left(x^p \\left( 1 + \\int_1^x \\frac{g(u)}{u^{p+1}} du\\right)\\right) \\end{aligned} \\] 该定理在Akra-Bazzi的基础上，进一步考虑了递归式参数中带余项的情况，因此适用面更广。与Akra-Bazzi类似，其正确性同样可以使用数学归纳法验证，不过篇幅较长，这里就不详细阐述了。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"最长公共子序列","slug":"algorithm/course-exp/algorithm-exp7","date":"2020-11-20T03:45:00.000Z","updated":"2021-05-20T12:05:39.847Z","comments":true,"path":"2020/11/20/algorithm/course-exp/algorithm-exp7/","link":"","permalink":"http://gonggongjohn.me/2020/11/20/algorithm/course-exp/algorithm-exp7/","excerpt":"内容与设计思想 编写随机整数生成算法，生成0到9范围内的N个随机整数并输出； 编写计算最长公共子序列方法的代码； 随机生成两组范围为0到9的5、50、500、5000个随机整数，并求两组整数的最长公共子序列 随机生成一组范围为0到9的5000个随机整数和另一组范围为0到9的5、50、500、5000个随机整数，并求两组整数的最长公共子序列","text":"内容与设计思想 编写随机整数生成算法，生成0到9范围内的N个随机整数并输出； 编写计算最长公共子序列方法的代码； 随机生成两组范围为0到9的5、50、500、5000个随机整数，并求两组整数的最长公共子序列 随机生成一组范围为0到9的5000个随机整数和另一组范围为0到9的5、50、500、5000个随机整数，并求两组整数的最长公共子序列 实现代码 随机数生成器 1234567891011121314151617#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;using namespace std;int main() &#123; ofstream fout1(&quot;data1.txt&quot;); ofstream fout2(&quot;data2.txt&quot;); srand(time(0)); int n1, n2; cin&gt;&gt;n1&gt;&gt;n2; for(int i = 0; i &lt; n1; i++) fout1&lt;&lt;rand() % 10&lt;&lt;&quot; &quot;; for(int i = 0; i &lt; n2; i++) fout2&lt;&lt;rand() % 10&lt;&lt;&quot; &quot;; fout1.close(); fout2.close(); return 0;&#125; 最长公共子序列 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;using namespace std;int d[5005][5005];int main()&#123; ifstream fin1(&quot;data1.txt&quot;); ifstream fin2(&quot;data2.txt&quot;); clock_t start, stop; int a[5005], b[5005], r[5005], n1 = 0, n2 = 0, p, q, cnt; cout&lt;&lt;&quot;原始序列1: &quot;; while (!fin1.eof())&#123; fin1&gt;&gt;a[n1 + 1]; n1++; &#125; for(int i = 1; i &lt;= n1 - 1; i++) cout&lt;&lt;a[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl; cout&lt;&lt;&quot;原始序列2: &quot;; while(!fin2.eof())&#123; fin2&gt;&gt;b[n2 + 1]; n2++; &#125; for(int i = 1; i &lt;= n2 - 1; i++) cout&lt;&lt;b[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl; n1--; n2--; start = clock(); for(int i = 0; i &lt;= n1; i++) for(int j = 0; j &lt;= n2; j++)&#123; if(i == 0 || j == 0) d[i][j] = 0; else&#123; if(a[i] == b[j]) d[i][j] = d[i - 1][j - 1] + 1; else d[i][j] = max(d[i][j - 1], d[i - 1][j]); &#125; &#125; p = n1; q = n2; cnt = d[n1][n2] - 1; while (p &gt; 0 &amp;&amp; q &gt; 0)&#123; if(d[p][q] == (d[p - 1][q - 1] + 1) &amp;&amp; a[p] == b[q])&#123; r[cnt] = a[p]; cnt--; p = p - 1; q = q - 1; continue; &#125; if(d[p][q-1] == d[p - 1][q])&#123; q = q - 1; &#125; else if(d[p][q] == d[p][q - 1])&#123; q = q - 1; &#125; else&#123; p = p - 1; &#125; &#125; stop = clock(); cout&lt;&lt;&quot;最长公共子序列: &quot;; for(int i = 0; i &lt; d[n1][n2]; i++) cout&lt;&lt;r[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; fin1.close(); fin2.close(); return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 总结 使用动态规划算法求两个长度分别为 \\[m\\] 和 \\[n\\] 的序列的公共子序列的时间复杂度为 \\[\\Theta(mn)\\]，回溯打印公共子序列串的时间复杂度为 \\[\\Theta(m+n)\\]，故总的时间复杂度为 \\[\\Theta(mn)\\]。在实验中，当 \\[m=n\\] 时，算法的时间复杂度始终为 \\[\\Theta(n^2)\\]，故在对数坐标下运行时间呈线性变化。而当 \\[m\\] 从远小于 \\[n\\] 逐渐增大到 \\[n\\] 时，算法的时间复杂度从 \\[\\Theta(n)\\] 逐渐变化为 \\[\\Theta(n^2)\\]，故在对数坐标下运行时间曲线的斜率逐渐增大。综上所述，实验结果与理论基本吻合。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"红黑树","slug":"algorithm/course-exp/algorithm-exp6","date":"2020-11-13T03:45:00.000Z","updated":"2021-05-20T11:58:03.342Z","comments":true,"path":"2020/11/13/algorithm/course-exp/algorithm-exp6/","link":"","permalink":"http://gonggongjohn.me/2020/11/13/algorithm/course-exp/algorithm-exp6/","excerpt":"内容与设计思想 编写随机整数生成算法，生成S到T范围内的N个随机整数并输出； 编写红黑树构建算法，中序遍历各节点，输出颜色和值； 随机生成 \\[10^2\\]、\\[10^3\\]、\\[10^4\\]、\\[10^5\\]、\\[10^6\\] 个不同的数，使用红黑树构建算法，并画图描述不同情况下的运行时间差异；","text":"内容与设计思想 编写随机整数生成算法，生成S到T范围内的N个随机整数并输出； 编写红黑树构建算法，中序遍历各节点，输出颜色和值； 随机生成 \\[10^2\\]、\\[10^3\\]、\\[10^4\\]、\\[10^5\\]、\\[10^6\\] 个不同的数，使用红黑树构建算法，并画图描述不同情况下的运行时间差异； 实现代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;using namespace std;struct node&#123; int data; int color; //0 is black, 1 is red struct node *parent; struct node *lchild; struct node *rchild;&#125;;void lrotate(struct node *n)&#123; struct node *nr = n-&gt;rchild; n-&gt;rchild = nr-&gt;lchild; if (nr-&gt;lchild) nr-&gt;lchild-&gt;parent = n; nr-&gt;parent = n-&gt;parent; if(n-&gt;parent) &#123; if (n == n-&gt;parent-&gt;lchild) n-&gt;parent-&gt;lchild = nr; else n-&gt;parent-&gt;rchild = nr; &#125; nr-&gt;lchild = n; n-&gt;parent = nr;&#125;void rrotate(struct node *n)&#123; struct node *nl = n-&gt;lchild; n-&gt;lchild = nl-&gt;rchild; if (nl-&gt;rchild) nl-&gt;rchild-&gt;parent = n; nl-&gt;parent = n-&gt;parent; if(n-&gt;parent) &#123; if (n == n-&gt;parent-&gt;lchild) n-&gt;parent-&gt;lchild = nl; else n-&gt;parent-&gt;rchild = nl; &#125; nl-&gt;rchild = n; n-&gt;parent = nl;&#125;struct node *fixup(struct node *n)&#123; struct node *t; while(n-&gt;parent &amp;&amp; n-&gt;parent-&gt;color == 1)&#123; if(n-&gt;parent == n-&gt;parent-&gt;parent-&gt;lchild)&#123; t = n-&gt;parent-&gt;parent-&gt;rchild; if (t &amp;&amp; t-&gt;color == 1)&#123; n-&gt;parent-&gt;color = 0; t-&gt;color = 0; n-&gt;parent-&gt;parent-&gt;color = 1; n = n-&gt;parent-&gt;parent; if(!n-&gt;parent) n-&gt;color = 0; &#125; else &#123; if (n == n-&gt;parent-&gt;rchild) &#123; n = n-&gt;parent; lrotate(n); &#125; n-&gt;parent-&gt;color = 0; n-&gt;parent-&gt;parent-&gt;color = 1; rrotate(n-&gt;parent-&gt;parent); &#125; &#125; else&#123; t = n-&gt;parent-&gt;parent-&gt;lchild; if (t &amp;&amp; t-&gt;color == 1)&#123; n-&gt;parent-&gt;color = 0; t-&gt;color = 0; n-&gt;parent-&gt;parent-&gt;color = 1; n = n-&gt;parent-&gt;parent; if(!n-&gt;parent) n-&gt;color = 0; &#125; else &#123; if (n == n-&gt;parent-&gt;lchild) &#123; n = n-&gt;parent; rrotate(n); &#125; n-&gt;parent-&gt;color = 0; n-&gt;parent-&gt;parent-&gt;color = 1; lrotate(n-&gt;parent-&gt;parent); &#125; &#125; &#125; t = n; while (t-&gt;parent)&#123; t = t-&gt;parent; &#125; t-&gt;color = 0; return t;&#125;struct node *insert(struct node *root, struct node *n)&#123; struct node *x, *y, *nroot; x = root; while(x)&#123; y = x; if(n-&gt;data &lt; x-&gt;data)&#123; x = x-&gt;lchild; &#125; else&#123; x = x-&gt;rchild; &#125; &#125; n-&gt;parent = y; if(n-&gt;data &lt; y-&gt;data)&#123; y-&gt;lchild = n; &#125; else&#123; y-&gt;rchild = n; &#125; n-&gt;color = 1; nroot = fixup(n); return nroot;&#125;void traverse(struct node *n)&#123; if(!n) return; traverse(n-&gt;lchild); cout&lt;&lt;n-&gt;data&lt;&lt;&quot; &quot;&lt;&lt;n-&gt;color&lt;&lt;endl; traverse(n-&gt;rchild);&#125;int main()&#123; ifstream fin(&quot;data.txt&quot;); clock_t start, stop; int a[1000005], n = 0; while (!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; start = clock(); node *r = new node&#123;a[0], 0, 0x0, 0x0&#125;; for(int i = 1; i &lt; n; i++)&#123; node *n = new node&#123;a[i], 1, 0x0, 0x0&#125;; r = insert(r, n); &#125; stop = clock(); traverse(r); cout&lt;&lt;&quot;Total Time: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;&quot;s&quot;&lt;&lt;endl; fin.close(); return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 总结 对于一颗有 \\[n\\] 个结点的红黑树，可以用 \\[\\mathcal{O}(\\lg n)\\] 的时间向其中插入一个新结点，故构建一棵有 \\[n\\] 个结点红黑树的总运行时间为\\[\\mathcal{O}(n \\lg n)\\]。从图表中可以看出，在对数坐标下，红黑树构建算法随数据规模的增大呈线性增长，与理论基本吻合。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"斐波那契数的相关算法","slug":"algorithm/theory/fibonacci","date":"2020-10-30T15:29:04.000Z","updated":"2021-01-21T07:10:05.314Z","comments":true,"path":"2020/10/30/algorithm/theory/fibonacci/","link":"","permalink":"http://gonggongjohn.me/2020/10/30/algorithm/theory/fibonacci/","excerpt":"斐波那契数列 斐波那契数列由以下递推式定义： \\[ \\left\\{ \\begin{aligned} &amp;F(0)=0 \\\\ &amp;F(1)=1 \\\\ &amp;F(n)=F(n-1)+F(n-2),n \\geq 2 \\end{aligned} \\right. \\]","text":"斐波那契数列 斐波那契数列由以下递推式定义： \\[ \\left\\{ \\begin{aligned} &amp;F(0)=0 \\\\ &amp;F(1)=1 \\\\ &amp;F(n)=F(n-1)+F(n-2),n \\geq 2 \\end{aligned} \\right. \\] 下面我们来推导斐波那契数列的通项公式 设矩阵 \\[M=\\begin{pmatrix} m_{11} &amp; m_{12} \\\\ m_{21} &amp; m_{22} \\end{pmatrix}\\]，使得 \\[\\begin{pmatrix} F_{n+1} \\\\ F_n \\end{pmatrix} =M \\begin{pmatrix} F_{n} \\\\ F_{n-1} \\end{pmatrix}\\] 故 \\[ \\begin{pmatrix} F_{n+1} \\\\ F_n \\end{pmatrix} =\\begin{pmatrix} m_{11} &amp; m_{12} \\\\ m_{21} &amp; m_{22} \\end{pmatrix} \\begin{pmatrix} F_{n} \\\\ F_{n-1} \\end{pmatrix} =\\begin{pmatrix} m_{11}F_{n}+m_{12}F_{n-1} \\\\ m_{21}F_{n}+m_{22}F_{n-1} \\end{pmatrix} \\] 对比等式左右可得 \\[m_{11}=m_{12}=m_{21}=1,m_{22}=0\\]，即 \\[M=\\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix}\\] 由此可知 \\[ \\begin{pmatrix} F_{n+1} \\\\ F_n \\end{pmatrix} =\\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix} \\begin{pmatrix} F_{n} \\\\ F_{n-1} \\end{pmatrix} \\] 对该矩阵等式做递推，可得 \\[ \\begin{pmatrix} F_{n+1} \\\\ F_n \\end{pmatrix} =\\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix}^n \\begin{pmatrix} F_{1} \\\\ F_{0} \\end{pmatrix} =\\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix}^n \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\] 易知 \\[\\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix}\\] 的特征多项式 \\[f(\\lambda) = \\begin{vmatrix} \\lambda - 1 &amp; -1 \\\\ -1 &amp; \\lambda \\end{vmatrix} = \\lambda^2 - \\lambda - 1\\] 令 \\[f(\\lambda) = 0\\]，可得该矩阵的特征值 \\[\\lambda_1 = \\frac{1 - \\sqrt{5}}{2}, \\lambda_2 = \\frac{1 + \\sqrt{5}}{2}\\] 由此可知该矩阵可相似对角化 对于 \\[\\lambda_1 = \\frac{1-\\sqrt{5}}{2}\\]，其对应的特征向量 \\[\\alpha_1 = \\left(\\frac{1-\\sqrt{5}}{2},1\\right)\\] 对于 \\[\\lambda_2 = \\frac{1+\\sqrt{5}}{2}\\]，其对应的特征向量 \\[\\alpha_2 = \\left(\\frac{1+\\sqrt{5}}{2},1\\right)\\] 故若令 \\[P=\\begin{pmatrix} \\frac{1-\\sqrt{5}}{2} &amp; \\frac{1+\\sqrt{5}}{2} \\\\ 1 &amp; 1 \\end{pmatrix}\\]，则 \\[ \\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix} =P \\begin{pmatrix} \\frac{1-\\sqrt{5}}{2} &amp; 0\\\\ 0 &amp; \\frac{1+\\sqrt{5}}{2} \\end{pmatrix} P^{-1} \\] 于是 \\[ \\begin{aligned} \\begin{pmatrix} F_{n+1} \\\\ F_n \\end{pmatrix} &amp;=P \\begin{pmatrix} \\frac{1-\\sqrt{5}}{2} &amp; 0\\\\ 0 &amp; \\frac{1+\\sqrt{5}}{2} \\end{pmatrix}^n P^{-1} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\\\ &amp;=\\begin{pmatrix} \\frac{1-\\sqrt{5}}{2} &amp; \\frac{1+\\sqrt{5}}{2} \\\\ 1 &amp; 1 \\end{pmatrix} \\begin{pmatrix} \\left(\\frac{1-\\sqrt{5}}{2}\\right)^n &amp; 0\\\\ 0 &amp; \\left(\\frac{1+\\sqrt{5}}{2}\\right)^n \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{\\sqrt{5}} &amp; \\frac{5 + \\sqrt{5}}{10} \\\\ \\frac{1}{\\sqrt{5}} &amp; \\frac{5 - \\sqrt{5}}{10} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\\\ &amp;=\\begin{pmatrix} \\frac{1-\\sqrt{5}}{2} &amp; \\frac{1+\\sqrt{5}}{2} \\\\ 1 &amp; 1 \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{\\sqrt{5}}\\left(\\frac{1-\\sqrt{5}}{2}\\right)^n \\\\ \\frac{1}{\\sqrt{5}}\\left(\\frac{1+\\sqrt{5}}{2}\\right)^n \\end{pmatrix} \\\\ &amp;=\\begin{pmatrix} \\frac{\\sqrt{5}-1}{2\\sqrt{5}}\\left(\\frac{1-\\sqrt{5}}{2}\\right)^n + \\frac{\\sqrt{5}+1}{2\\sqrt{5}}\\left(\\frac{1+\\sqrt{5}}{2}\\right)^n \\\\ -\\frac{1}{\\sqrt{5}}\\left(\\frac{1-\\sqrt{5}}{2}\\right)^n + \\frac{1}{\\sqrt{5}}\\left(\\frac{1+\\sqrt{5}}{2}\\right)^n \\end{pmatrix} \\end{aligned} \\] 由此我们得到了斐波那契数列的通项公式 \\[ F_n = \\frac{1}{\\sqrt{5}} \\left[\\left(\\frac{1+\\sqrt{5}}{2}\\right)^n - \\left(\\frac{1-\\sqrt{5}}{2}\\right)^n \\right] \\] 朴素递归算法 朴素递归算法即为递推式定义的程序表达，采用递归的方法实现。代码如下： 12345int Fibonacci(int n)&#123; if(n == 0) return 0; else if(n == 1) return 1; else return Fibonacci(n - 1) + Fibonacci(n - 2);&#125; 易得该算法时间复杂度的递推表达式为 \\[T(n)=T(n-1)+T(n-2)+\\Theta(1)\\] 观察递归树可以发现，所有叶子结点的和就是 \\[\\Theta(F_n)\\] ，而所有内部节点的和为 \\[\\Theta(F_n-1)\\] 故朴素递归算法的时间复杂度 \\[ \\begin{aligned} T(n)&amp;=\\Theta(F_n) + \\Theta(F_n-1) \\\\ &amp;=\\Theta(F_n) \\\\ &amp;=\\Theta\\left(\\left(\\frac{1+\\sqrt{5}}{2}\\right)^n\\right) \\\\ &amp;=\\mathcal{O}(1.62^n) \\end{aligned} \\] 自下而上算法 朴素递归算法的时间复杂度为指数级，这显然是难以接受的。观察发现朴素递归算法的主要问题是重复求解了许多子问题，其本质原因在于朴素递归算法是自上而下的求解子问题，而不同子问题中重叠的部分无法相互影响。故我们换一种思路，自下而上的求解，就可以很好的解决这一问题。代码如下： 123456789int Fibonacci(int n)&#123; int a[N]; //N is the biggest possible value a[0] = 0; a[1] = 1; for(int i = 2; i &lt;= n; i++)&#123; a[i] = a[i - 1] + a[i - 2]; &#125; return a[n];&#125; 易知该算法的时间复杂度 \\[T(n)=n-1=\\Theta(n)\\] 矩阵快速幂算法 自下而上算法已经将原本的指数级时间复杂度降低到了多项式级，我们希望能够进一步的将其降低到对数级别。自然的，我们首先想到的是利用其通项公式并通过快速幂的方法来求解。但斐波那契数列的通项公式中包含无理数，由于计算机的精度限制，计算结果可能并不正确，故这种方法显然是不可靠的。 注：事实上，若不存在精度限制的问题，斐波那契数列还可以表示为 \\[F_n = \\left[ \\left(\\frac{1+\\sqrt{5}}{2}\\right)^n \\right]\\] （其中 \\[[x]\\] 表示取整到离 \\[x\\] 最近的整数） 于是问题转化为是否存在一个仅需在整数域内进行运算的斐波那契通项公式。回顾上面求解斐波那契数列通项公式的过程，注意到 \\[\\begin{pmatrix} F_{n+1} \\\\ F_n \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix}^n \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\]，故我们可以通过求解该矩阵来得到 \\[F_n\\] 的值。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839struct matrix&#123; int a[2][2]; matrix(int a11, int a12, int a21, int a22)&#123; a[0][0] = a11; a[0][1] = a12; a[1][0] = a21; a[1][1] = a22; &#125;&#125;;//This function can only handle 2*2 matrix multiplicationmatrix matrixMult(matrix matA, matrix matB)&#123; matrix matR(0, 0, 0, 0); for(int i = 0; i &lt; 2; i++) for(int j = 0; j &lt; 2; j++) for(int k =0; k &lt; 2; k++) matR.a[i][j] += matA.a[i][k] * matB.a[k][j]; return matR;&#125;matrix matrixPow(matrix mat, int n)&#123; if(n == 1) return mat; if(n % 2 == 0)&#123; matrix matT = matrixPow(mat, n / 2); return matrixMult(matT, matT); &#125; else&#123; matrix matT1 = matrixPow(mat, (n - 1) / 2); matrix matT2 = matrixMult(matT1, matT1); return matrixMult(matT2, mat); &#125;&#125;int Fibonacci(int n)&#123; if(n == 0) return 0; else if(n == 1) return 1; else&#123; matrix matT(1, 1, 1, 0); matrix matR = matrixPow(matT, n); return matR.a[1][0]; &#125;&#125; 分析该算法，发现其时间复杂度的递推表达式为 \\[T(n) = T\\left(\\frac{n}{2}\\right) + \\Theta(1)\\]。故由主定理可知该矩阵快速幂算法的时间复杂度为 \\[T(n) = \\Theta(\\lg n)\\]","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"随机化快速选择算法","slug":"algorithm/course-exp/algorithm-exp5","date":"2020-10-23T03:45:00.000Z","updated":"2021-04-18T10:25:10.659Z","comments":true,"path":"2020/10/23/algorithm/course-exp/algorithm-exp5/","link":"","permalink":"http://gonggongjohn.me/2020/10/23/algorithm/course-exp/algorithm-exp5/","excerpt":"内容与设计思想 编写随机整数生成算法，生成S到T范围内的N个随机整数并输出； 编写随机选择算法和SELECT算法； 随机生成 \\[10^2、10^3、10^4、10^5、10^6\\] 个数，使用随机选择算法和SELECT算法找到第 \\[0.5N\\] 大的数输出，并画图描述不同情况下的运行时间差异； 随机生成 \\[10^6\\] 个数，使用随机选择算法和SELECT算法找到第 \\[0.2N, 0.4N, 0.6N, 0.8N\\] 大的数输出，并画图描述不同情况下的运行时间差异；","text":"内容与设计思想 编写随机整数生成算法，生成S到T范围内的N个随机整数并输出； 编写随机选择算法和SELECT算法； 随机生成 \\[10^2、10^3、10^4、10^5、10^6\\] 个数，使用随机选择算法和SELECT算法找到第 \\[0.5N\\] 大的数输出，并画图描述不同情况下的运行时间差异； 随机生成 \\[10^6\\] 个数，使用随机选择算法和SELECT算法找到第 \\[0.2N, 0.4N, 0.6N, 0.8N\\] 大的数输出，并画图描述不同情况下的运行时间差异； 实现代码 随机数生成器 1234567891011121314#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;using namespace std;int main() &#123; srand(time(0)); ofstream fout(&quot;data.txt&quot;); int s, t, n; cin&gt;&gt;s&gt;&gt;t&gt;&gt;n; for(int i = 0; i &lt; n; i++) fout&lt;&lt;s + rand() % (t - s)&lt;&lt;&quot; &quot;; fout.close(); return 0;&#125; 随机选择算法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;using namespace std;int a[1000005];void swap(int *m, int *n)&#123; int tmp; tmp = *m; *m = *n; *n = tmp;&#125;int partition(int p, int r)&#123; int x = a[r]; int i = p-1; for(int j = p;j &lt; r; j++)&#123; if(a[j] &lt;= x)&#123; i = i + 1; swap(&amp;a[i], &amp;a[j]); &#125; &#125; swap(&amp;a[i+1], &amp;a[r]); return i + 1;&#125;int random_partition(int p, int r)&#123; int t = p + rand() % (r - p + 1); swap(&amp;a[t], &amp;a[r]); return partition(p, r);&#125;int random_select(int p, int r, int i)&#123; if(p == r) return a[p]; int pivot = random_partition(p, r); int k = pivot - p + 1; if(i == k) return a[pivot]; else if(i &lt; k) return random_select(p, pivot - 1, i); else return random_select(pivot + 1, r, i - k);&#125;int main()&#123; srand(time(0)); clock_t start, stop; ifstream fin(&quot;data.txt&quot;); int n, i; n = 0; while(!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; cin&gt;&gt;i; start = clock(); cout&lt;&lt;random_select(0, n - 1, i)&lt;&lt;endl; stop = clock(); cout&lt;&lt;&quot;Total Time: &quot;&lt;&lt;(double) (stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; fin.close(); return 0;&#125; SELECT算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;using namespace std;int a[1000005];struct I2D&#123; int index; int value;&#125;;void swap(int *m, int *n)&#123; int tmp; tmp = *m; *m = *n; *n = tmp;&#125;int partition(int p, int r, int pivot)&#123; int x = a[pivot]; int i = p-1; for(int j = p;j &lt;= r; j++)&#123; if(a[j] &lt;= x)&#123; i = i + 1; swap(&amp;a[i], &amp;a[j]); &#125; &#125; swap(&amp;a[i], &amp;a[pivot]); return i;&#125;void insert_sort(int l, int r)&#123; int key, j; for(int i = l; i &lt;= r; i++)&#123; key = a[i]; j = i - 1; while(j &gt;= l &amp;&amp; a[j] &gt; key)&#123; a[j + 1] = a[j]; j--; &#125; a[j + 1] = key; &#125;&#125;I2D select(int p, int r, int i)&#123; if(r - p &lt; 140)&#123; insert_sort(p, r); I2D pack; pack.index = p + i - 1; pack.value = a[p + i - 1]; return pack; &#125; for(int u = 0; u &lt;= (r - p) / 5; u++)&#123; if(p + u * 5 + 4 &gt; r)&#123; insert_sort(p + u * 5, r); int mid = p + 5 * u + (r - (p + 5 * u)) / 2; swap(&amp;a[mid], &amp;a[p + u]); &#125; else&#123; insert_sort(p + u * 5, p + u * 5 + 4); int mid = p + 5 * u + 2; swap(&amp;a[mid], &amp;a[p + u]); &#125; &#125; I2D tmpPack = select(p, p + (r - p) / 5, ((r - p) / 5 + 1) / 2); int tmp = tmpPack.index; int pivot = partition(p, r, tmp); int k = pivot - p + 1; if(i == k) &#123; I2D subPack; subPack.index = pivot; subPack.value = a[pivot]; return subPack; &#125; else if(i &lt; k) return select(p, pivot - 1, i); else return select(pivot + 1, r, i - k);&#125;int main()&#123; srand(time(0)); clock_t start, stop; ifstream fin(&quot;data.txt&quot;); int n, i; n = 0; while(!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; cin&gt;&gt;i; start = clock(); I2D result = select(0, n-1, i); cout&lt;&lt;result.value&lt;&lt;endl; stop = clock(); cout&lt;&lt;&quot;Total Time: &quot;&lt;&lt;(double) (stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; fin.close(); return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 总结 从理论上看，随机选择算法（Rand-Select）的平均时间复杂度为 \\[\\mathcal{O}(n)\\]，而在最坏情况下会降为 \\[\\Theta(n^2)\\]；而选择算法（Select）在最坏情况下的时间复杂度也为\\[\\mathcal{O}(n)\\]，优于随机选择算法。然而在实际运行时，随机选择算法直接通过随机数确定了pivot，而选择算法需要通过插入排序并递归取中位数的方式找出区间最优的pivot，对数据的预处理耗时较大，故选择算法的实际运行效率反而不如随机选择算法，这也与实验结果相吻合。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"计数排序","slug":"algorithm/course-exp/algorithm-exp4","date":"2020-10-16T03:45:00.000Z","updated":"2021-04-18T10:25:00.153Z","comments":true,"path":"2020/10/16/algorithm/course-exp/algorithm-exp4/","link":"","permalink":"http://gonggongjohn.me/2020/10/16/algorithm/course-exp/algorithm-exp4/","excerpt":"内容与设计思想 随机生成 \\[1...M\\] 范围内的N个整数； 编写计数排序算法； 在相同 \\[M\\] 的条件下，\\[N\\] 分别等于 \\[0.1M, 0.2M, 0.5M, 1M\\] 时的运行时间； 在相同 \\[N\\] 的条件下，\\[M\\] 分别等于 \\[2N，5N，10N，20N\\] 时的运行时间。","text":"内容与设计思想 随机生成 \\[1...M\\] 范围内的N个整数； 编写计数排序算法； 在相同 \\[M\\] 的条件下，\\[N\\] 分别等于 \\[0.1M, 0.2M, 0.5M, 1M\\] 时的运行时间； 在相同 \\[N\\] 的条件下，\\[M\\] 分别等于 \\[2N，5N，10N，20N\\] 时的运行时间。 实现代码 随机数生成器 1234567891011121314#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;using namespace std;int main()&#123; srand(time(0)); ofstream fout(&quot;data.txt&quot;); int n, m; cin&gt;&gt;n&gt;&gt;m; for(int i = 0; i &lt; n; i++) fout&lt;&lt;1 + rand() % (m - 1)&lt;&lt;&quot; &quot;; fout.close(); return 0;&#125; 计数排序 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;#include &lt;vector&gt;using namespace std;int main() &#123; ifstream fin(&quot;data.txt&quot;); clock_t start, stop; vector&lt;int&gt; a; int n, tmp, maxn, minn; maxn = -99999999; minn = 99999999; while (!fin.eof())&#123; fin&gt;&gt;tmp; if(tmp &gt; maxn) maxn = tmp; else if(tmp &lt; minn) minn = tmp; a.push_back(tmp); n++; &#125; n--; vector&lt;int&gt; c(maxn - minn + 1, 0), r(n); start = clock(); for(int i = 0; i &lt; a.size(); i++)&#123; c[a[i] - minn]++; &#125; for(int i = 1; i &lt; c.size(); i++)&#123; c[i] = c[i-1] + c[i]; &#125; for(int i = 0; i &lt; a.size(); i++)&#123; r[c[a[i] - minn] - 1] = a[i]; c[a[i] - minn]--; &#125; stop = clock(); //for(int i = 0; i &lt; r.size(); i++) cout&lt;&lt;r[i]&lt;&lt;&quot; &quot;; //cout&lt;&lt;endl; cout&lt;&lt;&quot;Total time: &quot;&lt;&lt;(double) (stop - start) / CLOCKS_PER_SEC&lt;&lt;endl; fin.close(); return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 总结 计数排序的时间复杂度为 \\[O(n+k)\\]。实验中 \\[N\\] 和 \\[M\\] 的值分别影响 \\[n\\] 和 \\[k\\]，随着 \\[N\\] 和 \\[M\\] 的增大，运行时间呈线性增长。考虑到计算机在实际运行时的系统调度偏差，实验结果基本与理论分析吻合。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"和式的求解方法","slug":"math-combination/sum-solve","date":"2020-10-11T12:40:02.000Z","updated":"2020-10-11T12:44:47.214Z","comments":true,"path":"2020/10/11/math-combination/sum-solve/","link":"","permalink":"http://gonggongjohn.me/2020/10/11/math-combination/sum-solve/","excerpt":"扰动法 扰动法的主要思想是将原和式加上后一项并分离第一项，从而化简得到一个求和下标对齐的包含后一项的和式。若能将该和式写成原来和式的表达式，即可通过解方程求出原和式的通项公式。","text":"扰动法 扰动法的主要思想是将原和式加上后一项并分离第一项，从而化简得到一个求和下标对齐的包含后一项的和式。若能将该和式写成原来和式的表达式，即可通过解方程求出原和式的通项公式。 令 \\[S_n = \\sum_\\limits{0 \\leq k \\leq n} a_k\\] \\[ \\begin{aligned} S_n + a_{n+1} &amp;= \\sum_\\limits{0 \\leq k \\leq n+1} a_k \\\\ &amp;= a_0 + \\sum_\\limits{1 \\leq k \\leq n+1} a_k \\\\ &amp;= a_0 + \\sum_\\limits{1 \\leq k+1 \\leq n+1} a_{k+1} \\\\ &amp;= a_0 + \\sum_\\limits{0 \\leq k \\leq n} a_{k+1} \\end{aligned} \\] 若能将 \\[\\sum_\\limits{0 \\leq k \\leq n} a_{k+1}\\] 写为 \\[S_n\\] 的表达式，即可求出该求和式的通项公式 Example1: 求等比数列和 \\[S_n = \\sum_\\limits{0 \\leq k \\leq n} a q^k \\ \\ (q \\neq 1)\\] 的通项公式 解： 由上述公式可知 \\[ \\begin{aligned} S_n + a_{n+1} &amp;= a + \\sum_\\limits{0 \\leq k \\leq n} aq^{k+1} \\\\ &amp;=a + q \\sum_\\limits{0 \\leq k \\leq n} aq^k \\\\ &amp;=a + q S_n \\end{aligned} \\] 从而 \\((1-q)S_n = a - aq^{n+1}\\) 故 \\(S_n = \\frac{a\\left(1-q^{n+1} \\right)}{1-q} \\ \\ (q \\neq 1)\\) Example2: 求等比差数列和 \\[S_n = \\sum_\\limits{0 \\leq k \\leq n} k \\cdot q^k \\ \\ (q \\neq 1)\\] 的通项公式 解： 由上述公式可知 \\[ \\begin{aligned} S_n + a_{n+1} &amp;= 0 + \\sum_\\limits{0 \\leq k \\leq n} (k+1) \\cdot q^{k+1} \\\\ &amp;=\\sum_\\limits{0 \\leq k \\leq n} k \\cdot q^{k+1} + \\sum_\\limits{0 \\leq k \\leq n} q^{k+1} \\\\ &amp;=q \\sum_\\limits{0 \\leq k \\leq n} k \\cdot q^k + q \\sum_\\limits{0 \\leq k \\leq n} q^k \\\\ &amp;=q S_n + q \\cdot \\frac{1-q^{n+1}}{1-q} \\end{aligned} \\] 从而 \\((1-q)S_n = \\frac{q-q^{n+2}}{1-q} - (n+1) \\cdot q^{n+1}\\) 故 \\[ \\begin{aligned} S_n &amp;= \\frac{q-q^{n+2}}{(1-q)^2} - \\frac{(n+1) \\cdot q^{n+1}}{1-q} \\\\ &amp;= \\frac{q-(n+1)q^{n+1} + nq^{n+2}}{(1-q)^2} \\ \\ (q \\neq 1) \\end{aligned} \\]","categories":[],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"Sequence","slug":"Sequence","permalink":"http://gonggongjohn.me/tags/Sequence/"}]},{"title":"递归式的解法","slug":"math-combination/recursion-solve","date":"2020-10-11T12:39:48.000Z","updated":"2020-10-11T12:52:00.138Z","comments":true,"path":"2020/10/11/math-combination/recursion-solve/","link":"","permalink":"http://gonggongjohn.me/2020/10/11/math-combination/recursion-solve/","excerpt":"求和因子法 对于形如 \\[a_n T_n = b_n T_{n-1} + c_n\\]，我们可以求出其通项公式，下面我们来推导这一公式。 我们考虑通过变量替换的方式将 \\[T_n\\] 前的 \\[a_n\\] 和 \\[b_n\\] 隐去以方便求解。为了做到这一点，我们需要通过将等式左右同时乘以某个表达式使得 \\[b_n T_{n-1}\\] 能够通过 \\[a_n T_n\\] 表示出来（该表达式通常被称为求和因子）。设该表达式为 \\[s_n\\]，两边同乘以 \\[s_n\\]，即为 \\[s_n a_n T_n = s_n b_n T_{n-1} + s_n c_n\\]","text":"求和因子法 对于形如 \\[a_n T_n = b_n T_{n-1} + c_n\\]，我们可以求出其通项公式，下面我们来推导这一公式。 我们考虑通过变量替换的方式将 \\[T_n\\] 前的 \\[a_n\\] 和 \\[b_n\\] 隐去以方便求解。为了做到这一点，我们需要通过将等式左右同时乘以某个表达式使得 \\[b_n T_{n-1}\\] 能够通过 \\[a_n T_n\\] 表示出来（该表达式通常被称为求和因子）。设该表达式为 \\[s_n\\]，两边同乘以 \\[s_n\\]，即为 \\[s_n a_n T_n = s_n b_n T_{n-1} + s_n c_n\\] 注意到等式左边均为第 \\(n\\) 项，而右边为 \\[T_{n-1}\\]，故考虑将右边第一项变为 \\[s_{n-1}a_{n-1}T_{n-1}\\]。要做到这一点，就是要让 \\[s_n b_n = s_{n-1} a_{n-1}\\]，也即 \\[s_n = s_{n-1} \\cdot \\frac{a_{n-1}}{b_n}\\]。做递推，得到 \\[s_n = \\frac{a_{n-1} a_{n-2}...a_1}{b_n b_{n-1}...b_2} \\cdot s_1\\]。故仅需取 \\[s_n = \\frac{a_{n-1} a_{n-2}...a_1}{b_n b_{n-1}...b_2}\\] 或该式的常数倍即可。 现在，我们仅需令 \\[P_n = s_n a_n T_n\\]，即可将原式化简为 \\[P_n = P_{n-1} + s_n c_n\\] 故 \\[P_n = P_0 + \\sum_\\limits{k=1}^n s_k c_k\\] 故 \\[s_n a_n T_n = s_0 a_0 T_0 + \\sum_\\limits{k=1}^n s_kc_k = s_1b_1T_0 + \\sum_\\limits{k=1}^n s_kc_k\\] 故 \\[T_n = \\frac{1}{s_n a_n} \\left( s_1b_1T_0 + \\sum_\\limits{k=1}^n s_kc_k \\right)\\] Example: 已知Hanoi问题满足以下递归表达式，试求出其通项公式 \\[ \\left\\{ \\begin{aligned} &amp;T_0 = 0 \\\\ &amp;T_n = 2T_{n-1} + 1 \\end{aligned} \\right. \\] 解： 由 \\(a_n = 1, b_n = 2\\) 可知求和因子 \\(s_n = \\frac{1}{2^{n-1}}\\)。由于 \\(s_n\\) 乘以常数倍不影响其效果 ，故为了方便起见令 \\(s_n = \\frac{1}{2^n}\\) 两边同乘以 \\[s_n = \\frac{1}{2^n}\\]，得到 \\[\\frac{T_n}{2^n} = \\frac{T_{n-1}}{2^{n-1}} + \\frac{1}{2^n}\\] 令\\(P_n = \\frac{T_n}{2^n}\\)，则 \\[ \\left\\{ \\begin{aligned} &amp;P_n = P_{n-1} + \\frac{1}{2^n} \\\\ &amp;P_0 = 0 \\end{aligned} \\right. \\] 故 \\[P_n = \\sum_\\limits{k=1}^n \\frac{1}{2^k} = 1-\\left(\\frac{1}{2}\\right)^n\\]，即 \\[\\frac{T_n}{2^n} = 1-\\left(\\frac{1}{2}\\right)^n\\] 故 \\[T_n = 2^n - 1\\]","categories":[],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"Sequence","slug":"Sequence","permalink":"http://gonggongjohn.me/tags/Sequence/"}]},{"title":"快速排序时间复杂度分析","slug":"algorithm/theory/qsort-analyze","date":"2020-10-10T07:46:07.000Z","updated":"2021-01-21T07:09:44.427Z","comments":true,"path":"2020/10/10/algorithm/theory/qsort-analyze/","link":"","permalink":"http://gonggongjohn.me/2020/10/10/algorithm/theory/qsort-analyze/","excerpt":"随机化快速排序 随机化快速排序在快速排序的基础上，通过随机数选择一个数作为pivot，使得没有特定的输入数据可以使得该算法达到最坏情况。 下面我们来分析其平均时间复杂度。","text":"随机化快速排序 随机化快速排序在快速排序的基础上，通过随机数选择一个数作为pivot，使得没有特定的输入数据可以使得该算法达到最坏情况。 下面我们来分析其平均时间复杂度。 设 \\[X_k\\] 为一个随机变量，使得对任意 \\[k=0,1,...,n-1\\]，有 \\[ X_k = \\left\\{ \\begin{aligned} 1 &amp;, &amp;if \\ Partition \\ generates \\ (k:n-k-1) \\ split \\\\ 0 &amp;, &amp;otherwise \\end{aligned} \\right. \\] 若随机数生成每个数的概率相同，则 \\[ \\begin{aligned} E[X_k] &amp;= 0 \\cdot \\Pr \\{X_k = 0\\} + 1 \\cdot \\Pr \\{X_k = 1\\} \\\\ &amp;=\\Pr\\{X_k = 1\\} \\\\ &amp;=\\frac{1}{n} \\end{aligned} \\] 设 \\[T(n)\\] 为一个代表总运行时间的随机变量（假设所有的情况均为独立的） 即 \\[ T(n) = \\left\\{ \\begin{aligned} T(0) + T(n-1) + \\Theta(n) &amp;, &amp;if \\ Partition \\ generates \\ (0:n-1) \\ split \\\\ T(1) + T(n-2) + \\Theta(n) &amp;, &amp;if \\ Partition \\ generates \\ (1:n-2) \\ split \\\\ ...... \\\\ T(n-1) + T(0) + \\Theta(n) &amp;, &amp;if \\ Partition \\ generates \\ (n-1:0) \\ split \\end{aligned} \\right. \\] 通过引入 \\[X_k\\]，我们可以把 \\[T(n)\\] 改写为一个和式 \\[ T(n) = \\sum_\\limits{k=0}^{n-1} X_k \\left( T(k) + T(n-k-1) + \\Theta(n) \\right) \\] 故 \\[ \\begin{aligned} E[T(n)] &amp;= E \\left[\\sum_\\limits{k=0}^{n-1} X_k \\left( T(k) + T(n-k-1) + \\Theta(n) \\right) \\right] \\\\ &amp;=\\sum_\\limits{k=0}^{n-1} E \\left[ X_k \\left( T(k) + T(n-k-1) + \\Theta(n) \\right) \\right] \\\\ &amp;=\\sum_\\limits{k=0}^{n-1} E \\left[ X_k \\right] \\cdot E\\left[ \\left( T(k) + T(n-k-1) + \\Theta(n)\\right) \\right] \\\\ &amp;=\\frac{1}{n} \\sum_\\limits{k=0}^{n-1} E[T(k)] + \\frac{1}{n} \\sum_\\limits{k=0}^{n-1} E[T(n-k-1)] + \\frac{1}{n} \\sum_\\limits{k=0}^{n-1} E[\\Theta(n)] \\\\ &amp;=\\frac{2}{n} \\sum_\\limits{k=0}^{n-1} E[T(k)] + \\Theta(n) \\end{aligned} \\] 由此我们得到了一个关于 \\[E[T(n)]\\] 的递推式。下面我们使用第二数学归纳法证明：当 \\[n \\geq 3\\] 时，存在 \\[a&gt;0\\]，使得 \\[E[T(n)] \\leq an \\lg n\\] 为了方便起见，我们首先对原式进行适当变形 \\[ \\begin{aligned} E[T(n)] &amp;=\\frac{2}{n} \\sum_\\limits{k=0}^{n-1} E[T(k)] + \\Theta(n) \\\\ &amp;=\\frac{2}{n}E[T(0)] + \\frac{2}{n}E[T(1)] + \\frac{2}{n} \\sum_\\limits{k=2}^{n-1} E[T(k)] + \\Theta(n) \\\\ &amp;=\\frac{2}{n} \\sum_\\limits{k=2}^{n-1} E[T(k)] + \\Theta(n) \\end{aligned} \\] 随后，我们需要一个引理 Lemma: \\[ \\sum_\\limits{k=2}^{n-1} k \\lg k \\leq \\frac{1}{2}n^2 \\lg n - \\frac{1}{8} n^2 \\] 证明：令 \\[f(x) = x \\lg x\\] 则 \\[f&#39;(x) = \\lg k + \\frac{1}{\\ln 2}\\] 故当 \\[x \\geq 2\\] 时 \\[f(x)&gt;0\\] 且 \\[f(x)\\] 单调递增 因此 \\[ \\begin{aligned} \\sum_\\limits{k=2}^{n-1} k \\lg k &amp;\\leq \\int_2^n x \\lg x dx \\\\ &amp;=\\frac{1}{2} \\int_2^n \\lg x d(x^2) \\\\ &amp;=\\frac{1}{2} \\left(\\left[x^2 \\lg x\\right]\\Big|_2^n - \\int_2^n x^2 \\cdot \\frac{1}{x \\ln 2} dx\\right) \\\\ &amp;=\\frac{1}{2} \\left( n^2 \\lg n - 4 - \\frac{1}{2 \\ln 2} \\cdot \\left[x^2\\right]\\Big|_2^n\\right) \\\\ &amp;=\\frac{1}{2}n^2 \\lg n - \\frac{1}{4 \\ln 2}n^2 -2 + \\frac{1}{\\ln 2} \\\\ &amp;\\leq \\frac{1}{2}n^2 \\lg n -\\frac{1}{4\\ln2}n^2 \\\\ &amp;\\leq \\frac{1}{2}n^2 \\lg n - \\frac{1}{8}n^2 \\end{aligned} \\] 现在就可以对 \\[n\\] 进行归纳了 当 \\[n=3\\] 时，\\[E[T(3)]=\\Theta(1)\\]，仅需取一足够大的 \\[a\\]，则结论显然成立 若对 \\[\\forall k &lt; n\\]，存在 \\[a&gt;0\\] 使得 \\[E[T(n)] \\leq ak \\lg k\\] 成立 则 \\[ \\begin{aligned} E[T(n)] &amp;\\leq \\frac{2}{n} \\sum_\\limits{k=2}^{n-1} ak \\lg k + \\Theta(n) \\\\ &amp;\\leq \\frac{2a}{n} \\cdot \\left( \\frac{1}{2}n^2 \\lg n - \\frac{1}{8}n^2\\right) + \\Theta(n) \\\\ &amp;=an \\lg n - \\frac{an}{4} + \\Theta(n) \\end{aligned} \\] 故仅需取一足够大的 \\[a\\] 使得 \\[\\frac{an}{4}&gt; \\Theta(n)\\]，即可使得 \\[E[T(n)] \\leq an \\lg n\\] 因此 \\[E[T(n)] \\leq an \\lg n\\] 对 \\[\\forall n \\geq 3\\] 均成立 由此可知 \\[E[T(n)] = \\mathcal{O}(n \\lg n)\\] 同理可得 \\[E[T(n)] = \\Omega(n\\lg n)\\] 故 \\[E[T(n)] = \\Theta(n \\lg n)\\] 事实上，原始的快速排序中Partition的操作次数为 \\[n+1\\] 次，故总运行时间的期望还可以进一步写成以下递推式 \\[ \\left\\{ \\begin{aligned} &amp;E[T(0)] = 0 \\\\ &amp;E[T(n)] = \\frac{2}{n}\\sum_\\limits{k = 0}^{n-1} E[T(k)] + n+1 \\ \\ (n \\geq 1) \\end{aligned} \\right. \\] 下面我们来尝试推导该递推式的封闭解 首先将原式化简为整式，得到 \\[n \\cdot E[T(n)] = 2 \\sum_\\limits{k=0}^{n-1} E[T(k)] + n^2+n\\] 注意到等式右边有一个连续的求和式（即从 \\[E[T(0)]\\] 到 \\[E[T(n-1)]\\] 中没有缺项），故考虑做差项消去该求和式。 \\[ \\left\\{ \\begin{aligned} &amp;n \\cdot E[T(n)] = 2 \\sum_\\limits{k=0}^{n-1} E[T(k)] + n^2+n \\\\ &amp;(n-1) \\cdot E[T(n-1)] = 2 \\sum_\\limits{k=0}^{n-2} E[T(k)] + (n-1)^2+(n-1) \\end{aligned} \\right. \\] 两式相减，得到 \\(n \\cdot E[T(n)] - (n-1) \\cdot E[T(n-1)] = 2n + 2 \\cdot E[T(n-1)]\\) 化简得到 \\[n \\cdot E[T(n)] = (n+1) \\cdot E[T(n-1)] + 2n\\] 接下来我们考虑将 \\[E[T(n)]\\] 和 \\[E[T(n-1)]\\] 前的系数消去以找出通项公式。 两边同时乘以 \\[\\frac{2}{n(n+1)}\\] ，得到 \\[\\frac{2}{n+1} \\cdot E[T(n)] = \\frac{2}{n} \\cdot E[T(n-1)] + \\frac{4}{n+1}\\] 令 \\[S_n = \\frac{2}{n+1} \\cdot E[T(n)]\\]，于是原递归式化简为 \\[ \\left\\{ \\begin{aligned} &amp; S_0 = 0 \\\\ &amp; S_n = S_{n-1} + \\frac{4}{n+1} \\end{aligned} \\right. \\] 我们可以快速写出该递归式的通项公式 \\[S_n = 4\\sum_\\limits{k=2}^{n+1} \\frac{1}{k}\\] 即 \\(\\frac{2}{n+1} \\cdot E[T(n)] = 4\\sum_\\limits{k=2}^{n+1} \\frac{1}{k}\\) 化简即得 \\(E[T(n)] = 2(n+1)\\sum_\\limits{k=2}^{n+1} \\frac{1}{k}\\) 引入调和级数符号 \\(H_n = 1 + \\frac{1}{2} + \\frac{1}{3} + ... + \\frac{1}{n}\\) 注意到 \\(\\sum_\\limits{k=2}^{n+1} \\frac{1}{k} = H_n - 1 + \\frac{1}{n+1}\\) 故我们得到了原递推式的封闭解 \\[E[T(n)] = 2(n+1)H_n - 2n\\] 又由 \\(H_n = \\ln n + \\gamma + \\mathcal{O}\\left(\\frac{1}{n} \\right)\\) 故可得 \\[ \\begin{aligned} E[T(n)] &amp;= 2(n+1)\\left(\\ln n + \\gamma + \\mathcal{O} \\left(\\frac{1}{n} \\right)\\right) - 2n \\\\ &amp;= 2n \\ln n + 2(\\gamma - 1)n + 2\\ln n + 2\\gamma + \\mathcal{O}(1) + \\mathcal{O}\\left(\\frac{1}{n}\\right) \\\\ &amp;= \\Theta \\left( n \\ln n \\right) \\\\ &amp;= \\Theta \\left( n \\lg n\\right) \\end{aligned} \\] 由此我们得到了快速排序的平均时间复杂度为 \\(\\Theta (n \\lg n)\\)","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"优先队列","slug":"algorithm/course-exp/algorithm-exp3","date":"2020-10-09T03:45:00.000Z","updated":"2021-04-18T10:24:50.157Z","comments":true,"path":"2020/10/09/algorithm/course-exp/algorithm-exp3/","link":"","permalink":"http://gonggongjohn.me/2020/10/09/algorithm/course-exp/algorithm-exp3/","excerpt":"内容与设计思想 利用堆实现优先级队列； 按照顺序插入\\[1,3,5,7,9,2,4,6,8,10,11,13,15,12,14\\]，构建优先级队列，打印出整个数组的内容； 按照顺序插入\\[9,7,10,12,5,4,2,1,15,14,3,7,8,6,11,13\\]，构建优先级队列，打印出整个数组的内容，并且体会不同输入顺序的情况之下数组内元素排序的差异； 随机生成 \\[1000, 10000, 100000, 1000000\\] 个数，分别构建优先级队列，画图描述不同情况下的运行时间差异。","text":"内容与设计思想 利用堆实现优先级队列； 按照顺序插入\\[1,3,5,7,9,2,4,6,8,10,11,13,15,12,14\\]，构建优先级队列，打印出整个数组的内容； 按照顺序插入\\[9,7,10,12,5,4,2,1,15,14,3,7,8,6,11,13\\]，构建优先级队列，打印出整个数组的内容，并且体会不同输入顺序的情况之下数组内元素排序的差异； 随机生成 \\[1000, 10000, 100000, 1000000\\] 个数，分别构建优先级队列，画图描述不同情况下的运行时间差异。 实现代码 随机数生成器 1234567891011121314#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;using namespace std;int main()&#123; ofstream fout(&quot;data.txt&quot;); int n; srand(time(0)); cin&gt;&gt;n; for(int i = 0; i &lt; n; i++) fout&lt;&lt;rand()&lt;&lt;&quot; &quot;; fout.close(); return 0;&#125; 二叉堆优先队列 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt;using namespace std;int a[1000005], cur;void siftUp(int index)&#123; int parent, tmp; parent = (index - 1) / 2; while(index != 0 &amp;&amp; a[index] &gt; a[parent])&#123; tmp = a[parent]; a[parent] = a[index]; a[index] = tmp; index = parent; parent = (index - 1) / 2; &#125;&#125;void siftDown(int index)&#123; int lchild, rchild, tmp, tcur; lchild = index * 2 + 1; rchild = (index + 1) * 2; while(rchild &lt;= cur &amp;&amp; (a[index] &lt; a[lchild] || a[index] &lt; a[rchild]))&#123; tcur = a[lchild] &gt; a[rchild] ? lchild : rchild; tmp = a[tcur]; a[tcur] = a[index]; a[index] = tmp; index = tcur; lchild = tcur * 2 + 1; rchild = (tcur + 1) * 2; &#125; if(lchild &lt;= cur &amp;&amp; a[index] &lt; a[lchild])&#123; tmp = a[lchild]; a[lchild] = a[index]; a[index] = tmp; &#125;&#125;void add(int data)&#123; cur++; a[cur] = data; siftUp(cur);&#125;int popMax()&#123; int r = a[0]; a[0] = a[cur]; cur--; siftDown(0); return r;&#125;void heapify()&#123; int tcur; tcur = (cur - 1) / 2; while(tcur &gt;= 0)&#123; siftDown(tcur); tcur--; &#125;&#125;int main()&#123; ifstream fin(&quot;data.txt&quot;); clock_t start, stop; cur = 0; while(!fin.eof())&#123; fin&gt;&gt;a[cur]; cur++; &#125; cur--; start = clock(); heapify(); stop = clock(); for(int i = 0; i &lt; cur; i++) cout&lt;&lt;a[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl; cout&lt;&lt;&quot;Total time: &quot;&lt;&lt;((double) (stop - start)) / CLOCKS_PER_SEC&lt;&lt;endl; fin.close(); return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 总结 对 \\[1,3,5,7,9,2,4,6,8,10,11,13,15,12,14\\] 构建优先级队列的结果为：\\[15,11,14,8,10,13,12,6,7,3,9,5,2,1\\] 对 \\[9,7,10,12,5,4,2,1,15,14,3,7,8,6,11,13\\] 构建优先级队列的结果为：\\[15,14,11,13,9,8,10,7,12,5,3,7,4,6,2,1\\] 若将顺序改为 \\[10,5,6,7,12,4,2,14,15,1,3,7,13,9,11,8\\]，则构建优先级队列的结果为：\\[15,14,13,10,12,7,11,8,7,1,3,6,4,9,2,5\\] 经实测表明，随着数据规模的增大，运行时间逐步增加，但在数据规模为 \\[10^6\\] 以内时运行时间均小于0.1秒，这与堆实现优先级队列的插入时间复杂度为 \\[\\mathcal{O}(\\lg n)\\] 基本相符。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"《深入理解计算机系统》笔记整理（一）","slug":"computer-system/csapp-01","date":"2020-10-07T14:31:17.000Z","updated":"2020-10-11T12:39:08.176Z","comments":true,"path":"2020/10/07/computer-system/csapp-01/","link":"","permalink":"http://gonggongjohn.me/2020/10/07/computer-system/csapp-01/","excerpt":"Chapter 2：信息的表示和处理 基本概念 进制转换 进位计数制 定义：设一个 \\(m\\) 进制下\\(w\\) 位的位向量表示为 \\[[a_{w-1}, a_{w-2}, ..., a_0]\\]，则其表示的数为 \\(\\sum_\\limits{i=0}^{w-1} a_im^i\\) \\(m\\) 进制 \\(\\rightarrow\\) 十进制 设一个 \\(w\\) 位 \\(m\\) 进制整数的位相量表示为 \\[\\vec{x} = [ x_{w-1}, x_{w-2}, ..., x_0 ]\\] ，定义函数 \\(M2D(\\vec{x}) = \\sum_\\limits{i=0}^{w-1} x_i m^i\\)，则其对应的十进制数 \\(n = M2D(\\vec{x})\\)","text":"Chapter 2：信息的表示和处理 基本概念 进制转换 进位计数制 定义：设一个 \\(m\\) 进制下\\(w\\) 位的位向量表示为 \\[[a_{w-1}, a_{w-2}, ..., a_0]\\]，则其表示的数为 \\(\\sum_\\limits{i=0}^{w-1} a_im^i\\) \\(m\\) 进制 \\(\\rightarrow\\) 十进制 设一个 \\(w\\) 位 \\(m\\) 进制整数的位相量表示为 \\[\\vec{x} = [ x_{w-1}, x_{w-2}, ..., x_0 ]\\] ，定义函数 \\(M2D(\\vec{x}) = \\sum_\\limits{i=0}^{w-1} x_i m^i\\)，则其对应的十进制数 \\(n = M2D(\\vec{x})\\) 证明：由进位计数制的定义可直接得到结论 Example: 将 \\(3\\) 进制数 \\(12011\\) 转为十进制数 解： 令 \\(\\vec{x} = [1,2,0,1,1], m = 3\\) \\[ \\begin{align} \\therefore n = M2D(\\vec{x}) &amp;= 1 \\cdot 3^4 + 2 \\cdot 3^3 + 1 \\cdot 3^1 +1 \\cdot 3^0 \\\\ &amp;= 81+54+3+1 \\\\ &amp;= 139 \\end{align} \\] 故 \\[12011_3 = 139_{10}\\] 十进制 \\(\\rightarrow\\) \\(m\\) 进制 设一个十进制整数为 \\(n\\)，定义序列 \\[ \\begin{align} &amp;p_0 = \\lfloor \\frac{n}{m} \\rfloor, \\ r_0 = n \\ \\ mod \\ \\ m \\\\ &amp;p_1 = \\lfloor \\frac{p_0}{m}\\rfloor, \\ r_1 = p_0 \\ \\ mod \\ \\ m \\\\ &amp;... \\\\ &amp;p_{s-1} = \\lfloor \\frac{p_{s-2}}{m}\\rfloor = 0, \\ r_{s-1} = p_{s-2} \\ \\ mod \\ \\ m \\\\ \\end{align} \\] 则其对应的 \\(m\\) 进制数的位向量表示为 \\[\\vec{x} = [r_{s-1}, r_{s-2}, ..., r_0]\\] 证明：设 \\(n\\) 在 \\(m\\) 进制下的位相量表示为 \\[[r_{s-1}, r_{s-2}, ..., r_0]\\] 则由定义可知，\\[n = r_{s-1} \\cdot m^{s-1} + r_{s-2} \\cdot m^{s-2} + ...+ r_0\\] 故 \\[n = m \\cdot \\left( r_{s-1} \\cdot m^{s-2} + r_{s-2} \\cdot m^{s-3} + ... + r_1 \\right) + r_0\\] 故 \\(r_0 = n \\ \\ mod \\ \\ m\\) 又由 \\[ \\begin{align} p_0 = \\lfloor \\frac{n}{m} \\rfloor &amp;= r_{s-1} \\cdot m^{s-2} + r_{s-2} \\cdot m^{s-3} + ... + r_1 \\\\ &amp;= m \\cdot \\left( r_{s-1} \\cdot m^{s-3} + r_{s-2} \\cdot m^{s-4} + ... + r_2 \\right) + r_1 \\end{align} \\] 故 \\(r_1 = p_0 \\ \\ mod \\ \\ m\\) 以此类推，\\[r_{i} = p_{i-1} \\ \\ mod \\ \\ m \\ (i=s-2, ..., 1)\\] 故结论成立 Example: 将十进制数 \\(508\\) 转为八进制数 解： \\[ \\begin{align} 508 &amp;= 63 * 8 + 4 \\\\ 63 &amp;= 7 * 8 + 7 \\\\ 7 &amp;= 0 * 8 + 7 \\end{align} \\] 故 \\(508_{10} = 774_8\\) 信息的存储 字长（Word Size） 在计算机中，字（Word）是用来表示一次性处理数据的固定长度。字的位数称为字长（Word Size）。字长是计算机系统中的一个重要指标，字长的大小决定了虚拟地址空间的最大大小。 对于一个字长为 \\(w\\) 的机器来说，其虚拟地址的范围为 \\(0\\) ～ \\(2^w-1\\)，即可以存储 \\(2^w\\) 个字节 Example: 字长为32的机器的虚拟地址范围为 \\(0\\) ～ \\(2^{32}-1\\)，可以存储 \\(2^{32}\\) 个字节 小端序（Little Endian）和大端序（Big Endian） 超过一个字节的数据在计算机中有两种排列顺序：小端序（Little Endian）和大端序（Big Endian）。 小端序：将较低的有效字节放在较小的内存地址中。 大端序：将较低的有效字节放在较大的内存地址中。 Example: 原始数据：12 34 56 78 小端序存储：12 34 56 78 大端序存储：78 56 34 12 注：使用ASCII码存储的字符数据在任何系统上都能得到相同的结果，不受端序的影响。 基本运算 位级运算 计算机中有以下四种基本位级运算：按位与（&amp;），按位或（|），按位非（~），按位异或（^），其规则与布尔代数中的规则一致。 Example: 101100 &amp; 100110 = 100100 101100 | 100110 = 101110 ~101100 = 010011 101100 ^ 100110 = 001010 逻辑运算 计算机中提供了以下三种逻辑运算：且（&amp;&amp;），或（||），非（!），其规则与命题逻辑中的规则一致。 注：C语言中的逻辑运算有提早终止（Early Termination）的机制，即当两个表达式做逻辑运算时，若前一个表达式已经能确定最终结果，则不再计算后一个表达式。 Example: (1+1=2) &amp; (3=3) = 1 (1-1=0) || (1=2) = 1 !(2*5=10) = 0 !0x3F = 0 位移运算 计算机中提供了三种位移操作：左移（&lt;&lt;），逻辑右移（&gt;&gt;），算术右移（&gt;&gt;） \\(x\\) 左移 \\(k\\) 位：将 \\(x\\) 的最高 \\(k\\) 位丢弃并在最低位后补充 \\(k\\) 个零，相当于 \\(x \\cdot 2^k\\) \\(x\\) 逻辑右移 \\(k\\) 位：将 \\(x\\) 的最低 \\(k\\) 位丢弃并在最高位前补充 \\(k\\) 个零，相当于 \\(\\lfloor \\frac{x}{2^k} \\rfloor\\) 算术右移 \\(k\\) 位：将 \\(x\\) 的最低 \\(k\\) 位丢弃并在最高位前补充 \\(k\\) 个最高位值 整数的存储与运算 无符号整数 二进制数码不表示符号信息的整数称为无符号整数，其代码的数字与常规的进位计数制规则一致。即若定义 \\[B2U_w(\\vec{x}) = \\sum_\\limits{i=0}^{w-1}x_i 2^i\\]，则一个 \\(w\\) 位的二进制位相量 \\(\\vec{x}\\) 所对应的十进制数 \\(n = B2U_w(\\vec{x})\\) 由定义可知，一个 \\(w\\) 位的二进制位相量 \\(\\vec{x}\\) 可表示的整数范围为 \\(0\\) ～ \\(2^w-1\\) 有符号整数 有符号整数是采用补码进行存储的整数。补码是对二进制的一种新的解读方式，其严格的定义如下：若定义 \\[B2T_w(\\vec{x}) = -x_{w-1} 2^{w-1} + \\sum_\\limits{i=0}^{w-2}x_i 2^i\\]，则一个 \\(w\\) 位的二进制位相量 \\(\\vec{x}\\) 所对应的十进制数 \\(n = B2T_w(\\vec{x})\\)。通俗来说，补码将原本 \\(0\\) ～ \\(2^w-1\\) 中 \\(2^{w-1}\\) ～ \\(2^{w} - 1\\) 的部分重新解读为负数，从而使得其可以表示负数。从取模的角度来看， 对于一个 \\(0\\) ～ \\(2^{w-1} - 1\\) 中的数 \\(n\\) 和一个 \\(2^{w-1}\\) ～ \\(2^{w} - 1\\) 中的数 \\(m\\)，\\((n + m) \\ \\ mod \\ \\ 2^w = n - (2^w - m)\\)，故这样定义是合适的。且容易看出其与无符号整数间的转换关系为 \\[ U2T(x) = \\left\\{ \\begin{aligned} &amp;x &amp;, &amp;0 \\leq x \\leq 2^{w-1} - 1 \\\\ &amp;x - 2^w &amp;, &amp;2^{w-1} \\leq x \\leq 2^w - 1 \\end{aligned} \\right. \\] \\[ T2U(x) = \\left\\{ \\begin{aligned} &amp;x &amp;, &amp; 0 \\leq x \\leq 2^{w-1}-1 \\\\ &amp;x + 2^w &amp;, &amp; -2^{w-1} \\leq x \\leq -1 \\end{aligned} \\right. \\] 证明：设二进制位向量 \\(\\vec{x}\\) 当 \\[0 \\leq B2U_w(\\vec{x}) \\leq 2^{w-1} - 1\\] 时 \\[x_{w-1} = 0\\] 此时 \\[B2T_w(\\vec{x}) = \\sum_\\limits{i=0}^{w-2}x_i 2^i = B2U_w(\\vec{x})\\] 故 \\[U2T_w(x) = x\\] 当 \\[2^{w-1} \\leq x \\leq 2^w - 1\\] 时 \\[x_{w-1} = 1\\] 此时 \\[ \\left\\{ \\begin{aligned} B2T_w(\\vec{x}) &amp;= -2^{w-1} + \\sum_\\limits{i=0}^{w-2}x_i 2^i \\\\ B2U_w(\\vec{x}) &amp;= 2^{w-1} + \\sum_\\limits{i=0}^{w-2}x_i 2^i \\end{aligned} \\right. \\] 故 \\[B2T_w(\\vec{x}) = B2U_w(\\vec{x}) - 2^w\\] 故 \\[U2T_w(\\vec{x}) = x - 2^w\\] \\[T2U(x)\\]的情况同理可证 注：无符号或有符号整数仅为二进制解读为十进制时的不同解读方式，由于计算机在二进制层面进行运算，故计算机在进行底层运算时并不区分这两种解读方式。","categories":[],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"CSAPP","slug":"CSAPP","permalink":"http://gonggongjohn.me/tags/CSAPP/"}]},{"title":"Data Lab实验记录","slug":"computer-system/csapp-datalab","date":"2020-10-02T14:15:21.000Z","updated":"2021-04-17T11:14:04.166Z","comments":true,"path":"2020/10/02/computer-system/csapp-datalab/","link":"","permalink":"http://gonggongjohn.me/2020/10/02/computer-system/csapp-datalab/","excerpt":"Data Lab要求我们在有一系列运算限制的情况下实现某些运算操作，从而尽可能的开发位运算的作用。这个Lab中的绝大部分内容的技巧性都比较强，可以阅读《算法心得：高效算法的奥秘》一书作为参考。","text":"Data Lab要求我们在有一系列运算限制的情况下实现某些运算操作，从而尽可能的开发位运算的作用。这个Lab中的绝大部分内容的技巧性都比较强，可以阅读《算法心得：高效算法的奥秘》一书作为参考。 概述 在Lab中的bits.c文件内描述了一系列规则和我们需要实现的函数。具体来说，我们需要实现以下几个函数： bitAnd：按位与 getByte：从一个二进制整数中提取某个Byte（8位） logicalShift：逻辑右移 bitCount：计算一个二进制整数中1的位数 bang：逻辑取反 tmin：最小的补码能表示的int型整数 fitsBits：判断某个整数能否用n位补码表示 divpwr2：计算 \\[\\frac{x}{2^n}\\] 并向0取整 negate：取相反数 isPositive：判断某个数是否为正数 isLessOrEqual：判断x是否小于等于y ilog2：计算 \\[\\lfloor \\log_2 x \\rfloor\\] float_neg：在float型表示下取相反数 float_i2f：将int型表示转为float型表示 float_twice：在float型表示下计算 \\[2*x\\] 对于上面这些函数，我们一般只能使用以下几种运算操作： 逻辑取反（!），按位取反（~），按位与（&amp;），按位异或（^），按位或（|），加法（+），左移（&lt;&lt;），算数右移（&gt;&gt;） 在此基础之上，其中某些函数还有进一步的限制要求： bitAnd：只允许使用按位取反（~）和按位或（|）操作 bang：不允许使用逻辑取反（!）操作 float_neg/float_i2f/float_twice：允许使用一切整数操作、逻辑与（&amp;&amp;）、逻辑或（||）、if语句及while语句 Lab中提供了两种工具来帮助我们检查实现是否正确： 12&gt; ./dlc -e bits.c # 检查函数实现中操作是否符合要求&gt; ./driver.pl # 检查函数实现是否正确 具体实现 bitAnd 由De Morgan律可知 \\[\\neg (P \\land Q) = (\\neg P) \\lor (\\neg Q)\\] 故 \\[P \\land Q = \\neg ((\\neg P) \\lor (\\neg Q))\\] 123int bitAnd(int x, int y) &#123; return ~(~x | ~y);&#125; 一行代码搞定。 getByte 采用掩码的思想，要提取某个Byte的数值并屏蔽其他位的值，可以将目标位移动到最小的8位并将其和0xFF做按位与运算。观察输入的参数，要提取 \\[x\\] 中的第 \\[n\\] 个Byte，就要将 \\[x\\] 向右移动 \\[8*n\\] 位。使用位运算操作的话，也即x&gt;&gt;(n&lt;&lt;3)。 123int getByte(int x, int n) &#123; return (x&gt;&gt;(n&lt;&lt;3)) &amp; 0xFF;&#125; 同样可以一行搞定。 logicalShift 算数右移和逻辑右移的区别在于，算数右移会在高位填充最高位的值，而逻辑右移则不会，因此一个基本的思路就是使用算数右移后屏蔽掉高位的值，于是问题便转化为如何构造掩码。 我们的掩码要保证原数最高位之前均为0，最高位之后均为1。而利用算数右移会填充最高位的特性，我们可以将0x1移动到最高位，随后算数右移到目标位置，再取反即可满足要求，问题也迎刃而解。 123int logicalShift(int x, int n) &#123; return (x&gt;&gt;n)&amp;(~((0x01&lt;&lt;31)&gt;&gt;n&lt;&lt;1));&#125; bitCount 利用位运算统计一个字中1的个数是一个技巧性十分强的算法。它的主要思想是分治法（Divide And Conquer），将统计整个字中1的个数的问题转化为多个统计更小区间内1的个数的问题。具体来说，一个32位的整数中，我们可以将其划分为两个16位的区间，进而划分为4个8位的区间，再划分为8个4位的区间，最后划分为16个2位的区间，因此我们仅需要统计每两位中1的个数，再将结果逐步合并即可得到整个数中1的个数。 对于统计每2位中1的个数，我们同样可以采用掩码的思想，先对两位中第一位和0x1做与运算，再将整个数右移一位与0x1做与运算，将两个结果相加即可统计出这两位中1的个数。 此外，由于题目中规定不能使用超过0xFF的十六进制数，我们需要通过多步位移的方法来构造出我们想要的的掩码。 1234567891011121314151617int bitCount(int x) &#123; int cnt; int maskt1 = (0x55) | (0x55&lt;&lt;8); int maskt2 = (0x33) | (0x33&lt;&lt;8); int maskt3 = (0x0F) | (0x0F&lt;&lt;8); int mask1 = (maskt1) | (maskt1&lt;&lt;16); int mask2 = (maskt2) | (maskt2&lt;&lt;16); int mask3 = (maskt3) | (maskt3&lt;&lt;16); int mask4 = (0xFF) | (0xFF&lt;&lt;16); int mask5 = (0xFF) | (0xFF&lt;&lt;8); cnt = (x &amp; mask1) + ((x&gt;&gt;1) &amp; mask1); cnt = (cnt &amp; mask2) + ((cnt&gt;&gt;2) &amp; mask2); cnt = (cnt &amp; mask3) + ((cnt&gt;&gt;4) &amp; mask3); cnt = (cnt &amp; mask4) + ((cnt&gt;&gt;8) &amp; mask4); cnt = (cnt &amp; mask5) + ((cnt&gt;&gt;16) &amp; mask5); return cnt;&#125; negate 在补码表示中，对一个二进制表示下 \\[n\\] 位的整数 \\[x\\] 取相反数相当于做运算 \\[2^n-x\\]，而 \\[(2^n-1)-x\\] 相当于对x按位取反，因此总的位运算表示即为~x+1 123int negate(int x) &#123; return ~x+1;&#125; bang 逻辑取反操作即是要让0变为1，除0以外的任何数变为0，因此我们需要找到一个把0和其他数分开的位运算特性。利用补码表示中负数的最高位始终为1的特性，我们可以发现让一个数和它在补码下的相反数做按位或运算时，如果这个数不为0，那么它的最高位始终为1，而由于0的补码还是0，因此最高位为0。于是利用上一题的结论，我们就能得到最终的运算操作。 123int bang(int x) &#123; return ((x|(~x+1))&gt;&gt;31)+1;&#125; tmin 在模的剩余系下，最靠近中间的数即为离边界距离最远的数。利用这一特性可知补码表示下最小的负数最高位为1，其余全为0。 123int tmin(void) &#123; return 0x1&lt;&lt;31;&#125; fitsBits 如果一个数能用n为补码表示，那么取它的后n位做符号扩展到原来的长度后值应与原来一样。利用逻辑右移的特性，我们只需要将x与x&lt;&lt;(32 - n)&gt;&gt;(32 - n)相比较即可。利用位运算取相反数的结论，以及异或运算的性质 \\[x \\oplus x = 0\\]，即可得到最终的运算操作。 1234int fitsBits(int x, int n) &#123; int shift = 32 + ~n + 1; return !(x^((x&lt;&lt;shift)&gt;&gt;shift));&#125; divpwr2 要计算 \\[\\frac{x}{2^n}\\] 并向0取整，因此我们需要分类讨论。当 \\[x \\geq 0\\] 时，这一操作相当于x&gt;&gt;n；而当 \\[x&lt;0\\] 时，若直接对原数右移n位，相当于 \\[\\lfloor \\frac{x}{2^n} \\rfloor\\]，并不满足向0取整的要求。而对于整数，有如下定理成立： 对于整数 \\[x\\] 和 \\[y(y&gt;0)\\]，有 \\[\\lceil \\frac{x}{y} \\rceil = \\lfloor \\frac{x+y-1}{y} \\rfloor\\] 由此可知对于负数，我们只需将其加上一个偏置 \\[2^n -1\\]，即可将结果变为向上取整。因此当 \\[x&lt;0\\] 时的操作为 \\[(x+(1&lt;&lt;n)-1)&gt;&gt;n\\]。 现在我们要通过位运算将这两种情况整合到一起。通过观察可以发现，我们只需要让某个运算在 \\[x \\geq 0\\] 时的结果为0，在 \\[x &lt; 0\\] 时的结果为(1&lt;&lt;n)-1即可。同样的，我们可以使用掩码的思想来做到这一点。结合补码的性质及算数右移的性质，我们可以发现只需要将x右移31位即可得到掩码。由此最终的运算操作也迎刃而解。 12345int divpwr2(int x, int n) &#123; int tn = ~((~0)&lt;&lt;n); int tx = (~((x&gt;&gt;31) &amp; 0x01)) + 1; return (x + (tx &amp; tn)) &gt;&gt; n;&#125; isPositive 根据题意，我们要让大于0的数运算结果等于1，0和小于0的数运算结果等于0。根据补码的性质，对于除0以外的其他数，我们只需判断最高位是否为1即可；而对于0，我们可以将其单独讨论。 1234int isPositive(int x) &#123; int tx = (x&gt;&gt;31) &amp; 0x01; return !(tx | !x);&#125; isLessOrEqual 当两数异号时，如果直接相减可能会导致结果溢出，但此时我们仅需判断其中一个数的正负即可得知结果，因此无需做减法运算；而当两个数同号时，可以保证相减不会溢出，因此我们只需相减判断符号即可。 1234567891011int isLessOrEqual(int x, int y) &#123; int negx = ~x + 1; int addx = negx + y; int sign = addx&gt;&gt;31&amp;1; int left = 1&lt;&lt;31; int xleft = x &amp; left; int yleft = y &amp; left; int xor = xleft ^ yleft; xor = (xor &gt;&gt; 31) &amp; 1; return ((!xor)&amp;(!sign))|(xor&amp;(xleft&gt;&gt;31));&#125; ilog2 根据二进制的性质，我们只需要找到最高1的位置即可。仿照前面统计1的个数的思想，我们可以使用二分法来解决这一问题。 12345678910111213141516int ilog2(int x) &#123; int t1, t2, t3; t3 = x; t2 = (!!(t3&gt;&gt;16))&lt;&lt;4; t3 = t3&gt;&gt;t2; t1 = (!!(t3&gt;&gt;8))&lt;&lt;3; t3 = t3&gt;&gt;t1; t2 = t2 | t1; t1 = (!!(t3&gt;&gt;4))&lt;&lt;2; t3 = t3&gt;&gt;t1; t2 = t2 | t1; t1 = (!!(t3&gt;&gt;2))&lt;&lt;1; t3 = t3&gt;&gt;t1; t2 = t2 | t1; return (t2 | (t3&gt;&gt;1));&#125; float_neg 在IEEE标准下，float型的格式为1位符号位，8位指数位和23位尾数位。因此我们首先要判断输入的数能否表示为一个float型小数。具体的，我们只需要将其符号位去除（左移），随后将其与0xFF000000比较即可。若大于这个数，则表明其不能表示为float型小数；若小于等于这个数，只需要改变其符号位即可得到结果。 123456789unsigned float_neg(unsigned uf) &#123; unsigned x = 0x80000000; unsigned c = 0xFF000000; unsigned tuf = uf&lt;&lt;1; if((c &amp; tuf) == c)&#123; if(tuf != c) return uf; &#125; return uf ^ x;&#125; float_i2f 根据IEEE标准中float型的规则，我们需要先计算出符号尾及指数位的数值。随后，我们仅需利用位移操作将符号位、指数位、尾数位移动到相应的位置，再根据舍入的规则做一次微调即可。 12345678910111213141516171819unsigned float_i2f(int x) &#123; unsigned ax, sign, flag, tmp, shift, cur; ax = x; sign = x &amp; (1&lt;&lt;31); if(sign) ax = -x; shift = ax; if(!x) return 0; cur = 0; while(1)&#123; tmp = shift; shift = shift&lt;&lt;1; cur++; if(tmp &amp; 0x80000000) break; &#125; if((shift &amp; 0x01FF) &gt; 0x0100) flag = 1; else if((shift &amp; 0x03FF) == 0x0300) flag = 1; else flag = 0; return sign + ((159 - cur)&lt;&lt;23) + (shift&gt;&gt;9) + flag;&#125; float_twice 在二进制科学技术法下，对某个数x乘以2就相对于将其阶数加一。因此若原数阶码不为0且不为255，则直接将阶码加一即可。若阶码等于0，表明其为非规范化数，因此直接将尾数位左移一位即可。由于非规范化数与规范化数之间有一个平滑过渡关系，因此即使左移一位后尾数位的最高位移动至了阶码位，该操作仍然是合法的。当原数阶码为255时，表明其为 \\[\\infty\\] 或 \\[NaN\\]，不能进行算术运算，直接返回即可。 1234567unsigned float_twice(unsigned uf) &#123; if((uf &amp; 0x7F800000) == 0) uf = ((uf &amp; 0x007FFFFF) &lt;&lt; 1) | (uf &amp; 0x80000000); else if((uf &amp; 0x7F800000) != 0x7F800000) uf = uf + 0x800000; return uf;&#125;","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"http://gonggongjohn.me/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Computer-System","slug":"Computer-System","permalink":"http://gonggongjohn.me/tags/Computer-System/"}]},{"title":"Strassen矩阵乘法","slug":"algorithm/course-exp/algorithm-exp2","date":"2020-09-25T03:45:00.000Z","updated":"2021-08-26T09:22:05.885Z","comments":true,"path":"2020/09/25/algorithm/course-exp/algorithm-exp2/","link":"","permalink":"http://gonggongjohn.me/2020/09/25/algorithm/course-exp/algorithm-exp2/","excerpt":"内容与设计思想 设计一个随机数矩阵生成器，输入参数包括 \\[N, s, t\\]；可随机生成一个大小为 \\[N \\times N\\]、数值范围在 \\[[s, t]\\] 之间的矩阵。 编程实现普通的矩阵乘法； 编程实现Strassen’s Algorithm； 在不同数据规模情况下（数据规模 \\[N=2^4, 2^8, 2^9, 2^{10}, 2^{11}\\]）下，两种算法的运行时间各是多少； 修改Strassen’s Algorithm，使之适应矩阵规模 \\[N\\] 不是 \\[2\\] 的幂的情况； 改进后的算法与2中的算法在相同数据规模下进行比较。","text":"内容与设计思想 设计一个随机数矩阵生成器，输入参数包括 \\[N, s, t\\]；可随机生成一个大小为 \\[N \\times N\\]、数值范围在 \\[[s, t]\\] 之间的矩阵。 编程实现普通的矩阵乘法； 编程实现Strassen’s Algorithm； 在不同数据规模情况下（数据规模 \\[N=2^4, 2^8, 2^9, 2^{10}, 2^{11}\\]）下，两种算法的运行时间各是多少； 修改Strassen’s Algorithm，使之适应矩阵规模 \\[N\\] 不是 \\[2\\] 的幂的情况； 改进后的算法与2中的算法在相同数据规模下进行比较。 实现代码 （给后来者的一些Note：请大家尽可能用相对高级的语法特性实现这一算法（如STL中的vector结构），不要像我这样用原始指针重复造轮子orz！！！） 矩阵生成器 1234567891011121314151617181920212223#include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;cstdlib&gt; #include &lt;ctime&gt; using namespace std; int main() &#123; int n, s, t; srand(time(0)); ofstream fout1(&quot;data1.txt&quot;); ofstream fout2(&quot;data2.txt&quot;); cin&gt;&gt;n&gt;&gt;s&gt;&gt;t; for(int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; fout1 &lt;&lt; s + rand() % (t - s)&lt;&lt;&quot; &quot;; fout2 &lt;&lt; s + rand() % (t - s)&lt;&lt;&quot; &quot;; &#125; fout1&lt;&lt;endl; fout2&lt;&lt;endl; &#125; fout1.close(); fout2.close(); return 0; &#125; 朴素矩阵乘法 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;cmath&gt; using namespace std; int m1[2048][2048], m2[2048][2048], tm1[2048 * 2048], tm2[2048 * 2048]; int main()&#123; int cnt, n, tsum; ifstream fin1(&quot;data1.txt&quot;); ifstream fin2(&quot;data2.txt&quot;); while (!fin1.eof())&#123; fin1&gt;&gt;tm1[cnt]; fin2&gt;&gt;tm2[cnt]; cnt++; &#125; cnt--; n = sqrt(cnt); for(int i = 0; i &lt; n; i++)&#123; for(int j = 0; j &lt; n; j++)&#123; m1[i][j] = tm1[i * n + j]; m2[i][j] = tm2[i * n + j]; &#125; &#125; for(int i = 0; i &lt; n; i++)&#123; for(int j = 0; j &lt; n; j++)&#123; tsum = 0; for(int k = 0; k &lt; n; k++)&#123; tsum += m1[i][k] * m2[k][j]; &#125; cout&lt;&lt;tsum&lt;&lt;&quot; &quot;; &#125; cout&lt;&lt;endl; &#125; fin1.close(); fin2.close(); return 0; &#125; Strassen矩阵乘法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cmath&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;using namespace std;struct Matrix &#123; int row, column; int** m; Matrix(int r, int c) &#123; row = r; column = c; m = (int**) malloc(sizeof(int*)*r); for (int i = 0; i &lt; r; i++) m[i] = (int*)malloc(sizeof(int) * c); &#125; Matrix(const Matrix&amp; mat) &#123; row = mat.row; column = mat.column; m = (int**)malloc(sizeof(int*) * mat.row); for (int i = 0; i &lt; mat.row; i++) m[i] = (int*)malloc(sizeof(int) * mat.column); for (int i = 0; i &lt; row; i++) for (int j = 0; j &lt; column; j++) m[i][j] = mat.m[i][j]; &#125; Matrix&amp; operator = (const Matrix&amp; mat) &#123; if (this != &amp;mat) &#123; row = mat.row; column = mat.column; m = (int**)malloc(sizeof(int*) * mat.row); for (int i = 0; i &lt; mat.row; i++) m[i] = (int*)malloc(sizeof(int) * mat.column); for (int i = 0; i &lt; row; i++) for (int j = 0; j &lt; column; j++) m[i][j] = mat.m[i][j]; &#125; return *this; &#125; ~Matrix() &#123; if (m != NULL) &#123; for (int i = 0; i &lt; row; i++) &#123; delete[] m[i]; &#125; delete[] m; &#125; &#125;&#125;;int tm1[2048 * 2048], tm2[2048 * 2048], cntp;Matrix matAdd(Matrix* matA, Matrix* matB) &#123; Matrix matR = Matrix((*matA).row, (*matA).column); for (int i = 0; i &lt; (*matA).row; i++) for (int j = 0; j &lt; (*matA).column; j++) &#123; matR.m[i][j] = (*matA).m[i][j] + (*matB).m[i][j]; &#125; return matR;&#125;Matrix matSub(Matrix* matA, Matrix* matB) &#123; Matrix matR = Matrix((*matA).row, (*matA).column); for (int i = 0; i &lt; (*matA).row; i++) for (int j = 0; j &lt; (*matA).column; j++) &#123; matR.m[i][j] = (*matA).m[i][j] - (*matB).m[i][j]; &#125; return matR;&#125;Matrix matSplit(Matrix mat, int rowStart, int columnStart, int rowEnd, int columnEnd) &#123; Matrix matR = Matrix(rowEnd - rowStart + 1, columnEnd - columnStart + 1); for (int i = 0; i &lt;= rowEnd - rowStart; i++) for (int j = 0; j &lt;= columnEnd - columnStart; j++) &#123; matR.m[i][j] = mat.m[rowStart + i][columnStart + j]; &#125; return matR;&#125;Matrix matCombine(Matrix mat1, Matrix mat2, Matrix mat3, Matrix mat4) &#123; Matrix matR = Matrix(mat1.row + mat3.row, mat1.column + mat2.column); for (int i = 0; i &lt; mat1.row; i++) for (int j = 0; j &lt; mat1.column; j++) matR.m[i][j] = mat1.m[i][j]; for (int i = 0; i &lt; mat2.row; i++) for (int j = 0; j &lt; mat2.column; j++) matR.m[i][mat1.column + j] = mat2.m[i][j]; for (int i = 0; i &lt; mat3.row; i++) for (int j = 0; j &lt; mat3.column; j++) matR.m[mat1.row + i][j] = mat3.m[i][j]; for (int i = 0; i &lt; mat4.row; i++) for (int j = 0; j &lt; mat4.column; j++) matR.m[mat1.row + i][mat1.column + j] = mat4.m[i][j]; return matR;&#125;Matrix matProduct(Matrix* matA, Matrix* matB) &#123; if ((*matA).row == 1 &amp;&amp; (*matA).column == 1 &amp;&amp; (*matB).row == 1 &amp;&amp; (*matB).column == 1) &#123; Matrix matR = Matrix(1, 1); matR.m[0][0] = (*matA).m[0][0] * (*matB).m[0][0]; return matR; &#125; int midR = (*matA).row / 2 - 1; int midC = (*matA).column / 2 - 1; Matrix a11 = matSplit((*matA), 0, 0, midR, midC); Matrix a12 = matSplit((*matA), 0, midC + 1, midR, (*matA).column - 1); Matrix a21 = matSplit((*matA), midR + 1, 0, (*matA).row - 1, midC); Matrix a22 = matSplit((*matA), midR + 1, midC + 1, (*matA).row - 1, (*matA).column - 1); Matrix b11 = matSplit((*matB), 0, 0, midR, midC); Matrix b12 = matSplit((*matB), 0, midC + 1, midR, (*matA).column - 1); Matrix b21 = matSplit((*matB), midR + 1, 0, (*matA).row - 1, midC); Matrix b22 = matSplit((*matB), midR + 1, midC + 1, (*matA).row - 1, (*matA).column - 1); Matrix tmp1 = matAdd(&amp;a11, &amp;a22); Matrix tmp2 = matAdd(&amp;b11, &amp;b22); Matrix tmp3 = matAdd(&amp;a21, &amp;a22); Matrix tmp4 = matSub(&amp;b12, &amp;b22); Matrix tmp5 = matSub(&amp;b21, &amp;b11); Matrix tmp6 = matAdd(&amp;a11, &amp;a12); Matrix tmp7 = matSub(&amp;a21, &amp;a11); Matrix tmp8 = matAdd(&amp;b11, &amp;b12); Matrix tmp9 = matSub(&amp;a12, &amp;a22); Matrix tmp10 = matAdd(&amp;b21, &amp;b22); Matrix m1 = matProduct(&amp;tmp1, &amp;tmp2); Matrix m2 = matProduct(&amp;tmp3, &amp;b11); Matrix m3 = matProduct(&amp;a11, &amp;tmp4); Matrix m4 = matProduct(&amp;a22, &amp;tmp5); Matrix m5 = matProduct(&amp;tmp6, &amp;b22); Matrix m6 = matProduct(&amp;tmp7, &amp;tmp8); Matrix m7 = matProduct(&amp;tmp9, &amp;tmp10); Matrix mtmp1 = matAdd(&amp;m1, &amp;m4); Matrix mtmp2 = matSub(&amp;mtmp1, &amp;m5); Matrix mtmp3 = matSub(&amp;m1, &amp;m2); Matrix mtmp4 = matAdd(&amp;mtmp3, &amp;m3); Matrix c11 = matAdd(&amp;mtmp2, &amp;m7); Matrix c12 = matAdd(&amp;m3, &amp;m5); Matrix c21 = matAdd(&amp;m2, &amp;m4); Matrix c22 = matAdd(&amp;mtmp4, &amp;m6); //cntp++; //cout &lt;&lt; cntp &lt;&lt; endl; return matCombine(c11, c12, c21, c22);&#125;int main() &#123; int cnt = 0, n; clock_t start, stop; ifstream fin1(&quot;data1.txt&quot;); ifstream fin2(&quot;data2.txt&quot;); while (!fin1.eof() &amp;&amp; !fin2.eof()) &#123; fin1 &gt;&gt; tm1[cnt]; fin2 &gt;&gt; tm2[cnt]; cnt++; &#125; cnt--; n = sqrt(cnt); Matrix m1 = Matrix(n, n); Matrix m2 = Matrix(n, n); Matrix mr = Matrix(n, n); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; m1.m[i][j] = tm1[i * n + j]; m2.m[i][j] = tm2[i * n + j]; &#125; &#125; cntp = 0; start = clock(); mr = matProduct(&amp;m1, &amp;m2); stop = clock(); //for (int i = 0; i &lt; n; i++) &#123; // for (int j = 0; j &lt; n; j++) &#123; // cout &lt;&lt; mr.m[i][j] &lt;&lt; &quot; &quot;; // &#125; // cout &lt;&lt; endl; //&#125; cout &lt;&lt; &quot;Time Cost: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;&quot;s&quot;&lt;&lt; endl; fin1.close(); fin2.close(); return 0;&#125; 扩展的Strassen矩阵乘法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cmath&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;using namespace std;struct Matrix &#123; int row, column; int** m; Matrix(int r, int c) &#123; row = r; column = c; m = (int**) malloc(sizeof(int*)*r); for (int i = 0; i &lt; r; i++) m[i] = (int*)malloc(sizeof(int) * c); &#125; Matrix(const Matrix&amp; mat) &#123; row = mat.row; column = mat.column; m = (int**)malloc(sizeof(int*) * mat.row); for (int i = 0; i &lt; mat.row; i++) m[i] = (int*)malloc(sizeof(int) * mat.column); for (int i = 0; i &lt; row; i++) for (int j = 0; j &lt; column; j++) m[i][j] = mat.m[i][j]; &#125; Matrix&amp; operator = (const Matrix&amp; mat) &#123; if (this != &amp;mat) &#123; row = mat.row; column = mat.column; m = (int**)malloc(sizeof(int*) * mat.row); for (int i = 0; i &lt; mat.row; i++) m[i] = (int*)malloc(sizeof(int) * mat.column); for (int i = 0; i &lt; row; i++) for (int j = 0; j &lt; column; j++) m[i][j] = mat.m[i][j]; &#125; return *this; &#125; ~Matrix() &#123; if (m != NULL) &#123; for (int i = 0; i &lt; row; i++) &#123; delete[] m[i]; &#125; delete[] m; &#125; &#125;&#125;;int tm1[2048 * 2048], tm2[2048 * 2048], cntp;Matrix matExtend(Matrix* mat)&#123; int pos = 0, exn; int n = (*mat).row; while(n)&#123; pos++; n = n&gt;&gt;1; &#125; if(((*mat).row &amp; ((*mat).row - 1)) == 0) exn = (*mat).row; else exn = 1&lt;&lt;pos; Matrix matR = Matrix(exn, exn); for (int i = 0; i &lt; (*mat).row; i++) for (int j = 0; j &lt; (*mat).column; j++) matR.m[i][j] = (*mat).m[i][j]; for(int i = (*mat).row; i &lt; exn; i++) for(int j = (*mat).column; j &lt; exn; j++) matR.m[i][j] = 0; return matR;&#125;Matrix matAdd(Matrix* matA, Matrix* matB) &#123; Matrix matR = Matrix((*matA).row, (*matA).column); for (int i = 0; i &lt; (*matA).row; i++) for (int j = 0; j &lt; (*matA).column; j++) &#123; matR.m[i][j] = (*matA).m[i][j] + (*matB).m[i][j]; &#125; return matR;&#125;Matrix matSub(Matrix* matA, Matrix* matB) &#123; Matrix matR = Matrix((*matA).row, (*matA).column); for (int i = 0; i &lt; (*matA).row; i++) for (int j = 0; j &lt; (*matA).column; j++) &#123; matR.m[i][j] = (*matA).m[i][j] - (*matB).m[i][j]; &#125; return matR;&#125;Matrix matSplit(Matrix mat, int rowStart, int columnStart, int rowEnd, int columnEnd) &#123; Matrix matR = Matrix(rowEnd - rowStart + 1, columnEnd - columnStart + 1); for (int i = 0; i &lt;= rowEnd - rowStart; i++) for (int j = 0; j &lt;= columnEnd - columnStart; j++) &#123; matR.m[i][j] = mat.m[rowStart + i][columnStart + j]; &#125; return matR;&#125;Matrix matCombine(Matrix mat1, Matrix mat2, Matrix mat3, Matrix mat4) &#123; Matrix matR = Matrix(mat1.row + mat3.row, mat1.column + mat2.column); for (int i = 0; i &lt; mat1.row; i++) for (int j = 0; j &lt; mat1.column; j++) matR.m[i][j] = mat1.m[i][j]; for (int i = 0; i &lt; mat2.row; i++) for (int j = 0; j &lt; mat2.column; j++) matR.m[i][mat1.column + j] = mat2.m[i][j]; for (int i = 0; i &lt; mat3.row; i++) for (int j = 0; j &lt; mat3.column; j++) matR.m[mat1.row + i][j] = mat3.m[i][j]; for (int i = 0; i &lt; mat4.row; i++) for (int j = 0; j &lt; mat4.column; j++) matR.m[mat1.row + i][mat1.column + j] = mat4.m[i][j]; return matR;&#125;Matrix matProduct(Matrix* matA, Matrix* matB) &#123; if ((*matA).row == 1 &amp;&amp; (*matA).column == 1 &amp;&amp; (*matB).row == 1 &amp;&amp; (*matB).column == 1) &#123; Matrix matR = Matrix(1, 1); matR.m[0][0] = (*matA).m[0][0] * (*matB).m[0][0]; return matR; &#125; int midR = (*matA).row / 2 - 1; int midC = (*matA).column / 2 - 1; Matrix a11 = matSplit((*matA), 0, 0, midR, midC); Matrix a12 = matSplit((*matA), 0, midC + 1, midR, (*matA).column - 1); Matrix a21 = matSplit((*matA), midR + 1, 0, (*matA).row - 1, midC); Matrix a22 = matSplit((*matA), midR + 1, midC + 1, (*matA).row - 1, (*matA).column - 1); Matrix b11 = matSplit((*matB), 0, 0, midR, midC); Matrix b12 = matSplit((*matB), 0, midC + 1, midR, (*matA).column - 1); Matrix b21 = matSplit((*matB), midR + 1, 0, (*matA).row - 1, midC); Matrix b22 = matSplit((*matB), midR + 1, midC + 1, (*matA).row - 1, (*matA).column - 1); Matrix tmp1 = matAdd(&amp;a11, &amp;a22); Matrix tmp2 = matAdd(&amp;b11, &amp;b22); Matrix tmp3 = matAdd(&amp;a21, &amp;a22); Matrix tmp4 = matSub(&amp;b12, &amp;b22); Matrix tmp5 = matSub(&amp;b21, &amp;b11); Matrix tmp6 = matAdd(&amp;a11, &amp;a12); Matrix tmp7 = matSub(&amp;a21, &amp;a11); Matrix tmp8 = matAdd(&amp;b11, &amp;b12); Matrix tmp9 = matSub(&amp;a12, &amp;a22); Matrix tmp10 = matAdd(&amp;b21, &amp;b22); Matrix m1 = matProduct(&amp;tmp1, &amp;tmp2); Matrix m2 = matProduct(&amp;tmp3, &amp;b11); Matrix m3 = matProduct(&amp;a11, &amp;tmp4); Matrix m4 = matProduct(&amp;a22, &amp;tmp5); Matrix m5 = matProduct(&amp;tmp6, &amp;b22); Matrix m6 = matProduct(&amp;tmp7, &amp;tmp8); Matrix m7 = matProduct(&amp;tmp9, &amp;tmp10); Matrix mtmp1 = matAdd(&amp;m1, &amp;m4); Matrix mtmp2 = matSub(&amp;mtmp1, &amp;m5); Matrix mtmp3 = matSub(&amp;m1, &amp;m2); Matrix mtmp4 = matAdd(&amp;mtmp3, &amp;m3); Matrix c11 = matAdd(&amp;mtmp2, &amp;m7); Matrix c12 = matAdd(&amp;m3, &amp;m5); Matrix c21 = matAdd(&amp;m2, &amp;m4); Matrix c22 = matAdd(&amp;mtmp4, &amp;m6); //cntp++; //cout &lt;&lt; cntp &lt;&lt; endl; return matCombine(c11, c12, c21, c22);&#125;int main() &#123; int cnt = 0, n; clock_t start, stop; ifstream fin1(&quot;data1.txt&quot;); ifstream fin2(&quot;data2.txt&quot;); while (!fin1.eof() &amp;&amp; !fin2.eof()) &#123; fin1 &gt;&gt; tm1[cnt]; fin2 &gt;&gt; tm2[cnt]; cnt++; &#125; cnt--; n = sqrt(cnt); Matrix m1 = Matrix(n, n); Matrix m2 = Matrix(n, n); Matrix mr = Matrix(n, n); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; m1.m[i][j] = tm1[i * n + j]; m2.m[i][j] = tm2[i * n + j]; &#125; &#125; cntp = 0; start = clock(); Matrix m1e = matExtend(&amp;m1); Matrix m2e = matExtend(&amp;m2); mr = matProduct(&amp;m1e, &amp;m2e); stop = clock(); //for (int i = 0; i &lt; n; i++) &#123; // for (int j = 0; j &lt; n; j++) &#123; // cout &lt;&lt; mr.m[i][j] &lt;&lt; &quot; &quot;; // &#125; // cout &lt;&lt; endl; //&#125; cout &lt;&lt; &quot;Time Cost: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;&quot;s&quot;&lt;&lt; endl; fin1.close(); fin2.close(); return 0;&#125; Strassen矩阵乘法（剪枝优化） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;cmath&gt;#include&lt;cstdlib&gt;#include&lt;ctime&gt;using namespace std;struct Matrix &#123; int row, column; int** m; Matrix(int r, int c) &#123; row = r; column = c; m = (int**) malloc(sizeof(int*)*r); for (int i = 0; i &lt; r; i++) m[i] = (int*)malloc(sizeof(int) * c); &#125; Matrix(const Matrix&amp; mat) &#123; row = mat.row; column = mat.column; m = (int**)malloc(sizeof(int*) * mat.row); for (int i = 0; i &lt; mat.row; i++) m[i] = (int*)malloc(sizeof(int) * mat.column); for (int i = 0; i &lt; row; i++) for (int j = 0; j &lt; column; j++) m[i][j] = mat.m[i][j]; &#125; Matrix&amp; operator = (const Matrix&amp; mat) &#123; if (this != &amp;mat) &#123; row = mat.row; column = mat.column; m = (int**)malloc(sizeof(int*) * mat.row); for (int i = 0; i &lt; mat.row; i++) m[i] = (int*)malloc(sizeof(int) * mat.column); for (int i = 0; i &lt; row; i++) for (int j = 0; j &lt; column; j++) m[i][j] = mat.m[i][j]; &#125; return *this; &#125; ~Matrix() &#123; if (m != NULL) &#123; for (int i = 0; i &lt; row; i++) &#123; delete[] m[i]; &#125; delete[] m; &#125; &#125;&#125;;int tm1[2048 * 2048], tm2[2048 * 2048], cntp;Matrix matAdd(Matrix* matA, Matrix* matB) &#123; Matrix matR = Matrix((*matA).row, (*matA).column); for (int i = 0; i &lt; (*matA).row; i++) for (int j = 0; j &lt; (*matA).column; j++) &#123; matR.m[i][j] = (*matA).m[i][j] + (*matB).m[i][j]; &#125; return matR;&#125;Matrix matSub(Matrix* matA, Matrix* matB) &#123; Matrix matR = Matrix((*matA).row, (*matA).column); for (int i = 0; i &lt; (*matA).row; i++) for (int j = 0; j &lt; (*matA).column; j++) &#123; matR.m[i][j] = (*matA).m[i][j] - (*matB).m[i][j]; &#125; return matR;&#125;Matrix matSplit(Matrix mat, int rowStart, int columnStart, int rowEnd, int columnEnd) &#123; Matrix matR = Matrix(rowEnd - rowStart + 1, columnEnd - columnStart + 1); for (int i = 0; i &lt;= rowEnd - rowStart; i++) for (int j = 0; j &lt;= columnEnd - columnStart; j++) &#123; matR.m[i][j] = mat.m[rowStart + i][columnStart + j]; &#125; return matR;&#125;Matrix matCombine(Matrix mat1, Matrix mat2, Matrix mat3, Matrix mat4) &#123; Matrix matR = Matrix(mat1.row + mat3.row, mat1.column + mat2.column); for (int i = 0; i &lt; mat1.row; i++) for (int j = 0; j &lt; mat1.column; j++) matR.m[i][j] = mat1.m[i][j]; for (int i = 0; i &lt; mat2.row; i++) for (int j = 0; j &lt; mat2.column; j++) matR.m[i][mat1.column + j] = mat2.m[i][j]; for (int i = 0; i &lt; mat3.row; i++) for (int j = 0; j &lt; mat3.column; j++) matR.m[mat1.row + i][j] = mat3.m[i][j]; for (int i = 0; i &lt; mat4.row; i++) for (int j = 0; j &lt; mat4.column; j++) matR.m[mat1.row + i][mat1.column + j] = mat4.m[i][j]; return matR;&#125;Matrix matProduct(Matrix* matA, Matrix* matB, int leafcut) &#123; if ((*matA).row &lt;= leafcut &amp;&amp; (*matA).column &lt;= leafcut &amp;&amp; (*matB).row &lt;= leafcut &amp;&amp; (*matB).column &lt;= leafcut) &#123; Matrix matR = Matrix(leafcut, leafcut); int tsum; for(int i = 0; i &lt; leafcut; i++) &#123; for (int j = 0; j &lt; leafcut; j++) &#123; tsum = 0; for (int k = 0; k &lt; leafcut; k++) &#123; matR.m[i][j] += (*matA).m[i][k] * (*matB).m[k][j]; &#125; &#125; &#125; return matR; &#125; int midR = (*matA).row / 2 - 1; int midC = (*matA).column / 2 - 1; Matrix a11 = matSplit((*matA), 0, 0, midR, midC); Matrix a12 = matSplit((*matA), 0, midC + 1, midR, (*matA).column - 1); Matrix a21 = matSplit((*matA), midR + 1, 0, (*matA).row - 1, midC); Matrix a22 = matSplit((*matA), midR + 1, midC + 1, (*matA).row - 1, (*matA).column - 1); Matrix b11 = matSplit((*matB), 0, 0, midR, midC); Matrix b12 = matSplit((*matB), 0, midC + 1, midR, (*matA).column - 1); Matrix b21 = matSplit((*matB), midR + 1, 0, (*matA).row - 1, midC); Matrix b22 = matSplit((*matB), midR + 1, midC + 1, (*matA).row - 1, (*matA).column - 1); Matrix tmp1 = matAdd(&amp;a11, &amp;a22); Matrix tmp2 = matAdd(&amp;b11, &amp;b22); Matrix tmp3 = matAdd(&amp;a21, &amp;a22); Matrix tmp4 = matSub(&amp;b12, &amp;b22); Matrix tmp5 = matSub(&amp;b21, &amp;b11); Matrix tmp6 = matAdd(&amp;a11, &amp;a12); Matrix tmp7 = matSub(&amp;a21, &amp;a11); Matrix tmp8 = matAdd(&amp;b11, &amp;b12); Matrix tmp9 = matSub(&amp;a12, &amp;a22); Matrix tmp10 = matAdd(&amp;b21, &amp;b22); Matrix m1 = matProduct(&amp;tmp1, &amp;tmp2, leafcut); Matrix m2 = matProduct(&amp;tmp3, &amp;b11, leafcut); Matrix m3 = matProduct(&amp;a11, &amp;tmp4, leafcut); Matrix m4 = matProduct(&amp;a22, &amp;tmp5, leafcut); Matrix m5 = matProduct(&amp;tmp6, &amp;b22, leafcut); Matrix m6 = matProduct(&amp;tmp7, &amp;tmp8, leafcut); Matrix m7 = matProduct(&amp;tmp9, &amp;tmp10, leafcut); Matrix mtmp1 = matAdd(&amp;m1, &amp;m4); Matrix mtmp2 = matSub(&amp;mtmp1, &amp;m5); Matrix mtmp3 = matSub(&amp;m1, &amp;m2); Matrix mtmp4 = matAdd(&amp;mtmp3, &amp;m3); Matrix c11 = matAdd(&amp;mtmp2, &amp;m7); Matrix c12 = matAdd(&amp;m3, &amp;m5); Matrix c21 = matAdd(&amp;m2, &amp;m4); Matrix c22 = matAdd(&amp;mtmp4, &amp;m6); //cntp++; //cout &lt;&lt; cntp &lt;&lt; endl; return matCombine(c11, c12, c21, c22);&#125;int main() &#123; int cnt = 0, n; clock_t start, stop; ifstream fin1(&quot;data1.txt&quot;); ifstream fin2(&quot;data2.txt&quot;); while (!fin1.eof() &amp;&amp; !fin2.eof()) &#123; fin1 &gt;&gt; tm1[cnt]; fin2 &gt;&gt; tm2[cnt]; cnt++; &#125; cnt--; n = sqrt(cnt); Matrix m1 = Matrix(n, n); Matrix m2 = Matrix(n, n); Matrix mr = Matrix(n, n); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; m1.m[i][j] = tm1[i * n + j]; m2.m[i][j] = tm2[i * n + j]; &#125; &#125; cntp = 0; start = clock(); mr = matProduct(&amp;m1, &amp;m2, 16); stop = clock(); //for (int i = 0; i &lt; n; i++) &#123; // for (int j = 0; j &lt; n; j++) &#123; // cout &lt;&lt; mr.m[i][j] &lt;&lt; &quot; &quot;; // &#125; // cout &lt;&lt; endl; //&#125; cout &lt;&lt; &quot;Time Cost: &quot;&lt;&lt;(double)(stop - start) / CLOCKS_PER_SEC&lt;&lt;&quot;s&quot;&lt;&lt; endl; fin1.close(); fin2.close(); return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 3 总结 从理论上看，Strassen算法的时间复杂度为\\[\\mathcal{O}(n^{\\lg 7})\\]，相比朴素矩阵乘法 \\[\\mathcal{O}(n^3)\\] 的复杂度略快，但由于其在规模较小时的常数很大，相比朴素矩阵乘法优势并不明显。此外，由于使用Strassen算法需要动态申请大量的临时空间，而申请、访问和删除这些辅助空间的代价远大于运算本身的代价（使用Visual Studio性能检测工具分析程序可以发现仅创建和删除这些临时空间的耗时就占了整个程序运行时间的70%左右），因此从实际测试结果来看Strassen算法甚至还远慢于朴素矩阵乘法。 analysis-vscode 为了避免常数和内存交互时间对测试结果造成影响，我们可以对原算法进行适当的剪枝（Leaf-Cut）优化，即当矩阵规模缩小到一个固定值后改用朴素矩阵乘法继续处理该矩阵。经实测表明，当剪枝范围为16～64之间时，性能瓶颈得到了极大的缓解，且随着数据规模的增大，改进后的算法相比纯朴素矩阵乘法逐渐出现显著的性能优势，与理论计算值基本吻合。 对于矩阵大小不为2的幂次时，可以先将原矩阵扩展至最邻近的2的幂次大小（扩展部分全部用0补齐），随后即可使用Strassen算法进行分治计算。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"GDB使用指南","slug":"computer-system/gdb-guide","date":"2020-09-19T04:24:40.000Z","updated":"2020-09-28T08:06:30.878Z","comments":true,"path":"2020/09/19/computer-system/gdb-guide/","link":"","permalink":"http://gonggongjohn.me/2020/09/19/computer-system/gdb-guide/","excerpt":"GDB使用指南 GDB（GNU Project Debugger）是一款UNIX及类UNIX环境下的C/C++调试工具。 GDB官网：GDB: The GNU Project Debugger","text":"GDB使用指南 GDB（GNU Project Debugger）是一款UNIX及类UNIX环境下的C/C++调试工具。 GDB官网：GDB: The GNU Project Debugger GDB和LLDB LLDB是一款开源的具有REPL（Read-Evaluation-Print-Loop）特征的调试工具，相比GDB在部分场景下更加先进和高效。Xcode自4.3版本后默认内置了LLDB，因此macOS用户可以直接使用LLDB对程序进行调试。（当然macOS同样也可以安装GDB调试工具） GDB与LLDB命令对照表：GDB to LLDB command map WINDOWS下安装GCC和GDB MinGW（Minimalist GNU For Windows）是Windows下的一个小型GNU工具集。新版MinGW中集成了GCC和GDB的相关工具，因此只需安装MinGW即可使用GCC和GDB。 下载MinGW及GCC包 首先前往MinGW官方网站：MinGW 并在Download界面下载MinGW管理工具。 mingw-2 mingw-2 安装MinGW管理工具并打开。 mingw-3 选择所需的工具集，点击左上角的Installation-&gt;Apply Changes即可安装。（由于受国内网络环境影响，可能会出现下载失败的情况，可以多尝试几次或使用其他网络连接方式下载）。若使用C/C++进行开发，通常仅需安装mingw32-base-bin及mingw32-gcc-g++-bin即可。 配置系统环境变量 安装完成后，我们需要配置系统环境变量使得其可以在CMD中执行。 右键此电脑-&gt;属性-&gt;高级系统设置-&gt;环境变量，在系统变量框中找到Path变量，选择编辑，在最后新增一行填入**你的MinGW安装路径*，确定退出。 mingw-4 打开CMD，输入gcc -v及gdb -v，若显示相关版本信息，表明环境变量配置成功。 mingw-5 在其他IDE中调用GDB CLion CLion本身已经集成了十分完善的可视化调试工具，但如果想在CLion中使用GDB或LLDB调试程序同样十分方便。 使用通常的方法在需要的地方打上断点启动调试，在下方的Debug窗口中就可以看到GDB/LLDB窗口，在其中输入命令即可。 clion-1 Visual Studio Code VSCode本身并不自带GCC和GDB的相关功能，因此使用VSCode进行调试同样需要额外安装GDB/LLDB调试工具。不过，VSCode提供了一个可视化的C/C++调试插件，相比命令行调试会直观很多。该插件可直接在插件商店里搜索并安装。 vscode-1 和其他大型IDE类似，VSCode将一个目录视为一个项目，因此在创建项目时，你需要指定一个空的文件夹来存放项目文件（这也是一些人装了辅助插件却被提示要手动配置调试文件的一大重要原因）。在第一次运行程序时，选择Run-&gt;Start Debugging，在弹出的选项框中选择一个要使用的调试环境及编译环境，VSCode就会自动在当前的项目目录下创建相应的配置文件。（当然也可以手动指定配置文件，具体配置方法可参考VSCode官方文档） vscode-2 vscode-3 随后即可在调试界面中看到相关的调试信息。你也可以在下方的Debug Console中输入相关的GDB/LLDB命令来进行进一步的调试。 vscode-4 GDB的基本使用 启动调试 若要使用GDB来调试程序，需要在使用GCC编译源文件的时候打开-g选项。 1gcc -g [源文件名] -o [目标文件名] Example: 1gcc -g test.c -o test 若不打开调试选项，则在调试时无法添加断点。 使用gdb打开生成的可执行文件即可开始调试。 1gdb [目标文件名] GDB还可以关联正在运行的程序进行调试。我们可以通过ps命令查询目标进程的PID，随后进入GDB使用attach命令关联进程。 123ps -ef|grep [进程名]gdb(gdb) attach [PID] Linux用户在这一过程过可能会遇到权限不足的情况。解决方法：切换至root用户，进入/etc/stsctl.d/10-ptrace.conf中将kernel.yama.ptrace_scpoe = 1改为kernel.yama.ptrace_scpoe = 0即可。 添加断点 通常在调试过程中，我们需要在程序的某个位置添加断点，并让程序运行到这一位置时自动暂停以分析程序当前的运行状态。在GDB环境下，我们可以通过break命令来快速添加断点。 12(gdb) break [源文件名称]:[行号] #执行到某一行时中断(gdb) break [函数名] #执行到某个函数时中断 Example: 12(gdb) break test.c:5(gdb) break main 有时我们希望程序在特定条件下中断，这个时候我们可以使用break+if或condition语句来设置条件断点。 1(gdb) break [中断位置] if 触发条件 Example: 1(gdb) break test.c:10 if a==5 12(gdb) break [中断位置](gdb) condition [断点号] [触发条件] Example: 12(gdb) break test.c:10(gdb) condition 1 a==5 我们可以使用info指令查看已设置断点的断点号及相关信息 1(gdb) info breakpoints 通过clear和delete命令可以删除已创建的断点。 1234(gdb) clear [目标文件名]:[行号] #删除某一行处的断点(gdb) clear [函数名] #删除某个函数处的断点(gdb) delete #删除所有断点(gdb) delete [断点号] #删除某一特定断点 Example: 12(gdb) clear test:5(gdb) delete 1 运行程序 对于不需要向main函数传递参数的程序，可以直接使用run指令开始运行程序。 1(gdb) run 对于需要向main函数传递参数的程序，可以使用set args指令或直接在run后跟参数的方式运行程序。 12(gdb) set args [参数](gdb) run Example: 12(gdb) set args para1 para2 para3(gdb) run 1(gdb) run [参数] Example: 1(gdb) run para1 para2 para3 程序运行后，会一直运行至第一个断点处并暂停。若没有设置断点，则效果等同于直接运行程序。 当程序中断后，GDB提供了以下几种继续运行的指令。 12345(gdb) next #单步执行（不进入函数内部，等同于Clion中的Step Over）(gdb) step #单步进入（进入函数内部，等同于Clion的Step Into）(gdb) continue #继续执行至下一个断点处(gdb) until [行号] #继续执行直至某一行(gdb) finish #运行至程序结尾 查看变量及内存 在程序中断时，GDB提供了一系列指令来查看当前变量及内存中的各种信息。 通过print指令可以打印变量或表达式的值 1(gdb) print &#x27;[源文件名/函数名]&#x27;::[变量名/表达式] Example: 123(gdb) print &#x27;main&#x27;::a(gdb) print &#x27;test.c&#x27;::b(gdb) print &#x27;main&#x27;::*p 通过display命令可以使得每次程序中断时自动打印某个变量或表达式的值 1(gdb) display [变量名/表达式] 此外，我们还可以通过watch指令追踪某一变量，使其值发生改变时中断程序 1(gdb) watch [变量名] 通过backtrace指令可以查看函数调用栈的存储情况及相关信息。 1(gdb) backtrace 更多其他命令的详细用法，可以通过help指令查询 1(gdb) help [命令]","categories":[],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Language","slug":"Language","permalink":"http://gonggongjohn.me/tags/Language/"}]},{"title":"插入排序、归并排序及冒泡排序","slug":"algorithm/course-exp/algorithm-exp1","date":"2020-09-18T03:45:00.000Z","updated":"2021-08-26T08:42:58.420Z","comments":true,"path":"2020/09/18/algorithm/course-exp/algorithm-exp1/","link":"","permalink":"http://gonggongjohn.me/2020/09/18/algorithm/course-exp/algorithm-exp1/","excerpt":"内容与设计思想 设计一个数据生成器，输入参数包括 \\[N, s, t, T\\]；可随机生成一个大小为\\[N\\]、数值范围在 \\[[s, t]\\] 之间、类型为 \\[T\\] 的数据集合；\\[T\\] 包括三种类型（顺序递增、顺序递减、随机取值） 编程实现Merge sort算法和Insertion sort算法。 对于顺序递增类型的数据集合而言，在不同数据规模情况下（数据规模为\\[10^2, 10^3, 10^4, 10^5, 10^6\\]）下，两种算法的运行时间各是多少？ 对于顺序递减类型的数据集合而言，在不同数据规模情况下（数据规模为\\[10^2, 10^3, 10^4, 10^5, 10^6\\]）下，两种算法的运行时间各是多少？ 对于随机取值类型的数据集合而言，在不同数据规模情况下（数据规模为\\[10^2, 10^3, 10^4, 10^5, 10^6\\]）下，两种算法的运行时间各是多少？ 编程实现Bubble sort算法，并与上面两个算法进行对比。","text":"内容与设计思想 设计一个数据生成器，输入参数包括 \\[N, s, t, T\\]；可随机生成一个大小为\\[N\\]、数值范围在 \\[[s, t]\\] 之间、类型为 \\[T\\] 的数据集合；\\[T\\] 包括三种类型（顺序递增、顺序递减、随机取值） 编程实现Merge sort算法和Insertion sort算法。 对于顺序递增类型的数据集合而言，在不同数据规模情况下（数据规模为\\[10^2, 10^3, 10^4, 10^5, 10^6\\]）下，两种算法的运行时间各是多少？ 对于顺序递减类型的数据集合而言，在不同数据规模情况下（数据规模为\\[10^2, 10^3, 10^4, 10^5, 10^6\\]）下，两种算法的运行时间各是多少？ 对于随机取值类型的数据集合而言，在不同数据规模情况下（数据规模为\\[10^2, 10^3, 10^4, 10^5, 10^6\\]）下，两种算法的运行时间各是多少？ 编程实现Bubble sort算法，并与上面两个算法进行对比。 实现代码 随机数生成器 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;algorithm&gt;#include &lt;cstdlib&gt;#include &lt;ctime&gt;using namespace std;bool cmp(int a, int b)&#123; return b &lt; a;&#125;int main() &#123; int n,s,t,type,a[1000000]; srand(time(0)); cin&gt;&gt;n&gt;&gt;s&gt;&gt;t&gt;&gt;type; ofstream fout(&quot;data.txt&quot;); for(int i = 0; i &lt; n; i++) &#123; a[i] = s + rand() % (t - s); &#125; if(type == 1)&#123; sort(a, a + n); &#125; else if(type == 2)&#123; sort(a, a + n, cmp); &#125; for(int w = 0; w &lt; n; w++)&#123; fout&lt;&lt;a[w]&lt;&lt;&quot; &quot;; &#125; fout.close(); return 0;&#125; 插入排序 123456789101112131415161718192021222324252627#include&lt;iostream&gt;#include&lt;fstream&gt;using namespace std;int main()&#123; int a[1000000], n, key, j; ifstream fin(&quot;data.txt&quot;); n = 0; while(!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; for(int i = 1; i &lt; n; i++)&#123; key = a[i]; j = i - 1; while(j &gt;= 0 &amp;&amp; a[j] &gt; key)&#123; a[j + 1] = a[j]; j--; &#125; a[j + 1] = key; &#125; for(int w = 0; w &lt; n; w++)&#123; cout&lt;&lt;a[w]&lt;&lt;&quot; &quot;; &#125; fin.close(); return 0;&#125; 归并排序 12345678910111213141516171819202122232425262728293031323334#include&lt;iostream&gt;#include&lt;fstream&gt;using namespace std;int a[1000000], t[1000000], n;void merge(int left, int right) &#123; if (right - left &lt;= 1) return; int mid = left + (right - left &gt;&gt; 1); merge(left, mid); merge(mid, right); int p = left, q = mid, cur = left; while (cur &lt; right) &#123; if (p &gt;= mid || (q &lt; right &amp;&amp; a[p] &gt; a[q])) t[cur++] = a[q++]; else t[cur++] = a[p++]; &#125; for (int i = left; i &lt; right; i++) a[i] = t[i];&#125;int main() &#123; ifstream fin(&quot;data.txt&quot;); n = 0; while (!fin.eof()) &#123; fin &gt;&gt; a[n]; n++; &#125; n--; merge(0, n); for (int w = 0; w &lt; n; w++) &#123; cout &lt;&lt; a[w] &lt;&lt; &quot; &quot;; &#125; fin.close(); return 0;&#125; 冒泡排序 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;fstream&gt;using namespace std;int main()&#123; int a[1000000], n, temp; bool flag = true; ifstream fin(&quot;data.txt&quot;); n = 0; while(!fin.eof())&#123; fin&gt;&gt;a[n]; n++; &#125; n--; while(flag)&#123; flag = false; for(int i = 0; i &lt; n - 1; i++)&#123; if(a[i] &gt; a[i + 1])&#123; flag = true; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; &#125; &#125; &#125; for(int w = 0; w &lt; n; w++) cout&lt;&lt;a[w]&lt;&lt;&quot; &quot;; fin.close(); return 0;&#125; 运行效率 时间记录使用了C++自带的clock()函数，通过在程序开头和结尾分别调用clock()函数并将两值相减，即可得到程序运行时间。结果如下： 1 2 3 总结 从上面的图表中可以发现，当数据集合为已经排序好（顺序递增）的集合时，插入排序和冒泡排序的运行效率高于归并排序。但当数据集合为顺序递减或随机取值时，归并排序的运行效率要明显高于插入排序和冒泡排序。且随着数据规模的增大，归并排序所需的运行时间增长较为缓慢，而插入排序和冒泡排序的运行时间迅速增长，且冒泡排序的增长幅度要高于插入排序。通过理论计算可以得知插入排序的最好时间复杂度为 \\[\\mathcal{O}(n)\\]，平均和最坏时间复杂度均为 \\[\\mathcal{O}(n^2)\\]；归并排序的最好，平均，最坏时间复杂度均为 \\[\\mathcal{O}(n \\lg n)\\]；冒泡排序的最好时间复杂度为 \\[\\mathcal{O}(n)\\]，平均和最坏时间复杂度均为 \\[\\mathcal{O}(n^2)\\]，这与实验结果基本吻合。","categories":[{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"}]},{"title":"实数的严格定义","slug":"math-analysis/real-number","date":"2020-08-26T11:03:01.000Z","updated":"2021-01-21T07:09:14.876Z","comments":true,"path":"2020/08/26/math-analysis/real-number/","link":"","permalink":"http://gonggongjohn.me/2020/08/26/math-analysis/real-number/","excerpt":"","text":"对于整数和有理数，我们可以很轻松的从直观上理解并将他们表示出来。对于整数 \\(1,2,3,4,...\\)，我们只需要通过写出各数位上的数字便可将他们精确的表出；对于有理数，我们也只需要写出构成分母和分子的两个整数便可以精确表示。","categories":[{"name":"分析学","slug":"分析学","permalink":"http://gonggongjohn.me/categories/%E5%88%86%E6%9E%90%E5%AD%A6/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"Analysis","slug":"Analysis","permalink":"http://gonggongjohn.me/tags/Analysis/"}]},{"title":"代数概念整理：映射","slug":"math-algebra/algebra-projection","date":"2020-07-31T07:00:00.000Z","updated":"2021-01-21T07:09:04.830Z","comments":true,"path":"2020/07/31/math-algebra/algebra-projection/","link":"","permalink":"http://gonggongjohn.me/2020/07/31/math-algebra/algebra-projection/","excerpt":"定义 设 \\(X,Y\\) 为两个集合，\\(f\\) 为某种使得 \\(X\\) 中的每一个元素都对应于 \\(Y\\) 中某个元素的规则，则称 \\(f\\) 为 \\(X\\) 到 \\(Y\\) 的一个映射，记为 \\(f:X \\to Y\\) ， \\(X\\) 称为 \\(f\\) 的定义域， \\(Y\\) 称为 \\(f\\) 的陪域 设 \\(f:X \\to Y\\) 为一映射，则 \\(X\\) 中的元素 \\(a\\) 在 \\(f\\) 下对应的 \\(Y\\) 中的元素 \\(b\\) 称为 \\(a\\) 的象，记为 \\(f(a)\\) ； \\(a\\) 称为 \\(b\\) 的原象，记为 \\(f^{-1}(b)\\) ；集合 \\(\\{f(x) \\big| x \\in X\\}\\) 称为 \\(f\\) 的值域或 \\(f\\) 的象，记为\\(f(X)\\) 或 \\(Imf\\) 设 \\(f:X \\to Y\\) 为一映射，若 \\(\\forall x_1 \\neq x_2 \\in X, f(x_1) \\neq f(x_2)\\) ，则称 \\(f\\) 为一个单射 设 \\(f:X \\to Y\\) 为一映射，若 \\(\\forall y \\in Y, \\exists x \\in X\\) ，使得 \\(f(x)=y\\) ，即 \\(Imf=Y\\) ，则称 \\(f\\) 为一个满射","text":"定义 设 \\(X,Y\\) 为两个集合，\\(f\\) 为某种使得 \\(X\\) 中的每一个元素都对应于 \\(Y\\) 中某个元素的规则，则称 \\(f\\) 为 \\(X\\) 到 \\(Y\\) 的一个映射，记为 \\(f:X \\to Y\\) ， \\(X\\) 称为 \\(f\\) 的定义域， \\(Y\\) 称为 \\(f\\) 的陪域 设 \\(f:X \\to Y\\) 为一映射，则 \\(X\\) 中的元素 \\(a\\) 在 \\(f\\) 下对应的 \\(Y\\) 中的元素 \\(b\\) 称为 \\(a\\) 的象，记为 \\(f(a)\\) ； \\(a\\) 称为 \\(b\\) 的原象，记为 \\(f^{-1}(b)\\) ；集合 \\(\\{f(x) \\big| x \\in X\\}\\) 称为 \\(f\\) 的值域或 \\(f\\) 的象，记为\\(f(X)\\) 或 \\(Imf\\) 设 \\(f:X \\to Y\\) 为一映射，若 \\(\\forall x_1 \\neq x_2 \\in X, f(x_1) \\neq f(x_2)\\) ，则称 \\(f\\) 为一个单射 设 \\(f:X \\to Y\\) 为一映射，若 \\(\\forall y \\in Y, \\exists x \\in X\\) ，使得 \\(f(x)=y\\) ，即 \\(Imf=Y\\) ，则称 \\(f\\) 为一个满射 设 \\(f:X \\to Y\\) 为一映射，若 \\(f\\) 即是单射又是满射，则称 \\(f\\) 为一个双射 设 \\(f: X \\to Y\\) 为一映射，若 \\(Y=X\\) ，且 \\(\\forall x \\in X, f(x) = x\\) ，则称 \\(f\\) 为一个恒等映射，记为 \\(Id_X\\) 或 \\(e_X\\) 设 \\(f: A \\to C, g: B \\to D\\) 为两个映射，若 \\(A = B,C=D\\) ，且 \\(\\forall x \\in A, f(x)=g(x)\\) ，则称映射 \\(f\\) 与 \\(g\\) 相等 设 \\(f: X \\to Y, g: Y \\to Z\\) 为两个映射，则由法则 \\((g \\circ f)(x) = g(f(x))\\) 定义的映射称为 \\(f\\) 与 \\(g\\) 的合成，记为 \\(g \\circ f: X \\to Z\\) 或 \\(gf: X \\to Z\\) 设 \\(f:X \\to Y,g: Y \\to X\\) 为两个映射，若 \\(g \\circ f = e_X\\) ，则称 \\(g\\) 为 \\(f\\) 的左逆， \\(f\\) 为 \\(g\\) 的右逆；若 \\(g \\circ f = e_X,f \\circ g = e_Y\\) ,则称 \\(g\\) 为 \\(f\\) 的双边逆或逆 基本性质 1、（映射的合成律） 设 \\(f: X \\to Y, g: Y \\to Z, h: Z \\to W\\) 为三个映射，则 \\(h(gf)=(hg)f\\) 证明： 对于 $ h(gf) $ ，\\((X \\to Y \\to Z) \\to W=X \\to W\\) ；对于 \\((hg)f\\) ，\\(X \\to (Y \\to Z \\to W)=X \\to W\\) \\(\\therefore\\) \\(h(gf)\\) 与 \\((hg)f\\) 的定义域及陪域相同 \\(\\forall x \\in X\\) ，由定义8可知 \\((h(gf))(x)=h((gf)(x))=h(g(f(x)))=(hg)(f(x))=((hg)f)(x)\\) \\(\\therefore\\) 由定义7可知，\\(h(gf)=(hg)f\\)","categories":[{"name":"代数学","slug":"代数学","permalink":"http://gonggongjohn.me/categories/%E4%BB%A3%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"Algebra","slug":"Algebra","permalink":"http://gonggongjohn.me/tags/Algebra/"}]},{"title":"代数概念整理：集合","slug":"math-algebra/algebra-set","date":"2020-07-30T07:31:34.000Z","updated":"2021-01-21T07:08:51.567Z","comments":true,"path":"2020/07/30/math-algebra/algebra-set/","link":"","permalink":"http://gonggongjohn.me/2020/07/30/math-algebra/algebra-set/","excerpt":"定义 若 \\(a\\) 为 \\(S\\) 中的一个元素，则称 \\(a\\) 包含于 \\(S\\) ，记为 \\(a \\in S\\) ；若 \\(a\\) 不为 \\(S\\) 中的任一元素，则称 \\(a\\) 不包含于 \\(S\\) ，记为 \\(a \\notin S\\) 设 \\(S,T\\) 为两个集合，若 \\(\\forall a \\in S\\) ，成立 \\(a \\in T\\) ，则称 \\(S\\) 是 \\(T\\) 的一个子集，记为 \\(S \\subset T\\) 设 \\(S,T\\) 为两个集合，若 \\(S \\subset T, T \\subset S\\) ，则称 \\(S\\) 与 \\(T\\) 相等，记为 \\(S=T\\) 设 \\(S,T\\) 为两个集合，将集合 \\(\\{ x \\big| x \\in S \\land x \\in T \\}\\) 称为 \\(S\\) 与 \\(T\\) 的交集，记为 \\(S \\cap T\\) ；将集合 \\(\\{ x \\big| x \\in S \\lor x \\in T \\}\\) 称为 \\(S\\) 与 \\(T\\) 的并集，记为 \\(S \\cup T\\)","text":"定义 若 \\(a\\) 为 \\(S\\) 中的一个元素，则称 \\(a\\) 包含于 \\(S\\) ，记为 \\(a \\in S\\) ；若 \\(a\\) 不为 \\(S\\) 中的任一元素，则称 \\(a\\) 不包含于 \\(S\\) ，记为 \\(a \\notin S\\) 设 \\(S,T\\) 为两个集合，若 \\(\\forall a \\in S\\) ，成立 \\(a \\in T\\) ，则称 \\(S\\) 是 \\(T\\) 的一个子集，记为 \\(S \\subset T\\) 设 \\(S,T\\) 为两个集合，若 \\(S \\subset T, T \\subset S\\) ，则称 \\(S\\) 与 \\(T\\) 相等，记为 \\(S=T\\) 设 \\(S,T\\) 为两个集合，将集合 \\(\\{ x \\big| x \\in S \\land x \\in T \\}\\) 称为 \\(S\\) 与 \\(T\\) 的交集，记为 \\(S \\cap T\\) ；将集合 \\(\\{ x \\big| x \\in S \\lor x \\in T \\}\\) 称为 \\(S\\) 与 \\(T\\) 的并集，记为 \\(S \\cup T\\) 设 \\(S,T\\) 为两个集合，将集合 \\(\\{ x \\big| x \\in S \\land x \\notin T \\}\\) 称为 \\(S\\) 与 \\(T\\) 的差集，记为 \\(S \\setminus T\\) 设 \\(S,T\\) 为两个集合，若 \\(T \\subset S\\) ，则将集合 \\(S \\setminus T\\) 称为 \\(T\\) 在 \\(S\\) 中的的补集，记为 \\(\\complement_S{T}\\) 设 \\(S,T\\) 为两个集合，则将集合 \\(\\{(x,y) \\big| x \\in S, y \\in T\\}\\) 称为 \\(S\\) 与 \\(T\\) 的笛卡尔积 ，记为 \\(S \\times T\\) ；将 \\(\\underbrace{X \\times X \\times ... \\times X}_{k个}\\) 简记为 \\(X^k\\) 设 \\(S\\) 为一个集合，则将 \\(S\\) 中元素的个数记为 \\(S\\) 的基数，记为 \\(|S|\\) 基本性质 1、（集合分配律）设 \\(R,S,T\\) 为三个集合，则 ① \\(R \\cap (S \\cup T)=(R \\cap S) \\cup (R \\cap T)\\) ② \\(R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)\\) 证明：① \\(\\forall x \\in R \\cap (S \\cup T)\\) \\(\\therefore x \\in R\\) 且 \\(x \\in S \\cup T\\) \\(\\therefore\\) （ \\(x \\in R\\) 且 \\(x \\in S\\) ） 或 （ \\(x \\in R 且 x \\in T\\) ） $ x (R S) (R T)$ \\(\\therefore\\) 由定义2可知， \\(R \\cap (S \\cup T)\\subset (R \\cap S) \\cup (R \\cap T)\\) 反之， \\(\\forall x \\in (R \\cap S) \\cup (R \\cap T)\\) \\(\\therefore\\) \\(x \\in R \\cap S\\) 或 \\(x \\in R \\cap T\\) \\(\\therefore x \\in R\\) 且（ \\(x \\in S\\) 或 \\(x \\in T\\) ） \\(\\therefore\\) 由定义2可知，\\((R \\cap S) \\cup (R \\cap T) \\subset R \\cap (S \\cup T)\\) \\(\\therefore\\) 由定义3可知， \\(R \\cap (S \\cup T)=(R \\cap S) \\cup (R \\cap T)\\) ② 同理即可证得结论 2、 设 \\(X,Y\\) 为两个集合，且 \\(|X|=n,|Y|=m\\) ，则 ① \\(|X \\times Y|=n \\cdot m\\) ② \\(|X \\cup Y|=n +m-|X \\cap Y|\\)","categories":[{"name":"代数学","slug":"代数学","permalink":"http://gonggongjohn.me/categories/%E4%BB%A3%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"Algebra","slug":"Algebra","permalink":"http://gonggongjohn.me/tags/Algebra/"}]}],"categories":[{"name":"当代人工智能","slug":"当代人工智能","permalink":"http://gonggongjohn.me/categories/%E5%BD%93%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"数据科学算法基础","slug":"数据科学算法基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"name":"数据科学数学基础","slug":"数据科学数学基础","permalink":"http://gonggongjohn.me/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"},{"name":"操作系统","slug":"操作系统","permalink":"http://gonggongjohn.me/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"概率论","slug":"概率论","permalink":"http://gonggongjohn.me/categories/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"分析学","slug":"分析学","permalink":"http://gonggongjohn.me/categories/%E5%88%86%E6%9E%90%E5%AD%A6/"},{"name":"计算机系统","slug":"计算机系统","permalink":"http://gonggongjohn.me/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"},{"name":"算法","slug":"算法","permalink":"http://gonggongjohn.me/categories/%E7%AE%97%E6%B3%95/"},{"name":"机器学习","slug":"机器学习","permalink":"http://gonggongjohn.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"代数学","slug":"代数学","permalink":"http://gonggongjohn.me/categories/%E4%BB%A3%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"Computer-Science","slug":"Computer-Science","permalink":"http://gonggongjohn.me/tags/Computer-Science/"},{"name":"Artificial-Intelligence","slug":"Artificial-Intelligence","permalink":"http://gonggongjohn.me/tags/Artificial-Intelligence/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"http://gonggongjohn.me/tags/Machine-Learning/"},{"name":"Database","slug":"Database","permalink":"http://gonggongjohn.me/tags/Database/"},{"name":"Mathematics","slug":"Mathematics","permalink":"http://gonggongjohn.me/tags/Mathematics/"},{"name":"DataScience","slug":"DataScience","permalink":"http://gonggongjohn.me/tags/DataScience/"},{"name":"Web","slug":"Web","permalink":"http://gonggongjohn.me/tags/Web/"},{"name":"Frontend","slug":"Frontend","permalink":"http://gonggongjohn.me/tags/Frontend/"},{"name":"Operating-System","slug":"Operating-System","permalink":"http://gonggongjohn.me/tags/Operating-System/"},{"name":"Probability","slug":"Probability","permalink":"http://gonggongjohn.me/tags/Probability/"},{"name":"Analysis","slug":"Analysis","permalink":"http://gonggongjohn.me/tags/Analysis/"},{"name":"Computer-System","slug":"Computer-System","permalink":"http://gonggongjohn.me/tags/Computer-System/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://gonggongjohn.me/tags/Algorithm/"},{"name":"Sequence","slug":"Sequence","permalink":"http://gonggongjohn.me/tags/Sequence/"},{"name":"CSAPP","slug":"CSAPP","permalink":"http://gonggongjohn.me/tags/CSAPP/"},{"name":"Language","slug":"Language","permalink":"http://gonggongjohn.me/tags/Language/"},{"name":"Algebra","slug":"Algebra","permalink":"http://gonggongjohn.me/tags/Algebra/"}]}